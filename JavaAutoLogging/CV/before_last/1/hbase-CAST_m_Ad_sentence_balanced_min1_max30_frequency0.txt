Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
/home/2014313303/taeha/JavaAutoLogging/model.py:53: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor("ou..., inputs=[<tf.Tenso...)`
  model = Model(input=[input1, input2], output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-18 10:47:03.394854: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-18 10:47:03.405078: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100005000 Hz
2019-09-18 10:47:03.407756: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x8efd1b0 executing computations on platform Host. Devices:
2019-09-18 10:47:03.407820: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Standard data
zero :  1744
one :  1716

First data
zero :  1744
one :  1716

Second data
zero :  1744
one :  1716

hbase-AST
After set document size of train data, the number of zero and one label data :  1567 1547
After set document size of test data, the number of zero and one label data :  177 168

Sentence length Average : 9

Under 10 : 1858
Over 10, Under 30 : 1572
Over 30, Under 100 : 29
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

After balance out data.
hbase-AST

Sentence length Average : 9

Under 10 : 1858
Over 10, Under 30 : 1572
Over 30, Under 100 : 29
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

39
hbase-depth_num
After set document size of train data, the number of zero and one label data :  1567 1547
After set document size of test data, the number of zero and one label data :  177 168
After balance out data.
hbase-depth_num

Sentence length Average : 9

Under 10 : 1858
Over 10, Under 30 : 1572
Over 30, Under 100 : 29
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

39
Count model parameter.
Get a short summary of each layer dimensions and parameters.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 39, 200)      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 39, 200)      0                                            
__________________________________________________________________________________________________
masking_1 (Masking)             (None, 39, 200)      0           input_1[0][0]                    
__________________________________________________________________________________________________
masking_2 (Masking)             (None, 39, 200)      0           input_2[0][0]                    
__________________________________________________________________________________________________
forwards_1 (LSTM)               (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
backwords_1 (LSTM)              (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
forwards_2 (LSTM)               (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
backwards_2 (LSTM)              (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
after_dp_forward_1 (Dropout)    (None, 64)           0           forwards_1[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_1 (Dropout)   (None, 64)           0           backwords_1[0][0]                
__________________________________________________________________________________________________
after_dp_forward_2 (Dropout)    (None, 64)           0           forwards_2[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_2 (Dropout)   (None, 64)           0           backwards_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128)          0           after_dp_forward_1[0][0]         
                                                                 after_dp_backward_1[0][0]        
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 128)          0           after_dp_forward_2[0][0]         
                                                                 after_dp_backward_2[0][0]        
__________________________________________________________________________________________________
after_dp_1 (Dropout)            (None, 128)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
after_dp_2 (Dropout)            (None, 128)          0           concatenate_2[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 256)          0           after_dp_1[0][0]                 
                                                                 after_dp_2[0][0]                 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 256)          65792       concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 128)          32896       dense_1[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 64)           8256        dense_2[0][0]                    
__________________________________________________________________________________________________
output (Dense)                  (None, 2)            130         dense_3[0][0]                    
==================================================================================================
Total params: 378,434
Trainable params: 378,434
Non-trainable params: 0
__________________________________________________________________________________________________
1

Epoch 1/1

  64/3114 [..............................] - ETA: 2:28 - loss: 0.6985 - acc: 0.4219
 128/3114 [>.............................] - ETA: 1:14 - loss: 0.6922 - acc: 0.5078
 192/3114 [>.............................] - ETA: 49s - loss: 0.6993 - acc: 0.5104 
 256/3114 [=>............................] - ETA: 36s - loss: 0.6965 - acc: 0.5195
 320/3114 [==>...........................] - ETA: 29s - loss: 0.6918 - acc: 0.5344
 384/3114 [==>...........................] - ETA: 24s - loss: 0.6862 - acc: 0.5599
 448/3114 [===>..........................] - ETA: 20s - loss: 0.6754 - acc: 0.5759
 512/3114 [===>..........................] - ETA: 17s - loss: 0.6756 - acc: 0.5684
 576/3114 [====>.........................] - ETA: 15s - loss: 0.6839 - acc: 0.5503
 640/3114 [=====>........................] - ETA: 14s - loss: 0.6789 - acc: 0.5547
 704/3114 [=====>........................] - ETA: 12s - loss: 0.6677 - acc: 0.5682
 768/3114 [======>.......................] - ETA: 11s - loss: 0.6643 - acc: 0.5729
 832/3114 [=======>......................] - ETA: 10s - loss: 0.6639 - acc: 0.5745
 896/3114 [=======>......................] - ETA: 9s - loss: 0.6556 - acc: 0.5882 
 960/3114 [========>.....................] - ETA: 8s - loss: 0.6529 - acc: 0.5948
1024/3114 [========>.....................] - ETA: 8s - loss: 0.6457 - acc: 0.6055
1088/3114 [=========>....................] - ETA: 7s - loss: 0.6399 - acc: 0.6176
1152/3114 [==========>...................] - ETA: 6s - loss: 0.6298 - acc: 0.6311
1216/3114 [==========>...................] - ETA: 6s - loss: 0.6243 - acc: 0.6332
1280/3114 [===========>..................] - ETA: 5s - loss: 0.6189 - acc: 0.6391
1344/3114 [===========>..................] - ETA: 5s - loss: 0.6164 - acc: 0.6429
1408/3114 [============>.................] - ETA: 5s - loss: 0.6054 - acc: 0.6520
1472/3114 [=============>................] - ETA: 4s - loss: 0.5954 - acc: 0.6596
1536/3114 [=============>................] - ETA: 4s - loss: 0.5916 - acc: 0.6641
1600/3114 [==============>...............] - ETA: 4s - loss: 0.5949 - acc: 0.6644
1728/3114 [===============>..............] - ETA: 3s - loss: 0.5905 - acc: 0.6696
1792/3114 [================>.............] - ETA: 3s - loss: 0.5871 - acc: 0.6747
1856/3114 [================>.............] - ETA: 3s - loss: 0.5850 - acc: 0.6773
1920/3114 [=================>............] - ETA: 2s - loss: 0.5784 - acc: 0.6828
1984/3114 [==================>...........] - ETA: 2s - loss: 0.5758 - acc: 0.6855
2048/3114 [==================>...........] - ETA: 2s - loss: 0.5695 - acc: 0.6909
2112/3114 [===================>..........] - ETA: 2s - loss: 0.5656 - acc: 0.6946
2176/3114 [===================>..........] - ETA: 2s - loss: 0.5643 - acc: 0.6953
2240/3114 [====================>.........] - ETA: 1s - loss: 0.5581 - acc: 0.6991
2304/3114 [=====================>........] - ETA: 1s - loss: 0.5544 - acc: 0.7014
2368/3114 [=====================>........] - ETA: 1s - loss: 0.5497 - acc: 0.7057
2432/3114 [======================>.......] - ETA: 1s - loss: 0.5456 - acc: 0.7081
2496/3114 [=======================>......] - ETA: 1s - loss: 0.5413 - acc: 0.7103
2560/3114 [=======================>......] - ETA: 1s - loss: 0.5357 - acc: 0.7148
2624/3114 [========================>.....] - ETA: 0s - loss: 0.5334 - acc: 0.7172
2688/3114 [========================>.....] - ETA: 0s - loss: 0.5293 - acc: 0.7188
2752/3114 [=========================>....] - ETA: 0s - loss: 0.5266 - acc: 0.7202
2816/3114 [==========================>...] - ETA: 0s - loss: 0.5235 - acc: 0.7230
2880/3114 [==========================>...] - ETA: 0s - loss: 0.5218 - acc: 0.7247
2944/3114 [===========================>..] - ETA: 0s - loss: 0.5200 - acc: 0.7259
3008/3114 [===========================>..] - ETA: 0s - loss: 0.5188 - acc: 0.7284
3072/3114 [============================>.] - ETA: 0s - loss: 0.5162 - acc: 0.7298
3114/3114 [==============================] - 6s 2ms/step - loss: 0.5161 - acc: 0.7306

Test accuracy: 82.02898550724638

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  221

choose_one :  124

F1score :  0.7876712328767123

AUC :  0.9201304815711595

Confusion Matrix
[[168   9]
 [ 53 115]]
True label 0
0.9491525423728814  
0.05084745762711865  
True label 1
0.31547619047619047  
0.6845238095238095  

Train_result {'acc': [0.7305716118448119], 'loss': [0.5161160225659972]}
Saved model to disk


2

Epoch 1/1

  64/3114 [..............................] - ETA: 3s - loss: 0.5064 - acc: 0.7188
 128/3114 [>.............................] - ETA: 3s - loss: 0.4396 - acc: 0.7734
 192/3114 [>.............................] - ETA: 3s - loss: 0.4153 - acc: 0.7917
 256/3114 [=>............................] - ETA: 2s - loss: 0.4402 - acc: 0.7695
 320/3114 [==>...........................] - ETA: 2s - loss: 0.4324 - acc: 0.7719
 384/3114 [==>...........................] - ETA: 2s - loss: 0.4316 - acc: 0.7786
 448/3114 [===>..........................] - ETA: 2s - loss: 0.4262 - acc: 0.7790
 512/3114 [===>..........................] - ETA: 2s - loss: 0.4199 - acc: 0.7871
 576/3114 [====>.........................] - ETA: 2s - loss: 0.4210 - acc: 0.7865
 640/3114 [=====>........................] - ETA: 2s - loss: 0.4264 - acc: 0.7875
 704/3114 [=====>........................] - ETA: 2s - loss: 0.4132 - acc: 0.7983
 768/3114 [======>.......................] - ETA: 2s - loss: 0.4171 - acc: 0.7969
 832/3114 [=======>......................] - ETA: 2s - loss: 0.4109 - acc: 0.8005
 896/3114 [=======>......................] - ETA: 2s - loss: 0.4143 - acc: 0.7946
 960/3114 [========>.....................] - ETA: 2s - loss: 0.4064 - acc: 0.8010
1024/3114 [========>.....................] - ETA: 1s - loss: 0.4037 - acc: 0.8047
1088/3114 [=========>....................] - ETA: 1s - loss: 0.4012 - acc: 0.8070
1152/3114 [==========>...................] - ETA: 1s - loss: 0.4047 - acc: 0.8056
1216/3114 [==========>...................] - ETA: 1s - loss: 0.4030 - acc: 0.8076
1280/3114 [===========>..................] - ETA: 1s - loss: 0.4024 - acc: 0.8086
1344/3114 [===========>..................] - ETA: 1s - loss: 0.4026 - acc: 0.8065
1408/3114 [============>.................] - ETA: 1s - loss: 0.3988 - acc: 0.8111
1472/3114 [=============>................] - ETA: 1s - loss: 0.3997 - acc: 0.8098
1536/3114 [=============>................] - ETA: 1s - loss: 0.4027 - acc: 0.8066
1600/3114 [==============>...............] - ETA: 1s - loss: 0.4004 - acc: 0.8075
1728/3114 [===============>..............] - ETA: 1s - loss: 0.3955 - acc: 0.8113
1856/3114 [================>.............] - ETA: 1s - loss: 0.3950 - acc: 0.8109
1920/3114 [=================>............] - ETA: 1s - loss: 0.3914 - acc: 0.8120
1984/3114 [==================>...........] - ETA: 0s - loss: 0.3910 - acc: 0.8130
2048/3114 [==================>...........] - ETA: 0s - loss: 0.3929 - acc: 0.8125
2112/3114 [===================>..........] - ETA: 0s - loss: 0.3892 - acc: 0.8149
2176/3114 [===================>..........] - ETA: 0s - loss: 0.3872 - acc: 0.8157
2240/3114 [====================>.........] - ETA: 0s - loss: 0.3846 - acc: 0.8165
2304/3114 [=====================>........] - ETA: 0s - loss: 0.3863 - acc: 0.8168
2368/3114 [=====================>........] - ETA: 0s - loss: 0.3859 - acc: 0.8180
2432/3114 [======================>.......] - ETA: 0s - loss: 0.3900 - acc: 0.8170
2496/3114 [=======================>......] - ETA: 0s - loss: 0.3912 - acc: 0.8173
2560/3114 [=======================>......] - ETA: 0s - loss: 0.3893 - acc: 0.8187
2624/3114 [========================>.....] - ETA: 0s - loss: 0.3921 - acc: 0.8182
2688/3114 [========================>.....] - ETA: 0s - loss: 0.3934 - acc: 0.8196
2752/3114 [=========================>....] - ETA: 0s - loss: 0.3911 - acc: 0.8205
2816/3114 [==========================>...] - ETA: 0s - loss: 0.3935 - acc: 0.8196
2880/3114 [==========================>...] - ETA: 0s - loss: 0.3924 - acc: 0.8194
2944/3114 [===========================>..] - ETA: 0s - loss: 0.3927 - acc: 0.8196
3008/3114 [===========================>..] - ETA: 0s - loss: 0.3938 - acc: 0.8201
3072/3114 [============================>.] - ETA: 0s - loss: 0.3917 - acc: 0.8216
3114/3114 [==============================] - 3s 864us/step - loss: 0.3910 - acc: 0.8221

Test accuracy: 84.34782608695653

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  181

choose_one :  164

F1score :  0.8373493975903614

AUC :  0.9299165994081249

Confusion Matrix
[[152  25]
 [ 29 139]]
True label 0
0.8587570621468926  
0.14124293785310735  
True label 1
0.17261904761904762  
0.8273809523809523  

Train_result {'acc': [0.8220937701854939], 'loss': [0.39104994534297716]}
Saved model to disk


3

Epoch 1/1

  64/3114 [..............................] - ETA: 3s - loss: 0.3380 - acc: 0.8906
 128/3114 [>.............................] - ETA: 3s - loss: 0.3080 - acc: 0.9141
 192/3114 [>.............................] - ETA: 2s - loss: 0.3372 - acc: 0.8802
 256/3114 [=>............................] - ETA: 2s - loss: 0.3474 - acc: 0.8672
 320/3114 [==>...........................] - ETA: 2s - loss: 0.3219 - acc: 0.8750
 384/3114 [==>...........................] - ETA: 2s - loss: 0.3383 - acc: 0.8672
 448/3114 [===>..........................] - ETA: 2s - loss: 0.3414 - acc: 0.8638
 576/3114 [====>.........................] - ETA: 2s - loss: 0.3334 - acc: 0.8611
 640/3114 [=====>........................] - ETA: 2s - loss: 0.3304 - acc: 0.8594
 704/3114 [=====>........................] - ETA: 2s - loss: 0.3399 - acc: 0.8551
 768/3114 [======>.......................] - ETA: 1s - loss: 0.3444 - acc: 0.8542
 832/3114 [=======>......................] - ETA: 1s - loss: 0.3517 - acc: 0.8510
 896/3114 [=======>......................] - ETA: 1s - loss: 0.3507 - acc: 0.8471
 960/3114 [========>.....................] - ETA: 1s - loss: 0.3456 - acc: 0.8500
1024/3114 [========>.....................] - ETA: 1s - loss: 0.3471 - acc: 0.8467
1088/3114 [=========>....................] - ETA: 1s - loss: 0.3441 - acc: 0.8483
1152/3114 [==========>...................] - ETA: 1s - loss: 0.3475 - acc: 0.8481
1280/3114 [===========>..................] - ETA: 1s - loss: 0.3518 - acc: 0.8484
1344/3114 [===========>..................] - ETA: 1s - loss: 0.3545 - acc: 0.8490
1408/3114 [============>.................] - ETA: 1s - loss: 0.3537 - acc: 0.8494
1472/3114 [=============>................] - ETA: 1s - loss: 0.3524 - acc: 0.8492
1536/3114 [=============>................] - ETA: 1s - loss: 0.3511 - acc: 0.8516
1664/3114 [===============>..............] - ETA: 1s - loss: 0.3510 - acc: 0.8492
1728/3114 [===============>..............] - ETA: 1s - loss: 0.3487 - acc: 0.8501
1856/3114 [================>.............] - ETA: 1s - loss: 0.3501 - acc: 0.8518
1920/3114 [=================>............] - ETA: 0s - loss: 0.3492 - acc: 0.8526
1984/3114 [==================>...........] - ETA: 0s - loss: 0.3455 - acc: 0.8548
2048/3114 [==================>...........] - ETA: 0s - loss: 0.3447 - acc: 0.8550
2176/3114 [===================>..........] - ETA: 0s - loss: 0.3460 - acc: 0.8529
2240/3114 [====================>.........] - ETA: 0s - loss: 0.3430 - acc: 0.8540
2368/3114 [=====================>........] - ETA: 0s - loss: 0.3424 - acc: 0.8530
2432/3114 [======================>.......] - ETA: 0s - loss: 0.3415 - acc: 0.8532
2496/3114 [=======================>......] - ETA: 0s - loss: 0.3455 - acc: 0.8506
2560/3114 [=======================>......] - ETA: 0s - loss: 0.3465 - acc: 0.8496
2624/3114 [========================>.....] - ETA: 0s - loss: 0.3504 - acc: 0.8479
2688/3114 [========================>.....] - ETA: 0s - loss: 0.3501 - acc: 0.8467
2752/3114 [=========================>....] - ETA: 0s - loss: 0.3515 - acc: 0.8456
2816/3114 [==========================>...] - ETA: 0s - loss: 0.3518 - acc: 0.8455
2944/3114 [===========================>..] - ETA: 0s - loss: 0.3519 - acc: 0.8438
3008/3114 [===========================>..] - ETA: 0s - loss: 0.3534 - acc: 0.8428
3072/3114 [============================>.] - ETA: 0s - loss: 0.3534 - acc: 0.8428
3114/3114 [==============================] - 3s 826us/step - loss: 0.3541 - acc: 0.8423

Test accuracy: 83.18840579710145

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  197

choose_one :  148

F1score :  0.8164556962025317

AUC :  0.9352972827549099

Confusion Matrix
[[158  19]
 [ 39 129]]
True label 0
0.8926553672316384  
0.10734463276836158  
True label 1
0.23214285714285715  
0.7678571428571429  

Train_result {'acc': [0.8423249840966079], 'loss': [0.35407605855298024]}
Saved model to disk


4

Epoch 1/1

  64/3114 [..............................] - ETA: 3s - loss: 0.4501 - acc: 0.8125
 128/3114 [>.............................] - ETA: 3s - loss: 0.4062 - acc: 0.8281
 192/3114 [>.............................] - ETA: 2s - loss: 0.3893 - acc: 0.8333
 320/3114 [==>...........................] - ETA: 2s - loss: 0.3438 - acc: 0.8594
 384/3114 [==>...........................] - ETA: 2s - loss: 0.3321 - acc: 0.8646
 448/3114 [===>..........................] - ETA: 2s - loss: 0.3166 - acc: 0.8728
 512/3114 [===>..........................] - ETA: 2s - loss: 0.3236 - acc: 0.8691
 576/3114 [====>.........................] - ETA: 2s - loss: 0.3267 - acc: 0.8628
 640/3114 [=====>........................] - ETA: 2s - loss: 0.3292 - acc: 0.8578
 704/3114 [=====>........................] - ETA: 2s - loss: 0.3237 - acc: 0.8594
 768/3114 [======>.......................] - ETA: 1s - loss: 0.3115 - acc: 0.8672
 832/3114 [=======>......................] - ETA: 1s - loss: 0.3080 - acc: 0.8714
 896/3114 [=======>......................] - ETA: 1s - loss: 0.3080 - acc: 0.8694
 960/3114 [========>.....................] - ETA: 1s - loss: 0.3119 - acc: 0.8688
1024/3114 [========>.....................] - ETA: 1s - loss: 0.3180 - acc: 0.8682
1088/3114 [=========>....................] - ETA: 1s - loss: 0.3159 - acc: 0.8667
1152/3114 [==========>...................] - ETA: 1s - loss: 0.3235 - acc: 0.8646
1216/3114 [==========>...................] - ETA: 1s - loss: 0.3256 - acc: 0.8602
1280/3114 [===========>..................] - ETA: 1s - loss: 0.3232 - acc: 0.8602
1344/3114 [===========>..................] - ETA: 1s - loss: 0.3221 - acc: 0.8586
1408/3114 [============>.................] - ETA: 1s - loss: 0.3209 - acc: 0.8587
1536/3114 [=============>................] - ETA: 1s - loss: 0.3230 - acc: 0.8561
1600/3114 [==============>...............] - ETA: 1s - loss: 0.3226 - acc: 0.8550
1664/3114 [===============>..............] - ETA: 1s - loss: 0.3223 - acc: 0.8540
1728/3114 [===============>..............] - ETA: 1s - loss: 0.3238 - acc: 0.8524
1856/3114 [================>.............] - ETA: 1s - loss: 0.3276 - acc: 0.8491
1920/3114 [=================>............] - ETA: 1s - loss: 0.3317 - acc: 0.8495
1984/3114 [==================>...........] - ETA: 0s - loss: 0.3327 - acc: 0.8498
2048/3114 [==================>...........] - ETA: 0s - loss: 0.3324 - acc: 0.8506
2112/3114 [===================>..........] - ETA: 0s - loss: 0.3315 - acc: 0.8504
2176/3114 [===================>..........] - ETA: 0s - loss: 0.3352 - acc: 0.8488
2240/3114 [====================>.........] - ETA: 0s - loss: 0.3381 - acc: 0.8482
2304/3114 [=====================>........] - ETA: 0s - loss: 0.3405 - acc: 0.8468
2368/3114 [=====================>........] - ETA: 0s - loss: 0.3375 - acc: 0.8488
2432/3114 [======================>.......] - ETA: 0s - loss: 0.3396 - acc: 0.8487
2496/3114 [=======================>......] - ETA: 0s - loss: 0.3395 - acc: 0.8486
2560/3114 [=======================>......] - ETA: 0s - loss: 0.3382 - acc: 0.8496
2624/3114 [========================>.....] - ETA: 0s - loss: 0.3373 - acc: 0.8491
2688/3114 [========================>.....] - ETA: 0s - loss: 0.3375 - acc: 0.8501
2752/3114 [=========================>....] - ETA: 0s - loss: 0.3361 - acc: 0.8514
2816/3114 [==========================>...] - ETA: 0s - loss: 0.3395 - acc: 0.8487
2880/3114 [==========================>...] - ETA: 0s - loss: 0.3397 - acc: 0.8486
2944/3114 [===========================>..] - ETA: 0s - loss: 0.3391 - acc: 0.8492
3008/3114 [===========================>..] - ETA: 0s - loss: 0.3398 - acc: 0.8481
3072/3114 [============================>.] - ETA: 0s - loss: 0.3402 - acc: 0.8477
3114/3114 [==============================] - 3s 847us/step - loss: 0.3399 - acc: 0.8481

Test accuracy: 84.34782608695653

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  201

choose_one :  144

F1score :  0.8269230769230769

AUC :  0.934658326607479

Confusion Matrix
[[162  15]
 [ 39 129]]
True label 0
0.9152542372881356  
0.0847457627118644  
True label 1
0.23214285714285715  
0.7678571428571429  

Train_result {'acc': [0.8481053304580365], 'loss': [0.3399132567487164]}
Saved model to disk


5

Epoch 1/1

  64/3114 [..............................] - ETA: 3s - loss: 0.3500 - acc: 0.8594
 128/3114 [>.............................] - ETA: 3s - loss: 0.3808 - acc: 0.8281
 192/3114 [>.............................] - ETA: 2s - loss: 0.3498 - acc: 0.8438
 256/3114 [=>............................] - ETA: 2s - loss: 0.3392 - acc: 0.8555
 320/3114 [==>...........................] - ETA: 2s - loss: 0.3351 - acc: 0.8562
 384/3114 [==>...........................] - ETA: 2s - loss: 0.3347 - acc: 0.8594
 448/3114 [===>..........................] - ETA: 2s - loss: 0.3214 - acc: 0.8638
 512/3114 [===>..........................] - ETA: 2s - loss: 0.3095 - acc: 0.8691
 576/3114 [====>.........................] - ETA: 2s - loss: 0.3145 - acc: 0.8681
 640/3114 [=====>........................] - ETA: 2s - loss: 0.3135 - acc: 0.8672
 704/3114 [=====>........................] - ETA: 2s - loss: 0.3119 - acc: 0.8651
 768/3114 [======>.......................] - ETA: 2s - loss: 0.3105 - acc: 0.8672
 832/3114 [=======>......................] - ETA: 1s - loss: 0.3165 - acc: 0.8642
 896/3114 [=======>......................] - ETA: 1s - loss: 0.3166 - acc: 0.8627
 960/3114 [========>.....................] - ETA: 1s - loss: 0.3137 - acc: 0.8625
1024/3114 [========>.....................] - ETA: 1s - loss: 0.3207 - acc: 0.8623
1088/3114 [=========>....................] - ETA: 1s - loss: 0.3206 - acc: 0.8612
1152/3114 [==========>...................] - ETA: 1s - loss: 0.3252 - acc: 0.8594
1216/3114 [==========>...................] - ETA: 1s - loss: 0.3262 - acc: 0.8586
1280/3114 [===========>..................] - ETA: 1s - loss: 0.3276 - acc: 0.8586
1344/3114 [===========>..................] - ETA: 1s - loss: 0.3277 - acc: 0.8579
1408/3114 [============>.................] - ETA: 1s - loss: 0.3287 - acc: 0.8580
1472/3114 [=============>................] - ETA: 1s - loss: 0.3264 - acc: 0.8573
1536/3114 [=============>................] - ETA: 1s - loss: 0.3274 - acc: 0.8561
1600/3114 [==============>...............] - ETA: 1s - loss: 0.3249 - acc: 0.8575
1664/3114 [===============>..............] - ETA: 1s - loss: 0.3231 - acc: 0.8570
1728/3114 [===============>..............] - ETA: 1s - loss: 0.3190 - acc: 0.8605
1792/3114 [================>.............] - ETA: 1s - loss: 0.3201 - acc: 0.8605
1856/3114 [================>.............] - ETA: 1s - loss: 0.3231 - acc: 0.8588
1920/3114 [=================>............] - ETA: 1s - loss: 0.3216 - acc: 0.8589
1984/3114 [==================>...........] - ETA: 0s - loss: 0.3209 - acc: 0.8589
2048/3114 [==================>...........] - ETA: 0s - loss: 0.3181 - acc: 0.8613
2112/3114 [===================>..........] - ETA: 0s - loss: 0.3160 - acc: 0.8613
2176/3114 [===================>..........] - ETA: 0s - loss: 0.3179 - acc: 0.8608
2240/3114 [====================>.........] - ETA: 0s - loss: 0.3169 - acc: 0.8616
2304/3114 [=====================>........] - ETA: 0s - loss: 0.3167 - acc: 0.8602
2368/3114 [=====================>........] - ETA: 0s - loss: 0.3160 - acc: 0.8611
2432/3114 [======================>.......] - ETA: 0s - loss: 0.3166 - acc: 0.8606
2496/3114 [=======================>......] - ETA: 0s - loss: 0.3188 - acc: 0.8590
2560/3114 [=======================>......] - ETA: 0s - loss: 0.3221 - acc: 0.8582
2688/3114 [========================>.....] - ETA: 0s - loss: 0.3197 - acc: 0.8594
2752/3114 [=========================>....] - ETA: 0s - loss: 0.3180 - acc: 0.8608
2816/3114 [==========================>...] - ETA: 0s - loss: 0.3188 - acc: 0.8604
2880/3114 [==========================>...] - ETA: 0s - loss: 0.3253 - acc: 0.8573
2944/3114 [===========================>..] - ETA: 0s - loss: 0.3259 - acc: 0.8563
3008/3114 [===========================>..] - ETA: 0s - loss: 0.3270 - acc: 0.8554
3072/3114 [============================>.] - ETA: 0s - loss: 0.3265 - acc: 0.8555
3114/3114 [==============================] - 3s 859us/step - loss: 0.3258 - acc: 0.8561

Test accuracy: 83.18840579710145

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  211

choose_one :  134

F1score :  0.8079470198675497

AUC :  0.9402071563088512

Confusion Matrix
[[165  12]
 [ 46 122]]
True label 0
0.9322033898305084  
0.06779661016949153  
True label 1
0.27380952380952384  
0.7261904761904762  

Train_result {'acc': [0.8561335903141999], 'loss': [0.32581518830668105]}
Saved model to disk


6

Epoch 1/1

  64/3114 [..............................] - ETA: 3s - loss: 0.4240 - acc: 0.8125
 128/3114 [>.............................] - ETA: 3s - loss: 0.3785 - acc: 0.8359
 192/3114 [>.............................] - ETA: 2s - loss: 0.3651 - acc: 0.8385
 320/3114 [==>...........................] - ETA: 2s - loss: 0.3556 - acc: 0.8531
 448/3114 [===>..........................] - ETA: 2s - loss: 0.3485 - acc: 0.8504
 512/3114 [===>..........................] - ETA: 2s - loss: 0.3529 - acc: 0.8496
 576/3114 [====>.........................] - ETA: 2s - loss: 0.3551 - acc: 0.8472
 640/3114 [=====>........................] - ETA: 2s - loss: 0.3501 - acc: 0.8500
 704/3114 [=====>........................] - ETA: 2s - loss: 0.3426 - acc: 0.8509
 768/3114 [======>.......................] - ETA: 2s - loss: 0.3428 - acc: 0.8516
 832/3114 [=======>......................] - ETA: 1s - loss: 0.3353 - acc: 0.8558
 896/3114 [=======>......................] - ETA: 1s - loss: 0.3340 - acc: 0.8549
 960/3114 [========>.....................] - ETA: 1s - loss: 0.3326 - acc: 0.8562
1024/3114 [========>.....................] - ETA: 1s - loss: 0.3285 - acc: 0.8594
1088/3114 [=========>....................] - ETA: 1s - loss: 0.3227 - acc: 0.8612
1152/3114 [==========>...................] - ETA: 1s - loss: 0.3190 - acc: 0.8637
1216/3114 [==========>...................] - ETA: 1s - loss: 0.3143 - acc: 0.8643
1280/3114 [===========>..................] - ETA: 1s - loss: 0.3100 - acc: 0.8656
1344/3114 [===========>..................] - ETA: 1s - loss: 0.3117 - acc: 0.8668
1472/3114 [=============>................] - ETA: 1s - loss: 0.3107 - acc: 0.8682
1536/3114 [=============>................] - ETA: 1s - loss: 0.3136 - acc: 0.8691
1600/3114 [==============>...............] - ETA: 1s - loss: 0.3135 - acc: 0.8681
1664/3114 [===============>..............] - ETA: 1s - loss: 0.3132 - acc: 0.8684
1728/3114 [===============>..............] - ETA: 1s - loss: 0.3114 - acc: 0.8692
1792/3114 [================>.............] - ETA: 1s - loss: 0.3167 - acc: 0.8677
1856/3114 [================>.............] - ETA: 1s - loss: 0.3199 - acc: 0.8653
1920/3114 [=================>............] - ETA: 1s - loss: 0.3200 - acc: 0.8651
1984/3114 [==================>...........] - ETA: 0s - loss: 0.3221 - acc: 0.8644
2048/3114 [==================>...........] - ETA: 0s - loss: 0.3229 - acc: 0.8647
2112/3114 [===================>..........] - ETA: 0s - loss: 0.3221 - acc: 0.8641
2176/3114 [===================>..........] - ETA: 0s - loss: 0.3232 - acc: 0.8621
2240/3114 [====================>.........] - ETA: 0s - loss: 0.3261 - acc: 0.8607
2304/3114 [=====================>........] - ETA: 0s - loss: 0.3233 - acc: 0.8620
2368/3114 [=====================>........] - ETA: 0s - loss: 0.3222 - acc: 0.8636
2496/3114 [=======================>......] - ETA: 0s - loss: 0.3250 - acc: 0.8606
2560/3114 [=======================>......] - ETA: 0s - loss: 0.3232 - acc: 0.8613
2624/3114 [========================>.....] - ETA: 0s - loss: 0.3222 - acc: 0.8624
2752/3114 [=========================>....] - ETA: 0s - loss: 0.3202 - acc: 0.8634
2816/3114 [==========================>...] - ETA: 0s - loss: 0.3201 - acc: 0.8636
2880/3114 [==========================>...] - ETA: 0s - loss: 0.3193 - acc: 0.8646
2944/3114 [===========================>..] - ETA: 0s - loss: 0.3186 - acc: 0.8645
3008/3114 [===========================>..] - ETA: 0s - loss: 0.3188 - acc: 0.8637
3072/3114 [============================>.] - ETA: 0s - loss: 0.3192 - acc: 0.8630
3114/3114 [==============================] - 3s 848us/step - loss: 0.3174 - acc: 0.8642

Test accuracy: 85.79710144927536

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  174

choose_one :  171

F1score :  0.855457227138643

AUC :  0.9418213613128867

Confusion Matrix
[[151  26]
 [ 23 145]]
True label 0
0.8531073446327684  
0.14689265536723164  
True label 1
0.13690476190476192  
0.8630952380952381  

Train_result {'acc': [0.8641618497492644], 'loss': [0.3173549097550551]}
Saved model to disk


7

Epoch 1/1

  64/3114 [..............................] - ETA: 3s - loss: 0.4218 - acc: 0.8125
 128/3114 [>.............................] - ETA: 3s - loss: 0.3699 - acc: 0.8359
 192/3114 [>.............................] - ETA: 2s - loss: 0.4074 - acc: 0.8281
 256/3114 [=>............................] - ETA: 2s - loss: 0.3860 - acc: 0.8398
 320/3114 [==>...........................] - ETA: 2s - loss: 0.3702 - acc: 0.8375
 384/3114 [==>...........................] - ETA: 2s - loss: 0.3771 - acc: 0.8333
 448/3114 [===>..........................] - ETA: 2s - loss: 0.3629 - acc: 0.8393
 512/3114 [===>..........................] - ETA: 2s - loss: 0.3424 - acc: 0.8516
 576/3114 [====>.........................] - ETA: 2s - loss: 0.3357 - acc: 0.8524
 640/3114 [=====>........................] - ETA: 2s - loss: 0.3318 - acc: 0.8562
 704/3114 [=====>........................] - ETA: 2s - loss: 0.3246 - acc: 0.8608
 768/3114 [======>.......................] - ETA: 2s - loss: 0.3202 - acc: 0.8607
 832/3114 [=======>......................] - ETA: 2s - loss: 0.3151 - acc: 0.8630
 896/3114 [=======>......................] - ETA: 1s - loss: 0.3108 - acc: 0.8638
 960/3114 [========>.....................] - ETA: 1s - loss: 0.3142 - acc: 0.8625
1024/3114 [========>.....................] - ETA: 1s - loss: 0.3138 - acc: 0.8613
1088/3114 [=========>....................] - ETA: 1s - loss: 0.3105 - acc: 0.8603
1152/3114 [==========>...................] - ETA: 1s - loss: 0.3075 - acc: 0.8611
1216/3114 [==========>...................] - ETA: 1s - loss: 0.3105 - acc: 0.8586
1280/3114 [===========>..................] - ETA: 1s - loss: 0.3167 - acc: 0.8531
1344/3114 [===========>..................] - ETA: 1s - loss: 0.3156 - acc: 0.8534
1408/3114 [============>.................] - ETA: 1s - loss: 0.3178 - acc: 0.8537
1472/3114 [=============>................] - ETA: 1s - loss: 0.3244 - acc: 0.8519
1536/3114 [=============>................] - ETA: 1s - loss: 0.3272 - acc: 0.8509
1664/3114 [===============>..............] - ETA: 1s - loss: 0.3206 - acc: 0.8546
1728/3114 [===============>..............] - ETA: 1s - loss: 0.3237 - acc: 0.8542
1792/3114 [================>.............] - ETA: 1s - loss: 0.3260 - acc: 0.8527
1856/3114 [================>.............] - ETA: 1s - loss: 0.3265 - acc: 0.8534
1920/3114 [=================>............] - ETA: 1s - loss: 0.3291 - acc: 0.8547
1984/3114 [==================>...........] - ETA: 1s - loss: 0.3264 - acc: 0.8543
2048/3114 [==================>...........] - ETA: 0s - loss: 0.3294 - acc: 0.8535
2112/3114 [===================>..........] - ETA: 0s - loss: 0.3271 - acc: 0.8537
2240/3114 [====================>.........] - ETA: 0s - loss: 0.3272 - acc: 0.8540
2304/3114 [=====================>........] - ETA: 0s - loss: 0.3284 - acc: 0.8546
2368/3114 [=====================>........] - ETA: 0s - loss: 0.3271 - acc: 0.8577
2432/3114 [======================>.......] - ETA: 0s - loss: 0.3284 - acc: 0.8581
2496/3114 [=======================>......] - ETA: 0s - loss: 0.3255 - acc: 0.8590
2560/3114 [=======================>......] - ETA: 0s - loss: 0.3243 - acc: 0.8582
2624/3114 [========================>.....] - ETA: 0s - loss: 0.3248 - acc: 0.8582
2688/3114 [========================>.....] - ETA: 0s - loss: 0.3218 - acc: 0.8605
2752/3114 [=========================>....] - ETA: 0s - loss: 0.3194 - acc: 0.8612
2816/3114 [==========================>...] - ETA: 0s - loss: 0.3214 - acc: 0.8608
2880/3114 [==========================>...] - ETA: 0s - loss: 0.3220 - acc: 0.8601
2944/3114 [===========================>..] - ETA: 0s - loss: 0.3241 - acc: 0.8597
3008/3114 [===========================>..] - ETA: 0s - loss: 0.3229 - acc: 0.8600
3072/3114 [============================>.] - ETA: 0s - loss: 0.3221 - acc: 0.8604
3114/3114 [==============================] - 3s 880us/step - loss: 0.3231 - acc: 0.8600

Test accuracy: 85.79710144927536

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  176

choose_one :  169

F1score :  0.85459940652819

AUC :  0.9434691955878396

Confusion Matrix
[[152  25]
 [ 24 144]]
True label 0
0.8587570621468926  
0.14124293785310735  
True label 1
0.14285714285714285  
0.8571428571428571  

Train_result {'acc': [0.8599871545168706], 'loss': [0.3231206939973813]}
Saved model to disk


8

Epoch 1/1

  64/3114 [..............................] - ETA: 3s - loss: 0.2739 - acc: 0.9219
 128/3114 [>.............................] - ETA: 3s - loss: 0.2916 - acc: 0.8906
 192/3114 [>.............................] - ETA: 2s - loss: 0.2700 - acc: 0.8854
 320/3114 [==>...........................] - ETA: 2s - loss: 0.2912 - acc: 0.8781
 384/3114 [==>...........................] - ETA: 2s - loss: 0.3030 - acc: 0.8698
 448/3114 [===>..........................] - ETA: 2s - loss: 0.2981 - acc: 0.8728
 512/3114 [===>..........................] - ETA: 2s - loss: 0.3034 - acc: 0.8691
 576/3114 [====>.........................] - ETA: 2s - loss: 0.3017 - acc: 0.8681
 640/3114 [=====>........................] - ETA: 2s - loss: 0.2915 - acc: 0.8750
 704/3114 [=====>........................] - ETA: 2s - loss: 0.3002 - acc: 0.8707
 768/3114 [======>.......................] - ETA: 2s - loss: 0.3001 - acc: 0.8711
 832/3114 [=======>......................] - ETA: 1s - loss: 0.3036 - acc: 0.8702
 896/3114 [=======>......................] - ETA: 1s - loss: 0.3111 - acc: 0.8650
 960/3114 [========>.....................] - ETA: 1s - loss: 0.3076 - acc: 0.8646
1024/3114 [========>.....................] - ETA: 1s - loss: 0.3030 - acc: 0.8672
1088/3114 [=========>....................] - ETA: 1s - loss: 0.3090 - acc: 0.8621
1152/3114 [==========>...................] - ETA: 1s - loss: 0.3033 - acc: 0.8655
1216/3114 [==========>...................] - ETA: 1s - loss: 0.3048 - acc: 0.8660
1280/3114 [===========>..................] - ETA: 1s - loss: 0.3070 - acc: 0.8648
1344/3114 [===========>..................] - ETA: 1s - loss: 0.3065 - acc: 0.8631
1408/3114 [============>.................] - ETA: 1s - loss: 0.3067 - acc: 0.8643
1472/3114 [=============>................] - ETA: 1s - loss: 0.3121 - acc: 0.8621
1536/3114 [=============>................] - ETA: 1s - loss: 0.3079 - acc: 0.8639
1600/3114 [==============>...............] - ETA: 1s - loss: 0.3103 - acc: 0.8638
1664/3114 [===============>..............] - ETA: 1s - loss: 0.3064 - acc: 0.8648
1728/3114 [===============>..............] - ETA: 1s - loss: 0.3028 - acc: 0.8669
1792/3114 [================>.............] - ETA: 1s - loss: 0.3044 - acc: 0.8661
1856/3114 [================>.............] - ETA: 1s - loss: 0.3023 - acc: 0.8680
1920/3114 [=================>............] - ETA: 1s - loss: 0.3026 - acc: 0.8677
1984/3114 [==================>...........] - ETA: 0s - loss: 0.3023 - acc: 0.8690
2048/3114 [==================>...........] - ETA: 0s - loss: 0.3033 - acc: 0.8696
2112/3114 [===================>..........] - ETA: 0s - loss: 0.3067 - acc: 0.8684
2176/3114 [===================>..........] - ETA: 0s - loss: 0.3060 - acc: 0.8695
2240/3114 [====================>.........] - ETA: 0s - loss: 0.3051 - acc: 0.8701
2304/3114 [=====================>........] - ETA: 0s - loss: 0.3046 - acc: 0.8707
2368/3114 [=====================>........] - ETA: 0s - loss: 0.3046 - acc: 0.8712
2432/3114 [======================>.......] - ETA: 0s - loss: 0.3028 - acc: 0.8729
2496/3114 [=======================>......] - ETA: 0s - loss: 0.3024 - acc: 0.8730
2560/3114 [=======================>......] - ETA: 0s - loss: 0.3031 - acc: 0.8727
2624/3114 [========================>.....] - ETA: 0s - loss: 0.3020 - acc: 0.8731
2752/3114 [=========================>....] - ETA: 0s - loss: 0.3056 - acc: 0.8714
2816/3114 [==========================>...] - ETA: 0s - loss: 0.3067 - acc: 0.8707
2880/3114 [==========================>...] - ETA: 0s - loss: 0.3051 - acc: 0.8715
2944/3114 [===========================>..] - ETA: 0s - loss: 0.3046 - acc: 0.8719
3008/3114 [===========================>..] - ETA: 0s - loss: 0.3047 - acc: 0.8717
3072/3114 [============================>.] - ETA: 0s - loss: 0.3031 - acc: 0.8724
3114/3114 [==============================] - 3s 850us/step - loss: 0.3018 - acc: 0.8728

Test accuracy: 84.92753623188406

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  175

choose_one :  170

F1score :  0.8461538461538461

AUC :  0.9362052730696798

Confusion Matrix
[[150  27]
 [ 25 143]]
True label 0
0.847457627118644  
0.15254237288135594  
True label 1
0.1488095238095238  
0.8511904761904762  

Train_result {'acc': [0.87283237001876], 'loss': [0.30180741703004965]}
Saved model to disk


9

Epoch 1/1

  64/3114 [..............................] - ETA: 4s - loss: 0.3593 - acc: 0.8438
 128/3114 [>.............................] - ETA: 3s - loss: 0.2904 - acc: 0.8984
 192/3114 [>.............................] - ETA: 3s - loss: 0.2938 - acc: 0.8854
 320/3114 [==>...........................] - ETA: 2s - loss: 0.2710 - acc: 0.8938
 384/3114 [==>...........................] - ETA: 2s - loss: 0.2718 - acc: 0.8932
 448/3114 [===>..........................] - ETA: 2s - loss: 0.2612 - acc: 0.8973
 512/3114 [===>..........................] - ETA: 2s - loss: 0.2752 - acc: 0.8809
 576/3114 [====>.........................] - ETA: 2s - loss: 0.2659 - acc: 0.8872
 640/3114 [=====>........................] - ETA: 2s - loss: 0.2674 - acc: 0.8891
 704/3114 [=====>........................] - ETA: 2s - loss: 0.2890 - acc: 0.8807
 768/3114 [======>.......................] - ETA: 2s - loss: 0.2969 - acc: 0.8750
 832/3114 [=======>......................] - ETA: 2s - loss: 0.2976 - acc: 0.8738
 896/3114 [=======>......................] - ETA: 1s - loss: 0.3015 - acc: 0.8705
 960/3114 [========>.....................] - ETA: 1s - loss: 0.3037 - acc: 0.8698
1024/3114 [========>.....................] - ETA: 1s - loss: 0.3004 - acc: 0.8711
1088/3114 [=========>....................] - ETA: 1s - loss: 0.3103 - acc: 0.8676
1152/3114 [==========>...................] - ETA: 1s - loss: 0.3118 - acc: 0.8689
1216/3114 [==========>...................] - ETA: 1s - loss: 0.3117 - acc: 0.8684
1280/3114 [===========>..................] - ETA: 1s - loss: 0.3072 - acc: 0.8695
1344/3114 [===========>..................] - ETA: 1s - loss: 0.3061 - acc: 0.8698
1408/3114 [============>.................] - ETA: 1s - loss: 0.3063 - acc: 0.8679
1472/3114 [=============>................] - ETA: 1s - loss: 0.3065 - acc: 0.8689
1536/3114 [=============>................] - ETA: 1s - loss: 0.3060 - acc: 0.8672
1664/3114 [===============>..............] - ETA: 1s - loss: 0.3089 - acc: 0.8666
1792/3114 [================>.............] - ETA: 1s - loss: 0.3068 - acc: 0.8677
1856/3114 [================>.............] - ETA: 1s - loss: 0.3061 - acc: 0.8669
1920/3114 [=================>............] - ETA: 1s - loss: 0.3075 - acc: 0.8651
1984/3114 [==================>...........] - ETA: 0s - loss: 0.3083 - acc: 0.8644
2048/3114 [==================>...........] - ETA: 0s - loss: 0.3105 - acc: 0.8623
2112/3114 [===================>..........] - ETA: 0s - loss: 0.3102 - acc: 0.8636
2176/3114 [===================>..........] - ETA: 0s - loss: 0.3095 - acc: 0.8635
2240/3114 [====================>.........] - ETA: 0s - loss: 0.3137 - acc: 0.8616
2304/3114 [=====================>........] - ETA: 0s - loss: 0.3128 - acc: 0.8620
2368/3114 [=====================>........] - ETA: 0s - loss: 0.3127 - acc: 0.8615
2432/3114 [======================>.......] - ETA: 0s - loss: 0.3095 - acc: 0.8631
2496/3114 [=======================>......] - ETA: 0s - loss: 0.3090 - acc: 0.8626
2560/3114 [=======================>......] - ETA: 0s - loss: 0.3105 - acc: 0.8609
2624/3114 [========================>.....] - ETA: 0s - loss: 0.3097 - acc: 0.8620
2688/3114 [========================>.....] - ETA: 0s - loss: 0.3119 - acc: 0.8605
2752/3114 [=========================>....] - ETA: 0s - loss: 0.3108 - acc: 0.8612
2816/3114 [==========================>...] - ETA: 0s - loss: 0.3096 - acc: 0.8612
2880/3114 [==========================>...] - ETA: 0s - loss: 0.3089 - acc: 0.8615
2944/3114 [===========================>..] - ETA: 0s - loss: 0.3091 - acc: 0.8614
3008/3114 [===========================>..] - ETA: 0s - loss: 0.3084 - acc: 0.8627
3072/3114 [============================>.] - ETA: 0s - loss: 0.3085 - acc: 0.8623
3114/3114 [==============================] - 3s 858us/step - loss: 0.3089 - acc: 0.8622

Test accuracy: 84.63768115942028

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  186

choose_one :  159

F1score :  0.8379204892966361

AUC :  0.9390637610976593

Confusion Matrix
[[155  22]
 [ 31 137]]
True label 0
0.8757062146892656  
0.12429378531073447  
True label 1
0.18452380952380953  
0.8154761904761905  

Train_result {'acc': [0.8622350675522248], 'loss': [0.3089293678295329]}
Saved model to disk


10

Epoch 1/1

  64/3114 [..............................] - ETA: 3s - loss: 0.3281 - acc: 0.8281
 128/3114 [>.............................] - ETA: 3s - loss: 0.2677 - acc: 0.8672
 192/3114 [>.............................] - ETA: 2s - loss: 0.2664 - acc: 0.8698
 256/3114 [=>............................] - ETA: 2s - loss: 0.2816 - acc: 0.8711
 320/3114 [==>...........................] - ETA: 2s - loss: 0.2844 - acc: 0.8719
 384/3114 [==>...........................] - ETA: 2s - loss: 0.2870 - acc: 0.8750
 448/3114 [===>..........................] - ETA: 2s - loss: 0.2900 - acc: 0.8817
 576/3114 [====>.........................] - ETA: 2s - loss: 0.3070 - acc: 0.8646
 640/3114 [=====>........................] - ETA: 2s - loss: 0.2975 - acc: 0.8672
 704/3114 [=====>........................] - ETA: 2s - loss: 0.3023 - acc: 0.8565
 768/3114 [======>.......................] - ETA: 2s - loss: 0.3024 - acc: 0.8542
 832/3114 [=======>......................] - ETA: 1s - loss: 0.2970 - acc: 0.8606
 896/3114 [=======>......................] - ETA: 1s - loss: 0.3052 - acc: 0.8583
 960/3114 [========>.....................] - ETA: 1s - loss: 0.3069 - acc: 0.8552
1024/3114 [========>.....................] - ETA: 1s - loss: 0.3097 - acc: 0.8535
1088/3114 [=========>....................] - ETA: 1s - loss: 0.3144 - acc: 0.8539
1152/3114 [==========>...................] - ETA: 1s - loss: 0.3131 - acc: 0.8559
1216/3114 [==========>...................] - ETA: 1s - loss: 0.3058 - acc: 0.8594
1280/3114 [===========>..................] - ETA: 1s - loss: 0.2990 - acc: 0.8625
1344/3114 [===========>..................] - ETA: 1s - loss: 0.2963 - acc: 0.8646
1408/3114 [============>.................] - ETA: 1s - loss: 0.2907 - acc: 0.8679
1472/3114 [=============>................] - ETA: 1s - loss: 0.2952 - acc: 0.8655
1536/3114 [=============>................] - ETA: 1s - loss: 0.2958 - acc: 0.8639
1600/3114 [==============>...............] - ETA: 1s - loss: 0.2951 - acc: 0.8650
1664/3114 [===============>..............] - ETA: 1s - loss: 0.2976 - acc: 0.8654
1728/3114 [===============>..............] - ETA: 1s - loss: 0.2984 - acc: 0.8652
1856/3114 [================>.............] - ETA: 1s - loss: 0.2982 - acc: 0.8675
1920/3114 [=================>............] - ETA: 1s - loss: 0.3004 - acc: 0.8667
1984/3114 [==================>...........] - ETA: 0s - loss: 0.3007 - acc: 0.8679
2048/3114 [==================>...........] - ETA: 0s - loss: 0.3064 - acc: 0.8647
2112/3114 [===================>..........] - ETA: 0s - loss: 0.3017 - acc: 0.8674
2240/3114 [====================>.........] - ETA: 0s - loss: 0.3028 - acc: 0.8670
2304/3114 [=====================>........] - ETA: 0s - loss: 0.3013 - acc: 0.8681
2368/3114 [=====================>........] - ETA: 0s - loss: 0.3025 - acc: 0.8670
2432/3114 [======================>.......] - ETA: 0s - loss: 0.2998 - acc: 0.8680
2496/3114 [=======================>......] - ETA: 0s - loss: 0.2988 - acc: 0.8678
2560/3114 [=======================>......] - ETA: 0s - loss: 0.2991 - acc: 0.8676
2624/3114 [========================>.....] - ETA: 0s - loss: 0.2988 - acc: 0.8685
2688/3114 [========================>.....] - ETA: 0s - loss: 0.3005 - acc: 0.8690
2752/3114 [=========================>....] - ETA: 0s - loss: 0.2995 - acc: 0.8695
2816/3114 [==========================>...] - ETA: 0s - loss: 0.3011 - acc: 0.8683
2944/3114 [===========================>..] - ETA: 0s - loss: 0.3005 - acc: 0.8675
3008/3114 [===========================>..] - ETA: 0s - loss: 0.3004 - acc: 0.8674
3072/3114 [============================>.] - ETA: 0s - loss: 0.3001 - acc: 0.8669
3114/3114 [==============================] - 3s 850us/step - loss: 0.3002 - acc: 0.8674

Test accuracy: 85.21739130434783

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  192

choose_one :  153

F1score :  0.8411214953271029

AUC :  0.9417204735001345

Confusion Matrix
[[159  18]
 [ 33 135]]
True label 0
0.8983050847457628  
0.1016949152542373  
True label 1
0.19642857142857142  
0.8035714285714286  

Train_result {'acc': [0.8673731535768846], 'loss': [0.3002481265334495]}
Saved model to disk


11

Epoch 1/1

  64/3114 [..............................] - ETA: 3s - loss: 0.3018 - acc: 0.8906
 128/3114 [>.............................] - ETA: 3s - loss: 0.3070 - acc: 0.8672
 192/3114 [>.............................] - ETA: 2s - loss: 0.3150 - acc: 0.8594
 256/3114 [=>............................] - ETA: 2s - loss: 0.2937 - acc: 0.8672
 320/3114 [==>...........................] - ETA: 2s - loss: 0.2985 - acc: 0.8656
 384/3114 [==>...........................] - ETA: 2s - loss: 0.2910 - acc: 0.8776
 448/3114 [===>..........................] - ETA: 2s - loss: 0.2809 - acc: 0.8862
 512/3114 [===>..........................] - ETA: 2s - loss: 0.2918 - acc: 0.8770
 640/3114 [=====>........................] - ETA: 2s - loss: 0.2916 - acc: 0.8734
 704/3114 [=====>........................] - ETA: 2s - loss: 0.2890 - acc: 0.8736
 832/3114 [=======>......................] - ETA: 1s - loss: 0.2896 - acc: 0.8702
 896/3114 [=======>......................] - ETA: 1s - loss: 0.2933 - acc: 0.8717
 960/3114 [========>.....................] - ETA: 1s - loss: 0.2948 - acc: 0.8719
1024/3114 [========>.....................] - ETA: 1s - loss: 0.2924 - acc: 0.8701
1088/3114 [=========>....................] - ETA: 1s - loss: 0.2988 - acc: 0.8667
1152/3114 [==========>...................] - ETA: 1s - loss: 0.3053 - acc: 0.8663
1216/3114 [==========>...................] - ETA: 1s - loss: 0.3033 - acc: 0.8660
1280/3114 [===========>..................] - ETA: 1s - loss: 0.2992 - acc: 0.8680
1344/3114 [===========>..................] - ETA: 1s - loss: 0.3020 - acc: 0.8653
1408/3114 [============>.................] - ETA: 1s - loss: 0.3013 - acc: 0.8658
1472/3114 [=============>................] - ETA: 1s - loss: 0.3022 - acc: 0.8641
1536/3114 [=============>................] - ETA: 1s - loss: 0.3037 - acc: 0.8607
1600/3114 [==============>...............] - ETA: 1s - loss: 0.3043 - acc: 0.8619
1664/3114 [===============>..............] - ETA: 1s - loss: 0.3027 - acc: 0.8636
1792/3114 [================>.............] - ETA: 1s - loss: 0.3083 - acc: 0.8605
1920/3114 [=================>............] - ETA: 0s - loss: 0.3019 - acc: 0.8635
1984/3114 [==================>...........] - ETA: 0s - loss: 0.3014 - acc: 0.8639
2048/3114 [==================>...........] - ETA: 0s - loss: 0.3049 - acc: 0.8628
2112/3114 [===================>..........] - ETA: 0s - loss: 0.3034 - acc: 0.8627
2176/3114 [===================>..........] - ETA: 0s - loss: 0.3033 - acc: 0.8626
2240/3114 [====================>.........] - ETA: 0s - loss: 0.3024 - acc: 0.8634
2304/3114 [=====================>........] - ETA: 0s - loss: 0.3028 - acc: 0.8641
2368/3114 [=====================>........] - ETA: 0s - loss: 0.3062 - acc: 0.8628
2432/3114 [======================>.......] - ETA: 0s - loss: 0.3032 - acc: 0.8643
2496/3114 [=======================>......] - ETA: 0s - loss: 0.3034 - acc: 0.8634
2560/3114 [=======================>......] - ETA: 0s - loss: 0.3031 - acc: 0.8633
2624/3114 [========================>.....] - ETA: 0s - loss: 0.3024 - acc: 0.8636
2688/3114 [========================>.....] - ETA: 0s - loss: 0.2993 - acc: 0.8657
2752/3114 [=========================>....] - ETA: 0s - loss: 0.2998 - acc: 0.8659
2816/3114 [==========================>...] - ETA: 0s - loss: 0.3004 - acc: 0.8654
2880/3114 [==========================>...] - ETA: 0s - loss: 0.3001 - acc: 0.8646
3008/3114 [===========================>..] - ETA: 0s - loss: 0.2973 - acc: 0.8657
3072/3114 [============================>.] - ETA: 0s - loss: 0.2948 - acc: 0.8665
3114/3114 [==============================] - 3s 839us/step - loss: 0.2960 - acc: 0.8667

Test accuracy: 87.82608695652175

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  157

choose_one :  188

F1score :  0.8820224719101124

AUC :  0.9335149313962873

Confusion Matrix
[[146  31]
 [ 11 157]]
True label 0
0.8248587570621468  
0.1751412429378531  
True label 1
0.06547619047619048  
0.9345238095238095  

Train_result {'acc': [0.8667308924361996], 'loss': [0.2959595288155396]}
Saved model to disk


12

Epoch 1/1

  64/3114 [..............................] - ETA: 3s - loss: 0.2953 - acc: 0.8438
 128/3114 [>.............................] - ETA: 3s - loss: 0.2989 - acc: 0.8438
 192/3114 [>.............................] - ETA: 2s - loss: 0.3040 - acc: 0.8438
 256/3114 [=>............................] - ETA: 2s - loss: 0.2667 - acc: 0.8594
 320/3114 [==>...........................] - ETA: 2s - loss: 0.2610 - acc: 0.8656
 384/3114 [==>...........................] - ETA: 2s - loss: 0.2795 - acc: 0.8620
 448/3114 [===>..........................] - ETA: 2s - loss: 0.2798 - acc: 0.8616
 512/3114 [===>..........................] - ETA: 2s - loss: 0.2957 - acc: 0.8535
 640/3114 [=====>........................] - ETA: 2s - loss: 0.2832 - acc: 0.8641
 768/3114 [======>.......................] - ETA: 1s - loss: 0.2806 - acc: 0.8646
 896/3114 [=======>......................] - ETA: 1s - loss: 0.2797 - acc: 0.8661
1024/3114 [========>.....................] - ETA: 1s - loss: 0.2701 - acc: 0.8701
1088/3114 [=========>....................] - ETA: 1s - loss: 0.2712 - acc: 0.8695
1152/3114 [==========>...................] - ETA: 1s - loss: 0.2675 - acc: 0.8707
1216/3114 [==========>...................] - ETA: 1s - loss: 0.2705 - acc: 0.8709
1280/3114 [===========>..................] - ETA: 1s - loss: 0.2725 - acc: 0.8688
1344/3114 [===========>..................] - ETA: 1s - loss: 0.2800 - acc: 0.8668
1408/3114 [============>.................] - ETA: 1s - loss: 0.2856 - acc: 0.8651
1472/3114 [=============>................] - ETA: 1s - loss: 0.2846 - acc: 0.8668
1536/3114 [=============>................] - ETA: 1s - loss: 0.2838 - acc: 0.8652
1600/3114 [==============>...............] - ETA: 1s - loss: 0.2814 - acc: 0.8675
1664/3114 [===============>..............] - ETA: 1s - loss: 0.2786 - acc: 0.8684
1792/3114 [================>.............] - ETA: 1s - loss: 0.2875 - acc: 0.8666
1920/3114 [=================>............] - ETA: 0s - loss: 0.2835 - acc: 0.8688
1984/3114 [==================>...........] - ETA: 0s - loss: 0.2845 - acc: 0.8700
2048/3114 [==================>...........] - ETA: 0s - loss: 0.2834 - acc: 0.8706
2176/3114 [===================>..........] - ETA: 0s - loss: 0.2841 - acc: 0.8718
2240/3114 [====================>.........] - ETA: 0s - loss: 0.2812 - acc: 0.8728
2304/3114 [=====================>........] - ETA: 0s - loss: 0.2837 - acc: 0.8711
2368/3114 [=====================>........] - ETA: 0s - loss: 0.2877 - acc: 0.8691
2432/3114 [======================>.......] - ETA: 0s - loss: 0.2879 - acc: 0.8684
2496/3114 [=======================>......] - ETA: 0s - loss: 0.2860 - acc: 0.8686
2624/3114 [========================>.....] - ETA: 0s - loss: 0.2892 - acc: 0.8670
2688/3114 [========================>.....] - ETA: 0s - loss: 0.2898 - acc: 0.8672
2752/3114 [=========================>....] - ETA: 0s - loss: 0.2889 - acc: 0.8677
2816/3114 [==========================>...] - ETA: 0s - loss: 0.2890 - acc: 0.8679
2880/3114 [==========================>...] - ETA: 0s - loss: 0.2895 - acc: 0.8681
2944/3114 [===========================>..] - ETA: 0s - loss: 0.2888 - acc: 0.8679
3008/3114 [===========================>..] - ETA: 0s - loss: 0.2883 - acc: 0.8677
3072/3114 [============================>.] - ETA: 0s - loss: 0.2896 - acc: 0.8678
3114/3114 [==============================] - 3s 831us/step - loss: 0.2924 - acc: 0.8664

Test accuracy: 87.2463768115942

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  169

choose_one :  176

F1score :  0.872093023255814

AUC :  0.9369451170298628

Confusion Matrix
[[151  26]
 [ 18 150]]
True label 0
0.8531073446327684  
0.14689265536723164  
True label 1
0.10714285714285714  
0.8928571428571429  

Train_result {'acc': [0.8664097625549282], 'loss': [0.2923533444842545]}
Saved model to disk


13

Epoch 1/1

  64/3114 [..............................] - ETA: 4s - loss: 0.3415 - acc: 0.8594
 128/3114 [>.............................] - ETA: 3s - loss: 0.3028 - acc: 0.8594
 192/3114 [>.............................] - ETA: 3s - loss: 0.2909 - acc: 0.8698
 256/3114 [=>............................] - ETA: 2s - loss: 0.2728 - acc: 0.8828
 320/3114 [==>...........................] - ETA: 2s - loss: 0.2834 - acc: 0.8688
 384/3114 [==>...........................] - ETA: 2s - loss: 0.2879 - acc: 0.8672
 512/3114 [===>..........................] - ETA: 2s - loss: 0.2861 - acc: 0.8691
 576/3114 [====>.........................] - ETA: 2s - loss: 0.3038 - acc: 0.8576
 640/3114 [=====>........................] - ETA: 2s - loss: 0.3004 - acc: 0.8625
 704/3114 [=====>........................] - ETA: 2s - loss: 0.2927 - acc: 0.8693
 768/3114 [======>.......................] - ETA: 2s - loss: 0.2937 - acc: 0.8698
 832/3114 [=======>......................] - ETA: 2s - loss: 0.2885 - acc: 0.8726
 896/3114 [=======>......................] - ETA: 1s - loss: 0.2894 - acc: 0.8717
1024/3114 [========>.....................] - ETA: 1s - loss: 0.2846 - acc: 0.8760
1152/3114 [==========>...................] - ETA: 1s - loss: 0.2944 - acc: 0.8741
1216/3114 [==========>...................] - ETA: 1s - loss: 0.2907 - acc: 0.8725
1280/3114 [===========>..................] - ETA: 1s - loss: 0.2894 - acc: 0.8742
1408/3114 [============>.................] - ETA: 1s - loss: 0.2788 - acc: 0.8786
1472/3114 [=============>................] - ETA: 1s - loss: 0.2826 - acc: 0.8777
1536/3114 [=============>................] - ETA: 1s - loss: 0.2823 - acc: 0.8783
1600/3114 [==============>...............] - ETA: 1s - loss: 0.2830 - acc: 0.8781
1664/3114 [===============>..............] - ETA: 1s - loss: 0.2807 - acc: 0.8792
1728/3114 [===============>..............] - ETA: 1s - loss: 0.2795 - acc: 0.8791
1792/3114 [================>.............] - ETA: 1s - loss: 0.2789 - acc: 0.8795
1856/3114 [================>.............] - ETA: 1s - loss: 0.2831 - acc: 0.8766
1920/3114 [=================>............] - ETA: 1s - loss: 0.2842 - acc: 0.8771
1984/3114 [==================>...........] - ETA: 0s - loss: 0.2852 - acc: 0.8755
2048/3114 [==================>...........] - ETA: 0s - loss: 0.2864 - acc: 0.8745
2176/3114 [===================>..........] - ETA: 0s - loss: 0.2914 - acc: 0.8755
2240/3114 [====================>.........] - ETA: 0s - loss: 0.2907 - acc: 0.8759
2304/3114 [=====================>........] - ETA: 0s - loss: 0.2901 - acc: 0.8763
2432/3114 [======================>.......] - ETA: 0s - loss: 0.2894 - acc: 0.8775
2496/3114 [=======================>......] - ETA: 0s - loss: 0.2902 - acc: 0.8770
2560/3114 [=======================>......] - ETA: 0s - loss: 0.2906 - acc: 0.8766
2624/3114 [========================>.....] - ETA: 0s - loss: 0.2903 - acc: 0.8761
2688/3114 [========================>.....] - ETA: 0s - loss: 0.2896 - acc: 0.8769
2752/3114 [=========================>....] - ETA: 0s - loss: 0.2917 - acc: 0.8761
2816/3114 [==========================>...] - ETA: 0s - loss: 0.2926 - acc: 0.8746
2880/3114 [==========================>...] - ETA: 0s - loss: 0.2928 - acc: 0.8747
2944/3114 [===========================>..] - ETA: 0s - loss: 0.2933 - acc: 0.8736
3008/3114 [===========================>..] - ETA: 0s - loss: 0.2925 - acc: 0.8737
3072/3114 [============================>.] - ETA: 0s - loss: 0.2929 - acc: 0.8747
3114/3114 [==============================] - 3s 838us/step - loss: 0.2941 - acc: 0.8738

Test accuracy: 87.53623188405797

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  164

choose_one :  181

F1score :  0.8767908309455588

AUC :  0.9403753026634383

Confusion Matrix
[[149  28]
 [ 15 153]]
True label 0
0.8418079096045198  
0.15819209039548024  
True label 1
0.08928571428571429  
0.9107142857142857  

Train_result {'acc': [0.873795761232125], 'loss': [0.29414389132687735]}
Saved model to disk


14

Epoch 1/1

  64/3114 [..............................] - ETA: 3s - loss: 0.4167 - acc: 0.8281
 128/3114 [>.............................] - ETA: 3s - loss: 0.3882 - acc: 0.8203
 192/3114 [>.............................] - ETA: 2s - loss: 0.3435 - acc: 0.8229
 256/3114 [=>............................] - ETA: 2s - loss: 0.3081 - acc: 0.8398
 320/3114 [==>...........................] - ETA: 2s - loss: 0.3140 - acc: 0.8313
 384/3114 [==>...........................] - ETA: 2s - loss: 0.3150 - acc: 0.8333
 448/3114 [===>..........................] - ETA: 2s - loss: 0.3143 - acc: 0.8304
 512/3114 [===>..........................] - ETA: 2s - loss: 0.3019 - acc: 0.8398
 576/3114 [====>.........................] - ETA: 2s - loss: 0.3137 - acc: 0.8385
 640/3114 [=====>........................] - ETA: 2s - loss: 0.3081 - acc: 0.8406
 704/3114 [=====>........................] - ETA: 2s - loss: 0.2997 - acc: 0.8480
 768/3114 [======>.......................] - ETA: 2s - loss: 0.2964 - acc: 0.8490
 832/3114 [=======>......................] - ETA: 1s - loss: 0.2916 - acc: 0.8546
 896/3114 [=======>......................] - ETA: 1s - loss: 0.2855 - acc: 0.8594
1024/3114 [========>.....................] - ETA: 1s - loss: 0.2960 - acc: 0.8584
1088/3114 [=========>....................] - ETA: 1s - loss: 0.2902 - acc: 0.8603
1216/3114 [==========>...................] - ETA: 1s - loss: 0.3032 - acc: 0.8561
1280/3114 [===========>..................] - ETA: 1s - loss: 0.2981 - acc: 0.8586
1344/3114 [===========>..................] - ETA: 1s - loss: 0.2981 - acc: 0.8586
1408/3114 [============>.................] - ETA: 1s - loss: 0.2925 - acc: 0.8629
1472/3114 [=============>................] - ETA: 1s - loss: 0.2929 - acc: 0.8635
1536/3114 [=============>................] - ETA: 1s - loss: 0.2905 - acc: 0.8652
1600/3114 [==============>...............] - ETA: 1s - loss: 0.2897 - acc: 0.8662
1664/3114 [===============>..............] - ETA: 1s - loss: 0.2950 - acc: 0.8630
1728/3114 [===============>..............] - ETA: 1s - loss: 0.2971 - acc: 0.8623
1792/3114 [================>.............] - ETA: 1s - loss: 0.3008 - acc: 0.8622
1856/3114 [================>.............] - ETA: 1s - loss: 0.3001 - acc: 0.8637
1920/3114 [=================>............] - ETA: 1s - loss: 0.2984 - acc: 0.8641
1984/3114 [==================>...........] - ETA: 0s - loss: 0.2966 - acc: 0.8649
2048/3114 [==================>...........] - ETA: 0s - loss: 0.2978 - acc: 0.8652
2112/3114 [===================>..........] - ETA: 0s - loss: 0.2955 - acc: 0.8670
2176/3114 [===================>..........] - ETA: 0s - loss: 0.2967 - acc: 0.8667
2304/3114 [=====================>........] - ETA: 0s - loss: 0.2941 - acc: 0.8663
2368/3114 [=====================>........] - ETA: 0s - loss: 0.2949 - acc: 0.8666
2432/3114 [======================>.......] - ETA: 0s - loss: 0.2972 - acc: 0.8660
2496/3114 [=======================>......] - ETA: 0s - loss: 0.2967 - acc: 0.8666
2560/3114 [=======================>......] - ETA: 0s - loss: 0.2972 - acc: 0.8664
2624/3114 [========================>.....] - ETA: 0s - loss: 0.2953 - acc: 0.8678
2688/3114 [========================>.....] - ETA: 0s - loss: 0.2964 - acc: 0.8664
2752/3114 [=========================>....] - ETA: 0s - loss: 0.2956 - acc: 0.8674
2816/3114 [==========================>...] - ETA: 0s - loss: 0.2942 - acc: 0.8675
2880/3114 [==========================>...] - ETA: 0s - loss: 0.2936 - acc: 0.8684
2944/3114 [===========================>..] - ETA: 0s - loss: 0.2915 - acc: 0.8699
3008/3114 [===========================>..] - ETA: 0s - loss: 0.2899 - acc: 0.8700
3072/3114 [============================>.] - ETA: 0s - loss: 0.2872 - acc: 0.8724
3114/3114 [==============================] - 3s 842us/step - loss: 0.2873 - acc: 0.8728

Test accuracy: 85.5072463768116

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  189

choose_one :  156

F1score :  0.845679012345679

AUC :  0.9395345708905031

Confusion Matrix
[[158  19]
 [ 31 137]]
True label 0
0.8926553672316384  
0.10734463276836158  
True label 1
0.18452380952380953  
0.8154761904761905  

Train_result {'acc': [0.87283237001876], 'loss': [0.2872508008394321]}
Saved model to disk


15

Epoch 1/1

  64/3114 [..............................] - ETA: 4s - loss: 0.2434 - acc: 0.8438
 128/3114 [>.............................] - ETA: 3s - loss: 0.2440 - acc: 0.8672
 192/3114 [>.............................] - ETA: 2s - loss: 0.2787 - acc: 0.8646
 256/3114 [=>............................] - ETA: 2s - loss: 0.2863 - acc: 0.8789
 320/3114 [==>...........................] - ETA: 2s - loss: 0.2798 - acc: 0.8844
 384/3114 [==>...........................] - ETA: 2s - loss: 0.2703 - acc: 0.8750
 448/3114 [===>..........................] - ETA: 2s - loss: 0.2692 - acc: 0.8795
 512/3114 [===>..........................] - ETA: 2s - loss: 0.2565 - acc: 0.8887
 576/3114 [====>.........................] - ETA: 2s - loss: 0.2639 - acc: 0.8837
 640/3114 [=====>........................] - ETA: 2s - loss: 0.2683 - acc: 0.8797
 704/3114 [=====>........................] - ETA: 2s - loss: 0.2621 - acc: 0.8821
 768/3114 [======>.......................] - ETA: 2s - loss: 0.2560 - acc: 0.8841
 832/3114 [=======>......................] - ETA: 2s - loss: 0.2534 - acc: 0.8870
 896/3114 [=======>......................] - ETA: 1s - loss: 0.2588 - acc: 0.8839
 960/3114 [========>.....................] - ETA: 1s - loss: 0.2528 - acc: 0.8865
1088/3114 [=========>....................] - ETA: 1s - loss: 0.2548 - acc: 0.8860
1216/3114 [==========>...................] - ETA: 1s - loss: 0.2581 - acc: 0.8865
1280/3114 [===========>..................] - ETA: 1s - loss: 0.2640 - acc: 0.8844
1344/3114 [===========>..................] - ETA: 1s - loss: 0.2626 - acc: 0.8839
1472/3114 [=============>................] - ETA: 1s - loss: 0.2657 - acc: 0.8818
1536/3114 [=============>................] - ETA: 1s - loss: 0.2678 - acc: 0.8828
1600/3114 [==============>...............] - ETA: 1s - loss: 0.2669 - acc: 0.8825
1664/3114 [===============>..............] - ETA: 1s - loss: 0.2636 - acc: 0.8840
1728/3114 [===============>..............] - ETA: 1s - loss: 0.2646 - acc: 0.8831
1792/3114 [================>.............] - ETA: 1s - loss: 0.2674 - acc: 0.8834
1856/3114 [================>.............] - ETA: 1s - loss: 0.2664 - acc: 0.8831
1920/3114 [=================>............] - ETA: 1s - loss: 0.2661 - acc: 0.8839
1984/3114 [==================>...........] - ETA: 0s - loss: 0.2692 - acc: 0.8805
2048/3114 [==================>...........] - ETA: 0s - loss: 0.2663 - acc: 0.8813
2112/3114 [===================>..........] - ETA: 0s - loss: 0.2679 - acc: 0.8816
2176/3114 [===================>..........] - ETA: 0s - loss: 0.2675 - acc: 0.8824
2240/3114 [====================>.........] - ETA: 0s - loss: 0.2675 - acc: 0.8812
2368/3114 [=====================>........] - ETA: 0s - loss: 0.2655 - acc: 0.8822
2432/3114 [======================>.......] - ETA: 0s - loss: 0.2686 - acc: 0.8812
2496/3114 [=======================>......] - ETA: 0s - loss: 0.2732 - acc: 0.8794
2624/3114 [========================>.....] - ETA: 0s - loss: 0.2740 - acc: 0.8807
2752/3114 [=========================>....] - ETA: 0s - loss: 0.2737 - acc: 0.8815
2880/3114 [==========================>...] - ETA: 0s - loss: 0.2747 - acc: 0.8816
2944/3114 [===========================>..] - ETA: 0s - loss: 0.2767 - acc: 0.8818
3008/3114 [===========================>..] - ETA: 0s - loss: 0.2756 - acc: 0.8823
3072/3114 [============================>.] - ETA: 0s - loss: 0.2774 - acc: 0.8815
3114/3114 [==============================] - 3s 842us/step - loss: 0.2798 - acc: 0.8793

Test accuracy: 85.21739130434783

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  198

choose_one :  147

F1score :  0.838095238095238

AUC :  0.9393327952649986

Confusion Matrix
[[162  15]
 [ 36 132]]
True label 0
0.9152542372881356  
0.0847457627118644  
True label 1
0.21428571428571427  
0.7857142857142857  

Train_result {'acc': [0.8792549777505638], 'loss': [0.2798441893869129]}
Saved model to disk


[[82.02898550724638, 1], [84.34782608695653, 2], [83.18840579710145, 3], [84.34782608695653, 4], [83.18840579710145, 5], [85.79710144927536, 6], [85.79710144927536, 7], [84.92753623188406, 8], [84.63768115942028, 9], [85.21739130434783, 10], [87.82608695652175, 11], [87.2463768115942, 12], [87.53623188405797, 13], [85.5072463768116, 14], [85.21739130434783, 15]]
max accuracy :  [87.82608695652175, 11]
