Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Standard data
zero :  1744
one :  1716

First data
zero :  1744
one :  1716

Second data
zero :  1744
one :  1716

Third data
zero :  1744
one :  1716

4th data
zero :  1744
one :  1716

hbase-code
After set document size of train data, the number of zero and one label data :  1567 1547
After set document size of test data, the number of zero and one label data :  177 168

Sentence length Average : 17

Under 10 : 844
Over 10, Under 30 : 2491
Over 30, Under 100 : 124
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

After balance out data.
hbase-code

Sentence length Average : 17

Under 10 : 844
Over 10, Under 30 : 2491
Over 30, Under 100 : 124
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

32
hbase-AST
After set document size of train data, the number of zero and one label data :  1567 1547
After set document size of test data, the number of zero and one label data :  177 168
After balance out data.
hbase-AST

Sentence length Average : 9

Under 10 : 1858
Over 10, Under 30 : 1572
Over 30, Under 100 : 29
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

39
hbase-CAST
After set document size of train data, the number of zero and one label data :  1567 1547
After set document size of test data, the number of zero and one label data :  177 168
After balance out data.
hbase-CAST

Sentence length Average : 24

Under 10 : 768
Over 10, Under 30 : 1467
Over 30, Under 100 : 1224
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

97
hbase-depth_num
After set document size of train data, the number of zero and one label data :  1567 1547
After set document size of test data, the number of zero and one label data :  177 168
After balance out data.
hbase-depth_num

Sentence length Average : 9

Under 10 : 1858
Over 10, Under 30 : 1572
Over 30, Under 100 : 29
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

39
Count model parameter.
Get a short summary of each layer dimensions and parameters.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 200)      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 39, 200)      0                                            
__________________________________________________________________________________________________
masking_1 (Masking)             (None, 32, 200)      0           input_1[0][0]                    
__________________________________________________________________________________________________
masking_2 (Masking)             (None, 39, 200)      0           input_2[0][0]                    
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 97, 200)      0                                            
__________________________________________________________________________________________________
forwards_1 (LSTM)               (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
backwords_1 (LSTM)              (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
forwards_2 (LSTM)               (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
backwards_2 (LSTM)              (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
masking_3 (Masking)             (None, 97, 200)      0           input_3[0][0]                    
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 39, 200)      0                                            
__________________________________________________________________________________________________
after_dp_forward_1 (Dropout)    (None, 64)           0           forwards_1[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_1 (Dropout)   (None, 64)           0           backwords_1[0][0]                
__________________________________________________________________________________________________
after_dp_forward_2 (Dropout)    (None, 64)           0           forwards_2[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_2 (Dropout)   (None, 64)           0           backwards_2[0][0]                
__________________________________________________________________________________________________
forwards_3 (LSTM)               (None, 64)           67840       masking_3[0][0]                  
__________________________________________________________________________________________________
backwards_3 (LSTM)              (None, 64)           67840       masking_3[0][0]                  
__________________________________________________________________________________________________
masking_4 (Masking)             (None, 39, 200)      0           input_4[0][0]                    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128)          0           after_dp_forward_1[0][0]         
                                                                 after_dp_backward_1[0][0]        
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 128)          0           after_dp_forward_2[0][0]         
                                                                 after_dp_backward_2[0][0]        
__________________________________________________________________________________________________
after_dp_forward_3 (Dropout)    (None, 64)           0           forwards_3[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_3 (Dropout)   (None, 64)           0           backwards_3[0][0]                
__________________________________________________________________________________________________
forwards_4 (LSTM)               (None, 64)           67840       masking_4[0][0]                  
__________________________________________________________________________________________________
backwards_4 (LSTM)              (None, 64)           67840       masking_4[0][0]                  
__________________________________________________________________________________________________
after_dp_1 (Dropout)            (None, 128)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
after_dp_2 (Dropout)            (None, 128)          0           concatenate_2[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 128)          0           after_dp_forward_3[0][0]         
                                                                 after_dp_backward_3[0][0]        
__________________________________________________________________________________________________
after_dp_forward_4 (Dropout)    (None, 64)           0           forwards_4[0][0]                 
__________________________________________________________________________________________________/home/2014313303/taeha/JavaAutoLogging/model.py:154: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor("ou...)`
  model = Model(input=[input1, input2, input3, input4], output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-18 09:52:00.850498: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-18 09:52:00.880336: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100005000 Hz
2019-09-18 09:52:00.899667: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0xb12fee0 executing computations on platform Host. Devices:
2019-09-18 09:52:00.899709: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>

after_dp_backward_4 (Dropout)   (None, 64)           0           backwards_4[0][0]                
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 256)          0           after_dp_1[0][0]                 
                                                                 after_dp_2[0][0]                 
__________________________________________________________________________________________________
after_dp_3 (Dropout)            (None, 128)          0           concatenate_3[0][0]              
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 128)          0           after_dp_forward_4[0][0]         
                                                                 after_dp_backward_4[0][0]        
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 384)          0           concatenate_5[0][0]              
                                                                 after_dp_3[0][0]                 
__________________________________________________________________________________________________
after_dp_4 (Dropout)            (None, 128)          0           concatenate_4[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 512)          0           concatenate_6[0][0]              
                                                                 after_dp_4[0][0]                 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          262656      concatenate_7[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 768)          393984      dense_1[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 512)          393728      dense_2[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 256)          131328      dense_3[0][0]                    
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 128)          32896       dense_4[0][0]                    
__________________________________________________________________________________________________
output (Dense)                  (None, 2)            258         dense_5[0][0]                    
==================================================================================================
Total params: 1,757,570
Trainable params: 1,757,570
Non-trainable params: 0
__________________________________________________________________________________________________
1

Epoch 1/1

  64/3114 [..............................] - ETA: 5:13 - loss: 0.7029 - acc: 0.5156
 128/3114 [>.............................] - ETA: 2:37 - loss: 0.7186 - acc: 0.5156
 192/3114 [>.............................] - ETA: 1:44 - loss: 0.7342 - acc: 0.5000
 256/3114 [=>............................] - ETA: 1:18 - loss: 0.7214 - acc: 0.4922
 320/3114 [==>...........................] - ETA: 1:02 - loss: 0.7377 - acc: 0.4625
 384/3114 [==>...........................] - ETA: 52s - loss: 0.7200 - acc: 0.5000 
 448/3114 [===>..........................] - ETA: 44s - loss: 0.7201 - acc: 0.4955
 512/3114 [===>..........................] - ETA: 38s - loss: 0.7176 - acc: 0.4961
 576/3114 [====>.........................] - ETA: 34s - loss: 0.7012 - acc: 0.5278
 640/3114 [=====>........................] - ETA: 30s - loss: 0.6936 - acc: 0.5469
 704/3114 [=====>........................] - ETA: 27s - loss: 0.6796 - acc: 0.5668
 768/3114 [======>.......................] - ETA: 25s - loss: 0.6690 - acc: 0.5794
 832/3114 [=======>......................] - ETA: 23s - loss: 0.6562 - acc: 0.5962
 896/3114 [=======>......................] - ETA: 21s - loss: 0.6425 - acc: 0.6105
 960/3114 [========>.....................] - ETA: 19s - loss: 0.6385 - acc: 0.6167
1024/3114 [========>.....................] - ETA: 18s - loss: 0.6283 - acc: 0.6240
1088/3114 [=========>....................] - ETA: 16s - loss: 0.6151 - acc: 0.6360
1152/3114 [==========>...................] - ETA: 15s - loss: 0.6013 - acc: 0.6476
1216/3114 [==========>...................] - ETA: 14s - loss: 0.5834 - acc: 0.6595
1280/3114 [===========>..................] - ETA: 13s - loss: 0.5769 - acc: 0.6672
1344/3114 [===========>..................] - ETA: 12s - loss: 0.5675 - acc: 0.6771
1408/3114 [============>.................] - ETA: 11s - loss: 0.5618 - acc: 0.6818
1472/3114 [=============>................] - ETA: 11s - loss: 0.5567 - acc: 0.6848
1536/3114 [=============>................] - ETA: 10s - loss: 0.5459 - acc: 0.6934
1600/3114 [==============>...............] - ETA: 9s - loss: 0.5392 - acc: 0.6975 
1664/3114 [===============>..............] - ETA: 9s - loss: 0.5321 - acc: 0.7025
1728/3114 [===============>..............] - ETA: 8s - loss: 0.5268 - acc: 0.7072
1792/3114 [================>.............] - ETA: 7s - loss: 0.5210 - acc: 0.7137
1856/3114 [================>.............] - ETA: 7s - loss: 0.5150 - acc: 0.7193
1920/3114 [=================>............] - ETA: 6s - loss: 0.5108 - acc: 0.7234
1984/3114 [==================>...........] - ETA: 6s - loss: 0.5048 - acc: 0.7278
2048/3114 [==================>...........] - ETA: 5s - loss: 0.5012 - acc: 0.7314
2112/3114 [===================>..........] - ETA: 5s - loss: 0.4971 - acc: 0.7339
2176/3114 [===================>..........] - ETA: 5s - loss: 0.4931 - acc: 0.7376
2240/3114 [====================>.........] - ETA: 4s - loss: 0.4877 - acc: 0.7415
2304/3114 [=====================>........] - ETA: 4s - loss: 0.4812 - acc: 0.7465
2368/3114 [=====================>........] - ETA: 3s - loss: 0.4831 - acc: 0.7466
2432/3114 [======================>.......] - ETA: 3s - loss: 0.4808 - acc: 0.7500
2496/3114 [=======================>......] - ETA: 3s - loss: 0.4779 - acc: 0.7528
2560/3114 [=======================>......] - ETA: 2s - loss: 0.4739 - acc: 0.7562
2624/3114 [========================>.....] - ETA: 2s - loss: 0.4722 - acc: 0.7591
2688/3114 [========================>.....] - ETA: 2s - loss: 0.4707 - acc: 0.7600
2752/3114 [=========================>....] - ETA: 1s - loss: 0.4691 - acc: 0.7616
2816/3114 [==========================>...] - ETA: 1s - loss: 0.4676 - acc: 0.7642
2880/3114 [==========================>...] - ETA: 1s - loss: 0.4644 - acc: 0.7670
2944/3114 [===========================>..] - ETA: 0s - loss: 0.4617 - acc: 0.7694
3008/3114 [===========================>..] - ETA: 0s - loss: 0.4577 - acc: 0.7716
3072/3114 [============================>.] - ETA: 0s - loss: 0.4597 - acc: 0.7708
3114/3114 [==============================] - 14s 4ms/step - loss: 0.4597 - acc: 0.7710

Test accuracy: 87.53623188405797

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  152

choose_one :  193

F1score :  0.8808864265927978

AUC :  0.9512375571697606

Confusion Matrix
[[143  34]
 [  9 159]]
True label 0
0.807909604519774  
0.192090395480226  
True label 1
0.05357142857142857  
0.9464285714285714  

Train_result {'acc': [0.7710340395904767], 'loss': [0.4596716401740842]}
Saved model to disk


2

Epoch 1/1

  64/3114 [..............................] - ETA: 11s - loss: 0.4028 - acc: 0.8281
 128/3114 [>.............................] - ETA: 9s - loss: 0.3595 - acc: 0.8438 
 192/3114 [>.............................] - ETA: 8s - loss: 0.3869 - acc: 0.8281
 256/3114 [=>............................] - ETA: 8s - loss: 0.3733 - acc: 0.8359
 320/3114 [==>...........................] - ETA: 7s - loss: 0.3865 - acc: 0.8375
 384/3114 [==>...........................] - ETA: 7s - loss: 0.3675 - acc: 0.8438
 448/3114 [===>..........................] - ETA: 7s - loss: 0.3582 - acc: 0.8504
 512/3114 [===>..........................] - ETA: 6s - loss: 0.3475 - acc: 0.8613
 576/3114 [====>.........................] - ETA: 6s - loss: 0.3537 - acc: 0.8542
 640/3114 [=====>........................] - ETA: 6s - loss: 0.3605 - acc: 0.8531
 704/3114 [=====>........................] - ETA: 6s - loss: 0.3623 - acc: 0.8480
 768/3114 [======>.......................] - ETA: 6s - loss: 0.3496 - acc: 0.8542
 832/3114 [=======>......................] - ETA: 5s - loss: 0.3539 - acc: 0.8498
 896/3114 [=======>......................] - ETA: 5s - loss: 0.3551 - acc: 0.8460
 960/3114 [========>.....................] - ETA: 5s - loss: 0.3473 - acc: 0.8500
1024/3114 [========>.....................] - ETA: 5s - loss: 0.3466 - acc: 0.8496
1088/3114 [=========>....................] - ETA: 5s - loss: 0.3449 - acc: 0.8493
1152/3114 [==========>...................] - ETA: 5s - loss: 0.3463 - acc: 0.8472
1216/3114 [==========>...................] - ETA: 4s - loss: 0.3477 - acc: 0.8462
1280/3114 [===========>..................] - ETA: 4s - loss: 0.3466 - acc: 0.8438
1344/3114 [===========>..................] - ETA: 4s - loss: 0.3570 - acc: 0.8400
1408/3114 [============>.................] - ETA: 4s - loss: 0.3568 - acc: 0.8409
1472/3114 [=============>................] - ETA: 4s - loss: 0.3560 - acc: 0.8410
1536/3114 [=============>................] - ETA: 3s - loss: 0.3525 - acc: 0.8418
1600/3114 [==============>...............] - ETA: 3s - loss: 0.3512 - acc: 0.8413
1664/3114 [===============>..............] - ETA: 3s - loss: 0.3498 - acc: 0.8413
1728/3114 [===============>..............] - ETA: 3s - loss: 0.3466 - acc: 0.8438
1792/3114 [================>.............] - ETA: 3s - loss: 0.3508 - acc: 0.8421
1856/3114 [================>.............] - ETA: 3s - loss: 0.3488 - acc: 0.8427
1920/3114 [=================>............] - ETA: 2s - loss: 0.3462 - acc: 0.8438
1984/3114 [==================>...........] - ETA: 2s - loss: 0.3423 - acc: 0.8453
2048/3114 [==================>...........] - ETA: 2s - loss: 0.3454 - acc: 0.8438
2112/3114 [===================>..........] - ETA: 2s - loss: 0.3437 - acc: 0.8447
2176/3114 [===================>..........] - ETA: 2s - loss: 0.3396 - acc: 0.8470
2240/3114 [====================>.........] - ETA: 2s - loss: 0.3449 - acc: 0.8433
2304/3114 [=====================>........] - ETA: 1s - loss: 0.3430 - acc: 0.8446
2368/3114 [=====================>........] - ETA: 1s - loss: 0.3406 - acc: 0.8459
2432/3114 [======================>.......] - ETA: 1s - loss: 0.3419 - acc: 0.8446
2496/3114 [=======================>......] - ETA: 1s - loss: 0.3389 - acc: 0.8470
2560/3114 [=======================>......] - ETA: 1s - loss: 0.3388 - acc: 0.8480
2624/3114 [========================>.....] - ETA: 1s - loss: 0.3392 - acc: 0.8472
2688/3114 [========================>.....] - ETA: 1s - loss: 0.3387 - acc: 0.8471
2752/3114 [=========================>....] - ETA: 0s - loss: 0.3414 - acc: 0.8467
2816/3114 [==========================>...] - ETA: 0s - loss: 0.3392 - acc: 0.8477
2880/3114 [==========================>...] - ETA: 0s - loss: 0.3362 - acc: 0.8493
2944/3114 [===========================>..] - ETA: 0s - loss: 0.3375 - acc: 0.8482
3008/3114 [===========================>..] - ETA: 0s - loss: 0.3392 - acc: 0.8471
3072/3114 [============================>.] - ETA: 0s - loss: 0.3397 - acc: 0.8460
3114/3114 [==============================] - 8s 2ms/step - loss: 0.3384 - acc: 0.8462

Test accuracy: 85.79710144927536

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  138

choose_one :  207

F1score :  0.8693333333333333

AUC :  0.9621334409470003

Confusion Matrix
[[133  44]
 [  5 163]]
True label 0
0.751412429378531  
0.24858757062146894  
True label 1
0.02976190476190476  
0.9702380952380952  

Train_result {'acc': [0.8461785486055324], 'loss': [0.3383564291355621]}
Saved model to disk


3

Epoch 1/1

  64/3114 [..............................] - ETA: 9s - loss: 0.3019 - acc: 0.8281
 128/3114 [>.............................] - ETA: 8s - loss: 0.3727 - acc: 0.8281
 192/3114 [>.............................] - ETA: 7s - loss: 0.3134 - acc: 0.8490
 256/3114 [=>............................] - ETA: 7s - loss: 0.3256 - acc: 0.8438
 320/3114 [==>...........................] - ETA: 7s - loss: 0.3225 - acc: 0.8594
 384/3114 [==>...........................] - ETA: 7s - loss: 0.2997 - acc: 0.8750
 448/3114 [===>..........................] - ETA: 6s - loss: 0.2962 - acc: 0.8772
 512/3114 [===>..........................] - ETA: 6s - loss: 0.3012 - acc: 0.8730
 576/3114 [====>.........................] - ETA: 6s - loss: 0.3079 - acc: 0.8698
 640/3114 [=====>........................] - ETA: 6s - loss: 0.3100 - acc: 0.8703
 704/3114 [=====>........................] - ETA: 6s - loss: 0.3147 - acc: 0.8693
 768/3114 [======>.......................] - ETA: 5s - loss: 0.3130 - acc: 0.8685
 832/3114 [=======>......................] - ETA: 5s - loss: 0.3077 - acc: 0.8702
 896/3114 [=======>......................] - ETA: 5s - loss: 0.3029 - acc: 0.8717
 960/3114 [========>.....................] - ETA: 5s - loss: 0.2992 - acc: 0.8719
1024/3114 [========>.....................] - ETA: 5s - loss: 0.2977 - acc: 0.8711
1088/3114 [=========>....................] - ETA: 4s - loss: 0.2985 - acc: 0.8713
1152/3114 [==========>...................] - ETA: 4s - loss: 0.3011 - acc: 0.8689
1216/3114 [==========>...................] - ETA: 4s - loss: 0.3005 - acc: 0.8709
1280/3114 [===========>..................] - ETA: 4s - loss: 0.3011 - acc: 0.8688
1344/3114 [===========>..................] - ETA: 4s - loss: 0.2963 - acc: 0.8705
1408/3114 [============>.................] - ETA: 4s - loss: 0.2976 - acc: 0.8672
1472/3114 [=============>................] - ETA: 4s - loss: 0.2931 - acc: 0.8696
1536/3114 [=============>................] - ETA: 3s - loss: 0.2951 - acc: 0.8704
1600/3114 [==============>...............] - ETA: 3s - loss: 0.3010 - acc: 0.8669
1664/3114 [===============>..............] - ETA: 3s - loss: 0.3017 - acc: 0.8660
1728/3114 [===============>..............] - ETA: 3s - loss: 0.3007 - acc: 0.8663
1792/3114 [================>.............] - ETA: 3s - loss: 0.2988 - acc: 0.8677
1856/3114 [================>.............] - ETA: 3s - loss: 0.2971 - acc: 0.8691
1920/3114 [=================>............] - ETA: 2s - loss: 0.2994 - acc: 0.8698
1984/3114 [==================>...........] - ETA: 2s - loss: 0.2970 - acc: 0.8705
2048/3114 [==================>...........] - ETA: 2s - loss: 0.2995 - acc: 0.8672
2112/3114 [===================>..........] - ETA: 2s - loss: 0.2982 - acc: 0.8679
2176/3114 [===================>..........] - ETA: 2s - loss: 0.3004 - acc: 0.8667
2240/3114 [====================>.........] - ETA: 2s - loss: 0.3000 - acc: 0.8665
2304/3114 [=====================>........] - ETA: 1s - loss: 0.2990 - acc: 0.8676
2368/3114 [=====================>........] - ETA: 1s - loss: 0.2995 - acc: 0.8674
2432/3114 [======================>.......] - ETA: 1s - loss: 0.3016 - acc: 0.8664
2496/3114 [=======================>......] - ETA: 1s - loss: 0.3010 - acc: 0.8662
2560/3114 [=======================>......] - ETA: 1s - loss: 0.3042 - acc: 0.8645
2624/3114 [========================>.....] - ETA: 1s - loss: 0.3038 - acc: 0.8647
2688/3114 [========================>.....] - ETA: 1s - loss: 0.3010 - acc: 0.8661
2752/3114 [=========================>....] - ETA: 0s - loss: 0.3003 - acc: 0.8659
2816/3114 [==========================>...] - ETA: 0s - loss: 0.3007 - acc: 0.8661
2880/3114 [==========================>...] - ETA: 0s - loss: 0.2999 - acc: 0.8670
2944/3114 [===========================>..] - ETA: 0s - loss: 0.2984 - acc: 0.8668
3008/3114 [===========================>..] - ETA: 0s - loss: 0.2974 - acc: 0.8670
3072/3114 [============================>.] - ETA: 0s - loss: 0.2968 - acc: 0.8669
3114/3114 [==============================] - 8s 2ms/step - loss: 0.2964 - acc: 0.8671

Test accuracy: 86.08695652173914

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  149

choose_one :  196

F1score :  0.8681318681318683

AUC :  0.9547686306160883

Confusion Matrix
[[139  38]
 [ 10 158]]
True label 0
0.7853107344632768  
0.21468926553672316  
True label 1
0.05952380952380952  
0.9404761904761905  

Train_result {'acc': [0.8670520228151335], 'loss': [0.29640490360266136]}
Saved model to disk


4

Epoch 1/1

  64/3114 [..............................] - ETA: 9s - loss: 0.2236 - acc: 0.9219
 128/3114 [>.............................] - ETA: 8s - loss: 0.2855 - acc: 0.8906
 192/3114 [>.............................] - ETA: 7s - loss: 0.2665 - acc: 0.8854
 256/3114 [=>............................] - ETA: 7s - loss: 0.3378 - acc: 0.8438
 320/3114 [==>...........................] - ETA: 7s - loss: 0.3092 - acc: 0.8562
 384/3114 [==>...........................] - ETA: 7s - loss: 0.3110 - acc: 0.8490
 448/3114 [===>..........................] - ETA: 6s - loss: 0.3020 - acc: 0.8549
 512/3114 [===>..........................] - ETA: 6s - loss: 0.2968 - acc: 0.8613
 576/3114 [====>.........................] - ETA: 6s - loss: 0.2930 - acc: 0.8594
 640/3114 [=====>........................] - ETA: 6s - loss: 0.2974 - acc: 0.8594
 704/3114 [=====>........................] - ETA: 6s - loss: 0.2907 - acc: 0.8636
 768/3114 [======>.......................] - ETA: 5s - loss: 0.2849 - acc: 0.8685
 832/3114 [=======>......................] - ETA: 5s - loss: 0.2804 - acc: 0.8690
 896/3114 [=======>......................] - ETA: 5s - loss: 0.2837 - acc: 0.8683
 960/3114 [========>.....................] - ETA: 5s - loss: 0.2790 - acc: 0.8708
1024/3114 [========>.....................] - ETA: 5s - loss: 0.2768 - acc: 0.8721
1088/3114 [=========>....................] - ETA: 4s - loss: 0.2863 - acc: 0.8741
1152/3114 [==========>...................] - ETA: 4s - loss: 0.2856 - acc: 0.8767
1216/3114 [==========>...................] - ETA: 4s - loss: 0.2824 - acc: 0.8783
1280/3114 [===========>..................] - ETA: 4s - loss: 0.2760 - acc: 0.8805
1344/3114 [===========>..................] - ETA: 4s - loss: 0.2758 - acc: 0.8795
1408/3114 [============>.................] - ETA: 4s - loss: 0.2738 - acc: 0.8800
1472/3114 [=============>................] - ETA: 3s - loss: 0.2739 - acc: 0.8804
1536/3114 [=============>................] - ETA: 3s - loss: 0.2748 - acc: 0.8802
1600/3114 [==============>...............] - ETA: 3s - loss: 0.2761 - acc: 0.8788
1664/3114 [===============>..............] - ETA: 3s - loss: 0.2790 - acc: 0.8792
1728/3114 [===============>..............] - ETA: 3s - loss: 0.2788 - acc: 0.8802
1792/3114 [================>.............] - ETA: 3s - loss: 0.2794 - acc: 0.8800
1856/3114 [================>.............] - ETA: 3s - loss: 0.2778 - acc: 0.8809
1920/3114 [=================>............] - ETA: 2s - loss: 0.2824 - acc: 0.8766
1984/3114 [==================>...........] - ETA: 2s - loss: 0.2800 - acc: 0.8780
2048/3114 [==================>...........] - ETA: 2s - loss: 0.2794 - acc: 0.8789
2112/3114 [===================>..........] - ETA: 2s - loss: 0.2779 - acc: 0.8797
2176/3114 [===================>..........] - ETA: 2s - loss: 0.2779 - acc: 0.8796
2240/3114 [====================>.........] - ETA: 2s - loss: 0.2781 - acc: 0.8790
2304/3114 [=====================>........] - ETA: 1s - loss: 0.2778 - acc: 0.8789
2368/3114 [=====================>........] - ETA: 1s - loss: 0.2781 - acc: 0.8788
2432/3114 [======================>.......] - ETA: 1s - loss: 0.2768 - acc: 0.8787
2496/3114 [=======================>......] - ETA: 1s - loss: 0.2745 - acc: 0.8794
2560/3114 [=======================>......] - ETA: 1s - loss: 0.2791 - acc: 0.8781
2624/3114 [========================>.....] - ETA: 1s - loss: 0.2765 - acc: 0.8803
2688/3114 [========================>.....] - ETA: 1s - loss: 0.2761 - acc: 0.8798
2752/3114 [=========================>....] - ETA: 0s - loss: 0.2760 - acc: 0.8794
2816/3114 [==========================>...] - ETA: 0s - loss: 0.2751 - acc: 0.8796
2880/3114 [==========================>...] - ETA: 0s - loss: 0.2749 - acc: 0.8795
2944/3114 [===========================>..] - ETA: 0s - loss: 0.2742 - acc: 0.8791
3008/3114 [===========================>..] - ETA: 0s - loss: 0.2756 - acc: 0.8787
3072/3114 [============================>.] - ETA: 0s - loss: 0.2776 - acc: 0.8779
3114/3114 [==============================] - 7s 2ms/step - loss: 0.2779 - acc: 0.8770

Test accuracy: 87.2463768115942

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  149

choose_one :  196

F1score :  0.8791208791208791

AUC :  0.9648237826203928

Confusion Matrix
[[141  36]
 [  8 160]]
True label 0
0.7966101694915254  
0.2033898305084746  
True label 1
0.047619047619047616  
0.9523809523809523  

Train_result {'acc': [0.8770070650214634], 'loss': [0.27788387973031403]}
Saved model to disk


5

Epoch 1/1

  64/3114 [..............................] - ETA: 8s - loss: 0.2505 - acc: 0.8906
 128/3114 [>.............................] - ETA: 7s - loss: 0.2436 - acc: 0.8906
 192/3114 [>.............................] - ETA: 7s - loss: 0.2733 - acc: 0.8906
 256/3114 [=>............................] - ETA: 7s - loss: 0.2670 - acc: 0.8828
 320/3114 [==>...........................] - ETA: 6s - loss: 0.2615 - acc: 0.8812
 384/3114 [==>...........................] - ETA: 6s - loss: 0.2828 - acc: 0.8724
 448/3114 [===>..........................] - ETA: 6s - loss: 0.2852 - acc: 0.8772
 512/3114 [===>..........................] - ETA: 6s - loss: 0.2655 - acc: 0.8848
 576/3114 [====>.........................] - ETA: 6s - loss: 0.2563 - acc: 0.8837
 640/3114 [=====>........................] - ETA: 5s - loss: 0.2545 - acc: 0.8844
 704/3114 [=====>........................] - ETA: 5s - loss: 0.2512 - acc: 0.8793
 768/3114 [======>.......................] - ETA: 5s - loss: 0.2501 - acc: 0.8815
 832/3114 [=======>......................] - ETA: 5s - loss: 0.2486 - acc: 0.8834
 896/3114 [=======>......................] - ETA: 5s - loss: 0.2508 - acc: 0.8839
 960/3114 [========>.....................] - ETA: 5s - loss: 0.2593 - acc: 0.8802
1024/3114 [========>.....................] - ETA: 5s - loss: 0.2633 - acc: 0.8770
1088/3114 [=========>....................] - ETA: 4s - loss: 0.2625 - acc: 0.8768
1152/3114 [==========>...................] - ETA: 4s - loss: 0.2610 - acc: 0.8793
1216/3114 [==========>...................] - ETA: 4s - loss: 0.2620 - acc: 0.8791
1280/3114 [===========>..................] - ETA: 4s - loss: 0.2598 - acc: 0.8789
1344/3114 [===========>..................] - ETA: 4s - loss: 0.2556 - acc: 0.8817
1408/3114 [============>.................] - ETA: 4s - loss: 0.2649 - acc: 0.8778
1472/3114 [=============>................] - ETA: 3s - loss: 0.2620 - acc: 0.8811
1536/3114 [=============>................] - ETA: 3s - loss: 0.2602 - acc: 0.8828
1600/3114 [==============>...............] - ETA: 3s - loss: 0.2584 - acc: 0.8856
1664/3114 [===============>..............] - ETA: 3s - loss: 0.2592 - acc: 0.8846
1728/3114 [===============>..............] - ETA: 3s - loss: 0.2586 - acc: 0.8848
1792/3114 [================>.............] - ETA: 3s - loss: 0.2578 - acc: 0.8856
1856/3114 [================>.............] - ETA: 2s - loss: 0.2575 - acc: 0.8863
1920/3114 [=================>............] - ETA: 2s - loss: 0.2570 - acc: 0.8854
1984/3114 [==================>...........] - ETA: 2s - loss: 0.2544 - acc: 0.8871
2048/3114 [==================>...........] - ETA: 2s - loss: 0.2516 - acc: 0.8896
2112/3114 [===================>..........] - ETA: 2s - loss: 0.2534 - acc: 0.8883
2176/3114 [===================>..........] - ETA: 2s - loss: 0.2542 - acc: 0.8888
2240/3114 [====================>.........] - ETA: 2s - loss: 0.2560 - acc: 0.8879
2304/3114 [=====================>........] - ETA: 1s - loss: 0.2595 - acc: 0.8863
2368/3114 [=====================>........] - ETA: 1s - loss: 0.2608 - acc: 0.8851
2432/3114 [======================>.......] - ETA: 1s - loss: 0.2593 - acc: 0.8857
2496/3114 [=======================>......] - ETA: 1s - loss: 0.2590 - acc: 0.8854
2560/3114 [=======================>......] - ETA: 1s - loss: 0.2589 - acc: 0.8848
2624/3114 [========================>.....] - ETA: 1s - loss: 0.2565 - acc: 0.8864
2688/3114 [========================>.....] - ETA: 1s - loss: 0.2593 - acc: 0.8850
2752/3114 [=========================>....] - ETA: 0s - loss: 0.2610 - acc: 0.8848
2816/3114 [==========================>...] - ETA: 0s - loss: 0.2622 - acc: 0.8849
2880/3114 [==========================>...] - ETA: 0s - loss: 0.2632 - acc: 0.8851
2944/3114 [===========================>..] - ETA: 0s - loss: 0.2626 - acc: 0.8845
3008/3114 [===========================>..] - ETA: 0s - loss: 0.2631 - acc: 0.8833
3072/3114 [============================>.] - ETA: 0s - loss: 0.2625 - acc: 0.8828
3114/3114 [==============================] - 7s 2ms/step - loss: 0.2636 - acc: 0.8825

Test accuracy: 89.27536231884058

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  172

choose_one :  173

F1score :  0.8914956011730206

AUC :  0.9667070217917675

Confusion Matrix
[[156  21]
 [ 16 152]]
True label 0
0.8813559322033898  
0.11864406779661017  
True label 1
0.09523809523809523  
0.9047619047619048  

Train_result {'acc': [0.8824662814250571], 'loss': [0.26361053025944536]}
Saved model to disk


6

Epoch 1/1

  64/3114 [..............................] - ETA: 9s - loss: 0.1749 - acc: 0.9219
 128/3114 [>.............................] - ETA: 7s - loss: 0.1946 - acc: 0.8984
 192/3114 [>.............................] - ETA: 7s - loss: 0.2369 - acc: 0.8906
 256/3114 [=>............................] - ETA: 7s - loss: 0.2522 - acc: 0.8711
 320/3114 [==>...........................] - ETA: 7s - loss: 0.2408 - acc: 0.8844
 384/3114 [==>...........................] - ETA: 7s - loss: 0.2550 - acc: 0.8776
 448/3114 [===>..........................] - ETA: 6s - loss: 0.2434 - acc: 0.8817
 512/3114 [===>..........................] - ETA: 6s - loss: 0.2565 - acc: 0.8770
 576/3114 [====>.........................] - ETA: 6s - loss: 0.2543 - acc: 0.8785
 640/3114 [=====>........................] - ETA: 6s - loss: 0.2461 - acc: 0.8828
 704/3114 [=====>........................] - ETA: 6s - loss: 0.2473 - acc: 0.8807
 768/3114 [======>.......................] - ETA: 5s - loss: 0.2435 - acc: 0.8802
 832/3114 [=======>......................] - ETA: 5s - loss: 0.2428 - acc: 0.8810
 896/3114 [=======>......................] - ETA: 5s - loss: 0.2435 - acc: 0.8817
 960/3114 [========>.....................] - ETA: 5s - loss: 0.2561 - acc: 0.8781
1024/3114 [========>.....................] - ETA: 5s - loss: 0.2483 - acc: 0.8828
1088/3114 [=========>....................] - ETA: 5s - loss: 0.2461 - acc: 0.8824
1152/3114 [==========>...................] - ETA: 4s - loss: 0.2448 - acc: 0.8819
1216/3114 [==========>...................] - ETA: 4s - loss: 0.2454 - acc: 0.8791
1280/3114 [===========>..................] - ETA: 4s - loss: 0.2466 - acc: 0.8805
1344/3114 [===========>..................] - ETA: 4s - loss: 0.2448 - acc: 0.8832
1408/3114 [============>.................] - ETA: 4s - loss: 0.2448 - acc: 0.8835
1472/3114 [=============>................] - ETA: 4s - loss: 0.2501 - acc: 0.8811
1536/3114 [=============>................] - ETA: 3s - loss: 0.2486 - acc: 0.8822
1600/3114 [==============>...............] - ETA: 3s - loss: 0.2453 - acc: 0.8844
1664/3114 [===============>..............] - ETA: 3s - loss: 0.2429 - acc: 0.8858
1728/3114 [===============>..............] - ETA: 3s - loss: 0.2446 - acc: 0.8860
1792/3114 [================>.............] - ETA: 3s - loss: 0.2441 - acc: 0.8862
1856/3114 [================>.............] - ETA: 3s - loss: 0.2446 - acc: 0.8863
1920/3114 [=================>............] - ETA: 2s - loss: 0.2426 - acc: 0.8870
1984/3114 [==================>...........] - ETA: 2s - loss: 0.2445 - acc: 0.8866
2048/3114 [==================>...........] - ETA: 2s - loss: 0.2468 - acc: 0.8862
2112/3114 [===================>..........] - ETA: 2s - loss: 0.2482 - acc: 0.8859
2176/3114 [===================>..........] - ETA: 2s - loss: 0.2502 - acc: 0.8837
2240/3114 [====================>.........] - ETA: 2s - loss: 0.2495 - acc: 0.8839
2304/3114 [=====================>........] - ETA: 1s - loss: 0.2475 - acc: 0.8850
2368/3114 [=====================>........] - ETA: 1s - loss: 0.2477 - acc: 0.8856
2432/3114 [======================>.......] - ETA: 1s - loss: 0.2477 - acc: 0.8869
2496/3114 [=======================>......] - ETA: 1s - loss: 0.2463 - acc: 0.8870
2560/3114 [=======================>......] - ETA: 1s - loss: 0.2454 - acc: 0.8871
2624/3114 [========================>.....] - ETA: 1s - loss: 0.2442 - acc: 0.8880
2688/3114 [========================>.....] - ETA: 1s - loss: 0.2433 - acc: 0.8888
2752/3114 [=========================>....] - ETA: 0s - loss: 0.2423 - acc: 0.8903
2816/3114 [==========================>...] - ETA: 0s - loss: 0.2408 - acc: 0.8910
2880/3114 [==========================>...] - ETA: 0s - loss: 0.2399 - acc: 0.8917
2944/3114 [===========================>..] - ETA: 0s - loss: 0.2418 - acc: 0.8906
3008/3114 [===========================>..] - ETA: 0s - loss: 0.2406 - acc: 0.8920
3072/3114 [============================>.] - ETA: 0s - loss: 0.2419 - acc: 0.8913
3114/3114 [==============================] - 8s 2ms/step - loss: 0.2430 - acc: 0.8908

Test accuracy: 89.27536231884058

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  182

choose_one :  163

F1score :  0.8882175226586103

AUC :  0.9674468657519506

Confusion Matrix
[[161  16]
 [ 21 147]]
True label 0
0.9096045197740112  
0.0903954802259887  
True label 1
0.125  
0.875  

Train_result {'acc': [0.8908156712773372], 'loss': [0.2430456211992618]}
Saved model to disk


7

Epoch 1/1

  64/3114 [..............................] - ETA: 8s - loss: 0.2585 - acc: 0.9062
 128/3114 [>.............................] - ETA: 7s - loss: 0.2230 - acc: 0.9219
 192/3114 [>.............................] - ETA: 7s - loss: 0.2662 - acc: 0.9062
 256/3114 [=>............................] - ETA: 7s - loss: 0.2679 - acc: 0.9023
 320/3114 [==>...........................] - ETA: 7s - loss: 0.2685 - acc: 0.9031
 384/3114 [==>...........................] - ETA: 7s - loss: 0.2677 - acc: 0.8984
 448/3114 [===>..........................] - ETA: 6s - loss: 0.2592 - acc: 0.8996
 512/3114 [===>..........................] - ETA: 6s - loss: 0.2602 - acc: 0.9004
 576/3114 [====>.........................] - ETA: 6s - loss: 0.2631 - acc: 0.8941
 640/3114 [=====>........................] - ETA: 6s - loss: 0.2548 - acc: 0.9000
 704/3114 [=====>........................] - ETA: 6s - loss: 0.2564 - acc: 0.8991
 768/3114 [======>.......................] - ETA: 6s - loss: 0.2602 - acc: 0.8997
 832/3114 [=======>......................] - ETA: 5s - loss: 0.2536 - acc: 0.9014
 896/3114 [=======>......................] - ETA: 5s - loss: 0.2586 - acc: 0.8962
 960/3114 [========>.....................] - ETA: 5s - loss: 0.2535 - acc: 0.8969
1024/3114 [========>.....................] - ETA: 5s - loss: 0.2516 - acc: 0.8975
1088/3114 [=========>....................] - ETA: 5s - loss: 0.2458 - acc: 0.8998
1152/3114 [==========>...................] - ETA: 5s - loss: 0.2409 - acc: 0.9019
1216/3114 [==========>...................] - ETA: 4s - loss: 0.2371 - acc: 0.9030
1280/3114 [===========>..................] - ETA: 4s - loss: 0.2379 - acc: 0.9016
1344/3114 [===========>..................] - ETA: 4s - loss: 0.2396 - acc: 0.9003
1408/3114 [============>.................] - ETA: 4s - loss: 0.2389 - acc: 0.9013
1472/3114 [=============>................] - ETA: 4s - loss: 0.2344 - acc: 0.9035
1536/3114 [=============>................] - ETA: 4s - loss: 0.2331 - acc: 0.9017
1600/3114 [==============>...............] - ETA: 3s - loss: 0.2308 - acc: 0.9019
1664/3114 [===============>..............] - ETA: 3s - loss: 0.2274 - acc: 0.9032
1728/3114 [===============>..............] - ETA: 3s - loss: 0.2280 - acc: 0.9034
1792/3114 [================>.............] - ETA: 3s - loss: 0.2252 - acc: 0.9040
1856/3114 [================>.............] - ETA: 3s - loss: 0.2293 - acc: 0.9036
1920/3114 [=================>............] - ETA: 3s - loss: 0.2261 - acc: 0.9052
1984/3114 [==================>...........] - ETA: 2s - loss: 0.2235 - acc: 0.9052
2048/3114 [==================>...........] - ETA: 2s - loss: 0.2252 - acc: 0.9038
2112/3114 [===================>..........] - ETA: 2s - loss: 0.2255 - acc: 0.9029
2176/3114 [===================>..........] - ETA: 2s - loss: 0.2254 - acc: 0.9021
2240/3114 [====================>.........] - ETA: 2s - loss: 0.2256 - acc: 0.9022
2304/3114 [=====================>........] - ETA: 2s - loss: 0.2254 - acc: 0.9010
2368/3114 [=====================>........] - ETA: 1s - loss: 0.2245 - acc: 0.9012
2432/3114 [======================>.......] - ETA: 1s - loss: 0.2287 - acc: 0.8988
2496/3114 [=======================>......] - ETA: 1s - loss: 0.2299 - acc: 0.8982
2560/3114 [=======================>......] - ETA: 1s - loss: 0.2324 - acc: 0.8973
2624/3114 [========================>.....] - ETA: 1s - loss: 0.2358 - acc: 0.8944
2688/3114 [========================>.....] - ETA: 1s - loss: 0.2371 - acc: 0.8921
2752/3114 [=========================>....] - ETA: 0s - loss: 0.2392 - acc: 0.8899
2816/3114 [==========================>...] - ETA: 0s - loss: 0.2386 - acc: 0.8896
2880/3114 [==========================>...] - ETA: 0s - loss: 0.2372 - acc: 0.8903
2944/3114 [===========================>..] - ETA: 0s - loss: 0.2390 - acc: 0.8896
3008/3114 [===========================>..] - ETA: 0s - loss: 0.2372 - acc: 0.8900
3072/3114 [============================>.] - ETA: 0s - loss: 0.2379 - acc: 0.8896
3114/3114 [==============================] - 8s 3ms/step - loss: 0.2366 - acc: 0.8905

Test accuracy: 89.56521739130436

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  171

choose_one :  174

F1score :  0.8947368421052632

AUC :  0.9658999192897497

Confusion Matrix
[[156  21]
 [ 15 153]]
True label 0
0.8813559322033898  
0.11864406779661017  
True label 1
0.08928571428571429  
0.9107142857142857  

Train_result {'acc': [0.8904945408218399], 'loss': [0.23664705806538014]}
Saved model to disk


8

Epoch 1/1

  64/3114 [..............................] - ETA: 8s - loss: 0.1944 - acc: 0.9062
 128/3114 [>.............................] - ETA: 8s - loss: 0.2737 - acc: 0.8594
 192/3114 [>.............................] - ETA: 7s - loss: 0.2581 - acc: 0.8698
 256/3114 [=>............................] - ETA: 7s - loss: 0.2607 - acc: 0.8594
 320/3114 [==>...........................] - ETA: 7s - loss: 0.2588 - acc: 0.8719
 384/3114 [==>...........................] - ETA: 7s - loss: 0.2664 - acc: 0.8672
 448/3114 [===>..........................] - ETA: 6s - loss: 0.2622 - acc: 0.8683
 512/3114 [===>..........................] - ETA: 6s - loss: 0.2513 - acc: 0.8750
 576/3114 [====>.........................] - ETA: 6s - loss: 0.2428 - acc: 0.8785
 640/3114 [=====>........................] - ETA: 6s - loss: 0.2355 - acc: 0.8828
 704/3114 [=====>........................] - ETA: 6s - loss: 0.2329 - acc: 0.8835
 768/3114 [======>.......................] - ETA: 5s - loss: 0.2302 - acc: 0.8880
 832/3114 [=======>......................] - ETA: 5s - loss: 0.2259 - acc: 0.8930
 896/3114 [=======>......................] - ETA: 5s - loss: 0.2280 - acc: 0.8917
 960/3114 [========>.....................] - ETA: 5s - loss: 0.2239 - acc: 0.8927
1024/3114 [========>.....................] - ETA: 5s - loss: 0.2265 - acc: 0.8926
1088/3114 [=========>....................] - ETA: 5s - loss: 0.2246 - acc: 0.8915
1152/3114 [==========>...................] - ETA: 4s - loss: 0.2242 - acc: 0.8906
1216/3114 [==========>...................] - ETA: 4s - loss: 0.2231 - acc: 0.8914
1280/3114 [===========>..................] - ETA: 4s - loss: 0.2237 - acc: 0.8922
1344/3114 [===========>..................] - ETA: 4s - loss: 0.2220 - acc: 0.8929
1408/3114 [============>.................] - ETA: 4s - loss: 0.2161 - acc: 0.8963
1472/3114 [=============>................] - ETA: 4s - loss: 0.2128 - acc: 0.8974
1536/3114 [=============>................] - ETA: 3s - loss: 0.2137 - acc: 0.8971
1600/3114 [==============>...............] - ETA: 3s - loss: 0.2168 - acc: 0.8950
1664/3114 [===============>..............] - ETA: 3s - loss: 0.2132 - acc: 0.8966
1728/3114 [===============>..............] - ETA: 3s - loss: 0.2180 - acc: 0.8953
1792/3114 [================>.............] - ETA: 3s - loss: 0.2182 - acc: 0.8951
1856/3114 [================>.............] - ETA: 3s - loss: 0.2179 - acc: 0.8955
1920/3114 [=================>............] - ETA: 3s - loss: 0.2165 - acc: 0.8969
1984/3114 [==================>...........] - ETA: 2s - loss: 0.2160 - acc: 0.8972
2048/3114 [==================>...........] - ETA: 2s - loss: 0.2127 - acc: 0.8989
2112/3114 [===================>..........] - ETA: 2s - loss: 0.2135 - acc: 0.8991
2176/3114 [===================>..........] - ETA: 2s - loss: 0.2119 - acc: 0.9003
2240/3114 [====================>.........] - ETA: 2s - loss: 0.2118 - acc: 0.8996
2304/3114 [=====================>........] - ETA: 2s - loss: 0.2101 - acc: 0.9010
2368/3114 [=====================>........] - ETA: 1s - loss: 0.2090 - acc: 0.9008
2432/3114 [======================>.......] - ETA: 1s - loss: 0.2084 - acc: 0.9009
2496/3114 [=======================>......] - ETA: 1s - loss: 0.2079 - acc: 0.9002
2560/3114 [=======================>......] - ETA: 1s - loss: 0.2078 - acc: 0.9004
2624/3114 [========================>.....] - ETA: 1s - loss: 0.2062 - acc: 0.9021
2688/3114 [========================>.....] - ETA: 1s - loss: 0.2073 - acc: 0.9014
2752/3114 [=========================>....] - ETA: 0s - loss: 0.2074 - acc: 0.9012
2816/3114 [==========================>...] - ETA: 0s - loss: 0.2085 - acc: 0.9020
2880/3114 [==========================>...] - ETA: 0s - loss: 0.2084 - acc: 0.9017
2944/3114 [===========================>..] - ETA: 0s - loss: 0.2088 - acc: 0.9015
3008/3114 [===========================>..] - ETA: 0s - loss: 0.2079 - acc: 0.9023
3072/3114 [============================>.] - ETA: 0s - loss: 0.2066 - acc: 0.9033
3114/3114 [==============================] - 8s 2ms/step - loss: 0.2092 - acc: 0.9030

Test accuracy: 90.43478260869566

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  172

choose_one :  173

F1score :  0.9032258064516129

AUC :  0.9701035781544256

Confusion Matrix
[[158  19]
 [ 14 154]]
True label 0
0.8926553672316384  
0.10734463276836158  
True label 1
0.08333333333333333  
0.9166666666666666  

Train_result {'acc': [0.9030186252557244], 'loss': [0.20920981603627337]}
Saved model to disk


9

Epoch 1/1

  64/3114 [..............................] - ETA: 8s - loss: 0.1711 - acc: 0.9219
 128/3114 [>.............................] - ETA: 7s - loss: 0.1932 - acc: 0.9062
 192/3114 [>.............................] - ETA: 7s - loss: 0.1910 - acc: 0.9062
 256/3114 [=>............................] - ETA: 7s - loss: 0.1957 - acc: 0.9102
 320/3114 [==>...........................] - ETA: 7s - loss: 0.1807 - acc: 0.9219
 384/3114 [==>...........................] - ETA: 6s - loss: 0.1859 - acc: 0.9193
 448/3114 [===>..........................] - ETA: 6s - loss: 0.1928 - acc: 0.9129
 512/3114 [===>..........................] - ETA: 6s - loss: 0.1847 - acc: 0.9180
 576/3114 [====>.........................] - ETA: 6s - loss: 0.1850 - acc: 0.9167
 640/3114 [=====>........................] - ETA: 6s - loss: 0.1808 - acc: 0.9172
 704/3114 [=====>........................] - ETA: 5s - loss: 0.1798 - acc: 0.9176
 768/3114 [======>.......................] - ETA: 5s - loss: 0.1769 - acc: 0.9167
 832/3114 [=======>......................] - ETA: 5s - loss: 0.1828 - acc: 0.9183
 896/3114 [=======>......................] - ETA: 5s - loss: 0.1799 - acc: 0.9196
 960/3114 [========>.....................] - ETA: 5s - loss: 0.1868 - acc: 0.9187
1024/3114 [========>.....................] - ETA: 4s - loss: 0.1840 - acc: 0.9189
1088/3114 [=========>....................] - ETA: 4s - loss: 0.1910 - acc: 0.9173
1152/3114 [==========>...................] - ETA: 4s - loss: 0.1907 - acc: 0.9141
1216/3114 [==========>...................] - ETA: 4s - loss: 0.1890 - acc: 0.9137
1280/3114 [===========>..................] - ETA: 4s - loss: 0.1920 - acc: 0.9141
1344/3114 [===========>..................] - ETA: 4s - loss: 0.1931 - acc: 0.9137
1408/3114 [============>.................] - ETA: 4s - loss: 0.1920 - acc: 0.9141
1472/3114 [=============>................] - ETA: 3s - loss: 0.1918 - acc: 0.9151
1536/3114 [=============>................] - ETA: 3s - loss: 0.1924 - acc: 0.9160
1600/3114 [==============>...............] - ETA: 3s - loss: 0.1905 - acc: 0.9163
1664/3114 [===============>..............] - ETA: 3s - loss: 0.1894 - acc: 0.9153
1728/3114 [===============>..............] - ETA: 3s - loss: 0.1865 - acc: 0.9161
1792/3114 [================>.............] - ETA: 3s - loss: 0.1867 - acc: 0.9157
1856/3114 [================>.............] - ETA: 2s - loss: 0.1846 - acc: 0.9165
1920/3114 [=================>............] - ETA: 2s - loss: 0.1837 - acc: 0.9177
1984/3114 [==================>...........] - ETA: 2s - loss: 0.1857 - acc: 0.9163
2048/3114 [==================>...........] - ETA: 2s - loss: 0.1846 - acc: 0.9170
2112/3114 [===================>..........] - ETA: 2s - loss: 0.1833 - acc: 0.9171
2176/3114 [===================>..........] - ETA: 2s - loss: 0.1829 - acc: 0.9164
2240/3114 [====================>.........] - ETA: 2s - loss: 0.1819 - acc: 0.9161
2304/3114 [=====================>........] - ETA: 1s - loss: 0.1794 - acc: 0.9175
2368/3114 [=====================>........] - ETA: 1s - loss: 0.1799 - acc: 0.9168
2432/3114 [======================>.......] - ETA: 1s - loss: 0.1800 - acc: 0.9165
2496/3114 [=======================>......] - ETA: 1s - loss: 0.1824 - acc: 0.9167
2560/3114 [=======================>......] - ETA: 1s - loss: 0.1820 - acc: 0.9164
2624/3114 [========================>.....] - ETA: 1s - loss: 0.1840 - acc: 0.9158
2688/3114 [========================>.....] - ETA: 1s - loss: 0.1843 - acc: 0.9167
2752/3114 [=========================>....] - ETA: 0s - loss: 0.1815 - acc: 0.9179
2816/3114 [==========================>...] - ETA: 0s - loss: 0.1860 - acc: 0.9169
2880/3114 [==========================>...] - ETA: 0s - loss: 0.1888 - acc: 0.9160
2944/3114 [===========================>..] - ETA: 0s - loss: 0.1938 - acc: 0.9151
3008/3114 [===========================>..] - ETA: 0s - loss: 0.1941 - acc: 0.9142
3072/3114 [============================>.] - ETA: 0s - loss: 0.1942 - acc: 0.9141
3114/3114 [==============================] - 7s 2ms/step - loss: 0.1946 - acc: 0.9139

Test accuracy: 87.82608695652175

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  145

choose_one :  200

F1score :  0.8858695652173912

AUC :  0.9748789346246973

Confusion Matrix
[[140  37]
 [  5 163]]
True label 0
0.7909604519774012  
0.20903954802259886  
True label 1
0.02976190476190476  
0.9702380952380952  

Train_result {'acc': [0.9139370585222925], 'loss': [0.1945632687059824]}
Saved model to disk


10

Epoch 1/1

  64/3114 [..............................] - ETA: 8s - loss: 0.2296 - acc: 0.8750
 128/3114 [>.............................] - ETA: 7s - loss: 0.2273 - acc: 0.8828
 192/3114 [>.............................] - ETA: 7s - loss: 0.2094 - acc: 0.9010
 256/3114 [=>............................] - ETA: 7s - loss: 0.2035 - acc: 0.9141
 320/3114 [==>...........................] - ETA: 7s - loss: 0.1914 - acc: 0.9219
 384/3114 [==>...........................] - ETA: 6s - loss: 0.1986 - acc: 0.9115
 448/3114 [===>..........................] - ETA: 6s - loss: 0.1985 - acc: 0.9107
 512/3114 [===>..........................] - ETA: 6s - loss: 0.1935 - acc: 0.9102
 576/3114 [====>.........................] - ETA: 6s - loss: 0.1911 - acc: 0.9115
 640/3114 [=====>........................] - ETA: 6s - loss: 0.1914 - acc: 0.9109
 704/3114 [=====>........................] - ETA: 6s - loss: 0.1844 - acc: 0.9134
 768/3114 [======>.......................] - ETA: 5s - loss: 0.1892 - acc: 0.9128
 832/3114 [=======>......................] - ETA: 5s - loss: 0.1954 - acc: 0.9099
 896/3114 [=======>......................] - ETA: 5s - loss: 0.1977 - acc: 0.9107
 960/3114 [========>.....................] - ETA: 5s - loss: 0.1926 - acc: 0.9135
1024/3114 [========>.....................] - ETA: 5s - loss: 0.1866 - acc: 0.9160
1088/3114 [=========>....................] - ETA: 4s - loss: 0.1880 - acc: 0.9164
1152/3114 [==========>...................] - ETA: 4s - loss: 0.1877 - acc: 0.9167
1216/3114 [==========>...................] - ETA: 4s - loss: 0.1906 - acc: 0.9161
1280/3114 [===========>..................] - ETA: 4s - loss: 0.1860 - acc: 0.9187
1344/3114 [===========>..................] - ETA: 4s - loss: 0.1878 - acc: 0.9182
1408/3114 [============>.................] - ETA: 4s - loss: 0.1893 - acc: 0.9176
1472/3114 [=============>................] - ETA: 3s - loss: 0.1892 - acc: 0.9171
1536/3114 [=============>................] - ETA: 3s - loss: 0.1901 - acc: 0.9173
1600/3114 [==============>...............] - ETA: 3s - loss: 0.1923 - acc: 0.9169
1664/3114 [===============>..............] - ETA: 3s - loss: 0.1909 - acc: 0.9183
1728/3114 [===============>..............] - ETA: 3s - loss: 0.1908 - acc: 0.9178
1792/3114 [================>.............] - ETA: 3s - loss: 0.1907 - acc: 0.9169
1856/3114 [================>.............] - ETA: 3s - loss: 0.1912 - acc: 0.9165
1920/3114 [=================>............] - ETA: 2s - loss: 0.1917 - acc: 0.9167
1984/3114 [==================>...........] - ETA: 2s - loss: 0.1922 - acc: 0.9153
2048/3114 [==================>...........] - ETA: 2s - loss: 0.1905 - acc: 0.9160
2112/3114 [===================>..........] - ETA: 2s - loss: 0.1870 - acc: 0.9181
2176/3114 [===================>..........] - ETA: 2s - loss: 0.1874 - acc: 0.9196
2240/3114 [====================>.........] - ETA: 2s - loss: 0.1877 - acc: 0.9196
2304/3114 [=====================>........] - ETA: 1s - loss: 0.1871 - acc: 0.9197
2368/3114 [=====================>........] - ETA: 1s - loss: 0.1869 - acc: 0.9210
2432/3114 [======================>.......] - ETA: 1s - loss: 0.1841 - acc: 0.9227
2496/3114 [=======================>......] - ETA: 1s - loss: 0.1853 - acc: 0.9227
2560/3114 [=======================>......] - ETA: 1s - loss: 0.1872 - acc: 0.9215
2624/3114 [========================>.....] - ETA: 1s - loss: 0.1873 - acc: 0.9204
2688/3114 [========================>.....] - ETA: 1s - loss: 0.1886 - acc: 0.9193
2752/3114 [=========================>....] - ETA: 0s - loss: 0.1880 - acc: 0.9193
2816/3114 [==========================>...] - ETA: 0s - loss: 0.1876 - acc: 0.9194
2880/3114 [==========================>...] - ETA: 0s - loss: 0.1877 - acc: 0.9191
2944/3114 [===========================>..] - ETA: 0s - loss: 0.1863 - acc: 0.9198
3008/3114 [===========================>..] - ETA: 0s - loss: 0.1872 - acc: 0.9186
3072/3114 [============================>.] - ETA: 0s - loss: 0.1854 - acc: 0.9193
3114/3114 [==============================] - 8s 2ms/step - loss: 0.1845 - acc: 0.9197

Test accuracy: 90.14492753623189

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  169

choose_one :  176

F1score :  0.9011627906976746

AUC :  0.9685566316922251

Confusion Matrix
[[156  21]
 [ 13 155]]
True label 0
0.8813559322033898  
0.11864406779661017  
True label 1
0.07738095238095238  
0.9226190476190477  

Train_result {'acc': [0.9197174053048199], 'loss': [0.18447232983322118]}
Saved model to disk


11

Epoch 1/1

  64/3114 [..............................] - ETA: 8s - loss: 0.1385 - acc: 0.9375
 128/3114 [>.............................] - ETA: 7s - loss: 0.1008 - acc: 0.9688
 192/3114 [>.............................] - ETA: 7s - loss: 0.1209 - acc: 0.9531
 256/3114 [=>............................] - ETA: 7s - loss: 0.1310 - acc: 0.9492
 320/3114 [==>...........................] - ETA: 7s - loss: 0.1229 - acc: 0.9563
 384/3114 [==>...........................] - ETA: 6s - loss: 0.1136 - acc: 0.9609
 448/3114 [===>..........................] - ETA: 6s - loss: 0.1122 - acc: 0.9621
 512/3114 [===>..........................] - ETA: 6s - loss: 0.1199 - acc: 0.9570
 576/3114 [====>.........................] - ETA: 6s - loss: 0.1286 - acc: 0.9514
 640/3114 [=====>........................] - ETA: 6s - loss: 0.1270 - acc: 0.9516
 704/3114 [=====>........................] - ETA: 5s - loss: 0.1225 - acc: 0.9531
 768/3114 [======>.......................] - ETA: 5s - loss: 0.1335 - acc: 0.9492
 832/3114 [=======>......................] - ETA: 5s - loss: 0.1301 - acc: 0.9483
 896/3114 [=======>......................] - ETA: 5s - loss: 0.1303 - acc: 0.9464
 960/3114 [========>.....................] - ETA: 5s - loss: 0.1314 - acc: 0.9458
1024/3114 [========>.....................] - ETA: 5s - loss: 0.1362 - acc: 0.9434
1088/3114 [=========>....................] - ETA: 4s - loss: 0.1359 - acc: 0.9430
1152/3114 [==========>...................] - ETA: 4s - loss: 0.1345 - acc: 0.9436
1216/3114 [==========>...................] - ETA: 4s - loss: 0.1359 - acc: 0.9433
1280/3114 [===========>..................] - ETA: 4s - loss: 0.1337 - acc: 0.9445
1344/3114 [===========>..................] - ETA: 4s - loss: 0.1373 - acc: 0.9435
1408/3114 [============>.................] - ETA: 4s - loss: 0.1417 - acc: 0.9432
1472/3114 [=============>................] - ETA: 3s - loss: 0.1472 - acc: 0.9423
1536/3114 [=============>................] - ETA: 3s - loss: 0.1466 - acc: 0.9434
1600/3114 [==============>...............] - ETA: 3s - loss: 0.1444 - acc: 0.9444
1664/3114 [===============>..............] - ETA: 3s - loss: 0.1447 - acc: 0.9435
1728/3114 [===============>..............] - ETA: 3s - loss: 0.1453 - acc: 0.9444
1792/3114 [================>.............] - ETA: 3s - loss: 0.1454 - acc: 0.9442
1856/3114 [================>.............] - ETA: 3s - loss: 0.1464 - acc: 0.9440
1920/3114 [=================>............] - ETA: 2s - loss: 0.1458 - acc: 0.9443
1984/3114 [==================>...........] - ETA: 2s - loss: 0.1460 - acc: 0.9446
2048/3114 [==================>...........] - ETA: 2s - loss: 0.1474 - acc: 0.9434
2112/3114 [===================>..........] - ETA: 2s - loss: 0.1475 - acc: 0.9427
2176/3114 [===================>..........] - ETA: 2s - loss: 0.1461 - acc: 0.9426
2240/3114 [====================>.........] - ETA: 2s - loss: 0.1451 - acc: 0.9424
2304/3114 [=====================>........] - ETA: 1s - loss: 0.1467 - acc: 0.9418
2368/3114 [=====================>........] - ETA: 1s - loss: 0.1447 - acc: 0.9426
2432/3114 [======================>.......] - ETA: 1s - loss: 0.1470 - acc: 0.9412
2496/3114 [=======================>......] - ETA: 1s - loss: 0.1482 - acc: 0.9403
2560/3114 [=======================>......] - ETA: 1s - loss: 0.1492 - acc: 0.9391
2624/3114 [========================>.....] - ETA: 1s - loss: 0.1481 - acc: 0.9394
2688/3114 [========================>.....] - ETA: 1s - loss: 0.1480 - acc: 0.9394
2752/3114 [=========================>....] - ETA: 0s - loss: 0.1467 - acc: 0.9400
2816/3114 [==========================>...] - ETA: 0s - loss: 0.1459 - acc: 0.9407
2880/3114 [==========================>...] - ETA: 0s - loss: 0.1458 - acc: 0.9406
2944/3114 [===========================>..] - ETA: 0s - loss: 0.1469 - acc: 0.9402
3008/3114 [===========================>..] - ETA: 0s - loss: 0.1472 - acc: 0.9402
3072/3114 [============================>.] - ETA: 0s - loss: 0.1522 - acc: 0.9382
3114/3114 [==============================] - 8s 2ms/step - loss: 0.1553 - acc: 0.9367

Test accuracy: 88.69565217391305

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  176

choose_one :  169

F1score :  0.884272997032641

AUC :  0.9643866020984664

Confusion Matrix
[[157  20]
 [ 19 149]]
True label 0
0.8870056497175142  
0.11299435028248588  
True label 1
0.1130952380952381  
0.8869047619047619  

Train_result {'acc': [0.93673731508206], 'loss': [0.15530920690960354]}
Saved model to disk


12

Epoch 1/1

  64/3114 [..............................] - ETA: 8s - loss: 0.1045 - acc: 0.9688
 128/3114 [>.............................] - ETA: 7s - loss: 0.1929 - acc: 0.9219
 192/3114 [>.............................] - ETA: 7s - loss: 0.1806 - acc: 0.9271
 256/3114 [=>............................] - ETA: 7s - loss: 0.1731 - acc: 0.9297
 320/3114 [==>...........................] - ETA: 6s - loss: 0.1617 - acc: 0.9313
 384/3114 [==>...........................] - ETA: 6s - loss: 0.1763 - acc: 0.9323
 448/3114 [===>..........................] - ETA: 6s - loss: 0.1763 - acc: 0.9330
 512/3114 [===>..........................] - ETA: 6s - loss: 0.1640 - acc: 0.9395
 576/3114 [====>.........................] - ETA: 6s - loss: 0.1657 - acc: 0.9375
 640/3114 [=====>........................] - ETA: 6s - loss: 0.1609 - acc: 0.9391
 704/3114 [=====>........................] - ETA: 5s - loss: 0.1640 - acc: 0.9375
 768/3114 [======>.......................] - ETA: 5s - loss: 0.1649 - acc: 0.9362
 832/3114 [=======>......................] - ETA: 5s - loss: 0.1609 - acc: 0.9363
 896/3114 [=======>......................] - ETA: 5s - loss: 0.1589 - acc: 0.9353
 960/3114 [========>.....................] - ETA: 5s - loss: 0.1597 - acc: 0.9344
1024/3114 [========>.....................] - ETA: 5s - loss: 0.1578 - acc: 0.9355
1088/3114 [=========>....................] - ETA: 4s - loss: 0.1547 - acc: 0.9357
1152/3114 [==========>...................] - ETA: 4s - loss: 0.1571 - acc: 0.9340
1216/3114 [==========>...................] - ETA: 4s - loss: 0.1574 - acc: 0.9334
1280/3114 [===========>..................] - ETA: 4s - loss: 0.1545 - acc: 0.9352
1344/3114 [===========>..................] - ETA: 4s - loss: 0.1521 - acc: 0.9360
1408/3114 [============>.................] - ETA: 4s - loss: 0.1534 - acc: 0.9361
1472/3114 [=============>................] - ETA: 3s - loss: 0.1527 - acc: 0.9368
1536/3114 [=============>................] - ETA: 3s - loss: 0.1535 - acc: 0.9362
1600/3114 [==============>...............] - ETA: 3s - loss: 0.1531 - acc: 0.9363
1664/3114 [===============>..............] - ETA: 3s - loss: 0.1550 - acc: 0.9345
1728/3114 [===============>..............] - ETA: 3s - loss: 0.1556 - acc: 0.9329
1792/3114 [================>.............] - ETA: 3s - loss: 0.1527 - acc: 0.9342
1856/3114 [================>.............] - ETA: 3s - loss: 0.1523 - acc: 0.9337
1920/3114 [=================>............] - ETA: 2s - loss: 0.1500 - acc: 0.9349
1984/3114 [==================>...........] - ETA: 2s - loss: 0.1500 - acc: 0.9350
2048/3114 [==================>...........] - ETA: 2s - loss: 0.1491 - acc: 0.9351
2112/3114 [===================>..........] - ETA: 2s - loss: 0.1473 - acc: 0.9361
2176/3114 [===================>..........] - ETA: 2s - loss: 0.1514 - acc: 0.9347
2240/3114 [====================>.........] - ETA: 2s - loss: 0.1495 - acc: 0.9353
2304/3114 [=====================>........] - ETA: 1s - loss: 0.1471 - acc: 0.9366
2368/3114 [=====================>........] - ETA: 1s - loss: 0.1458 - acc: 0.9375
2432/3114 [======================>.......] - ETA: 1s - loss: 0.1469 - acc: 0.9371
2496/3114 [=======================>......] - ETA: 1s - loss: 0.1464 - acc: 0.9375
2560/3114 [=======================>......] - ETA: 1s - loss: 0.1470 - acc: 0.9371
2624/3114 [========================>.....] - ETA: 1s - loss: 0.1482 - acc: 0.9375
2688/3114 [========================>.....] - ETA: 1s - loss: 0.1492 - acc: 0.9371
2752/3114 [=========================>....] - ETA: 0s - loss: 0.1501 - acc: 0.9368
2816/3114 [==========================>...] - ETA: 0s - loss: 0.1506 - acc: 0.9361
2880/3114 [==========================>...] - ETA: 0s - loss: 0.1530 - acc: 0.9354
2944/3114 [===========================>..] - ETA: 0s - loss: 0.1540 - acc: 0.9351
3008/3114 [===========================>..] - ETA: 0s - loss: 0.1557 - acc: 0.9342
3072/3114 [============================>.] - ETA: 0s - loss: 0.1553 - acc: 0.9342
3114/3114 [==============================] - 8s 2ms/step - loss: 0.1547 - acc: 0.9345

Test accuracy: 89.56521739130436

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  177

choose_one :  168

F1score :  0.8928571428571429

AUC :  0.9611581920903954

Confusion Matrix
[[159  18]
 [ 18 150]]
True label 0
0.8983050847457628  
0.1016949152542373  
True label 1
0.10714285714285714  
0.8928571428571429  

Train_result {'acc': [0.9344894027357769], 'loss': [0.15470784160864223]}
Saved model to disk


13

Epoch 1/1

  64/3114 [..............................] - ETA: 8s - loss: 0.1075 - acc: 0.9531
 128/3114 [>.............................] - ETA: 8s - loss: 0.1280 - acc: 0.9531
 192/3114 [>.............................] - ETA: 7s - loss: 0.1414 - acc: 0.9427
 256/3114 [=>............................] - ETA: 7s - loss: 0.1346 - acc: 0.9492
 320/3114 [==>...........................] - ETA: 7s - loss: 0.1398 - acc: 0.9437
 384/3114 [==>...........................] - ETA: 6s - loss: 0.1419 - acc: 0.9427
 448/3114 [===>..........................] - ETA: 6s - loss: 0.1358 - acc: 0.9464
 512/3114 [===>..........................] - ETA: 6s - loss: 0.1499 - acc: 0.9414
 576/3114 [====>.........................] - ETA: 6s - loss: 0.1487 - acc: 0.9392
 640/3114 [=====>........................] - ETA: 6s - loss: 0.1420 - acc: 0.9391
 704/3114 [=====>........................] - ETA: 6s - loss: 0.1375 - acc: 0.9418
 768/3114 [======>.......................] - ETA: 5s - loss: 0.1385 - acc: 0.9427
 832/3114 [=======>......................] - ETA: 5s - loss: 0.1432 - acc: 0.9411
 896/3114 [=======>......................] - ETA: 5s - loss: 0.1516 - acc: 0.9375
 960/3114 [========>.....................] - ETA: 5s - loss: 0.1479 - acc: 0.9385
1024/3114 [========>.....................] - ETA: 5s - loss: 0.1414 - acc: 0.9404
1088/3114 [=========>....................] - ETA: 5s - loss: 0.1460 - acc: 0.9403
1152/3114 [==========>...................] - ETA: 4s - loss: 0.1428 - acc: 0.9410
1216/3114 [==========>...................] - ETA: 4s - loss: 0.1419 - acc: 0.9408
1280/3114 [===========>..................] - ETA: 4s - loss: 0.1400 - acc: 0.9414
1344/3114 [===========>..................] - ETA: 4s - loss: 0.1437 - acc: 0.9382
1408/3114 [============>.................] - ETA: 4s - loss: 0.1444 - acc: 0.9375
1472/3114 [=============>................] - ETA: 4s - loss: 0.1417 - acc: 0.9382
1536/3114 [=============>................] - ETA: 3s - loss: 0.1409 - acc: 0.9375
1600/3114 [==============>...............] - ETA: 3s - loss: 0.1370 - acc: 0.9400
1664/3114 [===============>..............] - ETA: 3s - loss: 0.1400 - acc: 0.9393
1728/3114 [===============>..............] - ETA: 3s - loss: 0.1431 - acc: 0.9381
1792/3114 [================>.............] - ETA: 3s - loss: 0.1449 - acc: 0.9369
1856/3114 [================>.............] - ETA: 3s - loss: 0.1453 - acc: 0.9380
1920/3114 [=================>............] - ETA: 2s - loss: 0.1442 - acc: 0.9391
1984/3114 [==================>...........] - ETA: 2s - loss: 0.1455 - acc: 0.9385
2048/3114 [==================>...........] - ETA: 2s - loss: 0.1463 - acc: 0.9385
2112/3114 [===================>..........] - ETA: 2s - loss: 0.1447 - acc: 0.9389
2176/3114 [===================>..........] - ETA: 2s - loss: 0.1449 - acc: 0.9380
2240/3114 [====================>.........] - ETA: 2s - loss: 0.1460 - acc: 0.9366
2304/3114 [=====================>........] - ETA: 1s - loss: 0.1464 - acc: 0.9362
2368/3114 [=====================>........] - ETA: 1s - loss: 0.1479 - acc: 0.9354
2432/3114 [======================>.......] - ETA: 1s - loss: 0.1473 - acc: 0.9354
2496/3114 [=======================>......] - ETA: 1s - loss: 0.1475 - acc: 0.9347
2560/3114 [=======================>......] - ETA: 1s - loss: 0.1455 - acc: 0.9355
2624/3114 [========================>.....] - ETA: 1s - loss: 0.1462 - acc: 0.9356
2688/3114 [========================>.....] - ETA: 1s - loss: 0.1491 - acc: 0.9353
2752/3114 [=========================>....] - ETA: 0s - loss: 0.1475 - acc: 0.9357
2816/3114 [==========================>...] - ETA: 0s - loss: 0.1487 - acc: 0.9354
2880/3114 [==========================>...] - ETA: 0s - loss: 0.1489 - acc: 0.9351
2944/3114 [===========================>..] - ETA: 0s - loss: 0.1476 - acc: 0.9358
3008/3114 [===========================>..] - ETA: 0s - loss: 0.1469 - acc: 0.9362
3072/3114 [============================>.] - ETA: 0s - loss: 0.1455 - acc: 0.9365
3114/3114 [==============================] - 8s 2ms/step - loss: 0.1454 - acc: 0.9364

Test accuracy: 88.98550724637681

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  183

choose_one :  162

F1score :  0.8848484848484849

AUC :  0.9555084745762712

Confusion Matrix
[[161  16]
 [ 22 146]]
True label 0
0.9096045197740112  
0.0903954802259887  
True label 1
0.13095238095238096  
0.8690476190476191  

Train_result {'acc': [0.9364161846265627], 'loss': [0.14540128257692664]}
Saved model to disk


14

Epoch 1/1

  64/3114 [..............................] - ETA: 8s - loss: 0.2264 - acc: 0.8906
 128/3114 [>.............................] - ETA: 7s - loss: 0.1567 - acc: 0.9297
 192/3114 [>.............................] - ETA: 7s - loss: 0.1513 - acc: 0.9323
 256/3114 [=>............................] - ETA: 7s - loss: 0.1547 - acc: 0.9336
 320/3114 [==>...........................] - ETA: 7s - loss: 0.1572 - acc: 0.9344
 384/3114 [==>...........................] - ETA: 6s - loss: 0.1482 - acc: 0.9375
 448/3114 [===>..........................] - ETA: 6s - loss: 0.1379 - acc: 0.9420
 512/3114 [===>..........................] - ETA: 6s - loss: 0.1397 - acc: 0.9375
 576/3114 [====>.........................] - ETA: 6s - loss: 0.1372 - acc: 0.9392
 640/3114 [=====>........................] - ETA: 6s - loss: 0.1370 - acc: 0.9391
 704/3114 [=====>........................] - ETA: 6s - loss: 0.1326 - acc: 0.9418
 768/3114 [======>.......................] - ETA: 5s - loss: 0.1285 - acc: 0.9440
 832/3114 [=======>......................] - ETA: 5s - loss: 0.1247 - acc: 0.9447
 896/3114 [=======>......................] - ETA: 5s - loss: 0.1212 - acc: 0.9475
 960/3114 [========>.....................] - ETA: 5s - loss: 0.1213 - acc: 0.9469
1024/3114 [========>.....................] - ETA: 5s - loss: 0.1201 - acc: 0.9482
1088/3114 [=========>....................] - ETA: 5s - loss: 0.1222 - acc: 0.9476
1152/3114 [==========>...................] - ETA: 4s - loss: 0.1210 - acc: 0.9470
1216/3114 [==========>...................] - ETA: 4s - loss: 0.1189 - acc: 0.9474
1280/3114 [===========>..................] - ETA: 4s - loss: 0.1183 - acc: 0.9477
1344/3114 [===========>..................] - ETA: 4s - loss: 0.1171 - acc: 0.9487
1408/3114 [============>.................] - ETA: 4s - loss: 0.1193 - acc: 0.9474
1472/3114 [=============>................] - ETA: 4s - loss: 0.1171 - acc: 0.9484
1536/3114 [=============>................] - ETA: 3s - loss: 0.1159 - acc: 0.9486
1600/3114 [==============>...............] - ETA: 3s - loss: 0.1168 - acc: 0.9481
1664/3114 [===============>..............] - ETA: 3s - loss: 0.1146 - acc: 0.9495
1728/3114 [===============>..............] - ETA: 3s - loss: 0.1156 - acc: 0.9491
1792/3114 [================>.............] - ETA: 3s - loss: 0.1150 - acc: 0.9503
1856/3114 [================>.............] - ETA: 3s - loss: 0.1137 - acc: 0.9504
1920/3114 [=================>............] - ETA: 2s - loss: 0.1143 - acc: 0.9495
1984/3114 [==================>...........] - ETA: 2s - loss: 0.1145 - acc: 0.9491
2048/3114 [==================>...........] - ETA: 2s - loss: 0.1130 - acc: 0.9497
2112/3114 [===================>..........] - ETA: 2s - loss: 0.1135 - acc: 0.9498
2176/3114 [===================>..........] - ETA: 2s - loss: 0.1131 - acc: 0.9499
2240/3114 [====================>.........] - ETA: 2s - loss: 0.1151 - acc: 0.9491
2304/3114 [=====================>........] - ETA: 1s - loss: 0.1142 - acc: 0.9501
2368/3114 [=====================>........] - ETA: 1s - loss: 0.1130 - acc: 0.9510
2432/3114 [======================>.......] - ETA: 1s - loss: 0.1139 - acc: 0.9502
2496/3114 [=======================>......] - ETA: 1s - loss: 0.1142 - acc: 0.9499
2560/3114 [=======================>......] - ETA: 1s - loss: 0.1141 - acc: 0.9500
2624/3114 [========================>.....] - ETA: 1s - loss: 0.1143 - acc: 0.9497
2688/3114 [========================>.....] - ETA: 1s - loss: 0.1159 - acc: 0.9483
2752/3114 [=========================>....] - ETA: 0s - loss: 0.1155 - acc: 0.9491
2816/3114 [==========================>...] - ETA: 0s - loss: 0.1146 - acc: 0.9499
2880/3114 [==========================>...] - ETA: 0s - loss: 0.1136 - acc: 0.9507
2944/3114 [===========================>..] - ETA: 0s - loss: 0.1138 - acc: 0.9504
3008/3114 [===========================>..] - ETA: 0s - loss: 0.1140 - acc: 0.9505
3072/3114 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9508
3114/3114 [==============================] - 8s 2ms/step - loss: 0.1133 - acc: 0.9512

Test accuracy: 90.72463768115942

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  169

choose_one :  176

F1score :  0.9069767441860465

AUC :  0.9687920365886468

Confusion Matrix
[[157  20]
 [ 12 156]]
True label 0
0.8870056497175142  
0.11299435028248588  
True label 1
0.07142857142857142  
0.9285714285714286  

Train_result {'acc': [0.9511881820192379], 'loss': [0.11334438557875945]}
Saved model to disk


15

Epoch 1/1

  64/3114 [..............................] - ETA: 8s - loss: 0.0874 - acc: 0.9531
 128/3114 [>.............................] - ETA: 7s - loss: 0.1102 - acc: 0.9453
 192/3114 [>.............................] - ETA: 7s - loss: 0.1133 - acc: 0.9531
 256/3114 [=>............................] - ETA: 7s - loss: 0.1085 - acc: 0.9570
 320/3114 [==>...........................] - ETA: 7s - loss: 0.1089 - acc: 0.9563
 384/3114 [==>...........................] - ETA: 7s - loss: 0.1056 - acc: 0.9583
 448/3114 [===>..........................] - ETA: 6s - loss: 0.1050 - acc: 0.9576
 512/3114 [===>..........................] - ETA: 6s - loss: 0.1104 - acc: 0.9570
 576/3114 [====>.........................] - ETA: 6s - loss: 0.1083 - acc: 0.9566
 640/3114 [=====>........................] - ETA: 6s - loss: 0.1020 - acc: 0.9594
 704/3114 [=====>........................] - ETA: 6s - loss: 0.1039 - acc: 0.9588
 768/3114 [======>.......................] - ETA: 5s - loss: 0.0968 - acc: 0.9622
 832/3114 [=======>......................] - ETA: 5s - loss: 0.1059 - acc: 0.9555
 896/3114 [=======>......................] - ETA: 5s - loss: 0.1028 - acc: 0.9576
 960/3114 [========>.....................] - ETA: 5s - loss: 0.1028 - acc: 0.9573
1024/3114 [========>.....................] - ETA: 5s - loss: 0.1072 - acc: 0.9561
1088/3114 [=========>....................] - ETA: 5s - loss: 0.1112 - acc: 0.9559
1152/3114 [==========>...................] - ETA: 4s - loss: 0.1116 - acc: 0.9557
1216/3114 [==========>...................] - ETA: 4s - loss: 0.1143 - acc: 0.9539
1280/3114 [===========>..................] - ETA: 4s - loss: 0.1181 - acc: 0.9508
1344/3114 [===========>..................] - ETA: 4s - loss: 0.1191 - acc: 0.9509
1408/3114 [============>.................] - ETA: 4s - loss: 0.1160 - acc: 0.9524
1472/3114 [=============>................] - ETA: 4s - loss: 0.1176 - acc: 0.9511
1536/3114 [=============>................] - ETA: 3s - loss: 0.1179 - acc: 0.9505
1600/3114 [==============>...............] - ETA: 3s - loss: 0.1164 - acc: 0.9513
1664/3114 [===============>..............] - ETA: 3s - loss: 0.1150 - acc: 0.9531
1728/3114 [===============>..............] - ETA: 3s - loss: 0.1176 - acc: 0.9514
1792/3114 [================>.............] - ETA: 3s - loss: 0.1161 - acc: 0.9520
1856/3114 [================>.............] - ETA: 3s - loss: 0.1147 - acc: 0.9526
1920/3114 [=================>............] - ETA: 2s - loss: 0.1157 - acc: 0.9510
1984/3114 [==================>...........] - ETA: 2s - loss: 0.1143 - acc: 0.9511
2048/3114 [==================>...........] - ETA: 2s - loss: 0.1143 - acc: 0.9517
2112/3114 [===================>..........] - ETA: 2s - loss: 0.1135 - acc: 0.9517
2176/3114 [===================>..........] - ETA: 2s - loss: 0.1126 - acc: 0.9517
2240/3114 [====================>.........] - ETA: 2s - loss: 0.1132 - acc: 0.9522
2304/3114 [=====================>........] - ETA: 1s - loss: 0.1116 - acc: 0.9531
2368/3114 [=====================>........] - ETA: 1s - loss: 0.1106 - acc: 0.9535
2432/3114 [======================>.......] - ETA: 1s - loss: 0.1116 - acc: 0.9531
2496/3114 [=======================>......] - ETA: 1s - loss: 0.1121 - acc: 0.9515
2560/3114 [=======================>......] - ETA: 1s - loss: 0.1116 - acc: 0.9516
2624/3114 [========================>.....] - ETA: 1s - loss: 0.1125 - acc: 0.9512
2688/3114 [========================>.....] - ETA: 1s - loss: 0.1138 - acc: 0.9516
2752/3114 [=========================>....] - ETA: 0s - loss: 0.1155 - acc: 0.9513
2816/3114 [==========================>...] - ETA: 0s - loss: 0.1185 - acc: 0.9510
2880/3114 [==========================>...] - ETA: 0s - loss: 0.1193 - acc: 0.9510
2944/3114 [===========================>..] - ETA: 0s - loss: 0.1216 - acc: 0.9501
3008/3114 [===========================>..] - ETA: 0s - loss: 0.1208 - acc: 0.9508
3072/3114 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9512
3114/3114 [==============================] - 8s 2ms/step - loss: 0.1202 - acc: 0.9512

Test accuracy: 89.56521739130436

data size :  3459

zero :  1744

one :  1715

train_zero :  1567

train_one :  1547

test_zero :  177

test_one :  168

choose_zero :  175

choose_one :  170

F1score :  0.893491124260355

AUC :  0.963276836158192

Confusion Matrix
[[158  19]
 [ 17 151]]
True label 0
0.8926553672316384  
0.10734463276836158  
True label 1
0.10119047619047619  
0.8988095238095238  

Train_result {'acc': [0.951188182440337], 'loss': [0.12021912958810325]}
Saved model to disk


[[87.53623188405797, 1], [85.79710144927536, 2], [86.08695652173914, 3], [87.2463768115942, 4], [89.27536231884058, 5], [89.27536231884058, 6], [89.56521739130436, 7], [90.43478260869566, 8], [87.82608695652175, 9], [90.14492753623189, 10], [88.69565217391305, 11], [89.56521739130436, 12], [88.98550724637681, 13], [90.72463768115942, 14], [89.56521739130436, 15]]
max accuracy :  [90.72463768115942, 14]
