Using TensorFlow backend.
Standard data
zero :  7657
one :  7650

First data
zero :  7657
one :  7650

Second data
zero :  7657
one :  7650

Third data
zero :  7657
one :  7650

4th data
zero :  7657
one :  7650

hbase-code
After set document size of train data, the number of zero and one label data :  6855 6922
After set document size of test data, the number of zero and one label data :  802 727

Sentence length Average : 82

Under 10 : 845
Over 10, Under 30 : 2491
Over 30, Under 100 : 7204
Over 100, Under 150 : 2501
Over 150, Under 200 : 1246
Over 200, Under 400 : 1019
Over 400 : 0

After balance out data.
hbase-code

Sentence length Average : 82

Under 10 : 845
Over 10, Under 30 : 2491
Over 30, Under 100 : 7204
Over 100, Under 150 : 2501
Over 150, Under 200 : 1246
Over 200, Under 400 : 1019
Over 400 : 0

300
hbase-AST
After set document size of train data, the number of zero and one label data :  6855 6922
After set document size of test data, the number of zero and one label data :  802 727
After balance out data.
hbase-AST

Sentence length Average : 60

Under 10 : 2072
Over 10, Under 30 : 3356
Over 30, Under 100 : 6944
Over 100, Under 150 : 1747
Over 150, Under 200 : 790
Over 200, Under 400 : 394
Over 400 : 3

704
hbase-CAST
After set document size of train data, the number of zero and one label data :  6855 6922
After set document size of test data, the number of zero and one label data :  802 727
After balance out data.
hbase-CAST

Sentence length Average : 143

Under 10 : 804
Over 10, Under 30 : 1553
Over 30, Under 100 : 4657
Over 100, Under 150 : 2509
Over 150, Under 200 : 1823
Over 200, Under 400 : 3205
Over 400 : 755

1434
hbase-depth_num
After set document size of train data, the number of zero and one label data :  6855 6922
After set document size of test data, the number of zero and one label data :  802 727
After balance out data.
hbase-depth_num

Sentence length Average : 60

Under 10 : 2072
Over 10, Under 30 : 3356
Over 30, Under 100 : 6944
Over 100, Under 150 : 1747
Over 150, Under 200 : 790
Over 200, Under 400 : 394
Over 400 : 3

704
Traceback (most recent call last):
  File "sentence_merge_network_input4_new.py", line 372, in <module>
    X_train4, Y_train4 = pr.create_deep_learning_input_data(train_data4, train_logging4, max_sentence_len4, embed_size_word2vec, vocabulary, wordvec_model)
  File "/home/2014313303/taeha/JavaAutoLogging/preprocessing_data.py", line 292, in create_deep_learning_input_data
    X = np.empty(shape=[len(data), max_sentence_len, embed_size_word2vec], dtype='float32')
MemoryError
