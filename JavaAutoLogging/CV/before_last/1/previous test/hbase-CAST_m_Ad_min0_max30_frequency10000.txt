Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
/home/2014313303/taeha/JavaAutoLogging/model.py:53: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor("ou..., inputs=[<tf.Tenso...)`
  model = Model(input=[input1, input2], output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-08 04:06:02.259375: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-08 04:06:02.269530: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100085000 Hz
2019-09-08 04:06:02.272319: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0xc14ca50 executing computations on platform Host. Devices:
2019-09-08 04:06:02.272358: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Standard data
zero :  39451
one :  9019

First data
zero :  39451
one :  9019

Second data
zero :  39451
one :  9019

hbase-AST
After set document size of train data, the number of zero and one label data :  27718 2356
After set document size of test data, the number of zero and one label data :  3087 253

Sentence length Average : 9

Under 10 : 21693
Over 10, Under 30 : 11721
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

After balance out data.
hbase-AST

Sentence length Average : 11

Under 10 : 2794
Over 10, Under 30 : 2426
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

hbase-depth_num
After set document size of train data, the number of zero and one label data :  27718 2356
After set document size of test data, the number of zero and one label data :  3087 253
After balance out data.
hbase-depth_num

Sentence length Average : 11

Under 10 : 2794
Over 10, Under 30 : 2426
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

Count model parameter.
Get a short summary of each layer dimensions and parameters.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 30, 200)      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 30, 200)      0                                            
__________________________________________________________________________________________________
masking_1 (Masking)             (None, 30, 200)      0           input_1[0][0]                    
__________________________________________________________________________________________________
masking_2 (Masking)             (None, 30, 200)      0           input_2[0][0]                    
__________________________________________________________________________________________________
forwards_1 (LSTM)               (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
backwords_1 (LSTM)              (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
forwards_2 (LSTM)               (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
backwards_2 (LSTM)              (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
after_dp_forward_1 (Dropout)    (None, 64)           0           forwards_1[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_1 (Dropout)   (None, 64)           0           backwords_1[0][0]                
__________________________________________________________________________________________________
after_dp_forward_2 (Dropout)    (None, 64)           0           forwards_2[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_2 (Dropout)   (None, 64)           0           backwards_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128)          0           after_dp_forward_1[0][0]         
                                                                 after_dp_backward_1[0][0]        
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 128)          0           after_dp_forward_2[0][0]         
                                                                 after_dp_backward_2[0][0]        
__________________________________________________________________________________________________
after_dp_1 (Dropout)            (None, 128)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
after_dp_2 (Dropout)            (None, 128)          0           concatenate_2[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 256)          0           after_dp_1[0][0]                 
                                                                 after_dp_2[0][0]                 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 256)          65792       concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 128)          32896       dense_1[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 64)           8256        dense_2[0][0]                    
__________________________________________________________________________________________________
output (Dense)                  (None, 2)            130         dense_3[0][0]                    
==================================================================================================
Total params: 378,434
Trainable params: 378,434
Non-trainable params: 0
__________________________________________________________________________________________________
1

Epoch 1/1

  64/4713 [..............................] - ETA: 3:42 - loss: 0.6871 - acc: 0.5312
 128/4713 [..............................] - ETA: 1:51 - loss: 0.6882 - acc: 0.5391
 192/4713 [>.............................] - ETA: 1:14 - loss: 0.6937 - acc: 0.5260
 320/4713 [=>............................] - ETA: 44s - loss: 0.6837 - acc: 0.5594 
 448/4713 [=>............................] - ETA: 31s - loss: 0.6785 - acc: 0.5692
 576/4713 [==>...........................] - ETA: 24s - loss: 0.6678 - acc: 0.6024
 704/4713 [===>..........................] - ETA: 20s - loss: 0.6554 - acc: 0.6278
 832/4713 [====>.........................] - ETA: 17s - loss: 0.6408 - acc: 0.6550
 960/4713 [=====>........................] - ETA: 14s - loss: 0.6356 - acc: 0.6562
1088/4713 [=====>........................] - ETA: 12s - loss: 0.6224 - acc: 0.6673
1216/4713 [======>.......................] - ETA: 11s - loss: 0.6208 - acc: 0.6694
1344/4713 [=======>......................] - ETA: 10s - loss: 0.6065 - acc: 0.6801
1472/4713 [========>.....................] - ETA: 9s - loss: 0.6060 - acc: 0.6821 
1600/4713 [=========>....................] - ETA: 8s - loss: 0.5964 - acc: 0.6913
1728/4713 [=========>....................] - ETA: 7s - loss: 0.5890 - acc: 0.6973
1856/4713 [==========>...................] - ETA: 6s - loss: 0.5826 - acc: 0.7026
1984/4713 [===========>..................] - ETA: 6s - loss: 0.5717 - acc: 0.7082
2112/4713 [============>.................] - ETA: 5s - loss: 0.5620 - acc: 0.7150
2240/4713 [=============>................] - ETA: 5s - loss: 0.5535 - acc: 0.7183
2368/4713 [==============>...............] - ETA: 4s - loss: 0.5433 - acc: 0.7259
2496/4713 [==============>...............] - ETA: 4s - loss: 0.5365 - acc: 0.7304
2624/4713 [===============>..............] - ETA: 3s - loss: 0.5335 - acc: 0.7317
2752/4713 [================>.............] - ETA: 3s - loss: 0.5272 - acc: 0.7355
2880/4713 [=================>............] - ETA: 3s - loss: 0.5225 - acc: 0.7406
3008/4713 [==================>...........] - ETA: 2s - loss: 0.5191 - acc: 0.7420
3136/4713 [==================>...........] - ETA: 2s - loss: 0.5176 - acc: 0.7439
3264/4713 [===================>..........] - ETA: 2s - loss: 0.5214 - acc: 0.7451
3392/4713 [====================>.........] - ETA: 2s - loss: 0.5248 - acc: 0.7441
3520/4713 [=====================>........] - ETA: 1s - loss: 0.5220 - acc: 0.7460
3648/4713 [======================>.......] - ETA: 1s - loss: 0.5204 - acc: 0.7467
3776/4713 [=======================>......] - ETA: 1s - loss: 0.5169 - acc: 0.7497
3904/4713 [=======================>......] - ETA: 1s - loss: 0.5136 - acc: 0.7520
4032/4713 [========================>.....] - ETA: 0s - loss: 0.5110 - acc: 0.7547
4160/4713 [=========================>....] - ETA: 0s - loss: 0.5063 - acc: 0.7575
4288/4713 [==========================>...] - ETA: 0s - loss: 0.5030 - acc: 0.7591
4416/4713 [===========================>..] - ETA: 0s - loss: 0.4994 - acc: 0.7611
4544/4713 [===========================>..] - ETA: 0s - loss: 0.4972 - acc: 0.7628
4672/4713 [============================>.] - ETA: 0s - loss: 0.4922 - acc: 0.7661
4713/4713 [==============================] - 6s 1ms/step - loss: 0.4924 - acc: 0.7662

Test accuracy: 84.41814595660749

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  229

choose_one :  278

F1score :  0.8512241054613936

AUC :  0.918536615729358

Confusion Matrix
[[202  52]
 [ 27 226]]
True label 0
0.7952755905511811  
0.2047244094488189  
True label 1
0.1067193675889328  
0.8932806324110671  

Train_result {'acc': [0.7661786545317011], 'loss': [0.49240208633280397]}
Saved model to disk


2

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.3748 - acc: 0.8281
 128/4713 [..............................] - ETA: 4s - loss: 0.4460 - acc: 0.7969
 256/4713 [>.............................] - ETA: 3s - loss: 0.4076 - acc: 0.8125
 384/4713 [=>............................] - ETA: 3s - loss: 0.3810 - acc: 0.8203
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3676 - acc: 0.8281
 640/4713 [===>..........................] - ETA: 3s - loss: 0.3887 - acc: 0.8156
 768/4713 [===>..........................] - ETA: 3s - loss: 0.3789 - acc: 0.8229
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3857 - acc: 0.8192
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3879 - acc: 0.8164
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3937 - acc: 0.8177
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3906 - acc: 0.8203
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3926 - acc: 0.8196
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3957 - acc: 0.8203
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3926 - acc: 0.8221
1792/4713 [==========>...................] - ETA: 2s - loss: 0.3944 - acc: 0.8220
1920/4713 [===========>..................] - ETA: 2s - loss: 0.3971 - acc: 0.8224
2048/4713 [============>.................] - ETA: 1s - loss: 0.3953 - acc: 0.8223
2176/4713 [============>.................] - ETA: 1s - loss: 0.3927 - acc: 0.8244
2304/4713 [=============>................] - ETA: 1s - loss: 0.3929 - acc: 0.8229
2432/4713 [==============>...............] - ETA: 1s - loss: 0.3942 - acc: 0.8203
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3921 - acc: 0.8215
2688/4713 [================>.............] - ETA: 1s - loss: 0.3955 - acc: 0.8185
2816/4713 [================>.............] - ETA: 1s - loss: 0.3908 - acc: 0.8235
2944/4713 [=================>............] - ETA: 1s - loss: 0.3881 - acc: 0.8257
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3888 - acc: 0.8245
3200/4713 [===================>..........] - ETA: 1s - loss: 0.3857 - acc: 0.8272
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3839 - acc: 0.8287
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3858 - acc: 0.8264
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3847 - acc: 0.8262
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3834 - acc: 0.8276
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3802 - acc: 0.8299
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3785 - acc: 0.8311
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3807 - acc: 0.8289
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3800 - acc: 0.8305
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3786 - acc: 0.8300
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3804 - acc: 0.8292
4608/4713 [============================>.] - ETA: 0s - loss: 0.3820 - acc: 0.8292
4713/4713 [==============================] - 3s 697us/step - loss: 0.3815 - acc: 0.8283

Test accuracy: 86.58777120315581

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  248

choose_one :  259

F1score :  0.8671875

AUC :  0.9260994055584949

Confusion Matrix
[[217  37]
 [ 31 222]]
True label 0
0.8543307086614174  
0.14566929133858267  
True label 1
0.1225296442687747  
0.8774703557312253  

Train_result {'acc': [0.8283471249228902], 'loss': [0.3814883412081498]}
Saved model to disk


3

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.3367 - acc: 0.8281
 128/4713 [..............................] - ETA: 3s - loss: 0.3055 - acc: 0.8516
 256/4713 [>.............................] - ETA: 3s - loss: 0.3756 - acc: 0.8164
 384/4713 [=>............................] - ETA: 3s - loss: 0.3655 - acc: 0.8255
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3668 - acc: 0.8281
 640/4713 [===>..........................] - ETA: 3s - loss: 0.3716 - acc: 0.8203
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3744 - acc: 0.8203
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3778 - acc: 0.8214
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3701 - acc: 0.8262
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3588 - acc: 0.8307
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3549 - acc: 0.8320
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3517 - acc: 0.8310
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3615 - acc: 0.8294
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3581 - acc: 0.8329
1792/4713 [==========>...................] - ETA: 2s - loss: 0.3567 - acc: 0.8359
1920/4713 [===========>..................] - ETA: 2s - loss: 0.3621 - acc: 0.8328
2048/4713 [============>.................] - ETA: 1s - loss: 0.3571 - acc: 0.8340
2176/4713 [============>.................] - ETA: 1s - loss: 0.3558 - acc: 0.8341
2304/4713 [=============>................] - ETA: 1s - loss: 0.3550 - acc: 0.8351
2432/4713 [==============>...............] - ETA: 1s - loss: 0.3619 - acc: 0.8347
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3588 - acc: 0.8371
2688/4713 [================>.............] - ETA: 1s - loss: 0.3585 - acc: 0.8378
2816/4713 [================>.............] - ETA: 1s - loss: 0.3551 - acc: 0.8391
2944/4713 [=================>............] - ETA: 1s - loss: 0.3528 - acc: 0.8421
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3539 - acc: 0.8421
3200/4713 [===================>..........] - ETA: 1s - loss: 0.3556 - acc: 0.8416
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3517 - acc: 0.8438
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3544 - acc: 0.8426
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3541 - acc: 0.8432
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3545 - acc: 0.8427
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3544 - acc: 0.8419
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3547 - acc: 0.8420
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3560 - acc: 0.8408
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3558 - acc: 0.8404
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3557 - acc: 0.8408
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3564 - acc: 0.8400
4608/4713 [============================>.] - ETA: 0s - loss: 0.3534 - acc: 0.8420
4713/4713 [==============================] - 3s 676us/step - loss: 0.3517 - acc: 0.8434

Test accuracy: 84.81262327416174

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  281

choose_one :  226

F1score :  0.8392484342379959

AUC :  0.9373813451184214

Confusion Matrix
[[229  25]
 [ 52 201]]
True label 0
0.9015748031496063  
0.0984251968503937  
True label 1
0.20553359683794467  
0.7944664031620553  

Train_result {'acc': [0.8434118396811442], 'loss': [0.35169324421108644]}
Saved model to disk


4

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.3028 - acc: 0.8906
 128/4713 [..............................] - ETA: 4s - loss: 0.2913 - acc: 0.8984
 256/4713 [>.............................] - ETA: 3s - loss: 0.3191 - acc: 0.8789
 384/4713 [=>............................] - ETA: 3s - loss: 0.3348 - acc: 0.8646
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3280 - acc: 0.8672
 640/4713 [===>..........................] - ETA: 3s - loss: 0.3284 - acc: 0.8594
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3458 - acc: 0.8542
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3463 - acc: 0.8538
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3403 - acc: 0.8564
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3465 - acc: 0.8533
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3563 - acc: 0.8484
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3580 - acc: 0.8466
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3610 - acc: 0.8431
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3570 - acc: 0.8450
1792/4713 [==========>...................] - ETA: 2s - loss: 0.3550 - acc: 0.8471
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3538 - acc: 0.8479
2048/4713 [============>.................] - ETA: 1s - loss: 0.3502 - acc: 0.8486
2176/4713 [============>.................] - ETA: 1s - loss: 0.3476 - acc: 0.8493
2240/4713 [=============>................] - ETA: 1s - loss: 0.3525 - acc: 0.8464
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3556 - acc: 0.8442
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3511 - acc: 0.8466
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3476 - acc: 0.8479
2752/4713 [================>.............] - ETA: 1s - loss: 0.3478 - acc: 0.8477
2880/4713 [=================>............] - ETA: 1s - loss: 0.3482 - acc: 0.8465
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3457 - acc: 0.8477
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3491 - acc: 0.8447
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3494 - acc: 0.8447
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3486 - acc: 0.8455
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3448 - acc: 0.8463
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3432 - acc: 0.8481
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3426 - acc: 0.8475
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3428 - acc: 0.8469
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3439 - acc: 0.8468
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3426 - acc: 0.8472
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3408 - acc: 0.8482
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3424 - acc: 0.8479
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3439 - acc: 0.8467
4608/4713 [============================>.] - ETA: 0s - loss: 0.3416 - acc: 0.8483
4713/4713 [==============================] - 3s 673us/step - loss: 0.3399 - acc: 0.8485

Test accuracy: 85.20710059171599

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  247

choose_one :  260

F1score :  0.8538011695906433

AUC :  0.9315302978432043

Confusion Matrix
[[213  41]
 [ 34 219]]
True label 0
0.8385826771653543  
0.16141732283464566  
True label 1
0.13438735177865613  
0.8656126482213439  

Train_result {'acc': [0.8485041372643999], 'loss': [0.33991495230105334]}
Saved model to disk


5

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.3462 - acc: 0.8750
 192/4713 [>.............................] - ETA: 3s - loss: 0.2773 - acc: 0.8906
 320/4713 [=>............................] - ETA: 3s - loss: 0.3006 - acc: 0.8781
 448/4713 [=>............................] - ETA: 3s - loss: 0.3161 - acc: 0.8705
 576/4713 [==>...........................] - ETA: 3s - loss: 0.3214 - acc: 0.8663
 704/4713 [===>..........................] - ETA: 2s - loss: 0.3407 - acc: 0.8551
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3564 - acc: 0.8462
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3394 - acc: 0.8542
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3303 - acc: 0.8566
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3263 - acc: 0.8569
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3228 - acc: 0.8586
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3219 - acc: 0.8594
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3318 - acc: 0.8538
1728/4713 [=========>....................] - ETA: 2s - loss: 0.3280 - acc: 0.8559
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3273 - acc: 0.8572
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3301 - acc: 0.8558
2112/4713 [============>.................] - ETA: 1s - loss: 0.3259 - acc: 0.8570
2240/4713 [=============>................] - ETA: 1s - loss: 0.3229 - acc: 0.8580
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3254 - acc: 0.8556
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3254 - acc: 0.8542
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3233 - acc: 0.8544
2752/4713 [================>.............] - ETA: 1s - loss: 0.3249 - acc: 0.8532
2880/4713 [=================>............] - ETA: 1s - loss: 0.3316 - acc: 0.8510
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3292 - acc: 0.8524
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3265 - acc: 0.8524
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3259 - acc: 0.8523
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3236 - acc: 0.8538
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3228 - acc: 0.8551
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3193 - acc: 0.8566
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3225 - acc: 0.8562
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3247 - acc: 0.8550
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3236 - acc: 0.8569
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3252 - acc: 0.8565
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3297 - acc: 0.8547
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3297 - acc: 0.8558
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3291 - acc: 0.8559
4672/4713 [============================>.] - ETA: 0s - loss: 0.3294 - acc: 0.8551
4713/4713 [==============================] - 3s 652us/step - loss: 0.3303 - acc: 0.8542

Test accuracy: 86.19329388560158

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  222

choose_one :  285

F1score :  0.8698884758364314

AUC :  0.935140518502381

Confusion Matrix
[[203  51]
 [ 19 234]]
True label 0
0.7992125984251969  
0.20078740157480315  
True label 1
0.07509881422924901  
0.924901185770751  

Train_result {'acc': [0.8542329725783113], 'loss': [0.3303468708536212]}
Saved model to disk


6

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2137 - acc: 0.9375
 192/4713 [>.............................] - ETA: 3s - loss: 0.2466 - acc: 0.9219
 320/4713 [=>............................] - ETA: 3s - loss: 0.2861 - acc: 0.8906
 448/4713 [=>............................] - ETA: 3s - loss: 0.3011 - acc: 0.8817
 576/4713 [==>...........................] - ETA: 3s - loss: 0.2925 - acc: 0.8819
 704/4713 [===>..........................] - ETA: 2s - loss: 0.3054 - acc: 0.8736
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3104 - acc: 0.8672
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3009 - acc: 0.8705
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3259 - acc: 0.8574
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3252 - acc: 0.8568
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3203 - acc: 0.8625
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3175 - acc: 0.8601
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3200 - acc: 0.8568
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3143 - acc: 0.8582
1792/4713 [==========>...................] - ETA: 2s - loss: 0.3151 - acc: 0.8560
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3139 - acc: 0.8573
2048/4713 [============>.................] - ETA: 1s - loss: 0.3143 - acc: 0.8560
2176/4713 [============>.................] - ETA: 1s - loss: 0.3167 - acc: 0.8566
2304/4713 [=============>................] - ETA: 1s - loss: 0.3164 - acc: 0.8585
2432/4713 [==============>...............] - ETA: 1s - loss: 0.3158 - acc: 0.8586
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3173 - acc: 0.8574
2688/4713 [================>.............] - ETA: 1s - loss: 0.3193 - acc: 0.8564
2816/4713 [================>.............] - ETA: 1s - loss: 0.3190 - acc: 0.8580
2944/4713 [=================>............] - ETA: 1s - loss: 0.3190 - acc: 0.8584
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3189 - acc: 0.8584
3200/4713 [===================>..........] - ETA: 1s - loss: 0.3210 - acc: 0.8581
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3209 - acc: 0.8582
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3223 - acc: 0.8576
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3196 - acc: 0.8605
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3180 - acc: 0.8610
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3180 - acc: 0.8615
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3176 - acc: 0.8627
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3193 - acc: 0.8625
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3173 - acc: 0.8636
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3170 - acc: 0.8636
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3198 - acc: 0.8612
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3194 - acc: 0.8614
4672/4713 [============================>.] - ETA: 0s - loss: 0.3189 - acc: 0.8613
4713/4713 [==============================] - 3s 661us/step - loss: 0.3208 - acc: 0.8604

Test accuracy: 86.3905325443787

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  261

choose_one :  246

F1score :  0.8617234468937877

AUC :  0.9367588932806324

Confusion Matrix
[[223  31]
 [ 38 215]]
True label 0
0.8779527559055118  
0.1220472440944882  
True label 1
0.15019762845849802  
0.849802371541502  

Train_result {'acc': [0.8603861658734524], 'loss': [0.32079024988199123]}
Saved model to disk


7

Epoch 1/1

  64/4713 [..............................] - ETA: 5s - loss: 0.2065 - acc: 0.8906
 128/4713 [..............................] - ETA: 4s - loss: 0.2530 - acc: 0.8672
 256/4713 [>.............................] - ETA: 3s - loss: 0.2891 - acc: 0.8672
 384/4713 [=>............................] - ETA: 3s - loss: 0.3174 - acc: 0.8490
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3148 - acc: 0.8574
 640/4713 [===>..........................] - ETA: 3s - loss: 0.3151 - acc: 0.8641
 768/4713 [===>..........................] - ETA: 3s - loss: 0.3112 - acc: 0.8672
 832/4713 [====>.........................] - ETA: 3s - loss: 0.3098 - acc: 0.8690
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3046 - acc: 0.8698
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2985 - acc: 0.8722
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2978 - acc: 0.8725
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2924 - acc: 0.8728
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2956 - acc: 0.8736
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2969 - acc: 0.8719
1728/4713 [=========>....................] - ETA: 2s - loss: 0.3092 - acc: 0.8663
1856/4713 [==========>...................] - ETA: 2s - loss: 0.3157 - acc: 0.8637
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3145 - acc: 0.8649
2112/4713 [============>.................] - ETA: 1s - loss: 0.3121 - acc: 0.8646
2240/4713 [=============>................] - ETA: 1s - loss: 0.3115 - acc: 0.8643
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3122 - acc: 0.8619
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3152 - acc: 0.8598
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3159 - acc: 0.8594
2752/4713 [================>.............] - ETA: 1s - loss: 0.3138 - acc: 0.8608
2880/4713 [=================>............] - ETA: 1s - loss: 0.3174 - acc: 0.8587
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3184 - acc: 0.8587
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3187 - acc: 0.8584
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3189 - acc: 0.8581
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3203 - acc: 0.8576
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3216 - acc: 0.8574
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3212 - acc: 0.8566
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3201 - acc: 0.8570
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3194 - acc: 0.8576
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3199 - acc: 0.8566
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3209 - acc: 0.8562
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3197 - acc: 0.8573
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3193 - acc: 0.8573
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3202 - acc: 0.8574
4672/4713 [============================>.] - ETA: 0s - loss: 0.3215 - acc: 0.8574
4713/4713 [==============================] - 3s 666us/step - loss: 0.3231 - acc: 0.8564

Test accuracy: 86.58777120315581

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  214

choose_one :  293

F1score :  0.8754578754578755

AUC :  0.9363387382901247

Confusion Matrix
[[200  54]
 [ 14 239]]
True label 0
0.7874015748031497  
0.2125984251968504  
True label 1
0.05533596837944664  
0.9446640316205533  

Train_result {'acc': [0.8563547635720891], 'loss': [0.32314514960803575]}
Saved model to disk


8

Epoch 1/1

  64/4713 [..............................] - ETA: 3s - loss: 0.2621 - acc: 0.8594
 128/4713 [..............................] - ETA: 3s - loss: 0.3047 - acc: 0.8438
 256/4713 [>.............................] - ETA: 3s - loss: 0.3223 - acc: 0.8438
 384/4713 [=>............................] - ETA: 3s - loss: 0.2983 - acc: 0.8594
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3170 - acc: 0.8574
 640/4713 [===>..........................] - ETA: 2s - loss: 0.3221 - acc: 0.8578
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3406 - acc: 0.8451
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3461 - acc: 0.8426
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3460 - acc: 0.8418
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3405 - acc: 0.8438
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3408 - acc: 0.8438
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3364 - acc: 0.8423
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3375 - acc: 0.8431
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3265 - acc: 0.8488
1728/4713 [=========>....................] - ETA: 2s - loss: 0.3296 - acc: 0.8507
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3259 - acc: 0.8529
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3213 - acc: 0.8553
2112/4713 [============>.................] - ETA: 1s - loss: 0.3216 - acc: 0.8570
2240/4713 [=============>................] - ETA: 1s - loss: 0.3216 - acc: 0.8589
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3216 - acc: 0.8602
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3211 - acc: 0.8610
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3195 - acc: 0.8605
2752/4713 [================>.............] - ETA: 1s - loss: 0.3204 - acc: 0.8605
2880/4713 [=================>............] - ETA: 1s - loss: 0.3179 - acc: 0.8615
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3207 - acc: 0.8600
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3232 - acc: 0.8587
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3228 - acc: 0.8588
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3205 - acc: 0.8603
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3210 - acc: 0.8597
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3219 - acc: 0.8586
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3197 - acc: 0.8591
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3185 - acc: 0.8594
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3182 - acc: 0.8591
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3180 - acc: 0.8596
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3176 - acc: 0.8594
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3181 - acc: 0.8582
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3169 - acc: 0.8589
4672/4713 [============================>.] - ETA: 0s - loss: 0.3156 - acc: 0.8592
4713/4713 [==============================] - 3s 663us/step - loss: 0.3188 - acc: 0.8589

Test accuracy: 87.17948717948718

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  241

choose_one :  266

F1score :  0.8747591522157996

AUC :  0.9406492172668139

Confusion Matrix
[[215  39]
 [ 26 227]]
True label 0
0.8464566929133859  
0.15354330708661418  
True label 1
0.10276679841897234  
0.8972332015810277  

Train_result {'acc': [0.8589009122309249], 'loss': [0.3187570633489616]}
Saved model to disk


9

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2747 - acc: 0.8594
 128/4713 [..............................] - ETA: 4s - loss: 0.2980 - acc: 0.8672
 256/4713 [>.............................] - ETA: 3s - loss: 0.2638 - acc: 0.8828
 384/4713 [=>............................] - ETA: 3s - loss: 0.2696 - acc: 0.8750
 512/4713 [==>...........................] - ETA: 3s - loss: 0.2790 - acc: 0.8730
 640/4713 [===>..........................] - ETA: 2s - loss: 0.2801 - acc: 0.8750
 768/4713 [===>..........................] - ETA: 2s - loss: 0.2994 - acc: 0.8659
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3149 - acc: 0.8594
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3131 - acc: 0.8633
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3206 - acc: 0.8637
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3235 - acc: 0.8609
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3197 - acc: 0.8594
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3175 - acc: 0.8607
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3130 - acc: 0.8666
1792/4713 [==========>...................] - ETA: 1s - loss: 0.3089 - acc: 0.8689
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3104 - acc: 0.8698
2048/4713 [============>.................] - ETA: 1s - loss: 0.3199 - acc: 0.8647
2176/4713 [============>.................] - ETA: 1s - loss: 0.3156 - acc: 0.8663
2304/4713 [=============>................] - ETA: 1s - loss: 0.3197 - acc: 0.8659
2432/4713 [==============>...............] - ETA: 1s - loss: 0.3185 - acc: 0.8664
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3199 - acc: 0.8656
2688/4713 [================>.............] - ETA: 1s - loss: 0.3178 - acc: 0.8668
2816/4713 [================>.............] - ETA: 1s - loss: 0.3169 - acc: 0.8672
2944/4713 [=================>............] - ETA: 1s - loss: 0.3150 - acc: 0.8689
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3147 - acc: 0.8691
3200/4713 [===================>..........] - ETA: 0s - loss: 0.3159 - acc: 0.8694
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3155 - acc: 0.8687
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3185 - acc: 0.8678
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3159 - acc: 0.8680
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3133 - acc: 0.8702
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3130 - acc: 0.8708
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3141 - acc: 0.8710
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3133 - acc: 0.8708
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3137 - acc: 0.8705
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3143 - acc: 0.8704
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3126 - acc: 0.8712
4608/4713 [============================>.] - ETA: 0s - loss: 0.3129 - acc: 0.8704
4713/4713 [==============================] - 3s 647us/step - loss: 0.3130 - acc: 0.8699

Test accuracy: 87.57396449704143

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  227

choose_one :  280

F1score :  0.8818011257035647

AUC :  0.9406180946749245

Confusion Matrix
[[209  45]
 [ 18 235]]
True label 0
0.8228346456692913  
0.17716535433070865  
True label 1
0.07114624505928854  
0.9288537549407114  

Train_result {'acc': [0.8699342243463503], 'loss': [0.3129862148860901]}
Saved model to disk


10

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2662 - acc: 0.8906
 192/4713 [>.............................] - ETA: 3s - loss: 0.2575 - acc: 0.8854
 320/4713 [=>............................] - ETA: 3s - loss: 0.2879 - acc: 0.8656
 448/4713 [=>............................] - ETA: 3s - loss: 0.2812 - acc: 0.8772
 576/4713 [==>...........................] - ETA: 3s - loss: 0.3175 - acc: 0.8611
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2958 - acc: 0.8750
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2979 - acc: 0.8762
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3119 - acc: 0.8667
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3113 - acc: 0.8658
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3152 - acc: 0.8646
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3116 - acc: 0.8648
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3058 - acc: 0.8693
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3030 - acc: 0.8704
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3020 - acc: 0.8696
1792/4713 [==========>...................] - ETA: 2s - loss: 0.2989 - acc: 0.8700
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3009 - acc: 0.8693
2048/4713 [============>.................] - ETA: 1s - loss: 0.3016 - acc: 0.8687
2176/4713 [============>.................] - ETA: 1s - loss: 0.3014 - acc: 0.8676
2304/4713 [=============>................] - ETA: 1s - loss: 0.2968 - acc: 0.8698
2432/4713 [==============>...............] - ETA: 1s - loss: 0.2956 - acc: 0.8705
2560/4713 [===============>..............] - ETA: 1s - loss: 0.2933 - acc: 0.8715
2688/4713 [================>.............] - ETA: 1s - loss: 0.2934 - acc: 0.8717
2816/4713 [================>.............] - ETA: 1s - loss: 0.2934 - acc: 0.8704
2944/4713 [=================>............] - ETA: 1s - loss: 0.3004 - acc: 0.8689
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3001 - acc: 0.8691
3200/4713 [===================>..........] - ETA: 1s - loss: 0.2987 - acc: 0.8703
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3008 - acc: 0.8687
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3016 - acc: 0.8689
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3006 - acc: 0.8697
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3026 - acc: 0.8691
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3046 - acc: 0.8688
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3063 - acc: 0.8677
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3064 - acc: 0.8674
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3040 - acc: 0.8686
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3018 - acc: 0.8695
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3014 - acc: 0.8696
4608/4713 [============================>.] - ETA: 0s - loss: 0.3017 - acc: 0.8700
4713/4713 [==============================] - 3s 660us/step - loss: 0.3002 - acc: 0.8704

Test accuracy: 86.58777120315581

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  236

choose_one :  271

F1score :  0.8702290076335878

AUC :  0.9367822352245494

Confusion Matrix
[[211  43]
 [ 25 228]]
True label 0
0.8307086614173228  
0.16929133858267717  
True label 1
0.09881422924901186  
0.9011857707509882  

Train_result {'acc': [0.8703585826184576], 'loss': [0.300202185513739]}
Saved model to disk


11

Epoch 1/1

  64/4713 [..............................] - ETA: 5s - loss: 0.3043 - acc: 0.9375
 128/4713 [..............................] - ETA: 4s - loss: 0.2488 - acc: 0.9453
 256/4713 [>.............................] - ETA: 3s - loss: 0.2811 - acc: 0.8984
 384/4713 [=>............................] - ETA: 3s - loss: 0.2561 - acc: 0.9010
 512/4713 [==>...........................] - ETA: 3s - loss: 0.2906 - acc: 0.8809
 640/4713 [===>..........................] - ETA: 3s - loss: 0.2810 - acc: 0.8766
 768/4713 [===>..........................] - ETA: 2s - loss: 0.2810 - acc: 0.8802
 896/4713 [====>.........................] - ETA: 2s - loss: 0.2899 - acc: 0.8772
1024/4713 [=====>........................] - ETA: 2s - loss: 0.2971 - acc: 0.8711
1152/4713 [======>.......................] - ETA: 2s - loss: 0.2975 - acc: 0.8672
1280/4713 [=======>......................] - ETA: 2s - loss: 0.2992 - acc: 0.8672
1408/4713 [=======>......................] - ETA: 2s - loss: 0.2943 - acc: 0.8665
1536/4713 [========>.....................] - ETA: 2s - loss: 0.2959 - acc: 0.8652
1664/4713 [=========>....................] - ETA: 2s - loss: 0.2928 - acc: 0.8666
1792/4713 [==========>...................] - ETA: 2s - loss: 0.2934 - acc: 0.8689
1920/4713 [===========>..................] - ETA: 1s - loss: 0.2882 - acc: 0.8729
2048/4713 [============>.................] - ETA: 1s - loss: 0.2885 - acc: 0.8721
2176/4713 [============>.................] - ETA: 1s - loss: 0.2912 - acc: 0.8704
2304/4713 [=============>................] - ETA: 1s - loss: 0.2926 - acc: 0.8702
2432/4713 [==============>...............] - ETA: 1s - loss: 0.2909 - acc: 0.8701
2560/4713 [===============>..............] - ETA: 1s - loss: 0.2929 - acc: 0.8699
2688/4713 [================>.............] - ETA: 1s - loss: 0.2945 - acc: 0.8694
2816/4713 [================>.............] - ETA: 1s - loss: 0.2960 - acc: 0.8690
2944/4713 [=================>............] - ETA: 1s - loss: 0.2992 - acc: 0.8675
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3017 - acc: 0.8675
3200/4713 [===================>..........] - ETA: 0s - loss: 0.3017 - acc: 0.8681
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3042 - acc: 0.8669
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3039 - acc: 0.8669
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3029 - acc: 0.8677
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3031 - acc: 0.8680
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3040 - acc: 0.8680
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3059 - acc: 0.8672
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3038 - acc: 0.8687
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3006 - acc: 0.8700
4352/4713 [==========================>...] - ETA: 0s - loss: 0.2989 - acc: 0.8709
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3004 - acc: 0.8703
4608/4713 [============================>.] - ETA: 0s - loss: 0.2988 - acc: 0.8702
4713/4713 [==============================] - 3s 648us/step - loss: 0.3016 - acc: 0.8693

Test accuracy: 85.79881656804734

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  246

choose_one :  261

F1score :  0.8599221789883268

AUC :  0.9402135009803616

Confusion Matrix
[[214  40]
 [ 32 221]]
True label 0
0.84251968503937  
0.15748031496062992  
True label 1
0.12648221343873517  
0.8735177865612648  

Train_result {'acc': [0.8692976870203939], 'loss': [0.3015859933914259]}
Saved model to disk


12

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2959 - acc: 0.8438
 128/4713 [..............................] - ETA: 3s - loss: 0.3893 - acc: 0.8203
 256/4713 [>.............................] - ETA: 3s - loss: 0.3129 - acc: 0.8672
 384/4713 [=>............................] - ETA: 3s - loss: 0.3091 - acc: 0.8646
 512/4713 [==>...........................] - ETA: 3s - loss: 0.2898 - acc: 0.8789
 640/4713 [===>..........................] - ETA: 3s - loss: 0.2870 - acc: 0.8797
 768/4713 [===>..........................] - ETA: 2s - loss: 0.2906 - acc: 0.8763
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3103 - acc: 0.8672
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3015 - acc: 0.8691
1152/4713 [======>.......................] - ETA: 2s - loss: 0.2960 - acc: 0.8733
1280/4713 [=======>......................] - ETA: 2s - loss: 0.2868 - acc: 0.8789
1408/4713 [=======>......................] - ETA: 2s - loss: 0.2866 - acc: 0.8778
1536/4713 [========>.....................] - ETA: 2s - loss: 0.2952 - acc: 0.8743
1664/4713 [=========>....................] - ETA: 2s - loss: 0.2943 - acc: 0.8738
1792/4713 [==========>...................] - ETA: 1s - loss: 0.2931 - acc: 0.8739
1920/4713 [===========>..................] - ETA: 1s - loss: 0.2991 - acc: 0.8729
2048/4713 [============>.................] - ETA: 1s - loss: 0.3011 - acc: 0.8706
2176/4713 [============>.................] - ETA: 1s - loss: 0.3040 - acc: 0.8690
2304/4713 [=============>................] - ETA: 1s - loss: 0.3008 - acc: 0.8720
2432/4713 [==============>...............] - ETA: 1s - loss: 0.2981 - acc: 0.8725
2560/4713 [===============>..............] - ETA: 1s - loss: 0.2966 - acc: 0.8742
2688/4713 [================>.............] - ETA: 1s - loss: 0.2949 - acc: 0.8757
2816/4713 [================>.............] - ETA: 1s - loss: 0.2962 - acc: 0.8754
2944/4713 [=================>............] - ETA: 1s - loss: 0.2988 - acc: 0.8733
3072/4713 [==================>...........] - ETA: 1s - loss: 0.2998 - acc: 0.8727
3200/4713 [===================>..........] - ETA: 1s - loss: 0.2977 - acc: 0.8731
3328/4713 [====================>.........] - ETA: 0s - loss: 0.2972 - acc: 0.8738
3456/4713 [====================>.........] - ETA: 0s - loss: 0.2965 - acc: 0.8750
3584/4713 [=====================>........] - ETA: 0s - loss: 0.2978 - acc: 0.8739
3712/4713 [======================>.......] - ETA: 0s - loss: 0.2990 - acc: 0.8737
3840/4713 [=======================>......] - ETA: 0s - loss: 0.2977 - acc: 0.8747
3968/4713 [========================>.....] - ETA: 0s - loss: 0.2986 - acc: 0.8737
4096/4713 [=========================>....] - ETA: 0s - loss: 0.2989 - acc: 0.8740
4224/4713 [=========================>....] - ETA: 0s - loss: 0.2981 - acc: 0.8741
4352/4713 [==========================>...] - ETA: 0s - loss: 0.2993 - acc: 0.8732
4480/4713 [===========================>..] - ETA: 0s - loss: 0.2992 - acc: 0.8739
4608/4713 [============================>.] - ETA: 0s - loss: 0.2992 - acc: 0.8737
4713/4713 [==============================] - 3s 648us/step - loss: 0.2974 - acc: 0.8746

Test accuracy: 84.81262327416174

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  293

choose_one :  214

F1score :  0.835117773019272

AUC :  0.9413805981762162

Confusion Matrix
[[235  19]
 [ 58 195]]
True label 0
0.9251968503937008  
0.07480314960629922  
True label 1
0.22924901185770752  
0.7707509881422925  

Train_result {'acc': [0.8746021642013135], 'loss': [0.29739777189567795]}
Saved model to disk


13

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.3278 - acc: 0.8281
 192/4713 [>.............................] - ETA: 3s - loss: 0.2978 - acc: 0.8594
 320/4713 [=>............................] - ETA: 3s - loss: 0.3086 - acc: 0.8594
 448/4713 [=>............................] - ETA: 3s - loss: 0.3066 - acc: 0.8661
 576/4713 [==>...........................] - ETA: 2s - loss: 0.2948 - acc: 0.8733
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2848 - acc: 0.8764
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2788 - acc: 0.8786
 960/4713 [=====>........................] - ETA: 2s - loss: 0.2785 - acc: 0.8823
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2843 - acc: 0.8787
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2885 - acc: 0.8766
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2909 - acc: 0.8750
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3001 - acc: 0.8730
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2934 - acc: 0.8769
1728/4713 [=========>....................] - ETA: 1s - loss: 0.2902 - acc: 0.8773
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2879 - acc: 0.8793
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2917 - acc: 0.8745
2112/4713 [============>.................] - ETA: 1s - loss: 0.2884 - acc: 0.8750
2240/4713 [=============>................] - ETA: 1s - loss: 0.2867 - acc: 0.8763
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2880 - acc: 0.8754
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2837 - acc: 0.8766
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2852 - acc: 0.8761
2752/4713 [================>.............] - ETA: 1s - loss: 0.2877 - acc: 0.8754
2880/4713 [=================>............] - ETA: 1s - loss: 0.2856 - acc: 0.8767
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2874 - acc: 0.8763
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2903 - acc: 0.8756
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2910 - acc: 0.8759
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2901 - acc: 0.8756
3520/4713 [=====================>........] - ETA: 0s - loss: 0.2922 - acc: 0.8741
3648/4713 [======================>.......] - ETA: 0s - loss: 0.2929 - acc: 0.8747
3776/4713 [=======================>......] - ETA: 0s - loss: 0.2927 - acc: 0.8739
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2930 - acc: 0.8735
4032/4713 [========================>.....] - ETA: 0s - loss: 0.2922 - acc: 0.8740
4160/4713 [=========================>....] - ETA: 0s - loss: 0.2920 - acc: 0.8750
4288/4713 [==========================>...] - ETA: 0s - loss: 0.2951 - acc: 0.8741
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2947 - acc: 0.8743
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2934 - acc: 0.8741
4672/4713 [============================>.] - ETA: 0s - loss: 0.2934 - acc: 0.8744
4713/4713 [==============================] - 3s 631us/step - loss: 0.2942 - acc: 0.8740

Test accuracy: 87.3767258382643

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  258

choose_one :  249

F1score :  0.8725099601593626

AUC :  0.9448585478198624

Confusion Matrix
[[224  30]
 [ 34 219]]
True label 0
0.8818897637795275  
0.11811023622047244  
True label 1
0.13438735177865613  
0.8656126482213439  

Train_result {'acc': [0.8739656268500634], 'loss': [0.2941813685573794]}
Saved model to disk


14

Epoch 1/1

  64/4713 [..............................] - ETA: 3s - loss: 0.2987 - acc: 0.8750
 192/4713 [>.............................] - ETA: 3s - loss: 0.2961 - acc: 0.8698
 320/4713 [=>............................] - ETA: 3s - loss: 0.2944 - acc: 0.8625
 448/4713 [=>............................] - ETA: 2s - loss: 0.3325 - acc: 0.8504
 576/4713 [==>...........................] - ETA: 2s - loss: 0.3259 - acc: 0.8507
 704/4713 [===>..........................] - ETA: 2s - loss: 0.3445 - acc: 0.8352
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3308 - acc: 0.8425
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3183 - acc: 0.8531
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3144 - acc: 0.8612
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3100 - acc: 0.8618
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3074 - acc: 0.8653
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3071 - acc: 0.8655
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3109 - acc: 0.8631
1728/4713 [=========>....................] - ETA: 1s - loss: 0.3079 - acc: 0.8652
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3080 - acc: 0.8658
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3027 - acc: 0.8679
2112/4713 [============>.................] - ETA: 1s - loss: 0.3014 - acc: 0.8684
2240/4713 [=============>................] - ETA: 1s - loss: 0.3008 - acc: 0.8696
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2990 - acc: 0.8699
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2991 - acc: 0.8702
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2966 - acc: 0.8700
2752/4713 [================>.............] - ETA: 1s - loss: 0.2954 - acc: 0.8688
2880/4713 [=================>............] - ETA: 1s - loss: 0.2943 - acc: 0.8694
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2904 - acc: 0.8717
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2936 - acc: 0.8709
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2932 - acc: 0.8707
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2914 - acc: 0.8718
3520/4713 [=====================>........] - ETA: 0s - loss: 0.2922 - acc: 0.8719
3648/4713 [======================>.......] - ETA: 0s - loss: 0.2921 - acc: 0.8723
3776/4713 [=======================>......] - ETA: 0s - loss: 0.2928 - acc: 0.8718
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2908 - acc: 0.8740
4032/4713 [========================>.....] - ETA: 0s - loss: 0.2892 - acc: 0.8752
4160/4713 [=========================>....] - ETA: 0s - loss: 0.2910 - acc: 0.8740
4288/4713 [==========================>...] - ETA: 0s - loss: 0.2883 - acc: 0.8757
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2865 - acc: 0.8766
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2864 - acc: 0.8772
4672/4713 [============================>.] - ETA: 0s - loss: 0.2870 - acc: 0.8771
4713/4713 [==============================] - 3s 635us/step - loss: 0.2874 - acc: 0.8769

Test accuracy: 86.58777120315581

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  236

choose_one :  271

F1score :  0.8702290076335878

AUC :  0.9432790762814727

Confusion Matrix
[[211  43]
 [ 25 228]]
True label 0
0.8307086614173228  
0.16929133858267717  
True label 1
0.09881422924901186  
0.9011857707509882  

Train_result {'acc': [0.876936134274234], 'loss': [0.28738514572830937]}
Saved model to disk


15

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2005 - acc: 0.9375
 128/4713 [..............................] - ETA: 3s - loss: 0.2739 - acc: 0.8750
 256/4713 [>.............................] - ETA: 3s - loss: 0.2677 - acc: 0.8789
 384/4713 [=>............................] - ETA: 3s - loss: 0.2838 - acc: 0.8750
 512/4713 [==>...........................] - ETA: 3s - loss: 0.2789 - acc: 0.8750
 640/4713 [===>..........................] - ETA: 2s - loss: 0.2674 - acc: 0.8781
 768/4713 [===>..........................] - ETA: 2s - loss: 0.2656 - acc: 0.8815
 896/4713 [====>.........................] - ETA: 2s - loss: 0.2727 - acc: 0.8772
1024/4713 [=====>........................] - ETA: 2s - loss: 0.2721 - acc: 0.8799
1152/4713 [======>.......................] - ETA: 2s - loss: 0.2734 - acc: 0.8759
1280/4713 [=======>......................] - ETA: 2s - loss: 0.2809 - acc: 0.8750
1408/4713 [=======>......................] - ETA: 2s - loss: 0.2762 - acc: 0.8743
1536/4713 [========>.....................] - ETA: 2s - loss: 0.2787 - acc: 0.8730
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2777 - acc: 0.8731
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2833 - acc: 0.8721
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2876 - acc: 0.8707
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2903 - acc: 0.8720
2112/4713 [============>.................] - ETA: 1s - loss: 0.2876 - acc: 0.8745
2240/4713 [=============>................] - ETA: 1s - loss: 0.2913 - acc: 0.8728
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2892 - acc: 0.8737
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2910 - acc: 0.8734
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2936 - acc: 0.8727
2752/4713 [================>.............] - ETA: 1s - loss: 0.2925 - acc: 0.8743
2880/4713 [=================>............] - ETA: 1s - loss: 0.2913 - acc: 0.8750
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2925 - acc: 0.8737
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2890 - acc: 0.8756
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2908 - acc: 0.8744
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2920 - acc: 0.8741
3520/4713 [=====================>........] - ETA: 0s - loss: 0.2900 - acc: 0.8753
3648/4713 [======================>.......] - ETA: 0s - loss: 0.2883 - acc: 0.8761
3776/4713 [=======================>......] - ETA: 0s - loss: 0.2881 - acc: 0.8758
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2862 - acc: 0.8770
4032/4713 [========================>.....] - ETA: 0s - loss: 0.2881 - acc: 0.8755
4160/4713 [=========================>....] - ETA: 0s - loss: 0.2888 - acc: 0.8752
4288/4713 [==========================>...] - ETA: 0s - loss: 0.2914 - acc: 0.8734
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2908 - acc: 0.8732
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2912 - acc: 0.8737
4672/4713 [============================>.] - ETA: 0s - loss: 0.2902 - acc: 0.8739
4713/4713 [==============================] - 3s 642us/step - loss: 0.2907 - acc: 0.8742

Test accuracy: 87.3767258382643

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  236

choose_one :  271

F1score :  0.8778625954198472

AUC :  0.9431234633220255

Confusion Matrix
[[213  41]
 [ 23 230]]
True label 0
0.8385826771653543  
0.16141732283464566  
True label 1
0.09090909090909091  
0.9090909090909091  

Train_result {'acc': [0.8741778058406782], 'loss': [0.29070685179451583]}
Saved model to disk


[[84.41814595660749, 1], [86.58777120315581, 2], [84.81262327416174, 3], [85.20710059171599, 4], [86.19329388560158, 5], [86.3905325443787, 6], [86.58777120315581, 7], [87.17948717948718, 8], [87.57396449704143, 9], [86.58777120315581, 10], [85.79881656804734, 11], [84.81262327416174, 12], [87.3767258382643, 13], [86.58777120315581, 14], [87.3767258382643, 15]]
max accuracy :  [87.57396449704143, 9]
