Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
/home/2014313303/taeha/JavaAutoLogging/model.py:154: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor("ou..., inputs=[<tf.Tenso...)`
  model = Model(input=[input1, input2, input3, input4], output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-10 03:10:02.709750: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-10 03:10:02.715965: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099840000 Hz
2019-09-10 03:10:02.717650: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x15b21550 executing computations on platform Host. Devices:
2019-09-10 03:10:02.717669: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Standard data
zero :  39451
one :  9019

First data
zero :  39451
one :  9019

Second data
zero :  39451
one :  9019

Third data
zero :  39451
one :  9019

4th data
zero :  39451
one :  9019

hbase-code
After set document size of train data, the number of zero and one label data :  23525 1507
After set document size of test data, the number of zero and one label data :  2614 166

Sentence length Average : 13

Under 10 : 9590
Over 10, Under 30 : 18222
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

After balance out data.
hbase-code

Sentence length Average : 14

Under 10 : 1039
Over 10, Under 30 : 2309
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

hbase-AST
After set document size of train data, the number of zero and one label data :  23525 1507
After set document size of test data, the number of zero and one label data :  2614 166
After balance out data.
hbase-AST

Sentence length Average : 9

Under 10 : 2145
Over 10, Under 30 : 1168
Over 30, Under 100 : 25
Over 100, Under 150 : 3
Over 150, Under 200 : 2
Over 200, Under 400 : 3
Over 400 : 2

hbase-CAST
After set document size of train data, the number of zero and one label data :  23525 1507
After set document size of test data, the number of zero and one label data :  2614 166
After balance out data.
hbase-CAST

Sentence length Average : 23

Under 10 : 923
Over 10, Under 30 : 1585
Over 30, Under 100 : 823
Over 100, Under 150 : 2
Over 150, Under 200 : 1
Over 200, Under 400 : 9
Over 400 : 5

hbase-depth_num
After set document size of train data, the number of zero and one label data :  23525 1507
After set document size of test data, the number of zero and one label data :  2614 166
After balance out data.
hbase-depth_num

Sentence length Average : 9

Under 10 : 2145
Over 10, Under 30 : 1168
Over 30, Under 100 : 25
Over 100, Under 150 : 3
Over 150, Under 200 : 2
Over 200, Under 400 : 3
Over 400 : 2

Count model parameter.
Get a short summary of each layer dimensions and parameters.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 30, 200)      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 60, 200)      0                                            
__________________________________________________________________________________________________
masking_1 (Masking)             (None, 30, 200)      0           input_1[0][0]                    
__________________________________________________________________________________________________
masking_2 (Masking)             (None, 60, 200)      0           input_2[0][0]                    
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 90, 200)      0                                            
__________________________________________________________________________________________________
forwards_1 (LSTM)               (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
backwords_1 (LSTM)              (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
forwards_2 (LSTM)               (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
backwards_2 (LSTM)              (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
masking_3 (Masking)             (None, 90, 200)      0           input_3[0][0]                    
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 60, 200)      0                                            
__________________________________________________________________________________________________
after_dp_forward_1 (Dropout)    (None, 64)           0           forwards_1[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_1 (Dropout)   (None, 64)           0           backwords_1[0][0]                
__________________________________________________________________________________________________
after_dp_forward_2 (Dropout)    (None, 64)           0           forwards_2[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_2 (Dropout)   (None, 64)           0           backwards_2[0][0]                
__________________________________________________________________________________________________
forwards_3 (LSTM)               (None, 64)           67840       masking_3[0][0]                  
__________________________________________________________________________________________________
backwards_3 (LSTM)              (None, 64)           67840       masking_3[0][0]                  
__________________________________________________________________________________________________
masking_4 (Masking)             (None, 60, 200)      0           input_4[0][0]                    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128)          0           after_dp_forward_1[0][0]         
                                                                 after_dp_backward_1[0][0]        
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 128)          0           after_dp_forward_2[0][0]         
                                                                 after_dp_backward_2[0][0]        
__________________________________________________________________________________________________
after_dp_forward_3 (Dropout)    (None, 64)           0           forwards_3[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_3 (Dropout)   (None, 64)           0           backwards_3[0][0]                
__________________________________________________________________________________________________
forwards_4 (LSTM)               (None, 64)           67840       masking_4[0][0]                  
__________________________________________________________________________________________________
backwards_4 (LSTM)              (None, 64)           67840       masking_4[0][0]                  
__________________________________________________________________________________________________
after_dp_1 (Dropout)            (None, 128)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
after_dp_2 (Dropout)            (None, 128)          0           concatenate_2[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 128)          0           after_dp_forward_3[0][0]         
                                                                 after_dp_backward_3[0][0]        
__________________________________________________________________________________________________
after_dp_forward_4 (Dropout)    (None, 64)           0           forwards_4[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_4 (Dropout)   (None, 64)           0           backwards_4[0][0]                
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 256)          0           after_dp_1[0][0]                 
                                                                 after_dp_2[0][0]                 
__________________________________________________________________________________________________
after_dp_3 (Dropout)            (None, 128)          0           concatenate_3[0][0]              
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 128)          0           after_dp_forward_4[0][0]         
                                                                 after_dp_backward_4[0][0]        
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 384)          0           concatenate_5[0][0]              
                                                                 after_dp_3[0][0]                 
__________________________________________________________________________________________________
after_dp_4 (Dropout)            (None, 128)          0           concatenate_4[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 512)          0           concatenate_6[0][0]              
                                                                 after_dp_4[0][0]                 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          262656      concatenate_7[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 768)          393984      dense_1[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 512)          393728      dense_2[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 256)          131328      dense_3[0][0]                    
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 128)          32896       dense_4[0][0]                    
__________________________________________________________________________________________________
output (Dense)                  (None, 2)            258         dense_5[0][0]                    
==================================================================================================
Total params: 1,757,570
Trainable params: 1,757,570
Non-trainable params: 0
__________________________________________________________________________________________________
1

Epoch 1/1

  64/3015 [..............................] - ETA: 5:30 - loss: 0.6939 - acc: 0.4375
 128/3015 [>.............................] - ETA: 2:45 - loss: 0.6788 - acc: 0.5391
 192/3015 [>.............................] - ETA: 1:50 - loss: 0.6812 - acc: 0.5417
 256/3015 [=>............................] - ETA: 1:22 - loss: 0.6728 - acc: 0.5430
 320/3015 [==>...........................] - ETA: 1:05 - loss: 0.6659 - acc: 0.5500
 384/3015 [==>...........................] - ETA: 54s - loss: 0.6536 - acc: 0.5729 
 448/3015 [===>..........................] - ETA: 47s - loss: 0.6511 - acc: 0.5871
 512/3015 [====>.........................] - ETA: 42s - loss: 0.6329 - acc: 0.6113
 576/3015 [====>.........................] - ETA: 37s - loss: 0.6106 - acc: 0.6337
 640/3015 [=====>........................] - ETA: 34s - loss: 0.6065 - acc: 0.6422
 704/3015 [======>.......................] - ETA: 31s - loss: 0.6005 - acc: 0.6534
 768/3015 [======>.......................] - ETA: 28s - loss: 0.5833 - acc: 0.6693
 832/3015 [=======>......................] - ETA: 26s - loss: 0.5606 - acc: 0.6851
 896/3015 [=======>......................] - ETA: 24s - loss: 0.5396 - acc: 0.6998
 960/3015 [========>.....................] - ETA: 22s - loss: 0.5360 - acc: 0.7042
1024/3015 [=========>....................] - ETA: 20s - loss: 0.5199 - acc: 0.7188
1088/3015 [=========>....................] - ETA: 19s - loss: 0.5143 - acc: 0.7215
1152/3015 [==========>...................] - ETA: 17s - loss: 0.5129 - acc: 0.7257
1216/3015 [===========>..................] - ETA: 16s - loss: 0.5093 - acc: 0.7294
1280/3015 [===========>..................] - ETA: 15s - loss: 0.4985 - acc: 0.7375
1344/3015 [============>.................] - ETA: 14s - loss: 0.4922 - acc: 0.7440
1408/3015 [=============>................] - ETA: 13s - loss: 0.4862 - acc: 0.7486
1472/3015 [=============>................] - ETA: 12s - loss: 0.4787 - acc: 0.7548
1536/3015 [==============>...............] - ETA: 11s - loss: 0.4718 - acc: 0.7591
1600/3015 [==============>...............] - ETA: 10s - loss: 0.4667 - acc: 0.7625
1664/3015 [===============>..............] - ETA: 10s - loss: 0.4634 - acc: 0.7662
1728/3015 [================>.............] - ETA: 9s - loss: 0.4572 - acc: 0.7714 
1792/3015 [================>.............] - ETA: 8s - loss: 0.4573 - acc: 0.7734
1856/3015 [=================>............] - ETA: 8s - loss: 0.4533 - acc: 0.7753
1920/3015 [==================>...........] - ETA: 7s - loss: 0.4478 - acc: 0.7781
1984/3015 [==================>...........] - ETA: 7s - loss: 0.4431 - acc: 0.7812
2048/3015 [===================>..........] - ETA: 6s - loss: 0.4389 - acc: 0.7852
2112/3015 [====================>.........] - ETA: 6s - loss: 0.4374 - acc: 0.7888
2176/3015 [====================>.........] - ETA: 5s - loss: 0.4313 - acc: 0.7927
2240/3015 [=====================>........] - ETA: 5s - loss: 0.4276 - acc: 0.7946
2304/3015 [=====================>........] - ETA: 4s - loss: 0.4219 - acc: 0.7973
2368/3015 [======================>.......] - ETA: 4s - loss: 0.4173 - acc: 0.8003
2432/3015 [=======================>......] - ETA: 3s - loss: 0.4163 - acc: 0.8018
2496/3015 [=======================>......] - ETA: 3s - loss: 0.4119 - acc: 0.8045
2560/3015 [========================>.....] - ETA: 2s - loss: 0.4094 - acc: 0.8059
2624/3015 [=========================>....] - ETA: 2s - loss: 0.4089 - acc: 0.8064
2688/3015 [=========================>....] - ETA: 1s - loss: 0.4082 - acc: 0.8073
2752/3015 [==========================>...] - ETA: 1s - loss: 0.4067 - acc: 0.8074
2816/3015 [===========================>..] - ETA: 1s - loss: 0.4102 - acc: 0.8058
2880/3015 [===========================>..] - ETA: 0s - loss: 0.4064 - acc: 0.8090
2944/3015 [============================>.] - ETA: 0s - loss: 0.4047 - acc: 0.8108
3008/3015 [============================>.] - ETA: 0s - loss: 0.4025 - acc: 0.8122
3015/3015 [==============================] - 17s 6ms/step - loss: 0.4021 - acc: 0.8126

Test accuracy: 89.7897897897898

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  171

choose_one :  162

F1score :  0.8963414634146342

AUC :  0.9527090397518216

Confusion Matrix
[[152  15]
 [ 19 147]]
True label 0
0.9101796407185628  
0.08982035928143713  
True label 1
0.1144578313253012  
0.8855421686746988  

Train_result {'acc': [0.8126036484245439], 'loss': [0.402071427068307]}
Saved model to disk


2

Epoch 1/1

  64/3015 [..............................] - ETA: 9s - loss: 0.3346 - acc: 0.8438
 128/3015 [>.............................] - ETA: 8s - loss: 0.2776 - acc: 0.8594
 192/3015 [>.............................] - ETA: 8s - loss: 0.3199 - acc: 0.8385
 256/3015 [=>............................] - ETA: 7s - loss: 0.3197 - acc: 0.8555
 320/3015 [==>...........................] - ETA: 7s - loss: 0.3439 - acc: 0.8469
 384/3015 [==>...........................] - ETA: 7s - loss: 0.3340 - acc: 0.8490
 448/3015 [===>..........................] - ETA: 7s - loss: 0.3647 - acc: 0.8393
 512/3015 [====>.........................] - ETA: 8s - loss: 0.3521 - acc: 0.8438
 576/3015 [====>.........................] - ETA: 8s - loss: 0.3454 - acc: 0.8472
 640/3015 [=====>........................] - ETA: 8s - loss: 0.3407 - acc: 0.8484
 704/3015 [======>.......................] - ETA: 8s - loss: 0.3394 - acc: 0.8494
 768/3015 [======>.......................] - ETA: 7s - loss: 0.3308 - acc: 0.8503
 832/3015 [=======>......................] - ETA: 7s - loss: 0.3250 - acc: 0.8558
 896/3015 [=======>......................] - ETA: 7s - loss: 0.3242 - acc: 0.8594
 960/3015 [========>.....................] - ETA: 7s - loss: 0.3198 - acc: 0.8583
1024/3015 [=========>....................] - ETA: 6s - loss: 0.3146 - acc: 0.8604
1088/3015 [=========>....................] - ETA: 6s - loss: 0.3089 - acc: 0.8631
1152/3015 [==========>...................] - ETA: 6s - loss: 0.3116 - acc: 0.8628
1216/3015 [===========>..................] - ETA: 5s - loss: 0.3088 - acc: 0.8660
1280/3015 [===========>..................] - ETA: 5s - loss: 0.3095 - acc: 0.8648
1344/3015 [============>.................] - ETA: 5s - loss: 0.3130 - acc: 0.8646
1408/3015 [=============>................] - ETA: 5s - loss: 0.3182 - acc: 0.8615
1472/3015 [=============>................] - ETA: 4s - loss: 0.3167 - acc: 0.8621
1536/3015 [==============>...............] - ETA: 4s - loss: 0.3132 - acc: 0.8652
1600/3015 [==============>...............] - ETA: 4s - loss: 0.3136 - acc: 0.8656
1664/3015 [===============>..............] - ETA: 4s - loss: 0.3143 - acc: 0.8666
1728/3015 [================>.............] - ETA: 4s - loss: 0.3136 - acc: 0.8686
1792/3015 [================>.............] - ETA: 4s - loss: 0.3108 - acc: 0.8700
1856/3015 [=================>............] - ETA: 3s - loss: 0.3052 - acc: 0.8734
1920/3015 [==================>...........] - ETA: 3s - loss: 0.3072 - acc: 0.8724
1984/3015 [==================>...........] - ETA: 3s - loss: 0.3065 - acc: 0.8730
2048/3015 [===================>..........] - ETA: 3s - loss: 0.3033 - acc: 0.8745
2112/3015 [====================>.........] - ETA: 3s - loss: 0.3007 - acc: 0.8755
2176/3015 [====================>.........] - ETA: 2s - loss: 0.2967 - acc: 0.8782
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2963 - acc: 0.8777
2304/3015 [=====================>........] - ETA: 2s - loss: 0.2963 - acc: 0.8780
2368/3015 [======================>.......] - ETA: 2s - loss: 0.2969 - acc: 0.8784
2432/3015 [=======================>......] - ETA: 1s - loss: 0.2982 - acc: 0.8771
2496/3015 [=======================>......] - ETA: 1s - loss: 0.3017 - acc: 0.8746
2560/3015 [========================>.....] - ETA: 1s - loss: 0.3020 - acc: 0.8730
2624/3015 [=========================>....] - ETA: 1s - loss: 0.2985 - acc: 0.8746
2688/3015 [=========================>....] - ETA: 1s - loss: 0.2978 - acc: 0.8750
2752/3015 [==========================>...] - ETA: 0s - loss: 0.2956 - acc: 0.8757
2816/3015 [===========================>..] - ETA: 0s - loss: 0.2944 - acc: 0.8761
2880/3015 [===========================>..] - ETA: 0s - loss: 0.2940 - acc: 0.8764
2944/3015 [============================>.] - ETA: 0s - loss: 0.2969 - acc: 0.8750
3008/3015 [============================>.] - ETA: 0s - loss: 0.2967 - acc: 0.8747
3015/3015 [==============================] - 10s 3ms/step - loss: 0.2964 - acc: 0.8746

Test accuracy: 89.4894894894895

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  156

choose_one :  177

F1score :  0.8979591836734694

AUC :  0.9565327176971359

Confusion Matrix
[[144  23]
 [ 12 154]]
True label 0
0.8622754491017964  
0.1377245508982036  
True label 1
0.07228915662650602  
0.927710843373494  

Train_result {'acc': [0.8746268656914111], 'loss': [0.29637666707904775]}
Saved model to disk


3

Epoch 1/1

  64/3015 [..............................] - ETA: 9s - loss: 0.2775 - acc: 0.8750
 128/3015 [>.............................] - ETA: 8s - loss: 0.2826 - acc: 0.8594
 192/3015 [>.............................] - ETA: 8s - loss: 0.2981 - acc: 0.8646
 256/3015 [=>............................] - ETA: 7s - loss: 0.2977 - acc: 0.8633
 320/3015 [==>...........................] - ETA: 7s - loss: 0.2742 - acc: 0.8750
 384/3015 [==>...........................] - ETA: 7s - loss: 0.2935 - acc: 0.8698
 448/3015 [===>..........................] - ETA: 7s - loss: 0.2945 - acc: 0.8750
 512/3015 [====>.........................] - ETA: 6s - loss: 0.2926 - acc: 0.8770
 576/3015 [====>.........................] - ETA: 6s - loss: 0.2784 - acc: 0.8802
 640/3015 [=====>........................] - ETA: 6s - loss: 0.2731 - acc: 0.8844
 704/3015 [======>.......................] - ETA: 6s - loss: 0.2637 - acc: 0.8906
 768/3015 [======>.......................] - ETA: 6s - loss: 0.2635 - acc: 0.8932
 832/3015 [=======>......................] - ETA: 6s - loss: 0.2587 - acc: 0.8918
 896/3015 [=======>......................] - ETA: 7s - loss: 0.2714 - acc: 0.8895
 960/3015 [========>.....................] - ETA: 6s - loss: 0.2675 - acc: 0.8917
1024/3015 [=========>....................] - ETA: 6s - loss: 0.2686 - acc: 0.8896
1088/3015 [=========>....................] - ETA: 6s - loss: 0.2684 - acc: 0.8888
1152/3015 [==========>...................] - ETA: 6s - loss: 0.2760 - acc: 0.8845
1216/3015 [===========>..................] - ETA: 5s - loss: 0.2792 - acc: 0.8824
1280/3015 [===========>..................] - ETA: 5s - loss: 0.2736 - acc: 0.8836
1344/3015 [============>.................] - ETA: 5s - loss: 0.2718 - acc: 0.8839
1408/3015 [=============>................] - ETA: 5s - loss: 0.2739 - acc: 0.8821
1472/3015 [=============>................] - ETA: 4s - loss: 0.2732 - acc: 0.8825
1536/3015 [==============>...............] - ETA: 4s - loss: 0.2753 - acc: 0.8809
1600/3015 [==============>...............] - ETA: 4s - loss: 0.2758 - acc: 0.8806
1664/3015 [===============>..............] - ETA: 4s - loss: 0.2791 - acc: 0.8792
1728/3015 [================>.............] - ETA: 3s - loss: 0.2801 - acc: 0.8779
1792/3015 [================>.............] - ETA: 3s - loss: 0.2769 - acc: 0.8795
1856/3015 [=================>............] - ETA: 3s - loss: 0.2792 - acc: 0.8766
1920/3015 [==================>...........] - ETA: 3s - loss: 0.2777 - acc: 0.8776
1984/3015 [==================>...........] - ETA: 3s - loss: 0.2756 - acc: 0.8785
2048/3015 [===================>..........] - ETA: 3s - loss: 0.2757 - acc: 0.8774
2112/3015 [====================>.........] - ETA: 2s - loss: 0.2725 - acc: 0.8793
2176/3015 [====================>.........] - ETA: 2s - loss: 0.2736 - acc: 0.8791
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2765 - acc: 0.8768
2304/3015 [=====================>........] - ETA: 2s - loss: 0.2736 - acc: 0.8776
2368/3015 [======================>.......] - ETA: 2s - loss: 0.2712 - acc: 0.8788
2432/3015 [=======================>......] - ETA: 1s - loss: 0.2682 - acc: 0.8799
2496/3015 [=======================>......] - ETA: 1s - loss: 0.2656 - acc: 0.8818
2560/3015 [========================>.....] - ETA: 1s - loss: 0.2671 - acc: 0.8816
2624/3015 [=========================>....] - ETA: 1s - loss: 0.2653 - acc: 0.8826
2688/3015 [=========================>....] - ETA: 1s - loss: 0.2662 - acc: 0.8832
2752/3015 [==========================>...] - ETA: 0s - loss: 0.2661 - acc: 0.8830
2816/3015 [===========================>..] - ETA: 0s - loss: 0.2664 - acc: 0.8828
2880/3015 [===========================>..] - ETA: 0s - loss: 0.2694 - acc: 0.8826
2944/3015 [============================>.] - ETA: 0s - loss: 0.2683 - acc: 0.8832
3008/3015 [============================>.] - ETA: 0s - loss: 0.2678 - acc: 0.8830
3015/3015 [==============================] - 10s 3ms/step - loss: 0.2678 - acc: 0.8829

Test accuracy: 89.4894894894895

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  154

choose_one :  179

F1score :  0.8985507246376812

AUC :  0.9629175384171417

Confusion Matrix
[[143  24]
 [ 11 155]]
True label 0
0.8562874251497006  
0.1437125748502994  
True label 1
0.06626506024096386  
0.9337349397590361  

Train_result {'acc': [0.882918739654927], 'loss': [0.26776059175012124]}
Saved model to disk


4

Epoch 1/1

  64/3015 [..............................] - ETA: 14s - loss: 0.2589 - acc: 0.9219
 128/3015 [>.............................] - ETA: 11s - loss: 0.2334 - acc: 0.9062
 192/3015 [>.............................] - ETA: 10s - loss: 0.2492 - acc: 0.8958
 256/3015 [=>............................] - ETA: 9s - loss: 0.2483 - acc: 0.9023 
 320/3015 [==>...........................] - ETA: 8s - loss: 0.2359 - acc: 0.9062
 384/3015 [==>...........................] - ETA: 8s - loss: 0.2449 - acc: 0.9062
 448/3015 [===>..........................] - ETA: 7s - loss: 0.2480 - acc: 0.9018
 512/3015 [====>.........................] - ETA: 7s - loss: 0.2584 - acc: 0.8945
 576/3015 [====>.........................] - ETA: 7s - loss: 0.2405 - acc: 0.9010
 640/3015 [=====>........................] - ETA: 6s - loss: 0.2331 - acc: 0.9047
 704/3015 [======>.......................] - ETA: 6s - loss: 0.2383 - acc: 0.9006
 768/3015 [======>.......................] - ETA: 6s - loss: 0.2391 - acc: 0.9010
 832/3015 [=======>......................] - ETA: 6s - loss: 0.2337 - acc: 0.9014
 896/3015 [=======>......................] - ETA: 6s - loss: 0.2265 - acc: 0.9051
 960/3015 [========>.....................] - ETA: 6s - loss: 0.2321 - acc: 0.9010
1024/3015 [=========>....................] - ETA: 6s - loss: 0.2289 - acc: 0.9023
1088/3015 [=========>....................] - ETA: 6s - loss: 0.2300 - acc: 0.9026
1152/3015 [==========>...................] - ETA: 5s - loss: 0.2401 - acc: 0.8993
1216/3015 [===========>..................] - ETA: 5s - loss: 0.2379 - acc: 0.9005
1280/3015 [===========>..................] - ETA: 5s - loss: 0.2394 - acc: 0.8984
1344/3015 [============>.................] - ETA: 5s - loss: 0.2376 - acc: 0.8988
1408/3015 [=============>................] - ETA: 5s - loss: 0.2430 - acc: 0.8963
1472/3015 [=============>................] - ETA: 4s - loss: 0.2446 - acc: 0.8967
1536/3015 [==============>...............] - ETA: 4s - loss: 0.2458 - acc: 0.8945
1600/3015 [==============>...............] - ETA: 4s - loss: 0.2492 - acc: 0.8944
1664/3015 [===============>..............] - ETA: 4s - loss: 0.2495 - acc: 0.8942
1728/3015 [================>.............] - ETA: 4s - loss: 0.2510 - acc: 0.8935
1792/3015 [================>.............] - ETA: 3s - loss: 0.2518 - acc: 0.8929
1856/3015 [=================>............] - ETA: 3s - loss: 0.2549 - acc: 0.8928
1920/3015 [==================>...........] - ETA: 3s - loss: 0.2558 - acc: 0.8922
1984/3015 [==================>...........] - ETA: 3s - loss: 0.2548 - acc: 0.8926
2048/3015 [===================>..........] - ETA: 2s - loss: 0.2607 - acc: 0.8926
2112/3015 [====================>.........] - ETA: 2s - loss: 0.2605 - acc: 0.8925
2176/3015 [====================>.........] - ETA: 2s - loss: 0.2587 - acc: 0.8920
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2574 - acc: 0.8929
2304/3015 [=====================>........] - ETA: 2s - loss: 0.2546 - acc: 0.8945
2368/3015 [======================>.......] - ETA: 2s - loss: 0.2546 - acc: 0.8944
2432/3015 [=======================>......] - ETA: 1s - loss: 0.2599 - acc: 0.8935
2496/3015 [=======================>......] - ETA: 1s - loss: 0.2607 - acc: 0.8934
2560/3015 [========================>.....] - ETA: 1s - loss: 0.2609 - acc: 0.8926
2624/3015 [=========================>....] - ETA: 1s - loss: 0.2598 - acc: 0.8921
2688/3015 [=========================>....] - ETA: 1s - loss: 0.2593 - acc: 0.8921
2752/3015 [==========================>...] - ETA: 0s - loss: 0.2582 - acc: 0.8921
2816/3015 [===========================>..] - ETA: 0s - loss: 0.2572 - acc: 0.8924
2880/3015 [===========================>..] - ETA: 0s - loss: 0.2569 - acc: 0.8924
2944/3015 [============================>.] - ETA: 0s - loss: 0.2563 - acc: 0.8930
3008/3015 [============================>.] - ETA: 0s - loss: 0.2564 - acc: 0.8933
3015/3015 [==============================] - 10s 3ms/step - loss: 0.2563 - acc: 0.8932

Test accuracy: 91.29129129129129

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  168

choose_one :  165

F1score :  0.9123867069486404

AUC :  0.9649015222566915

Confusion Matrix
[[153  14]
 [ 15 151]]
True label 0
0.9161676646706587  
0.08383233532934131  
True label 1
0.09036144578313253  
0.9096385542168675  

Train_result {'acc': [0.8932006633696864], 'loss': [0.25632953219745885]}
Saved model to disk


5

Epoch 1/1

  64/3015 [..............................] - ETA: 9s - loss: 0.2748 - acc: 0.8750
 128/3015 [>.............................] - ETA: 8s - loss: 0.2486 - acc: 0.8906
 192/3015 [>.............................] - ETA: 10s - loss: 0.2047 - acc: 0.9167
 256/3015 [=>............................] - ETA: 10s - loss: 0.1921 - acc: 0.9141
 320/3015 [==>...........................] - ETA: 9s - loss: 0.1709 - acc: 0.9250 
 384/3015 [==>...........................] - ETA: 9s - loss: 0.1848 - acc: 0.9167
 448/3015 [===>..........................] - ETA: 8s - loss: 0.1881 - acc: 0.9174
 512/3015 [====>.........................] - ETA: 8s - loss: 0.2089 - acc: 0.9043
 576/3015 [====>.........................] - ETA: 7s - loss: 0.1941 - acc: 0.9115
 640/3015 [=====>........................] - ETA: 7s - loss: 0.1938 - acc: 0.9094
 704/3015 [======>.......................] - ETA: 7s - loss: 0.1902 - acc: 0.9119
 768/3015 [======>.......................] - ETA: 6s - loss: 0.1997 - acc: 0.9076
 832/3015 [=======>......................] - ETA: 6s - loss: 0.2084 - acc: 0.9026
 896/3015 [=======>......................] - ETA: 6s - loss: 0.2087 - acc: 0.9029
 960/3015 [========>.....................] - ETA: 6s - loss: 0.2081 - acc: 0.9042
1024/3015 [=========>....................] - ETA: 6s - loss: 0.2106 - acc: 0.9023
1088/3015 [=========>....................] - ETA: 6s - loss: 0.2122 - acc: 0.9007
1152/3015 [==========>...................] - ETA: 6s - loss: 0.2103 - acc: 0.9010
1216/3015 [===========>..................] - ETA: 6s - loss: 0.2181 - acc: 0.8997
1280/3015 [===========>..................] - ETA: 5s - loss: 0.2221 - acc: 0.8992
1344/3015 [============>.................] - ETA: 5s - loss: 0.2287 - acc: 0.8966
1408/3015 [=============>................] - ETA: 5s - loss: 0.2359 - acc: 0.8949
1472/3015 [=============>................] - ETA: 5s - loss: 0.2396 - acc: 0.8920
1536/3015 [==============>...............] - ETA: 4s - loss: 0.2361 - acc: 0.8939
1600/3015 [==============>...............] - ETA: 4s - loss: 0.2394 - acc: 0.8925
1664/3015 [===============>..............] - ETA: 4s - loss: 0.2373 - acc: 0.8942
1728/3015 [================>.............] - ETA: 4s - loss: 0.2393 - acc: 0.8929
1792/3015 [================>.............] - ETA: 3s - loss: 0.2388 - acc: 0.8929
1856/3015 [=================>............] - ETA: 3s - loss: 0.2384 - acc: 0.8928
1920/3015 [==================>...........] - ETA: 3s - loss: 0.2378 - acc: 0.8943
1984/3015 [==================>...........] - ETA: 3s - loss: 0.2350 - acc: 0.8957
2048/3015 [===================>..........] - ETA: 3s - loss: 0.2321 - acc: 0.8975
2112/3015 [====================>.........] - ETA: 2s - loss: 0.2299 - acc: 0.8987
2176/3015 [====================>.........] - ETA: 2s - loss: 0.2323 - acc: 0.8984
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2313 - acc: 0.8987
2304/3015 [=====================>........] - ETA: 2s - loss: 0.2308 - acc: 0.8984
2368/3015 [======================>.......] - ETA: 2s - loss: 0.2289 - acc: 0.8991
2432/3015 [=======================>......] - ETA: 1s - loss: 0.2359 - acc: 0.8976
2496/3015 [=======================>......] - ETA: 1s - loss: 0.2358 - acc: 0.8990
2560/3015 [========================>.....] - ETA: 1s - loss: 0.2389 - acc: 0.8984
2624/3015 [=========================>....] - ETA: 1s - loss: 0.2370 - acc: 0.8994
2688/3015 [=========================>....] - ETA: 1s - loss: 0.2408 - acc: 0.8981
2752/3015 [==========================>...] - ETA: 0s - loss: 0.2405 - acc: 0.8986
2816/3015 [===========================>..] - ETA: 0s - loss: 0.2407 - acc: 0.8981
2880/3015 [===========================>..] - ETA: 0s - loss: 0.2402 - acc: 0.8986
2944/3015 [============================>.] - ETA: 0s - loss: 0.2395 - acc: 0.8995
3008/3015 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.8999
3015/3015 [==============================] - 10s 3ms/step - loss: 0.2401 - acc: 0.8998

Test accuracy: 90.39039039039038

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  157

choose_one :  176

F1score :  0.9064327485380117

AUC :  0.9639636389870861

Confusion Matrix
[[146  21]
 [ 11 155]]
True label 0
0.874251497005988  
0.12574850299401197  
True label 1
0.06626506024096386  
0.9337349397590361  

Train_result {'acc': [0.8998341625404991], 'loss': [0.240148028469402]}
Saved model to disk


6

Epoch 1/1

  64/3015 [..............................] - ETA: 16s - loss: 0.2230 - acc: 0.8906
 128/3015 [>.............................] - ETA: 14s - loss: 0.2600 - acc: 0.8750
 192/3015 [>.............................] - ETA: 13s - loss: 0.2357 - acc: 0.8958
 256/3015 [=>............................] - ETA: 12s - loss: 0.2050 - acc: 0.9180
 320/3015 [==>...........................] - ETA: 11s - loss: 0.2087 - acc: 0.9156
 384/3015 [==>...........................] - ETA: 10s - loss: 0.2113 - acc: 0.9115
 448/3015 [===>..........................] - ETA: 10s - loss: 0.2176 - acc: 0.9085
 512/3015 [====>.........................] - ETA: 10s - loss: 0.2189 - acc: 0.9121
 576/3015 [====>.........................] - ETA: 9s - loss: 0.2147 - acc: 0.9132 
 640/3015 [=====>........................] - ETA: 8s - loss: 0.2078 - acc: 0.9172
 704/3015 [======>.......................] - ETA: 8s - loss: 0.2075 - acc: 0.9134
 768/3015 [======>.......................] - ETA: 7s - loss: 0.2132 - acc: 0.9115
 832/3015 [=======>......................] - ETA: 7s - loss: 0.2171 - acc: 0.9123
 896/3015 [=======>......................] - ETA: 7s - loss: 0.2099 - acc: 0.9152
 960/3015 [========>.....................] - ETA: 6s - loss: 0.2083 - acc: 0.9146
1024/3015 [=========>....................] - ETA: 6s - loss: 0.2067 - acc: 0.9150
1088/3015 [=========>....................] - ETA: 6s - loss: 0.1995 - acc: 0.9191
1152/3015 [==========>...................] - ETA: 5s - loss: 0.2028 - acc: 0.9158
1216/3015 [===========>..................] - ETA: 5s - loss: 0.2042 - acc: 0.9145
1280/3015 [===========>..................] - ETA: 5s - loss: 0.2153 - acc: 0.9086
1344/3015 [============>.................] - ETA: 5s - loss: 0.2148 - acc: 0.9092
1408/3015 [=============>................] - ETA: 5s - loss: 0.2215 - acc: 0.9077
1472/3015 [=============>................] - ETA: 5s - loss: 0.2208 - acc: 0.9083
1536/3015 [==============>...............] - ETA: 5s - loss: 0.2230 - acc: 0.9095
1600/3015 [==============>...............] - ETA: 4s - loss: 0.2238 - acc: 0.9081
1664/3015 [===============>..............] - ETA: 4s - loss: 0.2243 - acc: 0.9075
1728/3015 [================>.............] - ETA: 4s - loss: 0.2236 - acc: 0.9080
1792/3015 [================>.............] - ETA: 4s - loss: 0.2206 - acc: 0.9090
1856/3015 [=================>............] - ETA: 3s - loss: 0.2179 - acc: 0.9116
1920/3015 [==================>...........] - ETA: 3s - loss: 0.2200 - acc: 0.9115
1984/3015 [==================>...........] - ETA: 3s - loss: 0.2233 - acc: 0.9103
2048/3015 [===================>..........] - ETA: 3s - loss: 0.2231 - acc: 0.9102
2112/3015 [====================>.........] - ETA: 2s - loss: 0.2251 - acc: 0.9086
2176/3015 [====================>.........] - ETA: 2s - loss: 0.2277 - acc: 0.9067
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2276 - acc: 0.9071
2304/3015 [=====================>........] - ETA: 2s - loss: 0.2253 - acc: 0.9076
2368/3015 [======================>.......] - ETA: 2s - loss: 0.2238 - acc: 0.9084
2432/3015 [=======================>......] - ETA: 1s - loss: 0.2245 - acc: 0.9071
2496/3015 [=======================>......] - ETA: 1s - loss: 0.2224 - acc: 0.9083
2560/3015 [========================>.....] - ETA: 1s - loss: 0.2212 - acc: 0.9086
2624/3015 [=========================>....] - ETA: 1s - loss: 0.2203 - acc: 0.9085
2688/3015 [=========================>....] - ETA: 1s - loss: 0.2184 - acc: 0.9092
2752/3015 [==========================>...] - ETA: 0s - loss: 0.2201 - acc: 0.9081
2816/3015 [===========================>..] - ETA: 0s - loss: 0.2176 - acc: 0.9091
2880/3015 [===========================>..] - ETA: 0s - loss: 0.2153 - acc: 0.9101
2944/3015 [============================>.] - ETA: 0s - loss: 0.2169 - acc: 0.9093
3008/3015 [============================>.] - ETA: 0s - loss: 0.2168 - acc: 0.9096
3015/3015 [==============================] - 10s 3ms/step - loss: 0.2166 - acc: 0.9098

Test accuracy: 90.39039039039038

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  149

choose_one :  184

F1score :  0.9085714285714285

AUC :  0.9658754779597433

Confusion Matrix
[[142  25]
 [  7 159]]
True label 0
0.8502994011976048  
0.1497005988023952  
True label 1
0.04216867469879518  
0.9578313253012049  

Train_result {'acc': [0.9097844112769486], 'loss': [0.21660005098353965]}
Saved model to disk


7

Epoch 1/1

  64/3015 [..............................] - ETA: 9s - loss: 0.2758 - acc: 0.9219
 128/3015 [>.............................] - ETA: 9s - loss: 0.2217 - acc: 0.9375
 192/3015 [>.............................] - ETA: 12s - loss: 0.2212 - acc: 0.9375
 256/3015 [=>............................] - ETA: 11s - loss: 0.2279 - acc: 0.9219
 320/3015 [==>...........................] - ETA: 11s - loss: 0.2121 - acc: 0.9187
 384/3015 [==>...........................] - ETA: 11s - loss: 0.2276 - acc: 0.9141
 448/3015 [===>..........................] - ETA: 10s - loss: 0.2187 - acc: 0.9129
 512/3015 [====>.........................] - ETA: 9s - loss: 0.2159 - acc: 0.9180 
 576/3015 [====>.........................] - ETA: 9s - loss: 0.2144 - acc: 0.9149
 640/3015 [=====>........................] - ETA: 9s - loss: 0.2229 - acc: 0.9125
 704/3015 [======>.......................] - ETA: 8s - loss: 0.2316 - acc: 0.9134
 768/3015 [======>.......................] - ETA: 8s - loss: 0.2281 - acc: 0.9154
 832/3015 [=======>......................] - ETA: 8s - loss: 0.2225 - acc: 0.9159
 896/3015 [=======>......................] - ETA: 7s - loss: 0.2272 - acc: 0.9152
 960/3015 [========>.....................] - ETA: 7s - loss: 0.2304 - acc: 0.9125
1024/3015 [=========>....................] - ETA: 6s - loss: 0.2345 - acc: 0.9092
1088/3015 [=========>....................] - ETA: 6s - loss: 0.2353 - acc: 0.9072
1152/3015 [==========>...................] - ETA: 6s - loss: 0.2356 - acc: 0.9045
1216/3015 [===========>..................] - ETA: 6s - loss: 0.2401 - acc: 0.9005
1280/3015 [===========>..................] - ETA: 5s - loss: 0.2417 - acc: 0.8992
1344/3015 [============>.................] - ETA: 5s - loss: 0.2411 - acc: 0.8988
1408/3015 [=============>................] - ETA: 5s - loss: 0.2387 - acc: 0.9013
1472/3015 [=============>................] - ETA: 5s - loss: 0.2380 - acc: 0.9022
1536/3015 [==============>...............] - ETA: 5s - loss: 0.2359 - acc: 0.9043
1600/3015 [==============>...............] - ETA: 4s - loss: 0.2372 - acc: 0.9025
1664/3015 [===============>..............] - ETA: 4s - loss: 0.2348 - acc: 0.9044
1728/3015 [================>.............] - ETA: 4s - loss: 0.2318 - acc: 0.9057
1792/3015 [================>.............] - ETA: 4s - loss: 0.2317 - acc: 0.9046
1856/3015 [=================>............] - ETA: 4s - loss: 0.2288 - acc: 0.9057
1920/3015 [==================>...........] - ETA: 3s - loss: 0.2273 - acc: 0.9062
1984/3015 [==================>...........] - ETA: 3s - loss: 0.2280 - acc: 0.9068
2048/3015 [===================>..........] - ETA: 3s - loss: 0.2328 - acc: 0.9062
2112/3015 [====================>.........] - ETA: 3s - loss: 0.2307 - acc: 0.9072
2176/3015 [====================>.........] - ETA: 2s - loss: 0.2293 - acc: 0.9067
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2277 - acc: 0.9067
2304/3015 [=====================>........] - ETA: 2s - loss: 0.2256 - acc: 0.9076
2368/3015 [======================>.......] - ETA: 2s - loss: 0.2269 - acc: 0.9067
2432/3015 [=======================>......] - ETA: 1s - loss: 0.2245 - acc: 0.9071
2496/3015 [=======================>......] - ETA: 1s - loss: 0.2220 - acc: 0.9083
2560/3015 [========================>.....] - ETA: 1s - loss: 0.2224 - acc: 0.9082
2624/3015 [=========================>....] - ETA: 1s - loss: 0.2214 - acc: 0.9089
2688/3015 [=========================>....] - ETA: 1s - loss: 0.2232 - acc: 0.9081
2752/3015 [==========================>...] - ETA: 0s - loss: 0.2218 - acc: 0.9084
2816/3015 [===========================>..] - ETA: 0s - loss: 0.2220 - acc: 0.9084
2880/3015 [===========================>..] - ETA: 0s - loss: 0.2216 - acc: 0.9083
2944/3015 [============================>.] - ETA: 0s - loss: 0.2205 - acc: 0.9093
3008/3015 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9086
3015/3015 [==============================] - 10s 3ms/step - loss: 0.2208 - acc: 0.9088

Test accuracy: 89.1891891891892

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  145

choose_one :  188

F1score :  0.8983050847457628

AUC :  0.9653704638914941

Confusion Matrix
[[138  29]
 [  7 159]]
True label 0
0.8263473053892215  
0.17365269461077845  
True label 1
0.04216867469879518  
0.9578313253012049  

Train_result {'acc': [0.9087893864013267], 'loss': [0.22084086250211074]}
Saved model to disk


8

Epoch 1/1

  64/3015 [..............................] - ETA: 9s - loss: 0.2267 - acc: 0.8906
 128/3015 [>.............................] - ETA: 8s - loss: 0.2401 - acc: 0.8828
 192/3015 [>.............................] - ETA: 8s - loss: 0.2625 - acc: 0.8906
 256/3015 [=>............................] - ETA: 8s - loss: 0.2320 - acc: 0.8984
 320/3015 [==>...........................] - ETA: 9s - loss: 0.2195 - acc: 0.9031
 384/3015 [==>...........................] - ETA: 10s - loss: 0.2177 - acc: 0.9036
 448/3015 [===>..........................] - ETA: 10s - loss: 0.2042 - acc: 0.9107
 512/3015 [====>.........................] - ETA: 9s - loss: 0.2047 - acc: 0.9102 
 576/3015 [====>.........................] - ETA: 9s - loss: 0.2075 - acc: 0.9132
 640/3015 [=====>........................] - ETA: 8s - loss: 0.2047 - acc: 0.9141
 704/3015 [======>.......................] - ETA: 8s - loss: 0.2039 - acc: 0.9119
 768/3015 [======>.......................] - ETA: 8s - loss: 0.2030 - acc: 0.9115
 832/3015 [=======>......................] - ETA: 8s - loss: 0.2008 - acc: 0.9123
 896/3015 [=======>......................] - ETA: 7s - loss: 0.2019 - acc: 0.9118
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1978 - acc: 0.9135
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1985 - acc: 0.9131
1088/3015 [=========>....................] - ETA: 6s - loss: 0.1979 - acc: 0.9145
1152/3015 [==========>...................] - ETA: 6s - loss: 0.2001 - acc: 0.9141
1216/3015 [===========>..................] - ETA: 6s - loss: 0.1950 - acc: 0.9178
1280/3015 [===========>..................] - ETA: 5s - loss: 0.1983 - acc: 0.9164
1344/3015 [============>.................] - ETA: 5s - loss: 0.2069 - acc: 0.9122
1408/3015 [=============>................] - ETA: 5s - loss: 0.2085 - acc: 0.9134
1472/3015 [=============>................] - ETA: 5s - loss: 0.2092 - acc: 0.9137
1536/3015 [==============>...............] - ETA: 5s - loss: 0.2082 - acc: 0.9141
1600/3015 [==============>...............] - ETA: 4s - loss: 0.2099 - acc: 0.9119
1664/3015 [===============>..............] - ETA: 4s - loss: 0.2081 - acc: 0.9123
1728/3015 [================>.............] - ETA: 4s - loss: 0.2048 - acc: 0.9144
1792/3015 [================>.............] - ETA: 4s - loss: 0.2038 - acc: 0.9157
1856/3015 [=================>............] - ETA: 4s - loss: 0.2023 - acc: 0.9159
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1992 - acc: 0.9177
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1975 - acc: 0.9194
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1971 - acc: 0.9189
2112/3015 [====================>.........] - ETA: 3s - loss: 0.1942 - acc: 0.9205
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1934 - acc: 0.9210
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1936 - acc: 0.9196
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1949 - acc: 0.9188
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1929 - acc: 0.9193
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1922 - acc: 0.9194
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1933 - acc: 0.9191
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1900 - acc: 0.9207
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1895 - acc: 0.9215
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1885 - acc: 0.9222
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1895 - acc: 0.9215
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1894 - acc: 0.9222
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1906 - acc: 0.9229
2944/3015 [============================>.] - ETA: 0s - loss: 0.1903 - acc: 0.9229
3008/3015 [============================>.] - ETA: 0s - loss: 0.1919 - acc: 0.9229
3015/3015 [==============================] - 10s 3ms/step - loss: 0.1919 - acc: 0.9227

Test accuracy: 88.88888888888889

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  144

choose_one :  189

F1score :  0.895774647887324

AUC :  0.9627732486833562

Confusion Matrix
[[137  30]
 [  7 159]]
True label 0
0.8203592814371258  
0.17964071856287425  
True label 1
0.04216867469879518  
0.9578313253012049  

Train_result {'acc': [0.9227197346798025], 'loss': [0.19190604561201574]}
Saved model to disk


9

Epoch 1/1

  64/3015 [..............................] - ETA: 8s - loss: 0.1766 - acc: 0.9062
 128/3015 [>.............................] - ETA: 7s - loss: 0.1785 - acc: 0.8984
 192/3015 [>.............................] - ETA: 7s - loss: 0.1710 - acc: 0.9010
 256/3015 [=>............................] - ETA: 7s - loss: 0.1498 - acc: 0.9219
 320/3015 [==>...........................] - ETA: 7s - loss: 0.1772 - acc: 0.9125
 384/3015 [==>...........................] - ETA: 8s - loss: 0.1700 - acc: 0.9219
 448/3015 [===>..........................] - ETA: 9s - loss: 0.1771 - acc: 0.9196
 512/3015 [====>.........................] - ETA: 9s - loss: 0.1837 - acc: 0.9180
 576/3015 [====>.........................] - ETA: 8s - loss: 0.1833 - acc: 0.9184
 640/3015 [=====>........................] - ETA: 8s - loss: 0.1911 - acc: 0.9141
 704/3015 [======>.......................] - ETA: 8s - loss: 0.1897 - acc: 0.9134
 768/3015 [======>.......................] - ETA: 8s - loss: 0.1922 - acc: 0.9141
 832/3015 [=======>......................] - ETA: 7s - loss: 0.1918 - acc: 0.9159
 896/3015 [=======>......................] - ETA: 7s - loss: 0.1980 - acc: 0.9129
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1934 - acc: 0.9156
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1909 - acc: 0.9170
1088/3015 [=========>....................] - ETA: 6s - loss: 0.1910 - acc: 0.9182
1152/3015 [==========>...................] - ETA: 6s - loss: 0.1949 - acc: 0.9149
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1938 - acc: 0.9161
1280/3015 [===========>..................] - ETA: 5s - loss: 0.2010 - acc: 0.9102
1344/3015 [============>.................] - ETA: 5s - loss: 0.2050 - acc: 0.9107
1408/3015 [=============>................] - ETA: 5s - loss: 0.2047 - acc: 0.9105
1472/3015 [=============>................] - ETA: 4s - loss: 0.2032 - acc: 0.9130
1536/3015 [==============>...............] - ETA: 4s - loss: 0.2064 - acc: 0.9128
1600/3015 [==============>...............] - ETA: 4s - loss: 0.2033 - acc: 0.9144
1664/3015 [===============>..............] - ETA: 4s - loss: 0.2022 - acc: 0.9141
1728/3015 [================>.............] - ETA: 4s - loss: 0.1996 - acc: 0.9161
1792/3015 [================>.............] - ETA: 4s - loss: 0.2041 - acc: 0.9174
1856/3015 [=================>............] - ETA: 3s - loss: 0.2039 - acc: 0.9181
1920/3015 [==================>...........] - ETA: 3s - loss: 0.2009 - acc: 0.9203
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1993 - acc: 0.9214
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1969 - acc: 0.9214
2112/3015 [====================>.........] - ETA: 3s - loss: 0.1941 - acc: 0.9228
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1922 - acc: 0.9228
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1913 - acc: 0.9237
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1930 - acc: 0.9232
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1952 - acc: 0.9231
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1949 - acc: 0.9235
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1954 - acc: 0.9235
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1979 - acc: 0.9211
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1960 - acc: 0.9219
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1966 - acc: 0.9211
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1951 - acc: 0.9219
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1958 - acc: 0.9212
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1974 - acc: 0.9208
2944/3015 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9215
3008/3015 [============================>.] - ETA: 0s - loss: 0.1944 - acc: 0.9229
3015/3015 [==============================] - 10s 3ms/step - loss: 0.1942 - acc: 0.9231

Test accuracy: 91.29129129129129

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  152

choose_one :  181

F1score :  0.9164265129682997

AUC :  0.9675348098982757

Confusion Matrix
[[145  22]
 [  7 159]]
True label 0
0.8682634730538922  
0.1317365269461078  
True label 1
0.04216867469879518  
0.9578313253012049  

Train_result {'acc': [0.9230514096185738], 'loss': [0.19417469469123022]}
Saved model to disk


10

Epoch 1/1

  64/3015 [..............................] - ETA: 8s - loss: 0.1526 - acc: 0.9688
 128/3015 [>.............................] - ETA: 7s - loss: 0.1842 - acc: 0.9219
 192/3015 [>.............................] - ETA: 7s - loss: 0.1839 - acc: 0.9219
 256/3015 [=>............................] - ETA: 7s - loss: 0.1700 - acc: 0.9297
 320/3015 [==>...........................] - ETA: 7s - loss: 0.1652 - acc: 0.9344
 384/3015 [==>...........................] - ETA: 6s - loss: 0.1561 - acc: 0.9375
 448/3015 [===>..........................] - ETA: 6s - loss: 0.1773 - acc: 0.9308
 512/3015 [====>.........................] - ETA: 7s - loss: 0.1799 - acc: 0.9277
 576/3015 [====>.........................] - ETA: 7s - loss: 0.1781 - acc: 0.9288
 640/3015 [=====>........................] - ETA: 7s - loss: 0.1794 - acc: 0.9266
 704/3015 [======>.......................] - ETA: 7s - loss: 0.1743 - acc: 0.9276
 768/3015 [======>.......................] - ETA: 7s - loss: 0.1798 - acc: 0.9258
 832/3015 [=======>......................] - ETA: 7s - loss: 0.1749 - acc: 0.9279
 896/3015 [=======>......................] - ETA: 7s - loss: 0.1806 - acc: 0.9241
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1847 - acc: 0.9240
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1927 - acc: 0.9229
1088/3015 [=========>....................] - ETA: 6s - loss: 0.1925 - acc: 0.9228
1152/3015 [==========>...................] - ETA: 6s - loss: 0.1924 - acc: 0.9201
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1871 - acc: 0.9227
1280/3015 [===========>..................] - ETA: 5s - loss: 0.1865 - acc: 0.9250
1344/3015 [============>.................] - ETA: 5s - loss: 0.1869 - acc: 0.9241
1408/3015 [=============>................] - ETA: 5s - loss: 0.1853 - acc: 0.9247
1472/3015 [=============>................] - ETA: 4s - loss: 0.1864 - acc: 0.9253
1536/3015 [==============>...............] - ETA: 4s - loss: 0.1860 - acc: 0.9258
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1850 - acc: 0.9269
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1801 - acc: 0.9291
1728/3015 [================>.............] - ETA: 4s - loss: 0.1773 - acc: 0.9306
1792/3015 [================>.............] - ETA: 3s - loss: 0.1770 - acc: 0.9302
1856/3015 [=================>............] - ETA: 3s - loss: 0.1798 - acc: 0.9289
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1820 - acc: 0.9286
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1833 - acc: 0.9279
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1808 - acc: 0.9292
2112/3015 [====================>.........] - ETA: 2s - loss: 0.1832 - acc: 0.9280
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1839 - acc: 0.9269
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1858 - acc: 0.9254
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1847 - acc: 0.9258
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1836 - acc: 0.9265
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1842 - acc: 0.9264
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1851 - acc: 0.9255
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1844 - acc: 0.9258
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1836 - acc: 0.9261
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1839 - acc: 0.9260
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1834 - acc: 0.9259
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1844 - acc: 0.9254
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1830 - acc: 0.9267
2944/3015 [============================>.] - ETA: 0s - loss: 0.1843 - acc: 0.9263
3008/3015 [============================>.] - ETA: 0s - loss: 0.1872 - acc: 0.9249
3015/3015 [==============================] - 10s 3ms/step - loss: 0.1870 - acc: 0.9250

Test accuracy: 90.990990990991

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  165

choose_one :  168

F1score :  0.9101796407185628

AUC :  0.9697352283385037

Confusion Matrix
[[151  16]
 [ 14 152]]
True label 0
0.9041916167664671  
0.09580838323353294  
True label 1
0.08433734939759036  
0.9156626506024096  

Train_result {'acc': [0.9250414593698176], 'loss': [0.18696547249952952]}
Saved model to disk


11

Epoch 1/1

  64/3015 [..............................] - ETA: 9s - loss: 0.1867 - acc: 0.9219
 128/3015 [>.............................] - ETA: 7s - loss: 0.1360 - acc: 0.9453
 192/3015 [>.............................] - ETA: 7s - loss: 0.1927 - acc: 0.9167
 256/3015 [=>............................] - ETA: 7s - loss: 0.1795 - acc: 0.9219
 320/3015 [==>...........................] - ETA: 7s - loss: 0.1789 - acc: 0.9250
 384/3015 [==>...........................] - ETA: 6s - loss: 0.1749 - acc: 0.9219
 448/3015 [===>..........................] - ETA: 6s - loss: 0.1804 - acc: 0.9196
 512/3015 [====>.........................] - ETA: 6s - loss: 0.1813 - acc: 0.9199
 576/3015 [====>.........................] - ETA: 6s - loss: 0.1721 - acc: 0.9236
 640/3015 [=====>........................] - ETA: 6s - loss: 0.1652 - acc: 0.9297
 704/3015 [======>.......................] - ETA: 6s - loss: 0.1577 - acc: 0.9332
 768/3015 [======>.......................] - ETA: 6s - loss: 0.1551 - acc: 0.9336
 832/3015 [=======>......................] - ETA: 6s - loss: 0.1511 - acc: 0.9363
 896/3015 [=======>......................] - ETA: 6s - loss: 0.1598 - acc: 0.9319
 960/3015 [========>.....................] - ETA: 6s - loss: 0.1538 - acc: 0.9344
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1510 - acc: 0.9346
1088/3015 [=========>....................] - ETA: 6s - loss: 0.1505 - acc: 0.9366
1152/3015 [==========>...................] - ETA: 6s - loss: 0.1502 - acc: 0.9358
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1496 - acc: 0.9350
1280/3015 [===========>..................] - ETA: 5s - loss: 0.1499 - acc: 0.9359
1344/3015 [============>.................] - ETA: 5s - loss: 0.1638 - acc: 0.9293
1408/3015 [=============>................] - ETA: 5s - loss: 0.1608 - acc: 0.9304
1472/3015 [=============>................] - ETA: 4s - loss: 0.1602 - acc: 0.9300
1536/3015 [==============>...............] - ETA: 4s - loss: 0.1565 - acc: 0.9323
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1589 - acc: 0.9306
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1574 - acc: 0.9309
1728/3015 [================>.............] - ETA: 3s - loss: 0.1566 - acc: 0.9323
1792/3015 [================>.............] - ETA: 3s - loss: 0.1602 - acc: 0.9319
1856/3015 [=================>............] - ETA: 3s - loss: 0.1580 - acc: 0.9332
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1594 - acc: 0.9333
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1583 - acc: 0.9340
2048/3015 [===================>..........] - ETA: 2s - loss: 0.1597 - acc: 0.9341
2112/3015 [====================>.........] - ETA: 2s - loss: 0.1608 - acc: 0.9328
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1582 - acc: 0.9334
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1572 - acc: 0.9339
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1575 - acc: 0.9340
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1553 - acc: 0.9354
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1577 - acc: 0.9350
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1584 - acc: 0.9343
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1577 - acc: 0.9348
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1589 - acc: 0.9348
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1583 - acc: 0.9345
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1577 - acc: 0.9346
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1567 - acc: 0.9343
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1561 - acc: 0.9337
2944/3015 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9327
3008/3015 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9328
3015/3015 [==============================] - 9s 3ms/step - loss: 0.1581 - acc: 0.9330

Test accuracy: 90.09009009009009

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  152

choose_one :  181

F1score :  0.9048991354466858

AUC :  0.967354447731044

Confusion Matrix
[[143  24]
 [  9 157]]
True label 0
0.8562874251497006  
0.1437125748502994  
True label 1
0.05421686746987952  
0.9457831325301205  

Train_result {'acc': [0.9330016583747927], 'loss': [0.1580586968357389]}
Saved model to disk


12

Epoch 1/1

  64/3015 [..............................] - ETA: 16s - loss: 0.0604 - acc: 0.9844
 128/3015 [>.............................] - ETA: 12s - loss: 0.1923 - acc: 0.9453
 192/3015 [>.............................] - ETA: 10s - loss: 0.2193 - acc: 0.9219
 256/3015 [=>............................] - ETA: 11s - loss: 0.2279 - acc: 0.9180
 320/3015 [==>...........................] - ETA: 10s - loss: 0.2303 - acc: 0.9156
 384/3015 [==>...........................] - ETA: 9s - loss: 0.2141 - acc: 0.9193 
 448/3015 [===>..........................] - ETA: 9s - loss: 0.2093 - acc: 0.9174
 512/3015 [====>.........................] - ETA: 8s - loss: 0.2129 - acc: 0.9199
 576/3015 [====>.........................] - ETA: 8s - loss: 0.2058 - acc: 0.9201
 640/3015 [=====>........................] - ETA: 7s - loss: 0.1958 - acc: 0.9266
 704/3015 [======>.......................] - ETA: 7s - loss: 0.1932 - acc: 0.9261
 768/3015 [======>.......................] - ETA: 6s - loss: 0.1885 - acc: 0.9271
 832/3015 [=======>......................] - ETA: 6s - loss: 0.1829 - acc: 0.9315
 896/3015 [=======>......................] - ETA: 6s - loss: 0.1845 - acc: 0.9319
 960/3015 [========>.....................] - ETA: 5s - loss: 0.1791 - acc: 0.9344
1024/3015 [=========>....................] - ETA: 5s - loss: 0.1807 - acc: 0.9336
1088/3015 [=========>....................] - ETA: 5s - loss: 0.1877 - acc: 0.9320
1152/3015 [==========>...................] - ETA: 5s - loss: 0.1856 - acc: 0.9332
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1807 - acc: 0.9350
1280/3015 [===========>..................] - ETA: 5s - loss: 0.1761 - acc: 0.9359
1344/3015 [============>.................] - ETA: 5s - loss: 0.1738 - acc: 0.9360
1408/3015 [=============>................] - ETA: 5s - loss: 0.1761 - acc: 0.9361
1472/3015 [=============>................] - ETA: 4s - loss: 0.1736 - acc: 0.9368
1536/3015 [==============>...............] - ETA: 4s - loss: 0.1719 - acc: 0.9362
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1693 - acc: 0.9363
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1680 - acc: 0.9363
1728/3015 [================>.............] - ETA: 4s - loss: 0.1685 - acc: 0.9346
1792/3015 [================>.............] - ETA: 3s - loss: 0.1676 - acc: 0.9342
1856/3015 [=================>............] - ETA: 3s - loss: 0.1653 - acc: 0.9348
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1629 - acc: 0.9359
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1650 - acc: 0.9350
2048/3015 [===================>..........] - ETA: 2s - loss: 0.1688 - acc: 0.9336
2112/3015 [====================>.........] - ETA: 2s - loss: 0.1688 - acc: 0.9332
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1662 - acc: 0.9343
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1665 - acc: 0.9339
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1639 - acc: 0.9353
2368/3015 [======================>.......] - ETA: 1s - loss: 0.1652 - acc: 0.9358
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1642 - acc: 0.9363
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1635 - acc: 0.9371
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1645 - acc: 0.9359
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1657 - acc: 0.9348
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1648 - acc: 0.9353
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1648 - acc: 0.9346
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1636 - acc: 0.9347
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1616 - acc: 0.9358
2944/3015 [============================>.] - ETA: 0s - loss: 0.1594 - acc: 0.9365
3008/3015 [============================>.] - ETA: 0s - loss: 0.1603 - acc: 0.9362
3015/3015 [==============================] - 10s 3ms/step - loss: 0.1600 - acc: 0.9363

Test accuracy: 91.8918918918919

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  176

choose_one :  157

F1score :  0.9164086687306501

AUC :  0.9712502705432507

Confusion Matrix
[[158   9]
 [ 18 148]]
True label 0
0.9461077844311377  
0.05389221556886228  
True label 1
0.10843373493975904  
0.891566265060241  

Train_result {'acc': [0.936318407960199], 'loss': [0.15999145107946142]}
Saved model to disk


13

Epoch 1/1

  64/3015 [..............................] - ETA: 10s - loss: 0.2180 - acc: 0.9062
 128/3015 [>.............................] - ETA: 9s - loss: 0.1969 - acc: 0.9297 
 192/3015 [>.............................] - ETA: 10s - loss: 0.1622 - acc: 0.9427
 256/3015 [=>............................] - ETA: 10s - loss: 0.1723 - acc: 0.9414
 320/3015 [==>...........................] - ETA: 10s - loss: 0.1721 - acc: 0.9406
 384/3015 [==>...........................] - ETA: 10s - loss: 0.1643 - acc: 0.9375
 448/3015 [===>..........................] - ETA: 10s - loss: 0.1712 - acc: 0.9397
 512/3015 [====>.........................] - ETA: 9s - loss: 0.1718 - acc: 0.9375 
 576/3015 [====>.........................] - ETA: 9s - loss: 0.1645 - acc: 0.9427
 640/3015 [=====>........................] - ETA: 9s - loss: 0.1725 - acc: 0.9375
 704/3015 [======>.......................] - ETA: 8s - loss: 0.1612 - acc: 0.9418
 768/3015 [======>.......................] - ETA: 8s - loss: 0.1558 - acc: 0.9427
 832/3015 [=======>......................] - ETA: 7s - loss: 0.1518 - acc: 0.9447
 896/3015 [=======>......................] - ETA: 7s - loss: 0.1500 - acc: 0.9442
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1433 - acc: 0.9479
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1425 - acc: 0.9502
1088/3015 [=========>....................] - ETA: 6s - loss: 0.1446 - acc: 0.9504
1152/3015 [==========>...................] - ETA: 6s - loss: 0.1388 - acc: 0.9523
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1361 - acc: 0.9531
1280/3015 [===========>..................] - ETA: 5s - loss: 0.1369 - acc: 0.9523
1344/3015 [============>.................] - ETA: 5s - loss: 0.1430 - acc: 0.9487
1408/3015 [=============>................] - ETA: 5s - loss: 0.1431 - acc: 0.9489
1472/3015 [=============>................] - ETA: 4s - loss: 0.1402 - acc: 0.9497
1536/3015 [==============>...............] - ETA: 4s - loss: 0.1442 - acc: 0.9486
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1490 - acc: 0.9469
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1502 - acc: 0.9459
1728/3015 [================>.............] - ETA: 4s - loss: 0.1485 - acc: 0.9468
1792/3015 [================>.............] - ETA: 4s - loss: 0.1476 - acc: 0.9470
1856/3015 [=================>............] - ETA: 3s - loss: 0.1502 - acc: 0.9461
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1497 - acc: 0.9464
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1509 - acc: 0.9456
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1500 - acc: 0.9453
2112/3015 [====================>.........] - ETA: 3s - loss: 0.1500 - acc: 0.9446
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1500 - acc: 0.9439
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1501 - acc: 0.9433
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1524 - acc: 0.9418
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1528 - acc: 0.9421
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1523 - acc: 0.9428
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1548 - acc: 0.9415
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1547 - acc: 0.9410
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1541 - acc: 0.9413
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1536 - acc: 0.9412
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1539 - acc: 0.9408
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1542 - acc: 0.9403
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1525 - acc: 0.9410
2944/3015 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9409
3008/3015 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9412
3015/3015 [==============================] - 10s 3ms/step - loss: 0.1510 - acc: 0.9410

Test accuracy: 90.990990990991

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  157

choose_one :  176

F1score :  0.912280701754386

AUC :  0.9680037515330784

Confusion Matrix
[[147  20]
 [ 10 156]]
True label 0
0.8802395209580839  
0.11976047904191617  
True label 1
0.060240963855421686  
0.9397590361445783  

Train_result {'acc': [0.9409618573995372], 'loss': [0.15101782229804675]}
Saved model to disk


14

Epoch 1/1

  64/3015 [..............................] - ETA: 8s - loss: 0.1813 - acc: 0.9688
 128/3015 [>.............................] - ETA: 7s - loss: 0.2106 - acc: 0.9297
 192/3015 [>.............................] - ETA: 7s - loss: 0.1724 - acc: 0.9427
 256/3015 [=>............................] - ETA: 7s - loss: 0.1696 - acc: 0.9414
 320/3015 [==>...........................] - ETA: 7s - loss: 0.1565 - acc: 0.9469
 384/3015 [==>...........................] - ETA: 8s - loss: 0.1454 - acc: 0.9453
 448/3015 [===>..........................] - ETA: 8s - loss: 0.1515 - acc: 0.9397
 512/3015 [====>.........................] - ETA: 8s - loss: 0.1494 - acc: 0.9414
 576/3015 [====>.........................] - ETA: 8s - loss: 0.1390 - acc: 0.9444
 640/3015 [=====>........................] - ETA: 8s - loss: 0.1504 - acc: 0.9406
 704/3015 [======>.......................] - ETA: 7s - loss: 0.1521 - acc: 0.9389
 768/3015 [======>.......................] - ETA: 7s - loss: 0.1501 - acc: 0.9401
 832/3015 [=======>......................] - ETA: 7s - loss: 0.1439 - acc: 0.9423
 896/3015 [=======>......................] - ETA: 7s - loss: 0.1402 - acc: 0.9442
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1390 - acc: 0.9448
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1451 - acc: 0.9443
1088/3015 [=========>....................] - ETA: 6s - loss: 0.1468 - acc: 0.9449
1152/3015 [==========>...................] - ETA: 6s - loss: 0.1519 - acc: 0.9436
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1488 - acc: 0.9441
1280/3015 [===========>..................] - ETA: 5s - loss: 0.1467 - acc: 0.9445
1344/3015 [============>.................] - ETA: 5s - loss: 0.1528 - acc: 0.9420
1408/3015 [=============>................] - ETA: 4s - loss: 0.1494 - acc: 0.9439
1472/3015 [=============>................] - ETA: 4s - loss: 0.1492 - acc: 0.9436
1536/3015 [==============>...............] - ETA: 4s - loss: 0.1501 - acc: 0.9440
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1535 - acc: 0.9425
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1545 - acc: 0.9429
1728/3015 [================>.............] - ETA: 3s - loss: 0.1572 - acc: 0.9427
1792/3015 [================>.............] - ETA: 3s - loss: 0.1580 - acc: 0.9425
1856/3015 [=================>............] - ETA: 3s - loss: 0.1543 - acc: 0.9445
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1538 - acc: 0.9443
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1509 - acc: 0.9451
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1516 - acc: 0.9438
2112/3015 [====================>.........] - ETA: 2s - loss: 0.1559 - acc: 0.9413
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1559 - acc: 0.9412
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1564 - acc: 0.9406
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1565 - acc: 0.9410
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1570 - acc: 0.9405
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1563 - acc: 0.9412
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1551 - acc: 0.9419
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1560 - acc: 0.9406
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1550 - acc: 0.9409
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1560 - acc: 0.9394
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1555 - acc: 0.9393
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1548 - acc: 0.9396
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1543 - acc: 0.9396
2944/3015 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9392
3008/3015 [============================>.] - ETA: 0s - loss: 0.1570 - acc: 0.9375
3015/3015 [==============================] - 9s 3ms/step - loss: 0.1566 - acc: 0.9376

Test accuracy: 91.8918918918919

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  164

choose_one :  169

F1score :  0.9194029850746269

AUC :  0.9668494336627949

Confusion Matrix
[[152  15]
 [ 12 154]]
True label 0
0.9101796407185628  
0.08982035928143713  
True label 1
0.07228915662650602  
0.927710843373494  

Train_result {'acc': [0.9376451077943615], 'loss': [0.1566356074503603]}
Saved model to disk


15

Epoch 1/1

  64/3015 [..............................] - ETA: 13s - loss: 0.1385 - acc: 0.9375
 128/3015 [>.............................] - ETA: 10s - loss: 0.1894 - acc: 0.9141
 192/3015 [>.............................] - ETA: 9s - loss: 0.1683 - acc: 0.9167 
 256/3015 [=>............................] - ETA: 8s - loss: 0.1597 - acc: 0.9258
 320/3015 [==>...........................] - ETA: 8s - loss: 0.1499 - acc: 0.9375
 384/3015 [==>...........................] - ETA: 7s - loss: 0.1405 - acc: 0.9427
 448/3015 [===>..........................] - ETA: 7s - loss: 0.1323 - acc: 0.9487
 512/3015 [====>.........................] - ETA: 7s - loss: 0.1314 - acc: 0.9473
 576/3015 [====>.........................] - ETA: 6s - loss: 0.1395 - acc: 0.9462
 640/3015 [=====>........................] - ETA: 6s - loss: 0.1406 - acc: 0.9484
 704/3015 [======>.......................] - ETA: 6s - loss: 0.1397 - acc: 0.9489
 768/3015 [======>.......................] - ETA: 6s - loss: 0.1428 - acc: 0.9505
 832/3015 [=======>......................] - ETA: 6s - loss: 0.1405 - acc: 0.9519
 896/3015 [=======>......................] - ETA: 6s - loss: 0.1433 - acc: 0.9509
 960/3015 [========>.....................] - ETA: 6s - loss: 0.1474 - acc: 0.9458
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1407 - acc: 0.9492
1088/3015 [=========>....................] - ETA: 6s - loss: 0.1350 - acc: 0.9513
1152/3015 [==========>...................] - ETA: 5s - loss: 0.1355 - acc: 0.9505
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1320 - acc: 0.9515
1280/3015 [===========>..................] - ETA: 5s - loss: 0.1321 - acc: 0.9531
1344/3015 [============>.................] - ETA: 5s - loss: 0.1304 - acc: 0.9531
1408/3015 [=============>................] - ETA: 5s - loss: 0.1282 - acc: 0.9538
1472/3015 [=============>................] - ETA: 4s - loss: 0.1267 - acc: 0.9545
1536/3015 [==============>...............] - ETA: 4s - loss: 0.1265 - acc: 0.9544
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1260 - acc: 0.9550
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1246 - acc: 0.9555
1728/3015 [================>.............] - ETA: 3s - loss: 0.1231 - acc: 0.9549
1792/3015 [================>.............] - ETA: 3s - loss: 0.1253 - acc: 0.9537
1856/3015 [=================>............] - ETA: 3s - loss: 0.1249 - acc: 0.9542
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1256 - acc: 0.9531
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1277 - acc: 0.9516
2048/3015 [===================>..........] - ETA: 2s - loss: 0.1273 - acc: 0.9521
2112/3015 [====================>.........] - ETA: 2s - loss: 0.1365 - acc: 0.9498
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1366 - acc: 0.9504
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1361 - acc: 0.9500
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1350 - acc: 0.9510
2368/3015 [======================>.......] - ETA: 1s - loss: 0.1361 - acc: 0.9502
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1363 - acc: 0.9494
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1369 - acc: 0.9491
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1391 - acc: 0.9480
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1400 - acc: 0.9474
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1392 - acc: 0.9479
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1406 - acc: 0.9473
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1398 - acc: 0.9474
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1405 - acc: 0.9465
2944/3015 [============================>.] - ETA: 0s - loss: 0.1396 - acc: 0.9467
3008/3015 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9471
3015/3015 [==============================] - 9s 3ms/step - loss: 0.1389 - acc: 0.9473

Test accuracy: 90.39039039039038

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  161

choose_one :  172

F1score :  0.9053254437869822

AUC :  0.9691219969699155

Confusion Matrix
[[148  19]
 [ 13 153]]
True label 0
0.8862275449101796  
0.11377245508982035  
True label 1
0.0783132530120482  
0.9216867469879518  

Train_result {'acc': [0.9472636815920398], 'loss': [0.13891582511881656]}
Saved model to disk


[[89.7897897897898, 1], [89.4894894894895, 2], [89.4894894894895, 3], [91.29129129129129, 4], [90.39039039039038, 5], [90.39039039039038, 6], [89.1891891891892, 7], [88.88888888888889, 8], [91.29129129129129, 9], [90.990990990991, 10], [90.09009009009009, 11], [91.8918918918919, 12], [90.990990990991, 13], [91.8918918918919, 14], [90.39039039039038, 15]]
max accuracy :  [91.8918918918919, 14]
