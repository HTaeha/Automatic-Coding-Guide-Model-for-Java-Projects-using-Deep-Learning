Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
/home/2014313303/taeha/JavaAutoLogging/model.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor("de..., inputs=Tensor("in...)`
  model = Model(input=inputs, output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-07 17:07:46.705749: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-07 17:07:46.711800: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100005000 Hz
2019-09-07 17:07:46.713231: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x9a584a0 executing computations on platform Host. Devices:
2019-09-07 17:07:46.713250: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
zero : 
39451

one : 
9019

Sentence length Average : 85

Under 10 : 7243
Over 10, Under 30 : 16559
Over 30, Under 100 : 12738
Over 100, Under 150 : 3895
Over 150, Under 200 : 2319
Over 200, Under 400 : 3915
Over 400 : 1801

After set document size of train data, the number of zero and one label data :  20266 2198
After set document size of test data, the number of zero and one label data :  2251 243
After balance out data.

Sentence length Average : 40

Under 10 : 82
Over 10, Under 30 : 1863
Over 30, Under 100 : 2337
Over 100, Under 150 : 102
Over 150, Under 200 : 2
Over 200, Under 400 : 8
Over 400 : 3


Sentence length Average : 41

Under 10 : 9
Over 10, Under 30 : 207
Over 30, Under 100 : 252
Over 100, Under 150 : 18
Over 150, Under 200 : 0
Over 200, Under 400 : 1
Over 400 : 0

Count model parameter.
Get a short summary of each layer dimensions and parameters.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 50, 200)      0                                            
__________________________________________________________________________________________________
masking_1 (Masking)             (None, 50, 200)      0           input_1[0][0]                    
__________________________________________________________________________________________________
lstm_1 (LSTM)                   (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
lstm_2 (LSTM)                   (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 64)           0           lstm_1[0][0]                     
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 64)           0           lstm_2[0][0]                     
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128)          0           dropout_1[0][0]                  
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 128)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2)            258         dropout_3[0][0]                  
==================================================================================================
Total params: 135,938
Trainable params: 135,938
Non-trainable params: 0
__________________________________________________________________________________________________
1

Epoch 1/1

  64/4397 [..............................] - ETA: 1:24 - loss: 0.6982 - acc: 0.5156
 128/4397 [..............................] - ETA: 43s - loss: 0.6818 - acc: 0.5391 
 192/4397 [>.............................] - ETA: 29s - loss: 0.6322 - acc: 0.6146
 256/4397 [>.............................] - ETA: 22s - loss: 0.6212 - acc: 0.6328
 320/4397 [=>............................] - ETA: 18s - loss: 0.6020 - acc: 0.6562
 384/4397 [=>............................] - ETA: 15s - loss: 0.5822 - acc: 0.6823
 448/4397 [==>...........................] - ETA: 13s - loss: 0.5787 - acc: 0.6808
 512/4397 [==>...........................] - ETA: 12s - loss: 0.5836 - acc: 0.6797
 576/4397 [==>...........................] - ETA: 11s - loss: 0.5829 - acc: 0.6823
 640/4397 [===>..........................] - ETA: 10s - loss: 0.5653 - acc: 0.7000
 704/4397 [===>..........................] - ETA: 9s - loss: 0.5565 - acc: 0.7074 
 768/4397 [====>.........................] - ETA: 8s - loss: 0.5534 - acc: 0.7122
 832/4397 [====>.........................] - ETA: 8s - loss: 0.5478 - acc: 0.7163
 896/4397 [=====>........................] - ETA: 7s - loss: 0.5389 - acc: 0.7221
 960/4397 [=====>........................] - ETA: 7s - loss: 0.5317 - acc: 0.7271
1024/4397 [=====>........................] - ETA: 6s - loss: 0.5317 - acc: 0.7285
1152/4397 [======>.......................] - ETA: 6s - loss: 0.5235 - acc: 0.7335
1216/4397 [=======>......................] - ETA: 5s - loss: 0.5196 - acc: 0.7368
1280/4397 [=======>......................] - ETA: 5s - loss: 0.5173 - acc: 0.7398
1344/4397 [========>.....................] - ETA: 5s - loss: 0.5146 - acc: 0.7403
1408/4397 [========>.....................] - ETA: 4s - loss: 0.5135 - acc: 0.7386
1472/4397 [=========>....................] - ETA: 4s - loss: 0.5116 - acc: 0.7391
1536/4397 [=========>....................] - ETA: 4s - loss: 0.5117 - acc: 0.7383
1600/4397 [=========>....................] - ETA: 4s - loss: 0.5043 - acc: 0.7450
1664/4397 [==========>...................] - ETA: 4s - loss: 0.5016 - acc: 0.7452
1728/4397 [==========>...................] - ETA: 4s - loss: 0.5027 - acc: 0.7454
1792/4397 [===========>..................] - ETA: 3s - loss: 0.4983 - acc: 0.7483
1856/4397 [===========>..................] - ETA: 3s - loss: 0.4966 - acc: 0.7505
1984/4397 [============>.................] - ETA: 3s - loss: 0.4968 - acc: 0.7520
2048/4397 [============>.................] - ETA: 3s - loss: 0.4967 - acc: 0.7515
2112/4397 [=============>................] - ETA: 3s - loss: 0.4950 - acc: 0.7528
2240/4397 [==============>...............] - ETA: 2s - loss: 0.4900 - acc: 0.7545
2304/4397 [==============>...............] - ETA: 2s - loss: 0.4872 - acc: 0.7561
2368/4397 [===============>..............] - ETA: 2s - loss: 0.4858 - acc: 0.7563
2432/4397 [===============>..............] - ETA: 2s - loss: 0.4870 - acc: 0.7558
2496/4397 [================>.............] - ETA: 2s - loss: 0.4867 - acc: 0.7580
2560/4397 [================>.............] - ETA: 2s - loss: 0.4867 - acc: 0.7582
2688/4397 [=================>............] - ETA: 2s - loss: 0.4849 - acc: 0.7600
2752/4397 [=================>............] - ETA: 2s - loss: 0.4837 - acc: 0.7609
2816/4397 [==================>...........] - ETA: 1s - loss: 0.4850 - acc: 0.7607
2880/4397 [==================>...........] - ETA: 1s - loss: 0.4848 - acc: 0.7611
2944/4397 [===================>..........] - ETA: 1s - loss: 0.4855 - acc: 0.7605
3008/4397 [===================>..........] - ETA: 1s - loss: 0.4838 - acc: 0.7620
3072/4397 [===================>..........] - ETA: 1s - loss: 0.4819 - acc: 0.7620
3136/4397 [====================>.........] - ETA: 1s - loss: 0.4790 - acc: 0.7640
3200/4397 [====================>.........] - ETA: 1s - loss: 0.4811 - acc: 0.7634
3328/4397 [=====================>........] - ETA: 1s - loss: 0.4846 - acc: 0.7626
3392/4397 [======================>.......] - ETA: 1s - loss: 0.4833 - acc: 0.7627
3456/4397 [======================>.......] - ETA: 1s - loss: 0.4821 - acc: 0.7633
3520/4397 [=======================>......] - ETA: 1s - loss: 0.4812 - acc: 0.7636
3584/4397 [=======================>......] - ETA: 0s - loss: 0.4800 - acc: 0.7653
3712/4397 [========================>.....] - ETA: 0s - loss: 0.4749 - acc: 0.7686
3840/4397 [=========================>....] - ETA: 0s - loss: 0.4730 - acc: 0.7693
3904/4397 [=========================>....] - ETA: 0s - loss: 0.4710 - acc: 0.7702
3968/4397 [==========================>...] - ETA: 0s - loss: 0.4703 - acc: 0.7709
4032/4397 [==========================>...] - ETA: 0s - loss: 0.4700 - acc: 0.7711
4096/4397 [==========================>...] - ETA: 0s - loss: 0.4672 - acc: 0.7729
4160/4397 [===========================>..] - ETA: 0s - loss: 0.4659 - acc: 0.7733
4224/4397 [===========================>..] - ETA: 0s - loss: 0.4652 - acc: 0.7737
4288/4397 [============================>.] - ETA: 0s - loss: 0.4626 - acc: 0.7752
4352/4397 [============================>.] - ETA: 0s - loss: 0.4630 - acc: 0.7753
4397/4397 [==============================] - 5s 1ms/step - loss: 0.4619 - acc: 0.7760

Test accuracy: 81.72484599589322

data size :  4884

zero :  2443

one :  2441

train_zero :  2199

train_one :  2198

test_zero :  244

test_one :  243

choose_zero :  217

choose_one :  270

F1score :  0.8265107212475634

AUC :  0.9153764420157863

Confusion Matrix
[[186  58]
 [ 31 212]]
True label 0
0.7622950819672131  
0.23770491803278687  
True label 1
0.12757201646090535  
0.8724279835390947  

Train_result {'acc': [0.7759836252938895], 'loss': [0.46185064050780933]}
Saved model to disk


2

Epoch 1/1

  64/4397 [..............................] - ETA: 4s - loss: 0.4711 - acc: 0.8125
 128/4397 [..............................] - ETA: 3s - loss: 0.4445 - acc: 0.7812
 192/4397 [>.............................] - ETA: 4s - loss: 0.4281 - acc: 0.7969
 256/4397 [>.............................] - ETA: 3s - loss: 0.4218 - acc: 0.8008
 320/4397 [=>............................] - ETA: 3s - loss: 0.4109 - acc: 0.8063
 448/4397 [==>...........................] - ETA: 3s - loss: 0.4037 - acc: 0.8214
 512/4397 [==>...........................] - ETA: 3s - loss: 0.4043 - acc: 0.8242
 640/4397 [===>..........................] - ETA: 3s - loss: 0.3932 - acc: 0.8266
 704/4397 [===>..........................] - ETA: 3s - loss: 0.3881 - acc: 0.8310
 768/4397 [====>.........................] - ETA: 3s - loss: 0.3962 - acc: 0.8255
 832/4397 [====>.........................] - ETA: 2s - loss: 0.3923 - acc: 0.8269
 896/4397 [=====>........................] - ETA: 2s - loss: 0.3807 - acc: 0.8326
 960/4397 [=====>........................] - ETA: 2s - loss: 0.3838 - acc: 0.8271
1024/4397 [=====>........................] - ETA: 2s - loss: 0.3879 - acc: 0.8281
1088/4397 [======>.......................] - ETA: 2s - loss: 0.3851 - acc: 0.8290
1152/4397 [======>.......................] - ETA: 2s - loss: 0.3893 - acc: 0.8281
1216/4397 [=======>......................] - ETA: 2s - loss: 0.3921 - acc: 0.8248
1280/4397 [=======>......................] - ETA: 2s - loss: 0.3871 - acc: 0.8289
1344/4397 [========>.....................] - ETA: 2s - loss: 0.3873 - acc: 0.8289
1408/4397 [========>.....................] - ETA: 2s - loss: 0.3891 - acc: 0.8288
1472/4397 [=========>....................] - ETA: 2s - loss: 0.3927 - acc: 0.8274
1536/4397 [=========>....................] - ETA: 2s - loss: 0.3943 - acc: 0.8262
1664/4397 [==========>...................] - ETA: 2s - loss: 0.3885 - acc: 0.8281
1728/4397 [==========>...................] - ETA: 2s - loss: 0.3828 - acc: 0.8316
1792/4397 [===========>..................] - ETA: 2s - loss: 0.3827 - acc: 0.8315
1856/4397 [===========>..................] - ETA: 2s - loss: 0.3845 - acc: 0.8292
1920/4397 [============>.................] - ETA: 2s - loss: 0.3827 - acc: 0.8302
2048/4397 [============>.................] - ETA: 1s - loss: 0.3876 - acc: 0.8286
2112/4397 [=============>................] - ETA: 1s - loss: 0.3914 - acc: 0.8258
2176/4397 [=============>................] - ETA: 1s - loss: 0.3925 - acc: 0.8249
2304/4397 [==============>...............] - ETA: 1s - loss: 0.3921 - acc: 0.8251
2368/4397 [===============>..............] - ETA: 1s - loss: 0.3879 - acc: 0.8269
2432/4397 [===============>..............] - ETA: 1s - loss: 0.3852 - acc: 0.8285
2496/4397 [================>.............] - ETA: 1s - loss: 0.3824 - acc: 0.8301
2560/4397 [================>.............] - ETA: 1s - loss: 0.3836 - acc: 0.8293
2624/4397 [================>.............] - ETA: 1s - loss: 0.3848 - acc: 0.8296
2688/4397 [=================>............] - ETA: 1s - loss: 0.3837 - acc: 0.8304
2752/4397 [=================>............] - ETA: 1s - loss: 0.3828 - acc: 0.8303
2816/4397 [==================>...........] - ETA: 1s - loss: 0.3818 - acc: 0.8303
2880/4397 [==================>...........] - ETA: 1s - loss: 0.3824 - acc: 0.8306
2944/4397 [===================>..........] - ETA: 1s - loss: 0.3802 - acc: 0.8325
3008/4397 [===================>..........] - ETA: 1s - loss: 0.3781 - acc: 0.8328
3136/4397 [====================>.........] - ETA: 1s - loss: 0.3798 - acc: 0.8329
3200/4397 [====================>.........] - ETA: 0s - loss: 0.3826 - acc: 0.8306
3264/4397 [=====================>........] - ETA: 0s - loss: 0.3813 - acc: 0.8309
3328/4397 [=====================>........] - ETA: 0s - loss: 0.3808 - acc: 0.8314
3392/4397 [======================>.......] - ETA: 0s - loss: 0.3817 - acc: 0.8314
3456/4397 [======================>.......] - ETA: 0s - loss: 0.3810 - acc: 0.8316
3520/4397 [=======================>......] - ETA: 0s - loss: 0.3806 - acc: 0.8304
3584/4397 [=======================>......] - ETA: 0s - loss: 0.3803 - acc: 0.8298
3648/4397 [=======================>......] - ETA: 0s - loss: 0.3808 - acc: 0.8298
3712/4397 [========================>.....] - ETA: 0s - loss: 0.3805 - acc: 0.8297
3776/4397 [========================>.....] - ETA: 0s - loss: 0.3803 - acc: 0.8294
3840/4397 [=========================>....] - ETA: 0s - loss: 0.3806 - acc: 0.8289
3904/4397 [=========================>....] - ETA: 0s - loss: 0.3805 - acc: 0.8289
3968/4397 [==========================>...] - ETA: 0s - loss: 0.3786 - acc: 0.8299
4032/4397 [==========================>...] - ETA: 0s - loss: 0.3790 - acc: 0.8294
4096/4397 [==========================>...] - ETA: 0s - loss: 0.3799 - acc: 0.8286
4160/4397 [===========================>..] - ETA: 0s - loss: 0.3793 - acc: 0.8279
4224/4397 [===========================>..] - ETA: 0s - loss: 0.3779 - acc: 0.8281
4288/4397 [============================>.] - ETA: 0s - loss: 0.3776 - acc: 0.8286
4352/4397 [============================>.] - ETA: 0s - loss: 0.3779 - acc: 0.8286
4397/4397 [==============================] - 4s 838us/step - loss: 0.3772 - acc: 0.8292

Test accuracy: 83.77823408624229

data size :  4884

zero :  2443

one :  2441

train_zero :  2199

train_one :  2198

test_zero :  244

test_one :  243

choose_zero :  255

choose_one :  232

F1score :  0.8336842105263157

AUC :  0.9191374890373069

Confusion Matrix
[[210  34]
 [ 45 198]]
True label 0
0.860655737704918  
0.13934426229508196  
True label 1
0.18518518518518517  
0.8148148148148148  

Train_result {'acc': [0.8292017285189955], 'loss': [0.3772283903924015]}
Saved model to disk


3

Epoch 1/1

  64/4397 [..............................] - ETA: 4s - loss: 0.2931 - acc: 0.8906
 128/4397 [..............................] - ETA: 4s - loss: 0.3200 - acc: 0.8672
 192/4397 [>.............................] - ETA: 3s - loss: 0.3116 - acc: 0.8698
 256/4397 [>.............................] - ETA: 3s - loss: 0.3124 - acc: 0.8672
 320/4397 [=>............................] - ETA: 3s - loss: 0.2988 - acc: 0.8750
 384/4397 [=>............................] - ETA: 3s - loss: 0.3221 - acc: 0.8594
 448/4397 [==>...........................] - ETA: 3s - loss: 0.3182 - acc: 0.8638
 512/4397 [==>...........................] - ETA: 3s - loss: 0.3219 - acc: 0.8574
 576/4397 [==>...........................] - ETA: 3s - loss: 0.3302 - acc: 0.8472
 640/4397 [===>..........................] - ETA: 3s - loss: 0.3282 - acc: 0.8484
 704/4397 [===>..........................] - ETA: 3s - loss: 0.3434 - acc: 0.8409
 768/4397 [====>.........................] - ETA: 3s - loss: 0.3485 - acc: 0.8359
 832/4397 [====>.........................] - ETA: 3s - loss: 0.3580 - acc: 0.8281
 896/4397 [=====>........................] - ETA: 3s - loss: 0.3580 - acc: 0.8281
1024/4397 [=====>........................] - ETA: 2s - loss: 0.3583 - acc: 0.8271
1088/4397 [======>.......................] - ETA: 2s - loss: 0.3621 - acc: 0.8244
1152/4397 [======>.......................] - ETA: 2s - loss: 0.3555 - acc: 0.8299
1216/4397 [=======>......................] - ETA: 2s - loss: 0.3501 - acc: 0.8322
1280/4397 [=======>......................] - ETA: 2s - loss: 0.3526 - acc: 0.8328
1344/4397 [========>.....................] - ETA: 2s - loss: 0.3532 - acc: 0.8341
1408/4397 [========>.....................] - ETA: 2s - loss: 0.3466 - acc: 0.8395
1472/4397 [=========>....................] - ETA: 2s - loss: 0.3527 - acc: 0.8383
1536/4397 [=========>....................] - ETA: 2s - loss: 0.3534 - acc: 0.8385
1600/4397 [=========>....................] - ETA: 2s - loss: 0.3525 - acc: 0.8394
1664/4397 [==========>...................] - ETA: 2s - loss: 0.3480 - acc: 0.8419
1728/4397 [==========>...................] - ETA: 2s - loss: 0.3514 - acc: 0.8397
1792/4397 [===========>..................] - ETA: 2s - loss: 0.3520 - acc: 0.8393
1856/4397 [===========>..................] - ETA: 2s - loss: 0.3486 - acc: 0.8416
1920/4397 [============>.................] - ETA: 2s - loss: 0.3506 - acc: 0.8401
1984/4397 [============>.................] - ETA: 2s - loss: 0.3503 - acc: 0.8402
2048/4397 [============>.................] - ETA: 1s - loss: 0.3511 - acc: 0.8403
2112/4397 [=============>................] - ETA: 1s - loss: 0.3498 - acc: 0.8404
2176/4397 [=============>................] - ETA: 1s - loss: 0.3521 - acc: 0.8387
2240/4397 [==============>...............] - ETA: 1s - loss: 0.3544 - acc: 0.8366
2304/4397 [==============>...............] - ETA: 1s - loss: 0.3541 - acc: 0.8377
2368/4397 [===============>..............] - ETA: 1s - loss: 0.3531 - acc: 0.8378
2432/4397 [===============>..............] - ETA: 1s - loss: 0.3532 - acc: 0.8372
2496/4397 [================>.............] - ETA: 1s - loss: 0.3517 - acc: 0.8381
2560/4397 [================>.............] - ETA: 1s - loss: 0.3489 - acc: 0.8402
2624/4397 [================>.............] - ETA: 1s - loss: 0.3479 - acc: 0.8407
2752/4397 [=================>............] - ETA: 1s - loss: 0.3452 - acc: 0.8427
2880/4397 [==================>...........] - ETA: 1s - loss: 0.3425 - acc: 0.8434
2944/4397 [===================>..........] - ETA: 1s - loss: 0.3472 - acc: 0.8410
3008/4397 [===================>..........] - ETA: 1s - loss: 0.3480 - acc: 0.8411
3072/4397 [===================>..........] - ETA: 1s - loss: 0.3477 - acc: 0.8408
3136/4397 [====================>.........] - ETA: 1s - loss: 0.3448 - acc: 0.8428
3264/4397 [=====================>........] - ETA: 0s - loss: 0.3447 - acc: 0.8434
3328/4397 [=====================>........] - ETA: 0s - loss: 0.3441 - acc: 0.8447
3392/4397 [======================>.......] - ETA: 0s - loss: 0.3461 - acc: 0.8440
3456/4397 [======================>.......] - ETA: 0s - loss: 0.3451 - acc: 0.8446
3520/4397 [=======================>......] - ETA: 0s - loss: 0.3450 - acc: 0.8452
3584/4397 [=======================>......] - ETA: 0s - loss: 0.3452 - acc: 0.8449
3648/4397 [=======================>......] - ETA: 0s - loss: 0.3433 - acc: 0.8454
3712/4397 [========================>.....] - ETA: 0s - loss: 0.3463 - acc: 0.8443
3776/4397 [========================>.....] - ETA: 0s - loss: 0.3477 - acc: 0.8432
3840/4397 [=========================>....] - ETA: 0s - loss: 0.3468 - acc: 0.8432
3904/4397 [=========================>....] - ETA: 0s - loss: 0.3472 - acc: 0.8427
3968/4397 [==========================>...] - ETA: 0s - loss: 0.3474 - acc: 0.8427
4032/4397 [==========================>...] - ETA: 0s - loss: 0.3473 - acc: 0.8430
4160/4397 [===========================>..] - ETA: 0s - loss: 0.3468 - acc: 0.8421
4224/4397 [===========================>..] - ETA: 0s - loss: 0.3480 - acc: 0.8419
4288/4397 [============================>.] - ETA: 0s - loss: 0.3474 - acc: 0.8417
4352/4397 [============================>.] - ETA: 0s - loss: 0.3479 - acc: 0.8403
4397/4397 [==============================] - 4s 829us/step - loss: 0.3467 - acc: 0.8408

Test accuracy: 82.54620123203286

data size :  4884

zero :  2443

one :  2441

train_zero :  2199

train_one :  2198

test_zero :  244

test_one :  243

choose_zero :  189

choose_one :  298

F1score :  0.8428835489833642

AUC :  0.9194579369898132

Confusion Matrix
[[174  70]
 [ 15 228]]
True label 0
0.7131147540983607  
0.28688524590163933  
True label 1
0.06172839506172839  
0.9382716049382716  

Train_result {'acc': [0.8408005458944788], 'loss': [0.34673820045595144]}
Saved model to disk


4

Epoch 1/1

  64/4397 [..............................] - ETA: 4s - loss: 0.3553 - acc: 0.8438
 128/4397 [..............................] - ETA: 4s - loss: 0.4256 - acc: 0.8047
 256/4397 [>.............................] - ETA: 3s - loss: 0.3707 - acc: 0.8281
 320/4397 [=>............................] - ETA: 3s - loss: 0.3421 - acc: 0.8375
 448/4397 [==>...........................] - ETA: 3s - loss: 0.3394 - acc: 0.8438
 512/4397 [==>...........................] - ETA: 3s - loss: 0.3473 - acc: 0.8418
 576/4397 [==>...........................] - ETA: 3s - loss: 0.3407 - acc: 0.8438
 640/4397 [===>..........................] - ETA: 3s - loss: 0.3207 - acc: 0.8531
 704/4397 [===>..........................] - ETA: 3s - loss: 0.3126 - acc: 0.8594
 768/4397 [====>.........................] - ETA: 2s - loss: 0.3140 - acc: 0.8581
 832/4397 [====>.........................] - ETA: 2s - loss: 0.3149 - acc: 0.8570
 960/4397 [=====>........................] - ETA: 2s - loss: 0.3080 - acc: 0.8594
1024/4397 [=====>........................] - ETA: 2s - loss: 0.3019 - acc: 0.8643
1152/4397 [======>.......................] - ETA: 2s - loss: 0.3069 - acc: 0.8620
1216/4397 [=======>......................] - ETA: 2s - loss: 0.3081 - acc: 0.8602
1280/4397 [=======>......................] - ETA: 2s - loss: 0.3167 - acc: 0.8578
1408/4397 [========>.....................] - ETA: 2s - loss: 0.3194 - acc: 0.8565
1472/4397 [=========>....................] - ETA: 2s - loss: 0.3194 - acc: 0.8573
1536/4397 [=========>....................] - ETA: 2s - loss: 0.3189 - acc: 0.8574
1600/4397 [=========>....................] - ETA: 2s - loss: 0.3156 - acc: 0.8600
1664/4397 [==========>...................] - ETA: 2s - loss: 0.3132 - acc: 0.8606
1728/4397 [==========>...................] - ETA: 2s - loss: 0.3117 - acc: 0.8617
1792/4397 [===========>..................] - ETA: 2s - loss: 0.3121 - acc: 0.8610
1856/4397 [===========>..................] - ETA: 2s - loss: 0.3124 - acc: 0.8605
1920/4397 [============>.................] - ETA: 2s - loss: 0.3161 - acc: 0.8594
1984/4397 [============>.................] - ETA: 1s - loss: 0.3215 - acc: 0.8584
2048/4397 [============>.................] - ETA: 1s - loss: 0.3214 - acc: 0.8584
2112/4397 [=============>................] - ETA: 1s - loss: 0.3201 - acc: 0.8575
2176/4397 [=============>................] - ETA: 1s - loss: 0.3205 - acc: 0.8566
2240/4397 [==============>...............] - ETA: 1s - loss: 0.3203 - acc: 0.8562
2304/4397 [==============>...............] - ETA: 1s - loss: 0.3174 - acc: 0.8576
2368/4397 [===============>..............] - ETA: 1s - loss: 0.3189 - acc: 0.8560
2432/4397 [===============>..............] - ETA: 1s - loss: 0.3197 - acc: 0.8561
2496/4397 [================>.............] - ETA: 1s - loss: 0.3208 - acc: 0.8554
2560/4397 [================>.............] - ETA: 1s - loss: 0.3229 - acc: 0.8551
2624/4397 [================>.............] - ETA: 1s - loss: 0.3226 - acc: 0.8559
2688/4397 [=================>............] - ETA: 1s - loss: 0.3261 - acc: 0.8542
2752/4397 [=================>............] - ETA: 1s - loss: 0.3272 - acc: 0.8532
2816/4397 [==================>...........] - ETA: 1s - loss: 0.3285 - acc: 0.8526
2880/4397 [==================>...........] - ETA: 1s - loss: 0.3293 - acc: 0.8528
2944/4397 [===================>..........] - ETA: 1s - loss: 0.3313 - acc: 0.8509
3008/4397 [===================>..........] - ETA: 1s - loss: 0.3312 - acc: 0.8514
3072/4397 [===================>..........] - ETA: 1s - loss: 0.3304 - acc: 0.8509
3136/4397 [====================>.........] - ETA: 1s - loss: 0.3315 - acc: 0.8508
3264/4397 [=====================>........] - ETA: 0s - loss: 0.3310 - acc: 0.8511
3328/4397 [=====================>........] - ETA: 0s - loss: 0.3319 - acc: 0.8504
3392/4397 [======================>.......] - ETA: 0s - loss: 0.3317 - acc: 0.8499
3456/4397 [======================>.......] - ETA: 0s - loss: 0.3309 - acc: 0.8513
3520/4397 [=======================>......] - ETA: 0s - loss: 0.3275 - acc: 0.8540
3584/4397 [=======================>......] - ETA: 0s - loss: 0.3294 - acc: 0.8532
3648/4397 [=======================>......] - ETA: 0s - loss: 0.3297 - acc: 0.8528
3712/4397 [========================>.....] - ETA: 0s - loss: 0.3314 - acc: 0.8516
3776/4397 [========================>.....] - ETA: 0s - loss: 0.3305 - acc: 0.8520
3840/4397 [=========================>....] - ETA: 0s - loss: 0.3309 - acc: 0.8518
3904/4397 [=========================>....] - ETA: 0s - loss: 0.3299 - acc: 0.8519
3968/4397 [==========================>...] - ETA: 0s - loss: 0.3289 - acc: 0.8531
4032/4397 [==========================>...] - ETA: 0s - loss: 0.3282 - acc: 0.8537
4096/4397 [==========================>...] - ETA: 0s - loss: 0.3293 - acc: 0.8530
4160/4397 [===========================>..] - ETA: 0s - loss: 0.3299 - acc: 0.8524
4224/4397 [===========================>..] - ETA: 0s - loss: 0.3295 - acc: 0.8523
4288/4397 [============================>.] - ETA: 0s - loss: 0.3318 - acc: 0.8512
4352/4397 [============================>.] - ETA: 0s - loss: 0.3313 - acc: 0.8511
4397/4397 [==============================] - 4s 827us/step - loss: 0.3321 - acc: 0.8504

Test accuracy: 84.80492813141683

data size :  4884

zero :  2443

one :  2441

train_zero :  2199

train_one :  2198

test_zero :  244

test_one :  243

choose_zero :  226

choose_one :  261

F1score :  0.8531746031746031

AUC :  0.9264065978546853

Confusion Matrix
[[198  46]
 [ 28 215]]
True label 0
0.8114754098360656  
0.1885245901639344  
True label 1
0.11522633744855967  
0.8847736625514403  

Train_result {'acc': [0.8503525132126556], 'loss': [0.3321040444667431]}
Saved model to disk


5

Epoch 1/1

  64/4397 [..............................] - ETA: 4s - loss: 0.2612 - acc: 0.9062
 128/4397 [..............................] - ETA: 4s - loss: 0.2944 - acc: 0.8750
 192/4397 [>.............................] - ETA: 3s - loss: 0.2776 - acc: 0.8802
 320/4397 [=>............................] - ETA: 3s - loss: 0.3011 - acc: 0.8625
 384/4397 [=>............................] - ETA: 3s - loss: 0.3139 - acc: 0.8646
 448/4397 [==>...........................] - ETA: 3s - loss: 0.3045 - acc: 0.8683
 576/4397 [==>...........................] - ETA: 3s - loss: 0.3070 - acc: 0.8698
 640/4397 [===>..........................] - ETA: 3s - loss: 0.3122 - acc: 0.8688
 704/4397 [===>..........................] - ETA: 3s - loss: 0.3067 - acc: 0.8707
 768/4397 [====>.........................] - ETA: 2s - loss: 0.3051 - acc: 0.8698
 832/4397 [====>.........................] - ETA: 2s - loss: 0.2991 - acc: 0.8726
 896/4397 [=====>........................] - ETA: 2s - loss: 0.2951 - acc: 0.8750
 960/4397 [=====>........................] - ETA: 2s - loss: 0.2985 - acc: 0.8740
1024/4397 [=====>........................] - ETA: 2s - loss: 0.2977 - acc: 0.8740
1088/4397 [======>.......................] - ETA: 2s - loss: 0.2979 - acc: 0.8741
1152/4397 [======>.......................] - ETA: 2s - loss: 0.2958 - acc: 0.8750
1216/4397 [=======>......................] - ETA: 2s - loss: 0.3004 - acc: 0.8709
1280/4397 [=======>......................] - ETA: 2s - loss: 0.2994 - acc: 0.8711
1408/4397 [========>.....................] - ETA: 2s - loss: 0.3089 - acc: 0.8665
1472/4397 [=========>....................] - ETA: 2s - loss: 0.3070 - acc: 0.8682
1536/4397 [=========>....................] - ETA: 2s - loss: 0.3096 - acc: 0.8665
1600/4397 [=========>....................] - ETA: 2s - loss: 0.3143 - acc: 0.8631
1664/4397 [==========>...................] - ETA: 2s - loss: 0.3152 - acc: 0.8618
1728/4397 [==========>...................] - ETA: 2s - loss: 0.3191 - acc: 0.8594
1856/4397 [===========>..................] - ETA: 2s - loss: 0.3211 - acc: 0.8567
1920/4397 [============>.................] - ETA: 1s - loss: 0.3205 - acc: 0.8568
1984/4397 [============>.................] - ETA: 1s - loss: 0.3209 - acc: 0.8569
2048/4397 [============>.................] - ETA: 1s - loss: 0.3185 - acc: 0.8579
2112/4397 [=============>................] - ETA: 1s - loss: 0.3201 - acc: 0.8580
2240/4397 [==============>...............] - ETA: 1s - loss: 0.3187 - acc: 0.8585
2304/4397 [==============>...............] - ETA: 1s - loss: 0.3195 - acc: 0.8581
2368/4397 [===============>..............] - ETA: 1s - loss: 0.3196 - acc: 0.8581
2432/4397 [===============>..............] - ETA: 1s - loss: 0.3207 - acc: 0.8586
2560/4397 [================>.............] - ETA: 1s - loss: 0.3228 - acc: 0.8570
2624/4397 [================>.............] - ETA: 1s - loss: 0.3227 - acc: 0.8571
2688/4397 [=================>............] - ETA: 1s - loss: 0.3240 - acc: 0.8557
2752/4397 [=================>............] - ETA: 1s - loss: 0.3242 - acc: 0.8557
2816/4397 [==================>...........] - ETA: 1s - loss: 0.3230 - acc: 0.8562
2880/4397 [==================>...........] - ETA: 1s - loss: 0.3225 - acc: 0.8573
2944/4397 [===================>..........] - ETA: 1s - loss: 0.3225 - acc: 0.8567
3008/4397 [===================>..........] - ETA: 1s - loss: 0.3230 - acc: 0.8561
3072/4397 [===================>..........] - ETA: 1s - loss: 0.3218 - acc: 0.8564
3136/4397 [====================>.........] - ETA: 1s - loss: 0.3198 - acc: 0.8575
3200/4397 [====================>.........] - ETA: 0s - loss: 0.3181 - acc: 0.8578
3264/4397 [=====================>........] - ETA: 0s - loss: 0.3194 - acc: 0.8569
3328/4397 [=====================>........] - ETA: 0s - loss: 0.3189 - acc: 0.8573
3392/4397 [======================>.......] - ETA: 0s - loss: 0.3184 - acc: 0.8573
3456/4397 [======================>.......] - ETA: 0s - loss: 0.3180 - acc: 0.8579
3520/4397 [=======================>......] - ETA: 0s - loss: 0.3187 - acc: 0.8571
3584/4397 [=======================>......] - ETA: 0s - loss: 0.3172 - acc: 0.8583
3648/4397 [=======================>......] - ETA: 0s - loss: 0.3174 - acc: 0.8577
3712/4397 [========================>.....] - ETA: 0s - loss: 0.3195 - acc: 0.8570
3776/4397 [========================>.....] - ETA: 0s - loss: 0.3190 - acc: 0.8578
3840/4397 [=========================>....] - ETA: 0s - loss: 0.3187 - acc: 0.8578
3904/4397 [=========================>....] - ETA: 0s - loss: 0.3186 - acc: 0.8578
3968/4397 [==========================>...] - ETA: 0s - loss: 0.3186 - acc: 0.8576
4032/4397 [==========================>...] - ETA: 0s - loss: 0.3176 - acc: 0.8586
4096/4397 [==========================>...] - ETA: 0s - loss: 0.3158 - acc: 0.8591
4160/4397 [===========================>..] - ETA: 0s - loss: 0.3161 - acc: 0.8584
4288/4397 [============================>.] - ETA: 0s - loss: 0.3166 - acc: 0.8582
4397/4397 [==============================] - 4s 824us/step - loss: 0.3146 - acc: 0.8594

Test accuracy: 84.39425051334702

data size :  4884

zero :  2443

one :  2441

train_zero :  2199

train_one :  2198

test_zero :  244

test_one :  243

choose_zero :  264

choose_one :  223

F1score :  0.8369098712446352

AUC :  0.9309266005531943

Confusion Matrix
[[216  28]
 [ 48 195]]
True label 0
0.8852459016393442  
0.11475409836065574  
True label 1
0.19753086419753085  
0.8024691358024691  

Train_result {'acc': [0.8594496248254783], 'loss': [0.31456092371435257]}
Saved model to disk


6

Epoch 1/1

  64/4397 [..............................] - ETA: 5s - loss: 0.3462 - acc: 0.8750
 128/4397 [..............................] - ETA: 4s - loss: 0.3244 - acc: 0.8438
 192/4397 [>.............................] - ETA: 4s - loss: 0.3009 - acc: 0.8594
 256/4397 [>.............................] - ETA: 3s - loss: 0.3068 - acc: 0.8594
 320/4397 [=>............................] - ETA: 3s - loss: 0.3307 - acc: 0.8469
 384/4397 [=>............................] - ETA: 3s - loss: 0.3206 - acc: 0.8516
 448/4397 [==>...........................] - ETA: 3s - loss: 0.3277 - acc: 0.8504
 512/4397 [==>...........................] - ETA: 3s - loss: 0.3228 - acc: 0.8555
 576/4397 [==>...........................] - ETA: 3s - loss: 0.3195 - acc: 0.8594
 640/4397 [===>..........................] - ETA: 3s - loss: 0.3255 - acc: 0.8578
 704/4397 [===>..........................] - ETA: 3s - loss: 0.3267 - acc: 0.8565
 768/4397 [====>.........................] - ETA: 3s - loss: 0.3242 - acc: 0.8581
 832/4397 [====>.........................] - ETA: 3s - loss: 0.3298 - acc: 0.8534
 896/4397 [=====>........................] - ETA: 3s - loss: 0.3266 - acc: 0.8538
 960/4397 [=====>........................] - ETA: 2s - loss: 0.3241 - acc: 0.8562
1024/4397 [=====>........................] - ETA: 2s - loss: 0.3187 - acc: 0.8584
1088/4397 [======>.......................] - ETA: 2s - loss: 0.3160 - acc: 0.8603
1152/4397 [======>.......................] - ETA: 2s - loss: 0.3182 - acc: 0.8594
1216/4397 [=======>......................] - ETA: 2s - loss: 0.3125 - acc: 0.8651
1280/4397 [=======>......................] - ETA: 2s - loss: 0.3103 - acc: 0.8648
1344/4397 [========>.....................] - ETA: 2s - loss: 0.3049 - acc: 0.8668
1408/4397 [========>.....................] - ETA: 2s - loss: 0.3037 - acc: 0.8679
1472/4397 [=========>....................] - ETA: 2s - loss: 0.3055 - acc: 0.8675
1536/4397 [=========>....................] - ETA: 2s - loss: 0.3021 - acc: 0.8691
1600/4397 [=========>....................] - ETA: 2s - loss: 0.2997 - acc: 0.8706
1664/4397 [==========>...................] - ETA: 2s - loss: 0.3008 - acc: 0.8696
1728/4397 [==========>...................] - ETA: 2s - loss: 0.3026 - acc: 0.8681
1792/4397 [===========>..................] - ETA: 2s - loss: 0.3045 - acc: 0.8683
1856/4397 [===========>..................] - ETA: 2s - loss: 0.3020 - acc: 0.8691
1920/4397 [============>.................] - ETA: 2s - loss: 0.3004 - acc: 0.8693
1984/4397 [============>.................] - ETA: 2s - loss: 0.3012 - acc: 0.8684
2048/4397 [============>.................] - ETA: 2s - loss: 0.3075 - acc: 0.8643
2112/4397 [=============>................] - ETA: 1s - loss: 0.3050 - acc: 0.8665
2176/4397 [=============>................] - ETA: 1s - loss: 0.3037 - acc: 0.8658
2240/4397 [==============>...............] - ETA: 1s - loss: 0.3051 - acc: 0.8665
2368/4397 [===============>..............] - ETA: 1s - loss: 0.3058 - acc: 0.8674
2432/4397 [===============>..............] - ETA: 1s - loss: 0.3060 - acc: 0.8672
2496/4397 [================>.............] - ETA: 1s - loss: 0.3086 - acc: 0.8666
2560/4397 [================>.............] - ETA: 1s - loss: 0.3071 - acc: 0.8672
2624/4397 [================>.............] - ETA: 1s - loss: 0.3081 - acc: 0.8655
2688/4397 [=================>............] - ETA: 1s - loss: 0.3085 - acc: 0.8653
2752/4397 [=================>............] - ETA: 1s - loss: 0.3064 - acc: 0.8670
2880/4397 [==================>...........] - ETA: 1s - loss: 0.3063 - acc: 0.8674
2944/4397 [===================>..........] - ETA: 1s - loss: 0.3046 - acc: 0.8679
3072/4397 [===================>..........] - ETA: 1s - loss: 0.3030 - acc: 0.8672
3136/4397 [====================>.........] - ETA: 1s - loss: 0.3053 - acc: 0.8661
3200/4397 [====================>.........] - ETA: 1s - loss: 0.3052 - acc: 0.8656
3264/4397 [=====================>........] - ETA: 0s - loss: 0.3054 - acc: 0.8655
3328/4397 [=====================>........] - ETA: 0s - loss: 0.3055 - acc: 0.8651
3392/4397 [======================>.......] - ETA: 0s - loss: 0.3074 - acc: 0.8644
3456/4397 [======================>.......] - ETA: 0s - loss: 0.3069 - acc: 0.8646
3520/4397 [=======================>......] - ETA: 0s - loss: 0.3080 - acc: 0.8631
3584/4397 [=======================>......] - ETA: 0s - loss: 0.3082 - acc: 0.8630
3648/4397 [=======================>......] - ETA: 0s - loss: 0.3098 - acc: 0.8629
3712/4397 [========================>.....] - ETA: 0s - loss: 0.3123 - acc: 0.8623
3776/4397 [========================>.....] - ETA: 0s - loss: 0.3117 - acc: 0.8623
3840/4397 [=========================>....] - ETA: 0s - loss: 0.3105 - acc: 0.8628
3904/4397 [=========================>....] - ETA: 0s - loss: 0.3107 - acc: 0.8627
3968/4397 [==========================>...] - ETA: 0s - loss: 0.3103 - acc: 0.8629
4032/4397 [==========================>...] - ETA: 0s - loss: 0.3090 - acc: 0.8638
4096/4397 [==========================>...] - ETA: 0s - loss: 0.3083 - acc: 0.8638
4160/4397 [===========================>..] - ETA: 0s - loss: 0.3088 - acc: 0.8630
4224/4397 [===========================>..] - ETA: 0s - loss: 0.3082 - acc: 0.8632
4288/4397 [============================>.] - ETA: 0s - loss: 0.3067 - acc: 0.8645
4352/4397 [============================>.] - ETA: 0s - loss: 0.3060 - acc: 0.8647
4397/4397 [==============================] - 4s 863us/step - loss: 0.3052 - acc: 0.8651

Test accuracy: 83.5728952772074

data size :  4884

zero :  2443

one :  2441

train_zero :  2199

train_one :  2198

test_zero :  244

test_one :  243

choose_zero :  216

choose_one :  271

F1score :  0.8443579766536965

AUC :  0.9261030155838899

Confusion Matrix
[[190  54]
 [ 26 217]]
True label 0
0.7786885245901639  
0.22131147540983606  
True label 1
0.10699588477366255  
0.8930041152263375  

Train_result {'acc': [0.8651353195902703], 'loss': [0.30516334168133424]}
Saved model to disk


7

Epoch 1/1

  64/4397 [..............................] - ETA: 4s - loss: 0.2134 - acc: 0.9062
 128/4397 [..............................] - ETA: 4s - loss: 0.3060 - acc: 0.8438
 192/4397 [>.............................] - ETA: 3s - loss: 0.2950 - acc: 0.8438
 256/4397 [>.............................] - ETA: 3s - loss: 0.2747 - acc: 0.8672
 320/4397 [=>............................] - ETA: 3s - loss: 0.2733 - acc: 0.8781
 384/4397 [=>............................] - ETA: 3s - loss: 0.2840 - acc: 0.8724
 448/4397 [==>...........................] - ETA: 3s - loss: 0.2894 - acc: 0.8683
 512/4397 [==>...........................] - ETA: 3s - loss: 0.2982 - acc: 0.8652
 576/4397 [==>...........................] - ETA: 3s - loss: 0.3017 - acc: 0.8646
 704/4397 [===>..........................] - ETA: 3s - loss: 0.3049 - acc: 0.8622
 768/4397 [====>.........................] - ETA: 3s - loss: 0.3097 - acc: 0.8594
 832/4397 [====>.........................] - ETA: 3s - loss: 0.3095 - acc: 0.8570
 896/4397 [=====>........................] - ETA: 2s - loss: 0.3100 - acc: 0.8549
 960/4397 [=====>........................] - ETA: 2s - loss: 0.3185 - acc: 0.8500
1024/4397 [=====>........................] - ETA: 2s - loss: 0.3148 - acc: 0.8525
1088/4397 [======>.......................] - ETA: 2s - loss: 0.3144 - acc: 0.8502
1152/4397 [======>.......................] - ETA: 2s - loss: 0.3091 - acc: 0.8516
1216/4397 [=======>......................] - ETA: 2s - loss: 0.3045 - acc: 0.8561
1280/4397 [=======>......................] - ETA: 2s - loss: 0.2997 - acc: 0.8602
1344/4397 [========>.....................] - ETA: 2s - loss: 0.3020 - acc: 0.8586
1408/4397 [========>.....................] - ETA: 2s - loss: 0.3007 - acc: 0.8587
1472/4397 [=========>....................] - ETA: 2s - loss: 0.2987 - acc: 0.8594
1536/4397 [=========>....................] - ETA: 2s - loss: 0.2951 - acc: 0.8607
1600/4397 [=========>....................] - ETA: 2s - loss: 0.2959 - acc: 0.8588
1664/4397 [==========>...................] - ETA: 2s - loss: 0.2954 - acc: 0.8582
1728/4397 [==========>...................] - ETA: 2s - loss: 0.2992 - acc: 0.8571
1792/4397 [===========>..................] - ETA: 2s - loss: 0.2961 - acc: 0.8594
1920/4397 [============>.................] - ETA: 2s - loss: 0.2910 - acc: 0.8625
2048/4397 [============>.................] - ETA: 1s - loss: 0.2878 - acc: 0.8638
2112/4397 [=============>................] - ETA: 1s - loss: 0.2844 - acc: 0.8651
2240/4397 [==============>...............] - ETA: 1s - loss: 0.2825 - acc: 0.8665
2304/4397 [==============>...............] - ETA: 1s - loss: 0.2790 - acc: 0.8685
2368/4397 [===============>..............] - ETA: 1s - loss: 0.2788 - acc: 0.8678
2432/4397 [===============>..............] - ETA: 1s - loss: 0.2797 - acc: 0.8684
2496/4397 [================>.............] - ETA: 1s - loss: 0.2823 - acc: 0.8670
2560/4397 [================>.............] - ETA: 1s - loss: 0.2830 - acc: 0.8680
2624/4397 [================>.............] - ETA: 1s - loss: 0.2863 - acc: 0.8666
2688/4397 [=================>............] - ETA: 1s - loss: 0.2863 - acc: 0.8664
2752/4397 [=================>............] - ETA: 1s - loss: 0.2885 - acc: 0.8659
2816/4397 [==================>...........] - ETA: 1s - loss: 0.2874 - acc: 0.8661
2880/4397 [==================>...........] - ETA: 1s - loss: 0.2878 - acc: 0.8663
2944/4397 [===================>..........] - ETA: 1s - loss: 0.2890 - acc: 0.8668
3008/4397 [===================>..........] - ETA: 1s - loss: 0.2875 - acc: 0.8684
3072/4397 [===================>..........] - ETA: 1s - loss: 0.2872 - acc: 0.8685
3136/4397 [====================>.........] - ETA: 1s - loss: 0.2878 - acc: 0.8686
3200/4397 [====================>.........] - ETA: 0s - loss: 0.2892 - acc: 0.8684
3264/4397 [=====================>........] - ETA: 0s - loss: 0.2893 - acc: 0.8689
3392/4397 [======================>.......] - ETA: 0s - loss: 0.2887 - acc: 0.8697
3456/4397 [======================>.......] - ETA: 0s - loss: 0.2895 - acc: 0.8695
3520/4397 [=======================>......] - ETA: 0s - loss: 0.2895 - acc: 0.8696
3584/4397 [=======================>......] - ETA: 0s - loss: 0.2926 - acc: 0.8689
3648/4397 [=======================>......] - ETA: 0s - loss: 0.2927 - acc: 0.8692
3776/4397 [========================>.....] - ETA: 0s - loss: 0.2897 - acc: 0.8708
3904/4397 [=========================>....] - ETA: 0s - loss: 0.2897 - acc: 0.8712
3968/4397 [==========================>...] - ETA: 0s - loss: 0.2893 - acc: 0.8707
4096/4397 [==========================>...] - ETA: 0s - loss: 0.2928 - acc: 0.8689
4224/4397 [===========================>..] - ETA: 0s - loss: 0.2911 - acc: 0.8700
4288/4397 [============================>.] - ETA: 0s - loss: 0.2904 - acc: 0.8701
4397/4397 [==============================] - 4s 821us/step - loss: 0.2924 - acc: 0.8699

Test accuracy: 86.0369609856263

data size :  4884

zero :  2443

one :  2441

train_zero :  2199

train_one :  2198

test_zero :  244

test_one :  243

choose_zero :  236

choose_one :  251

F1score :  0.8623481781376519

AUC :  0.931887944410713

Confusion Matrix
[[206  38]
 [ 30 213]]
True label 0
0.8442622950819673  
0.1557377049180328  
True label 1
0.12345679012345678  
0.8765432098765432  

Train_result {'acc': [0.8699113031883579], 'loss': [0.29244647568698795]}
Saved model to disk


8

Epoch 1/1

  64/4397 [..............................] - ETA: 4s - loss: 0.2514 - acc: 0.8750
 128/4397 [..............................] - ETA: 4s - loss: 0.2860 - acc: 0.8516
 192/4397 [>.............................] - ETA: 3s - loss: 0.2579 - acc: 0.8698
 256/4397 [>.............................] - ETA: 3s - loss: 0.2697 - acc: 0.8711
 320/4397 [=>............................] - ETA: 3s - loss: 0.2714 - acc: 0.8688
 384/4397 [=>............................] - ETA: 3s - loss: 0.2639 - acc: 0.8724
 448/4397 [==>...........................] - ETA: 3s - loss: 0.2661 - acc: 0.8705
 512/4397 [==>...........................] - ETA: 3s - loss: 0.2717 - acc: 0.8711
 576/4397 [==>...........................] - ETA: 3s - loss: 0.2562 - acc: 0.8819
 640/4397 [===>..........................] - ETA: 3s - loss: 0.2549 - acc: 0.8797
 704/4397 [===>..........................] - ETA: 3s - loss: 0.2613 - acc: 0.8750
 768/4397 [====>.........................] - ETA: 3s - loss: 0.2577 - acc: 0.8750
 832/4397 [====>.........................] - ETA: 3s - loss: 0.2543 - acc: 0.8762
 896/4397 [=====>........................] - ETA: 3s - loss: 0.2554 - acc: 0.8761
 960/4397 [=====>........................] - ETA: 2s - loss: 0.2575 - acc: 0.8760
1024/4397 [=====>........................] - ETA: 2s - loss: 0.2604 - acc: 0.8740
1088/4397 [======>.......................] - ETA: 2s - loss: 0.2625 - acc: 0.8741
1152/4397 [======>.......................] - ETA: 2s - loss: 0.2629 - acc: 0.8767
1216/4397 [=======>......................] - ETA: 2s - loss: 0.2624 - acc: 0.8791
1280/4397 [=======>......................] - ETA: 2s - loss: 0.2609 - acc: 0.8789
1344/4397 [========>.....................] - ETA: 2s - loss: 0.2622 - acc: 0.8780
1408/4397 [========>.....................] - ETA: 2s - loss: 0.2645 - acc: 0.8793
1472/4397 [=========>....................] - ETA: 2s - loss: 0.2663 - acc: 0.8804
1536/4397 [=========>....................] - ETA: 2s - loss: 0.2662 - acc: 0.8789
1600/4397 [=========>....................] - ETA: 2s - loss: 0.2655 - acc: 0.8806
1664/4397 [==========>...................] - ETA: 2s - loss: 0.2666 - acc: 0.8798
1728/4397 [==========>...................] - ETA: 2s - loss: 0.2645 - acc: 0.8819
1792/4397 [===========>..................] - ETA: 2s - loss: 0.2663 - acc: 0.8811
1856/4397 [===========>..................] - ETA: 2s - loss: 0.2670 - acc: 0.8804
1920/4397 [============>.................] - ETA: 2s - loss: 0.2711 - acc: 0.8786
1984/4397 [============>.................] - ETA: 2s - loss: 0.2735 - acc: 0.8765
2048/4397 [============>.................] - ETA: 2s - loss: 0.2748 - acc: 0.8770
2112/4397 [=============>................] - ETA: 2s - loss: 0.2757 - acc: 0.8759
2176/4397 [=============>................] - ETA: 1s - loss: 0.2746 - acc: 0.8764
2240/4397 [==============>...............] - ETA: 1s - loss: 0.2749 - acc: 0.8754
2304/4397 [==============>...............] - ETA: 1s - loss: 0.2760 - acc: 0.8754
2368/4397 [===============>..............] - ETA: 1s - loss: 0.2780 - acc: 0.8742
2432/4397 [===============>..............] - ETA: 1s - loss: 0.2769 - acc: 0.8750
2496/4397 [================>.............] - ETA: 1s - loss: 0.2771 - acc: 0.8762
2560/4397 [================>.............] - ETA: 1s - loss: 0.2762 - acc: 0.8770
2624/4397 [================>.............] - ETA: 1s - loss: 0.2736 - acc: 0.8784
2688/4397 [=================>............] - ETA: 1s - loss: 0.2726 - acc: 0.8787
2752/4397 [=================>............] - ETA: 1s - loss: 0.2737 - acc: 0.8779
2816/4397 [==================>...........] - ETA: 1s - loss: 0.2713 - acc: 0.8796
2880/4397 [==================>...........] - ETA: 1s - loss: 0.2710 - acc: 0.8795
2944/4397 [===================>..........] - ETA: 1s - loss: 0.2702 - acc: 0.8801
3008/4397 [===================>..........] - ETA: 1s - loss: 0.2700 - acc: 0.8800
3072/4397 [===================>..........] - ETA: 1s - loss: 0.2701 - acc: 0.8802
3136/4397 [====================>.........] - ETA: 1s - loss: 0.2755 - acc: 0.8776
3200/4397 [====================>.........] - ETA: 1s - loss: 0.2790 - acc: 0.8766
3264/4397 [=====================>........] - ETA: 1s - loss: 0.2801 - acc: 0.8762
3328/4397 [=====================>........] - ETA: 0s - loss: 0.2792 - acc: 0.8768
3392/4397 [======================>.......] - ETA: 0s - loss: 0.2798 - acc: 0.8759
3456/4397 [======================>.......] - ETA: 0s - loss: 0.2785 - acc: 0.8764
3520/4397 [=======================>......] - ETA: 0s - loss: 0.2775 - acc: 0.8770
3584/4397 [=======================>......] - ETA: 0s - loss: 0.2776 - acc: 0.8764
3648/4397 [=======================>......] - ETA: 0s - loss: 0.2769 - acc: 0.8772
3712/4397 [========================>.....] - ETA: 0s - loss: 0.2784 - acc: 0.8763
3776/4397 [========================>.....] - ETA: 0s - loss: 0.2792 - acc: 0.8761
3904/4397 [=========================>....] - ETA: 0s - loss: 0.2808 - acc: 0.8745
4032/4397 [==========================>...] - ETA: 0s - loss: 0.2801 - acc: 0.8752
4096/4397 [==========================>...] - ETA: 0s - loss: 0.2804 - acc: 0.8755
4160/4397 [===========================>..] - ETA: 0s - loss: 0.2802 - acc: 0.8760
4224/4397 [===========================>..] - ETA: 0s - loss: 0.2840 - acc: 0.8743
4288/4397 [============================>.] - ETA: 0s - loss: 0.2832 - acc: 0.8748
4352/4397 [============================>.] - ETA: 0s - loss: 0.2823 - acc: 0.8748
4397/4397 [==============================] - 4s 880us/step - loss: 0.2822 - acc: 0.8745

Test accuracy: 87.06365503080082

data size :  4884

zero :  2443

one :  2441

train_zero :  2199

train_one :  2198

test_zero :  244

test_one :  243

choose_zero :  223

choose_one :  264

F1score :  0.8757396449704142

AUC :  0.9355140659785469

Confusion Matrix
[[202  42]
 [ 21 222]]
True label 0
0.8278688524590164  
0.1721311475409836  
True label 1
0.08641975308641975  
0.9135802469135802  

Train_result {'acc': [0.8744598590896594], 'loss': [0.28218180767400497]}
Saved model to disk


9

Epoch 1/1

  64/4397 [..............................] - ETA: 6s - loss: 0.2430 - acc: 0.8906
 128/4397 [..............................] - ETA: 5s - loss: 0.2157 - acc: 0.8984
 192/4397 [>.............................] - ETA: 4s - loss: 0.2288 - acc: 0.8906
 256/4397 [>.............................] - ETA: 4s - loss: 0.2488 - acc: 0.8711
 320/4397 [=>............................] - ETA: 4s - loss: 0.2692 - acc: 0.8625
 384/4397 [=>............................] - ETA: 3s - loss: 0.2578 - acc: 0.8750
 448/4397 [==>...........................] - ETA: 3s - loss: 0.2454 - acc: 0.8839
 512/4397 [==>...........................] - ETA: 3s - loss: 0.2484 - acc: 0.8789
 576/4397 [==>...........................] - ETA: 3s - loss: 0.2423 - acc: 0.8837
 640/4397 [===>..........................] - ETA: 3s - loss: 0.2455 - acc: 0.8828
 704/4397 [===>..........................] - ETA: 3s - loss: 0.2613 - acc: 0.8778
 768/4397 [====>.........................] - ETA: 3s - loss: 0.2602 - acc: 0.8776
 832/4397 [====>.........................] - ETA: 3s - loss: 0.2532 - acc: 0.8834
 896/4397 [=====>........................] - ETA: 3s - loss: 0.2531 - acc: 0.8850
 960/4397 [=====>........................] - ETA: 3s - loss: 0.2451 - acc: 0.8885
1024/4397 [=====>........................] - ETA: 3s - loss: 0.2483 - acc: 0.8848
1088/4397 [======>.......................] - ETA: 2s - loss: 0.2490 - acc: 0.8860
1152/4397 [======>.......................] - ETA: 2s - loss: 0.2521 - acc: 0.8837
1216/4397 [=======>......................] - ETA: 2s - loss: 0.2573 - acc: 0.8808
1280/4397 [=======>......................] - ETA: 2s - loss: 0.2541 - acc: 0.8820
1344/4397 [========>.....................] - ETA: 2s - loss: 0.2597 - acc: 0.8802
1408/4397 [========>.....................] - ETA: 2s - loss: 0.2542 - acc: 0.8842
1472/4397 [=========>....................] - ETA: 2s - loss: 0.2527 - acc: 0.8838
1536/4397 [=========>....................] - ETA: 2s - loss: 0.2554 - acc: 0.8828
1600/4397 [=========>....................] - ETA: 2s - loss: 0.2575 - acc: 0.8812
1728/4397 [==========>...................] - ETA: 2s - loss: 0.2600 - acc: 0.8785
1792/4397 [===========>..................] - ETA: 2s - loss: 0.2611 - acc: 0.8789
1920/4397 [============>.................] - ETA: 2s - loss: 0.2637 - acc: 0.8781
2048/4397 [============>.................] - ETA: 1s - loss: 0.2730 - acc: 0.8726
2112/4397 [=============>................] - ETA: 1s - loss: 0.2742 - acc: 0.8731
2176/4397 [=============>................] - ETA: 1s - loss: 0.2723 - acc: 0.8750
2240/4397 [==============>...............] - ETA: 1s - loss: 0.2681 - acc: 0.8772
2304/4397 [==============>...............] - ETA: 1s - loss: 0.2702 - acc: 0.8746
2432/4397 [===============>..............] - ETA: 1s - loss: 0.2698 - acc: 0.8750
2496/4397 [================>.............] - ETA: 1s - loss: 0.2671 - acc: 0.8770
2560/4397 [================>.............] - ETA: 1s - loss: 0.2683 - acc: 0.8766
2624/4397 [================>.............] - ETA: 1s - loss: 0.2668 - acc: 0.8780
2688/4397 [=================>............] - ETA: 1s - loss: 0.2707 - acc: 0.8772
2752/4397 [=================>............] - ETA: 1s - loss: 0.2721 - acc: 0.8757
2816/4397 [==================>...........] - ETA: 1s - loss: 0.2696 - acc: 0.8771
2880/4397 [==================>...........] - ETA: 1s - loss: 0.2693 - acc: 0.8767
2944/4397 [===================>..........] - ETA: 1s - loss: 0.2705 - acc: 0.8753
3008/4397 [===================>..........] - ETA: 1s - loss: 0.2698 - acc: 0.8753
3072/4397 [===================>..........] - ETA: 1s - loss: 0.2732 - acc: 0.8747
3136/4397 [====================>.........] - ETA: 1s - loss: 0.2724 - acc: 0.8753
3200/4397 [====================>.........] - ETA: 1s - loss: 0.2696 - acc: 0.8762
3264/4397 [=====================>........] - ETA: 0s - loss: 0.2708 - acc: 0.8765
3328/4397 [=====================>........] - ETA: 0s - loss: 0.2694 - acc: 0.8771
3392/4397 [======================>.......] - ETA: 0s - loss: 0.2704 - acc: 0.8768
3456/4397 [======================>.......] - ETA: 0s - loss: 0.2707 - acc: 0.8770
3520/4397 [=======================>......] - ETA: 0s - loss: 0.2698 - acc: 0.8770
3584/4397 [=======================>......] - ETA: 0s - loss: 0.2692 - acc: 0.8772
3648/4397 [=======================>......] - ETA: 0s - loss: 0.2687 - acc: 0.8777
3712/4397 [========================>.....] - ETA: 0s - loss: 0.2685 - acc: 0.8780
3776/4397 [========================>.....] - ETA: 0s - loss: 0.2673 - acc: 0.8784
3840/4397 [=========================>....] - ETA: 0s - loss: 0.2673 - acc: 0.8784
3904/4397 [=========================>....] - ETA: 0s - loss: 0.2694 - acc: 0.8770
3968/4397 [==========================>...] - ETA: 0s - loss: 0.2704 - acc: 0.8765
4032/4397 [==========================>...] - ETA: 0s - loss: 0.2703 - acc: 0.8762
4096/4397 [==========================>...] - ETA: 0s - loss: 0.2724 - acc: 0.8752
4160/4397 [===========================>..] - ETA: 0s - loss: 0.2712 - acc: 0.8760
4224/4397 [===========================>..] - ETA: 0s - loss: 0.2710 - acc: 0.8762
4288/4397 [============================>.] - ETA: 0s - loss: 0.2698 - acc: 0.8771
4352/4397 [============================>.] - ETA: 0s - loss: 0.2702 - acc: 0.8768
4397/4397 [==============================] - 4s 841us/step - loss: 0.2709 - acc: 0.8767

Test accuracy: 85.62628336755647

data size :  4884

zero :  2443

one :  2441

train_zero :  2199

train_one :  2198

test_zero :  244

test_one :  243

choose_zero :  232

choose_one :  255

F1score :  0.8594377510040161

AUC :  0.9294086891992175

Confusion Matrix
[[203  41]
 [ 29 214]]
True label 0
0.8319672131147541  
0.1680327868852459  
True label 1
0.11934156378600823  
0.8806584362139918  

Train_result {'acc': [0.8767341369928651], 'loss': [0.27087260724767814]}
Saved model to disk


10

Epoch 1/1

  64/4397 [..............................] - ETA: 4s - loss: 0.2110 - acc: 0.9375
 128/4397 [..............................] - ETA: 4s - loss: 0.2126 - acc: 0.9219
 192/4397 [>.............................] - ETA: 4s - loss: 0.2060 - acc: 0.9219
 256/4397 [>.............................] - ETA: 3s - loss: 0.2361 - acc: 0.9023
 320/4397 [=>............................] - ETA: 3s - loss: 0.2552 - acc: 0.8875
 384/4397 [=>............................] - ETA: 3s - loss: 0.2429 - acc: 0.8906
 512/4397 [==>...........................] - ETA: 3s - loss: 0.2562 - acc: 0.8828
 576/4397 [==>...........................] - ETA: 3s - loss: 0.2506 - acc: 0.8889
 640/4397 [===>..........................] - ETA: 3s - loss: 0.2628 - acc: 0.8828
 704/4397 [===>..........................] - ETA: 3s - loss: 0.2739 - acc: 0.8778
 768/4397 [====>.........................] - ETA: 3s - loss: 0.2698 - acc: 0.8789
 832/4397 [====>.........................] - ETA: 2s - loss: 0.2636 - acc: 0.8798
 896/4397 [=====>........................] - ETA: 2s - loss: 0.2530 - acc: 0.8862
 960/4397 [=====>........................] - ETA: 2s - loss: 0.2539 - acc: 0.8885
1024/4397 [=====>........................] - ETA: 2s - loss: 0.2496 - acc: 0.8916
1088/4397 [======>.......................] - ETA: 2s - loss: 0.2555 - acc: 0.8888
1152/4397 [======>.......................] - ETA: 2s - loss: 0.2550 - acc: 0.8880
1216/4397 [=======>......................] - ETA: 2s - loss: 0.2521 - acc: 0.8890
1280/4397 [=======>......................] - ETA: 2s - loss: 0.2523 - acc: 0.8891
1408/4397 [========>.....................] - ETA: 2s - loss: 0.2591 - acc: 0.8835
1472/4397 [=========>....................] - ETA: 2s - loss: 0.2590 - acc: 0.8832
1536/4397 [=========>....................] - ETA: 2s - loss: 0.2632 - acc: 0.8809
1664/4397 [==========>...................] - ETA: 2s - loss: 0.2592 - acc: 0.8816
1728/4397 [==========>...................] - ETA: 2s - loss: 0.2624 - acc: 0.8796
1792/4397 [===========>..................] - ETA: 2s - loss: 0.2595 - acc: 0.8811
1856/4397 [===========>..................] - ETA: 2s - loss: 0.2607 - acc: 0.8804
1984/4397 [============>.................] - ETA: 2s - loss: 0.2620 - acc: 0.8800
2048/4397 [============>.................] - ETA: 1s - loss: 0.2661 - acc: 0.8789
2112/4397 [=============>................] - ETA: 1s - loss: 0.2630 - acc: 0.8807
2176/4397 [=============>................] - ETA: 1s - loss: 0.2614 - acc: 0.8819
2240/4397 [==============>...............] - ETA: 1s - loss: 0.2619 - acc: 0.8812
2368/4397 [===============>..............] - ETA: 1s - loss: 0.2629 - acc: 0.8813
2432/4397 [===============>..............] - ETA: 1s - loss: 0.2668 - acc: 0.8799
2496/4397 [================>.............] - ETA: 1s - loss: 0.2642 - acc: 0.8814
2560/4397 [================>.............] - ETA: 1s - loss: 0.2631 - acc: 0.8820
2624/4397 [================>.............] - ETA: 1s - loss: 0.2650 - acc: 0.8811
2688/4397 [=================>............] - ETA: 1s - loss: 0.2654 - acc: 0.8798
2816/4397 [==================>...........] - ETA: 1s - loss: 0.2654 - acc: 0.8793
2880/4397 [==================>...........] - ETA: 1s - loss: 0.2648 - acc: 0.8792
2944/4397 [===================>..........] - ETA: 1s - loss: 0.2635 - acc: 0.8798
3008/4397 [===================>..........] - ETA: 1s - loss: 0.2617 - acc: 0.8807
3072/4397 [===================>..........] - ETA: 1s - loss: 0.2625 - acc: 0.8818
3200/4397 [====================>.........] - ETA: 0s - loss: 0.2597 - acc: 0.8825
3264/4397 [=====================>........] - ETA: 0s - loss: 0.2584 - acc: 0.8833
3328/4397 [=====================>........] - ETA: 0s - loss: 0.2604 - acc: 0.8837
3392/4397 [======================>.......] - ETA: 0s - loss: 0.2601 - acc: 0.8833
3456/4397 [======================>.......] - ETA: 0s - loss: 0.2577 - acc: 0.8845
3520/4397 [=======================>......] - ETA: 0s - loss: 0.2575 - acc: 0.8847
3584/4397 [=======================>......] - ETA: 0s - loss: 0.2574 - acc: 0.8845
3648/4397 [=======================>......] - ETA: 0s - loss: 0.2576 - acc: 0.8838
3712/4397 [========================>.....] - ETA: 0s - loss: 0.2593 - acc: 0.8815
3776/4397 [========================>.....] - ETA: 0s - loss: 0.2589 - acc: 0.8822
3840/4397 [=========================>....] - ETA: 0s - loss: 0.2594 - acc: 0.8818
3904/4397 [=========================>....] - ETA: 0s - loss: 0.2597 - acc: 0.8819
3968/4397 [==========================>...] - ETA: 0s - loss: 0.2586 - acc: 0.8826
4032/4397 [==========================>...] - ETA: 0s - loss: 0.2596 - acc: 0.8817
4096/4397 [==========================>...] - ETA: 0s - loss: 0.2604 - acc: 0.8818
4224/4397 [===========================>..] - ETA: 0s - loss: 0.2605 - acc: 0.8821
4352/4397 [============================>.] - ETA: 0s - loss: 0.2577 - acc: 0.8833
4397/4397 [==============================] - 4s 832us/step - loss: 0.2566 - acc: 0.8836

Test accuracy: 83.9835728952772

data size :  4884

zero :  2443

one :  2441

train_zero :  2199

train_one :  2198

test_zero :  244

test_one :  243

choose_zero :  208

choose_one :  279

F1score :  0.8505747126436781

AUC :  0.9306230182823989

Confusion Matrix
[[187  57]
 [ 21 222]]
True label 0
0.7663934426229508  
0.2336065573770492  
True label 1
0.08641975308641975  
0.9135802469135802  

Train_result {'acc': [0.8835569707160379], 'loss': [0.2565540044937238]}
Saved model to disk


11

Epoch 1/1

  64/4397 [..............................] - ETA: 4s - loss: 0.2453 - acc: 0.8438
 128/4397 [..............................] - ETA: 4s - loss: 0.2119 - acc: 0.8672
 256/4397 [>.............................] - ETA: 3s - loss: 0.2486 - acc: 0.8555
 384/4397 [=>............................] - ETA: 3s - loss: 0.2435 - acc: 0.8776
 448/4397 [==>...........................] - ETA: 3s - loss: 0.2414 - acc: 0.8817
 512/4397 [==>...........................] - ETA: 3s - loss: 0.2483 - acc: 0.8770
 576/4397 [==>...........................] - ETA: 3s - loss: 0.2458 - acc: 0.8819
 640/4397 [===>..........................] - ETA: 3s - loss: 0.2495 - acc: 0.8812
 704/4397 [===>..........................] - ETA: 3s - loss: 0.2607 - acc: 0.8821
 768/4397 [====>.........................] - ETA: 2s - loss: 0.2569 - acc: 0.8880
 832/4397 [====>.........................] - ETA: 2s - loss: 0.2521 - acc: 0.8906
 896/4397 [=====>........................] - ETA: 2s - loss: 0.2489 - acc: 0.8917
 960/4397 [=====>........................] - ETA: 2s - loss: 0.2442 - acc: 0.8927
1088/4397 [======>.......................] - ETA: 2s - loss: 0.2537 - acc: 0.8869
1152/4397 [======>.......................] - ETA: 2s - loss: 0.2531 - acc: 0.8880
1216/4397 [=======>......................] - ETA: 2s - loss: 0.2513 - acc: 0.8882
1280/4397 [=======>......................] - ETA: 2s - loss: 0.2548 - acc: 0.8859
1344/4397 [========>.....................] - ETA: 2s - loss: 0.2531 - acc: 0.8862
1408/4397 [========>.....................] - ETA: 2s - loss: 0.2506 - acc: 0.8871
1472/4397 [=========>....................] - ETA: 2s - loss: 0.2517 - acc: 0.8872
1536/4397 [=========>....................] - ETA: 2s - loss: 0.2517 - acc: 0.8861
1664/4397 [==========>...................] - ETA: 2s - loss: 0.2446 - acc: 0.8900
1728/4397 [==========>...................] - ETA: 2s - loss: 0.2437 - acc: 0.8906
1792/4397 [===========>..................] - ETA: 2s - loss: 0.2402 - acc: 0.8929
1920/4397 [============>.................] - ETA: 2s - loss: 0.2465 - acc: 0.8911
1984/4397 [============>.................] - ETA: 1s - loss: 0.2450 - acc: 0.8921
2048/4397 [============>.................] - ETA: 1s - loss: 0.2411 - acc: 0.8936
2112/4397 [=============>................] - ETA: 1s - loss: 0.2410 - acc: 0.8935
2176/4397 [=============>................] - ETA: 1s - loss: 0.2396 - acc: 0.8952
2304/4397 [==============>...............] - ETA: 1s - loss: 0.2423 - acc: 0.8945
2432/4397 [===============>..............] - ETA: 1s - loss: 0.2414 - acc: 0.8960
2496/4397 [================>.............] - ETA: 1s - loss: 0.2401 - acc: 0.8966
2560/4397 [================>.............] - ETA: 1s - loss: 0.2439 - acc: 0.8953
2688/4397 [=================>............] - ETA: 1s - loss: 0.2449 - acc: 0.8943
2752/4397 [=================>............] - ETA: 1s - loss: 0.2440 - acc: 0.8943
2816/4397 [==================>...........] - ETA: 1s - loss: 0.2429 - acc: 0.8945
2880/4397 [==================>...........] - ETA: 1s - loss: 0.2420 - acc: 0.8948
2944/4397 [===================>..........] - ETA: 1s - loss: 0.2427 - acc: 0.8940
3008/4397 [===================>..........] - ETA: 1s - loss: 0.2416 - acc: 0.8946
3072/4397 [===================>..........] - ETA: 1s - loss: 0.2416 - acc: 0.8939
3136/4397 [====================>.........] - ETA: 1s - loss: 0.2411 - acc: 0.8941
3200/4397 [====================>.........] - ETA: 0s - loss: 0.2397 - acc: 0.8950
3264/4397 [=====================>........] - ETA: 0s - loss: 0.2408 - acc: 0.8946
3328/4397 [=====================>........] - ETA: 0s - loss: 0.2414 - acc: 0.8942
3392/4397 [======================>.......] - ETA: 0s - loss: 0.2410 - acc: 0.8950
3456/4397 [======================>.......] - ETA: 0s - loss: 0.2430 - acc: 0.8932
3520/4397 [=======================>......] - ETA: 0s - loss: 0.2423 - acc: 0.8935
3584/4397 [=======================>......] - ETA: 0s - loss: 0.2429 - acc: 0.8940
3648/4397 [=======================>......] - ETA: 0s - loss: 0.2437 - acc: 0.8939
3712/4397 [========================>.....] - ETA: 0s - loss: 0.2450 - acc: 0.8936
3776/4397 [========================>.....] - ETA: 0s - loss: 0.2444 - acc: 0.8941
3840/4397 [=========================>....] - ETA: 0s - loss: 0.2473 - acc: 0.8940
3904/4397 [=========================>....] - ETA: 0s - loss: 0.2471 - acc: 0.8929
3968/4397 [==========================>...] - ETA: 0s - loss: 0.2456 - acc: 0.8936
4032/4397 [==========================>...] - ETA: 0s - loss: 0.2455 - acc: 0.8938
4096/4397 [==========================>...] - ETA: 0s - loss: 0.2471 - acc: 0.8926
4160/4397 [===========================>..] - ETA: 0s - loss: 0.2502 - acc: 0.8911
4224/4397 [===========================>..] - ETA: 0s - loss: 0.2498 - acc: 0.8913
4288/4397 [============================>.] - ETA: 0s - loss: 0.2495 - acc: 0.8911
4352/4397 [============================>.] - ETA: 0s - loss: 0.2486 - acc: 0.8918
4397/4397 [==============================] - 4s 829us/step - loss: 0.2495 - acc: 0.8911

Test accuracy: 85.21560574948666

data size :  4884

zero :  2443

one :  2441

train_zero :  2199

train_one :  2198

test_zero :  244

test_one :  243

choose_zero :  266

choose_one :  221

F1score :  0.8448275862068966

AUC :  0.9301001821493625

Confusion Matrix
[[219  25]
 [ 47 196]]
True label 0
0.8975409836065574  
0.10245901639344263  
True label 1
0.1934156378600823  
0.8065843621399177  

Train_result {'acc': [0.8910620878955736], 'loss': [0.24947084707104403]}
Saved model to disk


12

Epoch 1/1

  64/4397 [..............................] - ETA: 4s - loss: 0.2451 - acc: 0.8750
 128/4397 [..............................] - ETA: 4s - loss: 0.2418 - acc: 0.8828
 256/4397 [>.............................] - ETA: 3s - loss: 0.2128 - acc: 0.9102
 384/4397 [=>............................] - ETA: 3s - loss: 0.1929 - acc: 0.9193
 512/4397 [==>...........................] - ETA: 3s - loss: 0.1928 - acc: 0.9199
 640/4397 [===>..........................] - ETA: 3s - loss: 0.1974 - acc: 0.9141
 704/4397 [===>..........................] - ETA: 3s - loss: 0.2024 - acc: 0.9119
 768/4397 [====>.........................] - ETA: 2s - loss: 0.2156 - acc: 0.9076
 832/4397 [====>.........................] - ETA: 2s - loss: 0.2248 - acc: 0.9050
 896/4397 [=====>........................] - ETA: 2s - loss: 0.2244 - acc: 0.9051
 960/4397 [=====>........................] - ETA: 2s - loss: 0.2253 - acc: 0.9031
1024/4397 [=====>........................] - ETA: 2s - loss: 0.2203 - acc: 0.9043
1088/4397 [======>.......................] - ETA: 2s - loss: 0.2294 - acc: 0.9017
1152/4397 [======>.......................] - ETA: 2s - loss: 0.2288 - acc: 0.9002
1216/4397 [=======>......................] - ETA: 2s - loss: 0.2332 - acc: 0.8997
1280/4397 [=======>......................] - ETA: 2s - loss: 0.2328 - acc: 0.9008
1408/4397 [========>.....................] - ETA: 2s - loss: 0.2370 - acc: 0.8970
1472/4397 [=========>....................] - ETA: 2s - loss: 0.2378 - acc: 0.8967
1536/4397 [=========>....................] - ETA: 2s - loss: 0.2363 - acc: 0.8991
1600/4397 [=========>....................] - ETA: 2s - loss: 0.2331 - acc: 0.9006
1664/4397 [==========>...................] - ETA: 2s - loss: 0.2316 - acc: 0.9002
1728/4397 [==========>...................] - ETA: 2s - loss: 0.2304 - acc: 0.9005
1792/4397 [===========>..................] - ETA: 2s - loss: 0.2336 - acc: 0.9012
1920/4397 [============>.................] - ETA: 2s - loss: 0.2386 - acc: 0.8974
1984/4397 [============>.................] - ETA: 1s - loss: 0.2450 - acc: 0.8936
2048/4397 [============>.................] - ETA: 1s - loss: 0.2494 - acc: 0.8921
2112/4397 [=============>................] - ETA: 1s - loss: 0.2499 - acc: 0.8916
2176/4397 [=============>................] - ETA: 1s - loss: 0.2470 - acc: 0.8929
2304/4397 [==============>...............] - ETA: 1s - loss: 0.2469 - acc: 0.8932
2368/4397 [===============>..............] - ETA: 1s - loss: 0.2461 - acc: 0.8936
2432/4397 [===============>..............] - ETA: 1s - loss: 0.2448 - acc: 0.8939
2496/4397 [================>.............] - ETA: 1s - loss: 0.2474 - acc: 0.8934
2560/4397 [================>.............] - ETA: 1s - loss: 0.2471 - acc: 0.8938
2624/4397 [================>.............] - ETA: 1s - loss: 0.2479 - acc: 0.8925
2688/4397 [=================>............] - ETA: 1s - loss: 0.2469 - acc: 0.8929
2752/4397 [=================>............] - ETA: 1s - loss: 0.2467 - acc: 0.8924
2816/4397 [==================>...........] - ETA: 1s - loss: 0.2468 - acc: 0.8928
2944/4397 [===================>..........] - ETA: 1s - loss: 0.2475 - acc: 0.8903
3008/4397 [===================>..........] - ETA: 1s - loss: 0.2472 - acc: 0.8913
3072/4397 [===================>..........] - ETA: 1s - loss: 0.2480 - acc: 0.8916
3200/4397 [====================>.........] - ETA: 0s - loss: 0.2463 - acc: 0.8919
3264/4397 [=====================>........] - ETA: 0s - loss: 0.2487 - acc: 0.8909
3392/4397 [======================>.......] - ETA: 0s - loss: 0.2442 - acc: 0.8933
3456/4397 [======================>.......] - ETA: 0s - loss: 0.2432 - acc: 0.8932
3520/4397 [=======================>......] - ETA: 0s - loss: 0.2430 - acc: 0.8932
3648/4397 [=======================>......] - ETA: 0s - loss: 0.2406 - acc: 0.8945
3776/4397 [========================>.....] - ETA: 0s - loss: 0.2390 - acc: 0.8951
3840/4397 [=========================>....] - ETA: 0s - loss: 0.2396 - acc: 0.8945
3968/4397 [==========================>...] - ETA: 0s - loss: 0.2402 - acc: 0.8949
4032/4397 [==========================>...] - ETA: 0s - loss: 0.2394 - acc: 0.8953
4096/4397 [==========================>...] - ETA: 0s - loss: 0.2397 - acc: 0.8953
4224/4397 [===========================>..] - ETA: 0s - loss: 0.2397 - acc: 0.8949
4288/4397 [============================>.] - ETA: 0s - loss: 0.2417 - acc: 0.8937
4397/4397 [==============================] - 4s 815us/step - loss: 0.2430 - acc: 0.8931

Test accuracy: 85.83162217659137

data size :  4884

zero :  2443

one :  2441

train_zero :  2199

train_one :  2198

test_zero :  244

test_one :  243

choose_zero :  235

choose_one :  252

F1score :  0.8606060606060606

AUC :  0.9297797341968563

Confusion Matrix
[[205  39]
 [ 30 213]]
True label 0
0.8401639344262295  
0.1598360655737705  
True label 1
0.12345679012345678  
0.8765432098765432  

Train_result {'acc': [0.8931089380206589], 'loss': [0.2430372571901812]}
Saved model to disk


13

Epoch 1/1

  64/4397 [..............................] - ETA: 5s - loss: 0.2276 - acc: 0.8906
 128/4397 [..............................] - ETA: 4s - loss: 0.1911 - acc: 0.9062
 192/4397 [>.............................] - ETA: 4s - loss: 0.1992 - acc: 0.9062
 256/4397 [>.............................] - ETA: 3s - loss: 0.1877 - acc: 0.9102
 320/4397 [=>............................] - ETA: 3s - loss: 0.1885 - acc: 0.9156
 384/4397 [=>............................] - ETA: 3s - loss: 0.2042 - acc: 0.9062
 448/4397 [==>...........................] - ETA: 3s - loss: 0.2339 - acc: 0.9018
 512/4397 [==>...........................] - ETA: 3s - loss: 0.2322 - acc: 0.9043
 576/4397 [==>...........................] - ETA: 3s - loss: 0.2287 - acc: 0.9062
 640/4397 [===>..........................] - ETA: 3s - loss: 0.2374 - acc: 0.8984
 704/4397 [===>..........................] - ETA: 3s - loss: 0.2362 - acc: 0.8991
 768/4397 [====>.........................] - ETA: 3s - loss: 0.2293 - acc: 0.9023
 832/4397 [====>.........................] - ETA: 3s - loss: 0.2325 - acc: 0.8990
 896/4397 [=====>........................] - ETA: 3s - loss: 0.2372 - acc: 0.8940
 960/4397 [=====>........................] - ETA: 2s - loss: 0.2302 - acc: 0.8990
1024/4397 [=====>........................] - ETA: 2s - loss: 0.2242 - acc: 0.9014
1088/4397 [======>.......................] - ETA: 2s - loss: 0.2243 - acc: 0.8998
1152/4397 [======>.......................] - ETA: 2s - loss: 0.2245 - acc: 0.9002
1216/4397 [=======>......................] - ETA: 2s - loss: 0.2260 - acc: 0.9005
1280/4397 [=======>......................] - ETA: 2s - loss: 0.2262 - acc: 0.9000
1344/4397 [========>.....................] - ETA: 2s - loss: 0.2330 - acc: 0.8981
1408/4397 [========>.....................] - ETA: 2s - loss: 0.2307 - acc: 0.8999
1472/4397 [=========>....................] - ETA: 2s - loss: 0.2286 - acc: 0.9015
1536/4397 [=========>....................] - ETA: 2s - loss: 0.2282 - acc: 0.9030
1600/4397 [=========>....................] - ETA: 2s - loss: 0.2252 - acc: 0.9038
1728/4397 [==========>...................] - ETA: 2s - loss: 0.2283 - acc: 0.9028
1856/4397 [===========>..................] - ETA: 2s - loss: 0.2273 - acc: 0.9030
1920/4397 [============>.................] - ETA: 2s - loss: 0.2333 - acc: 0.9005
1984/4397 [============>.................] - ETA: 2s - loss: 0.2325 - acc: 0.9002
2048/4397 [============>.................] - ETA: 1s - loss: 0.2344 - acc: 0.8984
2112/4397 [=============>................] - ETA: 1s - loss: 0.2321 - acc: 0.8991
2176/4397 [=============>................] - ETA: 1s - loss: 0.2300 - acc: 0.9007
2240/4397 [==============>...............] - ETA: 1s - loss: 0.2276 - acc: 0.9018
2304/4397 [==============>...............] - ETA: 1s - loss: 0.2261 - acc: 0.9015
2368/4397 [===============>..............] - ETA: 1s - loss: 0.2257 - acc: 0.9016
2432/4397 [===============>..............] - ETA: 1s - loss: 0.2269 - acc: 0.9013
2496/4397 [================>.............] - ETA: 1s - loss: 0.2247 - acc: 0.9026
2560/4397 [================>.............] - ETA: 1s - loss: 0.2263 - acc: 0.9020
2624/4397 [================>.............] - ETA: 1s - loss: 0.2282 - acc: 0.9017
2688/4397 [=================>............] - ETA: 1s - loss: 0.2307 - acc: 0.9010
2752/4397 [=================>............] - ETA: 1s - loss: 0.2288 - acc: 0.9015
2816/4397 [==================>...........] - ETA: 1s - loss: 0.2283 - acc: 0.9020
2880/4397 [==================>...........] - ETA: 1s - loss: 0.2302 - acc: 0.9007
3008/4397 [===================>..........] - ETA: 1s - loss: 0.2307 - acc: 0.9006
3072/4397 [===================>..........] - ETA: 1s - loss: 0.2303 - acc: 0.9010
3200/4397 [====================>.........] - ETA: 0s - loss: 0.2277 - acc: 0.9019
3264/4397 [=====================>........] - ETA: 0s - loss: 0.2277 - acc: 0.9013
3328/4397 [=====================>........] - ETA: 0s - loss: 0.2276 - acc: 0.9008
3456/4397 [======================>.......] - ETA: 0s - loss: 0.2308 - acc: 0.8987
3520/4397 [=======================>......] - ETA: 0s - loss: 0.2312 - acc: 0.8983
3648/4397 [=======================>......] - ETA: 0s - loss: 0.2302 - acc: 0.8997
3712/4397 [========================>.....] - ETA: 0s - loss: 0.2335 - acc: 0.8987
3776/4397 [========================>.....] - ETA: 0s - loss: 0.2328 - acc: 0.8988
3840/4397 [=========================>....] - ETA: 0s - loss: 0.2318 - acc: 0.8997
3968/4397 [==========================>...] - ETA: 0s - loss: 0.2314 - acc: 0.9002
4032/4397 [==========================>...] - ETA: 0s - loss: 0.2318 - acc: 0.9000
4096/4397 [==========================>...] - ETA: 0s - loss: 0.2333 - acc: 0.8989
4160/4397 [===========================>..] - ETA: 0s - loss: 0.2341 - acc: 0.8990
4224/4397 [===========================>..] - ETA: 0s - loss: 0.2345 - acc: 0.8984
4288/4397 [============================>.] - ETA: 0s - loss: 0.2341 - acc: 0.8988
4352/4397 [============================>.] - ETA: 0s - loss: 0.2336 - acc: 0.8991
4397/4397 [==============================] - 4s 826us/step - loss: 0.2341 - acc: 0.8988

Test accuracy: 82.75154004106776

data size :  4884

zero :  2443

one :  2441

train_zero :  2199

train_one :  2198

test_zero :  244

test_one :  243

choose_zero :  286

choose_one :  201

F1score :  0.8108108108108107

AUC :  0.9332034675841597

Confusion Matrix
[[223  21]
 [ 63 180]]
True label 0
0.9139344262295082  
0.0860655737704918  
True label 1
0.25925925925925924  
0.7407407407407407  

Train_result {'acc': [0.8987946327854509], 'loss': [0.23409576593731543]}
Saved model to disk


14

Epoch 1/1

  64/4397 [..............................] - ETA: 4s - loss: 0.3027 - acc: 0.7969
 128/4397 [..............................] - ETA: 4s - loss: 0.2748 - acc: 0.8281
 256/4397 [>.............................] - ETA: 3s - loss: 0.2493 - acc: 0.8711
 320/4397 [=>............................] - ETA: 3s - loss: 0.2265 - acc: 0.8844
 384/4397 [=>............................] - ETA: 3s - loss: 0.2205 - acc: 0.8932
 512/4397 [==>...........................] - ETA: 3s - loss: 0.2326 - acc: 0.9023
 576/4397 [==>...........................] - ETA: 3s - loss: 0.2272 - acc: 0.9045
 640/4397 [===>..........................] - ETA: 3s - loss: 0.2265 - acc: 0.9016
 704/4397 [===>..........................] - ETA: 3s - loss: 0.2265 - acc: 0.8991
 768/4397 [====>.........................] - ETA: 3s - loss: 0.2206 - acc: 0.9010
 832/4397 [====>.........................] - ETA: 2s - loss: 0.2134 - acc: 0.9062
 896/4397 [=====>........................] - ETA: 2s - loss: 0.2105 - acc: 0.9085
 960/4397 [=====>........................] - ETA: 2s - loss: 0.2138 - acc: 0.9073
1024/4397 [=====>........................] - ETA: 2s - loss: 0.2095 - acc: 0.9092
1088/4397 [======>.......................] - ETA: 2s - loss: 0.2156 - acc: 0.9072
1216/4397 [=======>......................] - ETA: 2s - loss: 0.2101 - acc: 0.9104
1280/4397 [=======>......................] - ETA: 2s - loss: 0.2102 - acc: 0.9102
1344/4397 [========>.....................] - ETA: 2s - loss: 0.2140 - acc: 0.9085
1472/4397 [=========>....................] - ETA: 2s - loss: 0.2156 - acc: 0.9096
1600/4397 [=========>....................] - ETA: 2s - loss: 0.2103 - acc: 0.9137
1728/4397 [==========>...................] - ETA: 2s - loss: 0.2148 - acc: 0.9120
1856/4397 [===========>..................] - ETA: 2s - loss: 0.2179 - acc: 0.9089
1984/4397 [============>.................] - ETA: 1s - loss: 0.2228 - acc: 0.9057
2112/4397 [=============>................] - ETA: 1s - loss: 0.2267 - acc: 0.9039
2176/4397 [=============>................] - ETA: 1s - loss: 0.2246 - acc: 0.9049
2240/4397 [==============>...............] - ETA: 1s - loss: 0.2235 - acc: 0.9049
2304/4397 [==============>...............] - ETA: 1s - loss: 0.2246 - acc: 0.9049
2368/4397 [===============>..............] - ETA: 1s - loss: 0.2220 - acc: 0.9071
2496/4397 [================>.............] - ETA: 1s - loss: 0.2254 - acc: 0.9038
2560/4397 [================>.............] - ETA: 1s - loss: 0.2266 - acc: 0.9031
2688/4397 [=================>............] - ETA: 1s - loss: 0.2273 - acc: 0.9014
2816/4397 [==================>...........] - ETA: 1s - loss: 0.2233 - acc: 0.9041
2944/4397 [===================>..........] - ETA: 1s - loss: 0.2220 - acc: 0.9042
3072/4397 [===================>..........] - ETA: 1s - loss: 0.2218 - acc: 0.9040
3136/4397 [====================>.........] - ETA: 1s - loss: 0.2215 - acc: 0.9043
3200/4397 [====================>.........] - ETA: 0s - loss: 0.2201 - acc: 0.9053
3264/4397 [=====================>........] - ETA: 0s - loss: 0.2201 - acc: 0.9059
3328/4397 [=====================>........] - ETA: 0s - loss: 0.2219 - acc: 0.9050
3392/4397 [======================>.......] - ETA: 0s - loss: 0.2220 - acc: 0.9048
3456/4397 [======================>.......] - ETA: 0s - loss: 0.2212 - acc: 0.9051
3520/4397 [=======================>......] - ETA: 0s - loss: 0.2211 - acc: 0.9054
3584/4397 [=======================>......] - ETA: 0s - loss: 0.2222 - acc: 0.9054
3648/4397 [=======================>......] - ETA: 0s - loss: 0.2218 - acc: 0.9057
3712/4397 [========================>.....] - ETA: 0s - loss: 0.2227 - acc: 0.9057
3776/4397 [========================>.....] - ETA: 0s - loss: 0.2232 - acc: 0.9057
3840/4397 [=========================>....] - ETA: 0s - loss: 0.2228 - acc: 0.9057
3904/4397 [=========================>....] - ETA: 0s - loss: 0.2221 - acc: 0.9055
3968/4397 [==========================>...] - ETA: 0s - loss: 0.2227 - acc: 0.9050
4032/4397 [==========================>...] - ETA: 0s - loss: 0.2236 - acc: 0.9048
4096/4397 [==========================>...] - ETA: 0s - loss: 0.2228 - acc: 0.9050
4160/4397 [===========================>..] - ETA: 0s - loss: 0.2226 - acc: 0.9050
4224/4397 [===========================>..] - ETA: 0s - loss: 0.2232 - acc: 0.9041
4288/4397 [============================>.] - ETA: 0s - loss: 0.2222 - acc: 0.9044
4352/4397 [============================>.] - ETA: 0s - loss: 0.2221 - acc: 0.9049
4397/4397 [==============================] - 4s 831us/step - loss: 0.2233 - acc: 0.9047

Test accuracy: 83.5728952772074

data size :  4884

zero :  2443

one :  2441

train_zero :  2199

train_one :  2198

test_zero :  244

test_one :  243

choose_zero :  224

choose_one :  263

F1score :  0.8418972332015812

AUC :  0.9244501787762262

Confusion Matrix
[[194  50]
 [ 30 213]]
True label 0
0.7950819672131147  
0.20491803278688525  
True label 1
0.12345679012345678  
0.8765432098765432  

Train_result {'acc': [0.9047077553554749], 'loss': [0.22330080332988117]}
Saved model to disk


15

Epoch 1/1

  64/4397 [..............................] - ETA: 4s - loss: 0.2358 - acc: 0.9062
 128/4397 [..............................] - ETA: 4s - loss: 0.2137 - acc: 0.8906
 256/4397 [>.............................] - ETA: 3s - loss: 0.2108 - acc: 0.8906
 320/4397 [=>............................] - ETA: 3s - loss: 0.2015 - acc: 0.9031
 384/4397 [=>............................] - ETA: 3s - loss: 0.2168 - acc: 0.8958
 448/4397 [==>...........................] - ETA: 3s - loss: 0.2223 - acc: 0.8973
 512/4397 [==>...........................] - ETA: 3s - loss: 0.2241 - acc: 0.8965
 576/4397 [==>...........................] - ETA: 3s - loss: 0.2134 - acc: 0.9028
 640/4397 [===>..........................] - ETA: 3s - loss: 0.2068 - acc: 0.9047
 704/4397 [===>..........................] - ETA: 3s - loss: 0.1994 - acc: 0.9091
 768/4397 [====>.........................] - ETA: 3s - loss: 0.1948 - acc: 0.9141
 832/4397 [====>.........................] - ETA: 2s - loss: 0.2016 - acc: 0.9135
 896/4397 [=====>........................] - ETA: 2s - loss: 0.2032 - acc: 0.9118
 960/4397 [=====>........................] - ETA: 2s - loss: 0.2084 - acc: 0.9104
1024/4397 [=====>........................] - ETA: 2s - loss: 0.2076 - acc: 0.9121
1088/4397 [======>.......................] - ETA: 2s - loss: 0.2056 - acc: 0.9118
1216/4397 [=======>......................] - ETA: 2s - loss: 0.2073 - acc: 0.9087
1280/4397 [=======>......................] - ETA: 2s - loss: 0.2069 - acc: 0.9086
1344/4397 [========>.....................] - ETA: 2s - loss: 0.2033 - acc: 0.9115
1408/4397 [========>.....................] - ETA: 2s - loss: 0.2009 - acc: 0.9112
1472/4397 [=========>....................] - ETA: 2s - loss: 0.2065 - acc: 0.9090
1536/4397 [=========>....................] - ETA: 2s - loss: 0.2041 - acc: 0.9121
1600/4397 [=========>....................] - ETA: 2s - loss: 0.2051 - acc: 0.9119
1664/4397 [==========>...................] - ETA: 2s - loss: 0.2115 - acc: 0.9105
1728/4397 [==========>...................] - ETA: 2s - loss: 0.2125 - acc: 0.9080
1792/4397 [===========>..................] - ETA: 2s - loss: 0.2122 - acc: 0.9074
1856/4397 [===========>..................] - ETA: 2s - loss: 0.2136 - acc: 0.9062
1920/4397 [============>.................] - ETA: 2s - loss: 0.2125 - acc: 0.9068
1984/4397 [============>.................] - ETA: 1s - loss: 0.2134 - acc: 0.9062
2048/4397 [============>.................] - ETA: 1s - loss: 0.2141 - acc: 0.9067
2112/4397 [=============>................] - ETA: 1s - loss: 0.2142 - acc: 0.9062
2176/4397 [=============>................] - ETA: 1s - loss: 0.2142 - acc: 0.9062
2240/4397 [==============>...............] - ETA: 1s - loss: 0.2123 - acc: 0.9076
2304/4397 [==============>...............] - ETA: 1s - loss: 0.2114 - acc: 0.9080
2368/4397 [===============>..............] - ETA: 1s - loss: 0.2121 - acc: 0.9084
2432/4397 [===============>..............] - ETA: 1s - loss: 0.2133 - acc: 0.9083
2560/4397 [================>.............] - ETA: 1s - loss: 0.2150 - acc: 0.9094
2688/4397 [=================>............] - ETA: 1s - loss: 0.2138 - acc: 0.9092
2752/4397 [=================>............] - ETA: 1s - loss: 0.2159 - acc: 0.9095
2816/4397 [==================>...........] - ETA: 1s - loss: 0.2152 - acc: 0.9098
2880/4397 [==================>...........] - ETA: 1s - loss: 0.2152 - acc: 0.9097
3008/4397 [===================>..........] - ETA: 1s - loss: 0.2142 - acc: 0.9109
3072/4397 [===================>..........] - ETA: 1s - loss: 0.2136 - acc: 0.9108
3136/4397 [====================>.........] - ETA: 1s - loss: 0.2155 - acc: 0.9114
3200/4397 [====================>.........] - ETA: 0s - loss: 0.2168 - acc: 0.9113
3264/4397 [=====================>........] - ETA: 0s - loss: 0.2192 - acc: 0.9090
3392/4397 [======================>.......] - ETA: 0s - loss: 0.2195 - acc: 0.9074
3520/4397 [=======================>......] - ETA: 0s - loss: 0.2200 - acc: 0.9071
3584/4397 [=======================>......] - ETA: 0s - loss: 0.2198 - acc: 0.9068
3712/4397 [========================>.....] - ETA: 0s - loss: 0.2196 - acc: 0.9073
3776/4397 [========================>.....] - ETA: 0s - loss: 0.2194 - acc: 0.9076
3840/4397 [=========================>....] - ETA: 0s - loss: 0.2194 - acc: 0.9076
3904/4397 [=========================>....] - ETA: 0s - loss: 0.2203 - acc: 0.9068
4032/4397 [==========================>...] - ETA: 0s - loss: 0.2199 - acc: 0.9077
4096/4397 [==========================>...] - ETA: 0s - loss: 0.2207 - acc: 0.9072
4224/4397 [===========================>..] - ETA: 0s - loss: 0.2210 - acc: 0.9072
4288/4397 [============================>.] - ETA: 0s - loss: 0.2247 - acc: 0.9058
4352/4397 [============================>.] - ETA: 0s - loss: 0.2247 - acc: 0.9058
4397/4397 [==============================] - 4s 814us/step - loss: 0.2239 - acc: 0.9061

Test accuracy: 85.83162217659137

data size :  4884

zero :  2443

one :  2441

train_zero :  2199

train_one :  2198

test_zero :  244

test_one :  243

choose_zero :  249

choose_one :  238

F1score :  0.8565488565488566

AUC :  0.936542872562909

Confusion Matrix
[[212  32]
 [ 37 206]]
True label 0
0.8688524590163934  
0.13114754098360656  
True label 1
0.1522633744855967  
0.8477366255144033  

Train_result {'acc': [0.9060723220784203], 'loss': [0.22389908515176152]}
Saved model to disk


[[81.72484599589322, 1], [83.77823408624229, 2], [82.54620123203286, 3], [84.80492813141683, 4], [84.39425051334702, 5], [83.5728952772074, 6], [86.0369609856263, 7], [87.06365503080082, 8], [85.62628336755647, 9], [83.9835728952772, 10], [85.21560574948666, 11], [85.83162217659137, 12], [82.75154004106776, 13], [83.5728952772074, 14], [85.83162217659137, 15]]
max accuracy :  [87.06365503080082, 8]
