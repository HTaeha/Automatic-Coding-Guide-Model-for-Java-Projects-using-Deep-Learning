Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
/home/2014313303/taeha/JavaAutoLogging/model.py:53: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor("ou...)`
  model = Model(input=[input1, input2], output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-08 03:59:28.923050: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-08 03:59:28.933748: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100085000 Hz
2019-09-08 03:59:28.936205: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0xd518780 executing computations on platform Host. Devices:
2019-09-08 03:59:28.936226: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Standard data
zero :  39451
one :  9019

First data
zero :  39451
one :  9019

Second data
zero :  39451
one :  9019

hbase-AST
After set document size of train data, the number of zero and one label data :  27718 2356
After set document size of test data, the number of zero and one label data :  3087 253

Sentence length Average : 9

Under 10 : 21693
Over 10, Under 30 : 11721
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

After balance out data.
hbase-AST

Sentence length Average : 11

Under 10 : 2794
Over 10, Under 30 : 2426
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

hbase-depth_num
After set document size of train data, the number of zero and one label data :  27718 2356
After set document size of test data, the number of zero and one label data :  3087 253
After balance out data.
hbase-depth_num

Sentence length Average : 11

Under 10 : 2794
Over 10, Under 30 : 2426
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

Count model parameter.
Get a short summary of each layer dimensions and parameters.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 30, 200)      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 30, 200)      0                                            
__________________________________________________________________________________________________
masking_1 (Masking)             (None, 30, 200)      0           input_1[0][0]                    
__________________________________________________________________________________________________
masking_2 (Masking)             (None, 30, 200)      0           input_2[0][0]                    
__________________________________________________________________________________________________
forwards_1 (LSTM)               (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
backwords_1 (LSTM)              (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
forwards_2 (LSTM)               (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
backwards_2 (LSTM)              (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
after_dp_forward_1 (Dropout)    (None, 64)           0           forwards_1[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_1 (Dropout)   (None, 64)           0           backwords_1[0][0]                
__________________________________________________________________________________________________
after_dp_forward_2 (Dropout)    (None, 64)           0           forwards_2[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_2 (Dropout)   (None, 64)           0           backwards_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128)          0           after_dp_forward_1[0][0]         
                                                                 after_dp_backward_1[0][0]        
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 128)          0           after_dp_forward_2[0][0]         
                                                                 after_dp_backward_2[0][0]        
__________________________________________________________________________________________________
after_dp_1 (Dropout)            (None, 128)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
after_dp_2 (Dropout)            (None, 128)          0           concatenate_2[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 256)          0           after_dp_1[0][0]                 
                                                                 after_dp_2[0][0]                 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 256)          65792       concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 128)          32896       dense_1[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 64)           8256        dense_2[0][0]                    
__________________________________________________________________________________________________
output (Dense)                  (None, 2)            130         dense_3[0][0]                    
==================================================================================================
Total params: 378,434
Trainable params: 378,434
Non-trainable params: 0
__________________________________________________________________________________________________
1

Epoch 1/1

  64/4713 [..............................] - ETA: 3:47 - loss: 0.7211 - acc: 0.4531
 192/4713 [>.............................] - ETA: 1:16 - loss: 0.7027 - acc: 0.5000
 320/4713 [=>............................] - ETA: 45s - loss: 0.6908 - acc: 0.5125 
 448/4713 [=>............................] - ETA: 32s - loss: 0.6820 - acc: 0.5625
 576/4713 [==>...........................] - ETA: 25s - loss: 0.6733 - acc: 0.5885
 704/4713 [===>..........................] - ETA: 20s - loss: 0.6576 - acc: 0.6179
 832/4713 [====>.........................] - ETA: 17s - loss: 0.6396 - acc: 0.6454
 896/4713 [====>.........................] - ETA: 15s - loss: 0.6310 - acc: 0.6540
1024/4713 [=====>........................] - ETA: 13s - loss: 0.6179 - acc: 0.6689
1152/4713 [======>.......................] - ETA: 12s - loss: 0.6016 - acc: 0.6806
1280/4713 [=======>......................] - ETA: 10s - loss: 0.5951 - acc: 0.6891
1408/4713 [=======>......................] - ETA: 9s - loss: 0.5802 - acc: 0.6982 
1536/4713 [========>.....................] - ETA: 8s - loss: 0.5735 - acc: 0.7070
1664/4713 [=========>....................] - ETA: 7s - loss: 0.5707 - acc: 0.7097
1792/4713 [==========>...................] - ETA: 7s - loss: 0.5760 - acc: 0.7109
1920/4713 [===========>..................] - ETA: 6s - loss: 0.5624 - acc: 0.7193
2048/4713 [============>.................] - ETA: 5s - loss: 0.5524 - acc: 0.7256
2176/4713 [============>.................] - ETA: 5s - loss: 0.5387 - acc: 0.7335
2304/4713 [=============>................] - ETA: 4s - loss: 0.5299 - acc: 0.7387
2432/4713 [==============>...............] - ETA: 4s - loss: 0.5238 - acc: 0.7438
2560/4713 [===============>..............] - ETA: 4s - loss: 0.5159 - acc: 0.7484
2688/4713 [================>.............] - ETA: 3s - loss: 0.5082 - acc: 0.7530
2816/4713 [================>.............] - ETA: 3s - loss: 0.5073 - acc: 0.7553
2944/4713 [=================>............] - ETA: 3s - loss: 0.4995 - acc: 0.7602
3072/4713 [==================>...........] - ETA: 2s - loss: 0.4973 - acc: 0.7614
3200/4713 [===================>..........] - ETA: 2s - loss: 0.4983 - acc: 0.7600
3328/4713 [====================>.........] - ETA: 2s - loss: 0.4998 - acc: 0.7599
3456/4713 [====================>.........] - ETA: 1s - loss: 0.4972 - acc: 0.7624
3584/4713 [=====================>........] - ETA: 1s - loss: 0.4936 - acc: 0.7637
3712/4713 [======================>.......] - ETA: 1s - loss: 0.4903 - acc: 0.7662
3776/4713 [=======================>......] - ETA: 1s - loss: 0.4871 - acc: 0.7685
3904/4713 [=======================>......] - ETA: 1s - loss: 0.4855 - acc: 0.7707
4032/4713 [========================>.....] - ETA: 0s - loss: 0.4839 - acc: 0.7711
4160/4713 [=========================>....] - ETA: 0s - loss: 0.4796 - acc: 0.7743
4288/4713 [==========================>...] - ETA: 0s - loss: 0.4748 - acc: 0.7773
4416/4713 [===========================>..] - ETA: 0s - loss: 0.4718 - acc: 0.7797
4544/4713 [===========================>..] - ETA: 0s - loss: 0.4690 - acc: 0.7810
4672/4713 [============================>.] - ETA: 0s - loss: 0.4632 - acc: 0.7834
4713/4713 [==============================] - 6s 1ms/step - loss: 0.4631 - acc: 0.7836

Test accuracy: 85.00986193293886

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  244

choose_one :  263

F1score :  0.8527131782945737

AUC :  0.9258115215835175

Confusion Matrix
[[211  43]
 [ 33 220]]
True label 0
0.8307086614173228  
0.16929133858267717  
True label 1
0.13043478260869565  
0.8695652173913043  

Train_result {'loss': [0.46311613894586423], 'acc': [0.7835773393375819]}
Saved model to disk


2

Epoch 1/1

  64/4713 [..............................] - ETA: 5s - loss: 0.3190 - acc: 0.8438
 128/4713 [..............................] - ETA: 4s - loss: 0.4522 - acc: 0.8125
 256/4713 [>.............................] - ETA: 3s - loss: 0.4058 - acc: 0.8281
 384/4713 [=>............................] - ETA: 3s - loss: 0.3713 - acc: 0.8411
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3538 - acc: 0.8438
 640/4713 [===>..........................] - ETA: 3s - loss: 0.3695 - acc: 0.8313
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3606 - acc: 0.8294
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3616 - acc: 0.8248
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3666 - acc: 0.8213
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3706 - acc: 0.8255
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3682 - acc: 0.8250
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3698 - acc: 0.8253
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3721 - acc: 0.8249
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3668 - acc: 0.8281
1792/4713 [==========>...................] - ETA: 2s - loss: 0.3676 - acc: 0.8309
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3695 - acc: 0.8313
2048/4713 [============>.................] - ETA: 1s - loss: 0.3729 - acc: 0.8311
2176/4713 [============>.................] - ETA: 1s - loss: 0.3707 - acc: 0.8318
2304/4713 [=============>................] - ETA: 1s - loss: 0.3686 - acc: 0.8333
2432/4713 [==============>...............] - ETA: 1s - loss: 0.3725 - acc: 0.8331
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3695 - acc: 0.8340
2688/4713 [================>.............] - ETA: 1s - loss: 0.3705 - acc: 0.8333
2816/4713 [================>.............] - ETA: 1s - loss: 0.3670 - acc: 0.8363
2944/4713 [=================>............] - ETA: 1s - loss: 0.3636 - acc: 0.8387
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3646 - acc: 0.8389
3200/4713 [===================>..........] - ETA: 1s - loss: 0.3617 - acc: 0.8403
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3609 - acc: 0.8413
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3625 - acc: 0.8400
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3608 - acc: 0.8412
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3614 - acc: 0.8413
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3580 - acc: 0.8443
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3560 - acc: 0.8460
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3572 - acc: 0.8455
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3575 - acc: 0.8459
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3578 - acc: 0.8449
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3599 - acc: 0.8444
4608/4713 [============================>.] - ETA: 0s - loss: 0.3596 - acc: 0.8442
4713/4713 [==============================] - 3s 662us/step - loss: 0.3585 - acc: 0.8449

Test accuracy: 85.60157790927022

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  269

choose_one :  238

F1score :  0.8513238289205701

AUC :  0.929616258442003

Confusion Matrix
[[225  29]
 [ 44 209]]
True label 0
0.8858267716535433  
0.1141732283464567  
True label 1
0.17391304347826086  
0.8260869565217391  

Train_result {'loss': [0.358479384363722], 'acc': [0.8448970933236718]}
Saved model to disk


3

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.3463 - acc: 0.8281
 128/4713 [..............................] - ETA: 4s - loss: 0.2990 - acc: 0.8672
 192/4713 [>.............................] - ETA: 3s - loss: 0.3036 - acc: 0.8750
 320/4713 [=>............................] - ETA: 3s - loss: 0.3706 - acc: 0.8344
 448/4713 [=>............................] - ETA: 3s - loss: 0.3558 - acc: 0.8460
 576/4713 [==>...........................] - ETA: 3s - loss: 0.3682 - acc: 0.8385
 704/4713 [===>..........................] - ETA: 3s - loss: 0.3598 - acc: 0.8438
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3576 - acc: 0.8438
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3575 - acc: 0.8458
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3478 - acc: 0.8511
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3414 - acc: 0.8536
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3364 - acc: 0.8564
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3471 - acc: 0.8499
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3410 - acc: 0.8525
1728/4713 [=========>....................] - ETA: 2s - loss: 0.3395 - acc: 0.8524
1856/4713 [==========>...................] - ETA: 2s - loss: 0.3419 - acc: 0.8502
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3429 - acc: 0.8498
2112/4713 [============>.................] - ETA: 1s - loss: 0.3416 - acc: 0.8513
2240/4713 [=============>................] - ETA: 1s - loss: 0.3400 - acc: 0.8531
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3452 - acc: 0.8505
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3457 - acc: 0.8510
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3441 - acc: 0.8514
2752/4713 [================>.............] - ETA: 1s - loss: 0.3431 - acc: 0.8510
2880/4713 [=================>............] - ETA: 1s - loss: 0.3421 - acc: 0.8514
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3433 - acc: 0.8507
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3427 - acc: 0.8514
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3437 - acc: 0.8505
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3429 - acc: 0.8511
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3436 - acc: 0.8511
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3457 - acc: 0.8501
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3449 - acc: 0.8493
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3449 - acc: 0.8499
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3455 - acc: 0.8497
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3459 - acc: 0.8498
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3459 - acc: 0.8498
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3466 - acc: 0.8490
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3477 - acc: 0.8480
4608/4713 [============================>.] - ETA: 0s - loss: 0.3450 - acc: 0.8496
4713/4713 [==============================] - 3s 671us/step - loss: 0.3425 - acc: 0.8511

Test accuracy: 85.4043392504931

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  264

choose_one :  243

F1score :  0.8508064516129032

AUC :  0.9353972798854688

Confusion Matrix
[[222  32]
 [ 42 211]]
True label 0
0.8740157480314961  
0.12598425196850394  
True label 1
0.16600790513833993  
0.83399209486166  

Train_result {'loss': [0.34248542790387104], 'acc': [0.8510502865302848]}
Saved model to disk


4

Epoch 1/1

  64/4713 [..............................] - ETA: 3s - loss: 0.3089 - acc: 0.8594
 128/4713 [..............................] - ETA: 3s - loss: 0.3085 - acc: 0.8750
 256/4713 [>.............................] - ETA: 3s - loss: 0.3296 - acc: 0.8594
 384/4713 [=>............................] - ETA: 3s - loss: 0.3484 - acc: 0.8516
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3372 - acc: 0.8613
 640/4713 [===>..........................] - ETA: 2s - loss: 0.3390 - acc: 0.8594
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3563 - acc: 0.8529
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3514 - acc: 0.8538
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3418 - acc: 0.8613
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3447 - acc: 0.8602
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3522 - acc: 0.8578
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3523 - acc: 0.8565
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3558 - acc: 0.8535
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3485 - acc: 0.8588
1792/4713 [==========>...................] - ETA: 2s - loss: 0.3465 - acc: 0.8583
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3452 - acc: 0.8562
2048/4713 [============>.................] - ETA: 1s - loss: 0.3408 - acc: 0.8594
2176/4713 [============>.................] - ETA: 1s - loss: 0.3372 - acc: 0.8598
2304/4713 [=============>................] - ETA: 1s - loss: 0.3456 - acc: 0.8542
2432/4713 [==============>...............] - ETA: 1s - loss: 0.3457 - acc: 0.8536
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3416 - acc: 0.8559
2688/4713 [================>.............] - ETA: 1s - loss: 0.3421 - acc: 0.8545
2816/4713 [================>.............] - ETA: 1s - loss: 0.3417 - acc: 0.8548
2944/4713 [=================>............] - ETA: 1s - loss: 0.3416 - acc: 0.8543
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3428 - acc: 0.8525
3200/4713 [===================>..........] - ETA: 1s - loss: 0.3429 - acc: 0.8512
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3417 - acc: 0.8516
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3401 - acc: 0.8516
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3381 - acc: 0.8526
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3371 - acc: 0.8547
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3375 - acc: 0.8538
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3394 - acc: 0.8532
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3386 - acc: 0.8534
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3384 - acc: 0.8536
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3367 - acc: 0.8549
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3403 - acc: 0.8528
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3379 - acc: 0.8539
4672/4713 [============================>.] - ETA: 0s - loss: 0.3380 - acc: 0.8532
4713/4713 [==============================] - 3s 660us/step - loss: 0.3379 - acc: 0.8532

Test accuracy: 86.19329388560158

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  270

choose_one :  237

F1score :  0.8571428571428571

AUC :  0.9360741962590645

Confusion Matrix
[[227  27]
 [ 43 210]]
True label 0
0.8937007874015748  
0.1062992125984252  
True label 1
0.16996047430830039  
0.8300395256916996  

Train_result {'loss': [0.3379155401209219], 'acc': [0.8531720774102408]}
Saved model to disk


5

Epoch 1/1

  64/4713 [..............................] - ETA: 5s - loss: 0.3463 - acc: 0.8281
 128/4713 [..............................] - ETA: 4s - loss: 0.2645 - acc: 0.8906
 256/4713 [>.............................] - ETA: 3s - loss: 0.2755 - acc: 0.8750
 384/4713 [=>............................] - ETA: 3s - loss: 0.3164 - acc: 0.8568
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3090 - acc: 0.8633
 640/4713 [===>..........................] - ETA: 3s - loss: 0.3403 - acc: 0.8578
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3567 - acc: 0.8516
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3548 - acc: 0.8504
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3356 - acc: 0.8604
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3381 - acc: 0.8568
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3344 - acc: 0.8586
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3295 - acc: 0.8622
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3345 - acc: 0.8600
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3359 - acc: 0.8588
1792/4713 [==========>...................] - ETA: 2s - loss: 0.3343 - acc: 0.8583
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3326 - acc: 0.8589
2048/4713 [============>.................] - ETA: 1s - loss: 0.3313 - acc: 0.8589
2176/4713 [============>.................] - ETA: 1s - loss: 0.3276 - acc: 0.8598
2304/4713 [=============>................] - ETA: 1s - loss: 0.3298 - acc: 0.8568
2432/4713 [==============>...............] - ETA: 1s - loss: 0.3309 - acc: 0.8544
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3274 - acc: 0.8559
2688/4713 [================>.............] - ETA: 1s - loss: 0.3302 - acc: 0.8523
2816/4713 [================>.............] - ETA: 1s - loss: 0.3320 - acc: 0.8509
2944/4713 [=================>............] - ETA: 1s - loss: 0.3335 - acc: 0.8509
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3320 - acc: 0.8512
3200/4713 [===================>..........] - ETA: 1s - loss: 0.3294 - acc: 0.8522
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3258 - acc: 0.8540
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3256 - acc: 0.8527
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3221 - acc: 0.8544
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3216 - acc: 0.8543
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3255 - acc: 0.8523
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3251 - acc: 0.8536
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3242 - acc: 0.8547
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3262 - acc: 0.8536
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3299 - acc: 0.8519
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3293 - acc: 0.8526
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3282 - acc: 0.8530
4672/4713 [============================>.] - ETA: 0s - loss: 0.3285 - acc: 0.8525
4713/4713 [==============================] - 3s 671us/step - loss: 0.3295 - acc: 0.8517

Test accuracy: 86.98224852071006

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  222

choose_one :  285

F1score :  0.8773234200743495

AUC :  0.935249447573994

Confusion Matrix
[[205  49]
 [ 17 236]]
True label 0
0.8070866141732284  
0.19291338582677164  
True label 1
0.06719367588932806  
0.932806324110672  

Train_result {'loss': [0.3295038461988705], 'acc': [0.8516868236285978]}
Saved model to disk


6

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.1883 - acc: 0.9688
 192/4713 [>.............................] - ETA: 3s - loss: 0.2249 - acc: 0.9115
 320/4713 [=>............................] - ETA: 3s - loss: 0.2741 - acc: 0.8719
 448/4713 [=>............................] - ETA: 3s - loss: 0.2909 - acc: 0.8616
 576/4713 [==>...........................] - ETA: 2s - loss: 0.2904 - acc: 0.8611
 704/4713 [===>..........................] - ETA: 2s - loss: 0.3042 - acc: 0.8580
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2995 - acc: 0.8630
 896/4713 [====>.........................] - ETA: 2s - loss: 0.2982 - acc: 0.8661
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3261 - acc: 0.8535
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3208 - acc: 0.8516
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3144 - acc: 0.8547
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3094 - acc: 0.8544
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3130 - acc: 0.8529
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3091 - acc: 0.8546
1792/4713 [==========>...................] - ETA: 1s - loss: 0.3117 - acc: 0.8538
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3115 - acc: 0.8531
2048/4713 [============>.................] - ETA: 1s - loss: 0.3137 - acc: 0.8521
2176/4713 [============>.................] - ETA: 1s - loss: 0.3145 - acc: 0.8543
2304/4713 [=============>................] - ETA: 1s - loss: 0.3118 - acc: 0.8563
2432/4713 [==============>...............] - ETA: 1s - loss: 0.3089 - acc: 0.8586
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3096 - acc: 0.8582
2688/4713 [================>.............] - ETA: 1s - loss: 0.3132 - acc: 0.8586
2816/4713 [================>.............] - ETA: 1s - loss: 0.3124 - acc: 0.8604
2944/4713 [=================>............] - ETA: 1s - loss: 0.3129 - acc: 0.8611
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3127 - acc: 0.8623
3200/4713 [===================>..........] - ETA: 0s - loss: 0.3144 - acc: 0.8625
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3146 - acc: 0.8624
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3160 - acc: 0.8626
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3132 - acc: 0.8650
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3133 - acc: 0.8645
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3140 - acc: 0.8648
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3138 - acc: 0.8654
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3155 - acc: 0.8645
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3139 - acc: 0.8653
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3141 - acc: 0.8647
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3160 - acc: 0.8632
4608/4713 [============================>.] - ETA: 0s - loss: 0.3146 - acc: 0.8639
4713/4713 [==============================] - 3s 648us/step - loss: 0.3164 - acc: 0.8629

Test accuracy: 85.99605522682445

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  259

choose_one :  248

F1score :  0.8582834331337326

AUC :  0.9377236936292055

Confusion Matrix
[[221  33]
 [ 38 215]]
True label 0
0.8700787401574803  
0.12992125984251968  
True label 1
0.15019762845849802  
0.849802371541502  

Train_result {'loss': [0.3163521917362565], 'acc': [0.862932314823166]}
Saved model to disk


7

Epoch 1/1

  64/4713 [..............................] - ETA: 6s - loss: 0.2099 - acc: 0.9219
 128/4713 [..............................] - ETA: 5s - loss: 0.2497 - acc: 0.8984
 256/4713 [>.............................] - ETA: 4s - loss: 0.2734 - acc: 0.9023
 384/4713 [=>............................] - ETA: 3s - loss: 0.3014 - acc: 0.8828
 512/4713 [==>...........................] - ETA: 3s - loss: 0.2968 - acc: 0.8828
 640/4713 [===>..........................] - ETA: 3s - loss: 0.3010 - acc: 0.8781
 704/4713 [===>..........................] - ETA: 3s - loss: 0.2923 - acc: 0.8821
 768/4713 [===>..........................] - ETA: 3s - loss: 0.2914 - acc: 0.8828
 832/4713 [====>.........................] - ETA: 3s - loss: 0.2912 - acc: 0.8810
 960/4713 [=====>........................] - ETA: 3s - loss: 0.2857 - acc: 0.8833
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2809 - acc: 0.8879
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2838 - acc: 0.8824
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2788 - acc: 0.8802
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2829 - acc: 0.8804
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2813 - acc: 0.8788
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2936 - acc: 0.8733
1856/4713 [==========>...................] - ETA: 2s - loss: 0.3001 - acc: 0.8696
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3000 - acc: 0.8695
2112/4713 [============>.................] - ETA: 1s - loss: 0.2999 - acc: 0.8684
2240/4713 [=============>................] - ETA: 1s - loss: 0.2992 - acc: 0.8679
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2990 - acc: 0.8691
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3027 - acc: 0.8670
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3037 - acc: 0.8670
2752/4713 [================>.............] - ETA: 1s - loss: 0.3019 - acc: 0.8685
2880/4713 [=================>............] - ETA: 1s - loss: 0.3056 - acc: 0.8674
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3066 - acc: 0.8680
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3072 - acc: 0.8677
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3071 - acc: 0.8670
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3089 - acc: 0.8665
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3095 - acc: 0.8665
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3106 - acc: 0.8660
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3097 - acc: 0.8657
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3100 - acc: 0.8665
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3113 - acc: 0.8666
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3125 - acc: 0.8663
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3108 - acc: 0.8678
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3103 - acc: 0.8684
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3115 - acc: 0.8684
4672/4713 [============================>.] - ETA: 0s - loss: 0.3120 - acc: 0.8679
4713/4713 [==============================] - 3s 673us/step - loss: 0.3134 - acc: 0.8676

Test accuracy: 86.58777120315581

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  218

choose_one :  289

F1score :  0.8745387453874539

AUC :  0.940672559210731

Confusion Matrix
[[202  52]
 [ 16 237]]
True label 0
0.7952755905511811  
0.2047244094488189  
True label 1
0.06324110671936758  
0.9367588932806324  

Train_result {'loss': [0.31338068512172523], 'acc': [0.8676002544757795]}
Saved model to disk


8

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2450 - acc: 0.8750
 192/4713 [>.............................] - ETA: 3s - loss: 0.3016 - acc: 0.8490
 320/4713 [=>............................] - ETA: 3s - loss: 0.2637 - acc: 0.8719
 448/4713 [=>............................] - ETA: 3s - loss: 0.2798 - acc: 0.8683
 576/4713 [==>...........................] - ETA: 3s - loss: 0.2744 - acc: 0.8767
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2988 - acc: 0.8665
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3180 - acc: 0.8570
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3130 - acc: 0.8583
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3127 - acc: 0.8566
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3154 - acc: 0.8561
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3105 - acc: 0.8564
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3106 - acc: 0.8580
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3035 - acc: 0.8612
1728/4713 [=========>....................] - ETA: 2s - loss: 0.3084 - acc: 0.8605
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3054 - acc: 0.8621
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3015 - acc: 0.8644
2112/4713 [============>.................] - ETA: 1s - loss: 0.3018 - acc: 0.8641
2240/4713 [=============>................] - ETA: 1s - loss: 0.3023 - acc: 0.8661
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3038 - acc: 0.8670
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3045 - acc: 0.8666
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3024 - acc: 0.8681
2752/4713 [================>.............] - ETA: 1s - loss: 0.3039 - acc: 0.8666
2880/4713 [=================>............] - ETA: 1s - loss: 0.3019 - acc: 0.8681
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3050 - acc: 0.8660
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3080 - acc: 0.8651
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3091 - acc: 0.8652
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3082 - acc: 0.8662
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3100 - acc: 0.8653
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3107 - acc: 0.8643
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3090 - acc: 0.8641
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3087 - acc: 0.8635
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3090 - acc: 0.8628
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3086 - acc: 0.8637
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3077 - acc: 0.8645
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3083 - acc: 0.8632
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3072 - acc: 0.8633
4672/4713 [============================>.] - ETA: 0s - loss: 0.3061 - acc: 0.8637
4713/4713 [==============================] - 3s 663us/step - loss: 0.3086 - acc: 0.8634

Test accuracy: 87.3767258382643

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  252

choose_one :  255

F1score :  0.8740157480314961

AUC :  0.9418318757586133

Confusion Matrix
[[221  33]
 [ 31 222]]
True label 0
0.8700787401574803  
0.12992125984251968  
True label 1
0.1225296442687747  
0.8774703557312253  

Train_result {'loss': [0.30860405774625427], 'acc': [0.8633566728929236]}
Saved model to disk


9

Epoch 1/1

  64/4713 [..............................] - ETA: 3s - loss: 0.2599 - acc: 0.8594
 192/4713 [>.............................] - ETA: 3s - loss: 0.2664 - acc: 0.8854
 320/4713 [=>............................] - ETA: 3s - loss: 0.2572 - acc: 0.8844
 448/4713 [=>............................] - ETA: 3s - loss: 0.2743 - acc: 0.8795
 576/4713 [==>...........................] - ETA: 2s - loss: 0.2615 - acc: 0.8924
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2932 - acc: 0.8750
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2928 - acc: 0.8750
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3059 - acc: 0.8677
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3131 - acc: 0.8667
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3184 - acc: 0.8643
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3199 - acc: 0.8609
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3170 - acc: 0.8648
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3127 - acc: 0.8675
1728/4713 [=========>....................] - ETA: 2s - loss: 0.3061 - acc: 0.8715
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3039 - acc: 0.8723
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3122 - acc: 0.8695
2112/4713 [============>.................] - ETA: 1s - loss: 0.3129 - acc: 0.8670
2240/4713 [=============>................] - ETA: 1s - loss: 0.3124 - acc: 0.8665
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3139 - acc: 0.8674
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3119 - acc: 0.8682
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3132 - acc: 0.8681
2752/4713 [================>.............] - ETA: 1s - loss: 0.3103 - acc: 0.8692
2880/4713 [=================>............] - ETA: 1s - loss: 0.3118 - acc: 0.8684
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3117 - acc: 0.8693
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3127 - acc: 0.8696
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3112 - acc: 0.8701
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3130 - acc: 0.8703
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3133 - acc: 0.8702
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3096 - acc: 0.8712
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3095 - acc: 0.8716
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3081 - acc: 0.8730
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3079 - acc: 0.8723
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3070 - acc: 0.8731
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3084 - acc: 0.8727
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3063 - acc: 0.8732
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3056 - acc: 0.8730
4672/4713 [============================>.] - ETA: 0s - loss: 0.3055 - acc: 0.8726
4713/4713 [==============================] - 3s 659us/step - loss: 0.3056 - acc: 0.8721

Test accuracy: 87.3767258382643

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  248

choose_one :  259

F1score :  0.875

AUC :  0.9428900438828546

Confusion Matrix
[[219  35]
 [ 29 224]]
True label 0
0.8622047244094488  
0.1377952755905512  
True label 1
0.11462450592885376  
0.8853754940711462  

Train_result {'loss': [0.3056495492432544], 'acc': [0.872056015340128]}
Saved model to disk


10

Epoch 1/1

  64/4713 [..............................] - ETA: 6s - loss: 0.2502 - acc: 0.9062
 128/4713 [..............................] - ETA: 4s - loss: 0.2676 - acc: 0.8750
 256/4713 [>.............................] - ETA: 3s - loss: 0.2730 - acc: 0.8789
 384/4713 [=>............................] - ETA: 3s - loss: 0.2806 - acc: 0.8698
 512/4713 [==>...........................] - ETA: 3s - loss: 0.2940 - acc: 0.8691
 640/4713 [===>..........................] - ETA: 3s - loss: 0.2922 - acc: 0.8719
 768/4713 [===>..........................] - ETA: 3s - loss: 0.2813 - acc: 0.8776
 896/4713 [====>.........................] - ETA: 2s - loss: 0.2926 - acc: 0.8783
1024/4713 [=====>........................] - ETA: 2s - loss: 0.2978 - acc: 0.8721
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3005 - acc: 0.8707
1280/4713 [=======>......................] - ETA: 2s - loss: 0.2973 - acc: 0.8703
1408/4713 [=======>......................] - ETA: 2s - loss: 0.2931 - acc: 0.8729
1536/4713 [========>.....................] - ETA: 2s - loss: 0.2920 - acc: 0.8724
1664/4713 [=========>....................] - ETA: 2s - loss: 0.2928 - acc: 0.8732
1792/4713 [==========>...................] - ETA: 2s - loss: 0.2896 - acc: 0.8744
1920/4713 [===========>..................] - ETA: 1s - loss: 0.2895 - acc: 0.8760
2048/4713 [============>.................] - ETA: 1s - loss: 0.2898 - acc: 0.8760
2176/4713 [============>.................] - ETA: 1s - loss: 0.2897 - acc: 0.8750
2304/4713 [=============>................] - ETA: 1s - loss: 0.2854 - acc: 0.8776
2432/4713 [==============>...............] - ETA: 1s - loss: 0.2844 - acc: 0.8779
2560/4713 [===============>..............] - ETA: 1s - loss: 0.2829 - acc: 0.8777
2688/4713 [================>.............] - ETA: 1s - loss: 0.2838 - acc: 0.8769
2816/4713 [================>.............] - ETA: 1s - loss: 0.2838 - acc: 0.8775
2944/4713 [=================>............] - ETA: 1s - loss: 0.2918 - acc: 0.8743
3072/4713 [==================>...........] - ETA: 1s - loss: 0.2922 - acc: 0.8737
3200/4713 [===================>..........] - ETA: 1s - loss: 0.2903 - acc: 0.8759
3328/4713 [====================>.........] - ETA: 0s - loss: 0.2928 - acc: 0.8744
3456/4713 [====================>.........] - ETA: 0s - loss: 0.2943 - acc: 0.8733
3584/4713 [=====================>........] - ETA: 0s - loss: 0.2929 - acc: 0.8742
3712/4713 [======================>.......] - ETA: 0s - loss: 0.2950 - acc: 0.8734
3840/4713 [=======================>......] - ETA: 0s - loss: 0.2966 - acc: 0.8732
3968/4713 [========================>.....] - ETA: 0s - loss: 0.2984 - acc: 0.8720
4096/4713 [=========================>....] - ETA: 0s - loss: 0.2988 - acc: 0.8706
4224/4713 [=========================>....] - ETA: 0s - loss: 0.2966 - acc: 0.8719
4352/4713 [==========================>...] - ETA: 0s - loss: 0.2945 - acc: 0.8729
4480/4713 [===========================>..] - ETA: 0s - loss: 0.2935 - acc: 0.8739
4608/4713 [============================>.] - ETA: 0s - loss: 0.2946 - acc: 0.8737
4713/4713 [==============================] - 3s 658us/step - loss: 0.2936 - acc: 0.8744

Test accuracy: 87.57396449704143

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  251

choose_one :  256

F1score :  0.8762278978388999

AUC :  0.9395210233108213

Confusion Matrix
[[221  33]
 [ 30 223]]
True label 0
0.8700787401574803  
0.12992125984251968  
True label 1
0.11857707509881422  
0.8814229249011858  

Train_result {'loss': [0.2935920149536869], 'acc': [0.874389984919821]}
Saved model to disk


11

Epoch 1/1

  64/4713 [..............................] - ETA: 3s - loss: 0.2822 - acc: 0.9531
 128/4713 [..............................] - ETA: 3s - loss: 0.2380 - acc: 0.9375
 256/4713 [>.............................] - ETA: 3s - loss: 0.2837 - acc: 0.8828
 384/4713 [=>............................] - ETA: 3s - loss: 0.2688 - acc: 0.8906
 512/4713 [==>...........................] - ETA: 3s - loss: 0.2975 - acc: 0.8750
 640/4713 [===>..........................] - ETA: 2s - loss: 0.2900 - acc: 0.8766
 768/4713 [===>..........................] - ETA: 2s - loss: 0.2858 - acc: 0.8789
 896/4713 [====>.........................] - ETA: 2s - loss: 0.2904 - acc: 0.8739
1024/4713 [=====>........................] - ETA: 2s - loss: 0.2985 - acc: 0.8691
1152/4713 [======>.......................] - ETA: 2s - loss: 0.2942 - acc: 0.8733
1280/4713 [=======>......................] - ETA: 2s - loss: 0.2906 - acc: 0.8766
1408/4713 [=======>......................] - ETA: 2s - loss: 0.2842 - acc: 0.8793
1536/4713 [========>.....................] - ETA: 2s - loss: 0.2886 - acc: 0.8750
1664/4713 [=========>....................] - ETA: 2s - loss: 0.2868 - acc: 0.8738
1792/4713 [==========>...................] - ETA: 1s - loss: 0.2904 - acc: 0.8728
1920/4713 [===========>..................] - ETA: 1s - loss: 0.2850 - acc: 0.8755
2048/4713 [============>.................] - ETA: 1s - loss: 0.2819 - acc: 0.8770
2176/4713 [============>.................] - ETA: 1s - loss: 0.2876 - acc: 0.8736
2304/4713 [=============>................] - ETA: 1s - loss: 0.2879 - acc: 0.8746
2432/4713 [==============>...............] - ETA: 1s - loss: 0.2877 - acc: 0.8734
2560/4713 [===============>..............] - ETA: 1s - loss: 0.2891 - acc: 0.8738
2688/4713 [================>.............] - ETA: 1s - loss: 0.2906 - acc: 0.8728
2816/4713 [================>.............] - ETA: 1s - loss: 0.2916 - acc: 0.8729
2944/4713 [=================>............] - ETA: 1s - loss: 0.2943 - acc: 0.8706
3072/4713 [==================>...........] - ETA: 1s - loss: 0.2974 - acc: 0.8698
3200/4713 [===================>..........] - ETA: 0s - loss: 0.2962 - acc: 0.8706
3328/4713 [====================>.........] - ETA: 0s - loss: 0.2980 - acc: 0.8696
3456/4713 [====================>.........] - ETA: 0s - loss: 0.2979 - acc: 0.8701
3584/4713 [=====================>........] - ETA: 0s - loss: 0.2971 - acc: 0.8708
3712/4713 [======================>.......] - ETA: 0s - loss: 0.2966 - acc: 0.8710
3840/4713 [=======================>......] - ETA: 0s - loss: 0.2983 - acc: 0.8693
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3015 - acc: 0.8682
4096/4713 [=========================>....] - ETA: 0s - loss: 0.2988 - acc: 0.8696
4224/4713 [=========================>....] - ETA: 0s - loss: 0.2967 - acc: 0.8698
4352/4713 [==========================>...] - ETA: 0s - loss: 0.2957 - acc: 0.8704
4480/4713 [===========================>..] - ETA: 0s - loss: 0.2970 - acc: 0.8703
4608/4713 [============================>.] - ETA: 0s - loss: 0.2956 - acc: 0.8707
4713/4713 [==============================] - 3s 645us/step - loss: 0.2973 - acc: 0.8704

Test accuracy: 87.57396449704143

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  251

choose_one :  256

F1score :  0.8762278978388999

AUC :  0.9412405465127136

Confusion Matrix
[[221  33]
 [ 30 223]]
True label 0
0.8700787401574803  
0.12992125984251968  
True label 1
0.11857707509881422  
0.8814229249011858  

Train_result {'loss': [0.29732291407072187], 'acc': [0.8703585826184576]}
Saved model to disk


12

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.3169 - acc: 0.8594
 192/4713 [>.............................] - ETA: 3s - loss: 0.3589 - acc: 0.8490
 320/4713 [=>............................] - ETA: 3s - loss: 0.3246 - acc: 0.8656
 448/4713 [=>............................] - ETA: 3s - loss: 0.2940 - acc: 0.8795
 576/4713 [==>...........................] - ETA: 3s - loss: 0.2898 - acc: 0.8819
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2970 - acc: 0.8793
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2979 - acc: 0.8762
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3052 - acc: 0.8771
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2977 - acc: 0.8768
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2889 - acc: 0.8840
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2888 - acc: 0.8802
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2879 - acc: 0.8825
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2908 - acc: 0.8812
1728/4713 [=========>....................] - ETA: 1s - loss: 0.2910 - acc: 0.8814
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2943 - acc: 0.8772
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2975 - acc: 0.8760
2112/4713 [============>.................] - ETA: 1s - loss: 0.3019 - acc: 0.8726
2240/4713 [=============>................] - ETA: 1s - loss: 0.3022 - acc: 0.8728
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2972 - acc: 0.8758
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2949 - acc: 0.8770
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2948 - acc: 0.8765
2752/4713 [================>.............] - ETA: 1s - loss: 0.2928 - acc: 0.8772
2880/4713 [=================>............] - ETA: 1s - loss: 0.2945 - acc: 0.8760
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2945 - acc: 0.8757
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2943 - acc: 0.8756
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2922 - acc: 0.8756
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2920 - acc: 0.8756
3520/4713 [=====================>........] - ETA: 0s - loss: 0.2907 - acc: 0.8761
3648/4713 [======================>.......] - ETA: 0s - loss: 0.2943 - acc: 0.8739
3776/4713 [=======================>......] - ETA: 0s - loss: 0.2913 - acc: 0.8753
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2955 - acc: 0.8737
4032/4713 [========================>.....] - ETA: 0s - loss: 0.2954 - acc: 0.8738
4160/4713 [=========================>....] - ETA: 0s - loss: 0.2943 - acc: 0.8740
4288/4713 [==========================>...] - ETA: 0s - loss: 0.2945 - acc: 0.8738
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2951 - acc: 0.8739
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2944 - acc: 0.8737
4672/4713 [============================>.] - ETA: 0s - loss: 0.2936 - acc: 0.8750
4713/4713 [==============================] - 3s 635us/step - loss: 0.2936 - acc: 0.8750

Test accuracy: 86.98224852071006

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  260

choose_one :  247

F1score :  0.8680000000000001

AUC :  0.9447107155083876

Confusion Matrix
[[224  30]
 [ 36 217]]
True label 0
0.8818897637795275  
0.11811023622047244  
True label 1
0.1422924901185771  
0.857707509881423  

Train_result {'loss': [0.2935934533820951], 'acc': [0.8750265223595991]}
Saved model to disk


13

Epoch 1/1

  64/4713 [..............................] - ETA: 6s - loss: 0.3161 - acc: 0.8750
 128/4713 [..............................] - ETA: 5s - loss: 0.3275 - acc: 0.8516
 192/4713 [>.............................] - ETA: 4s - loss: 0.2840 - acc: 0.8802
 320/4713 [=>............................] - ETA: 4s - loss: 0.2989 - acc: 0.8656
 448/4713 [=>............................] - ETA: 3s - loss: 0.2946 - acc: 0.8661
 576/4713 [==>...........................] - ETA: 3s - loss: 0.2877 - acc: 0.8663
 704/4713 [===>..........................] - ETA: 3s - loss: 0.2772 - acc: 0.8679
 832/4713 [====>.........................] - ETA: 3s - loss: 0.2708 - acc: 0.8738
 960/4713 [=====>........................] - ETA: 3s - loss: 0.2695 - acc: 0.8760
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2800 - acc: 0.8704
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2870 - acc: 0.8692
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2861 - acc: 0.8690
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2974 - acc: 0.8641
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2892 - acc: 0.8700
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2863 - acc: 0.8721
1856/4713 [==========>...................] - ETA: 2s - loss: 0.2848 - acc: 0.8728
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2890 - acc: 0.8705
2112/4713 [============>.................] - ETA: 1s - loss: 0.2859 - acc: 0.8726
2240/4713 [=============>................] - ETA: 1s - loss: 0.2830 - acc: 0.8737
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2839 - acc: 0.8742
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2796 - acc: 0.8770
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2828 - acc: 0.8746
2752/4713 [================>.............] - ETA: 1s - loss: 0.2834 - acc: 0.8735
2880/4713 [=================>............] - ETA: 1s - loss: 0.2806 - acc: 0.8757
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2822 - acc: 0.8750
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2849 - acc: 0.8750
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2867 - acc: 0.8747
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2862 - acc: 0.8747
3520/4713 [=====================>........] - ETA: 0s - loss: 0.2875 - acc: 0.8741
3648/4713 [======================>.......] - ETA: 0s - loss: 0.2881 - acc: 0.8745
3776/4713 [=======================>......] - ETA: 0s - loss: 0.2865 - acc: 0.8755
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2861 - acc: 0.8745
4032/4713 [========================>.....] - ETA: 0s - loss: 0.2851 - acc: 0.8755
4160/4713 [=========================>....] - ETA: 0s - loss: 0.2848 - acc: 0.8757
4288/4713 [==========================>...] - ETA: 0s - loss: 0.2866 - acc: 0.8745
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2861 - acc: 0.8743
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2858 - acc: 0.8743
4672/4713 [============================>.] - ETA: 0s - loss: 0.2864 - acc: 0.8739
4713/4713 [==============================] - 3s 673us/step - loss: 0.2867 - acc: 0.8738

Test accuracy: 87.77120315581854

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  248

choose_one :  259

F1score :  0.87890625

AUC :  0.9434502505368647

Confusion Matrix
[[220  34]
 [ 28 225]]
True label 0
0.8661417322834646  
0.13385826771653545  
True label 1
0.11067193675889328  
0.8893280632411067  

Train_result {'loss': [0.28672735117661985], 'acc': [0.8737534480870921]}
Saved model to disk


14

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2907 - acc: 0.8750
 128/4713 [..............................] - ETA: 3s - loss: 0.3078 - acc: 0.8594
 256/4713 [>.............................] - ETA: 3s - loss: 0.2948 - acc: 0.8672
 384/4713 [=>............................] - ETA: 3s - loss: 0.3068 - acc: 0.8724
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3250 - acc: 0.8633
 640/4713 [===>..........................] - ETA: 3s - loss: 0.3355 - acc: 0.8562
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3389 - acc: 0.8542
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3160 - acc: 0.8661
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3179 - acc: 0.8682
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3129 - acc: 0.8724
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3046 - acc: 0.8742
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3028 - acc: 0.8729
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3047 - acc: 0.8691
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3048 - acc: 0.8690
1792/4713 [==========>...................] - ETA: 2s - loss: 0.3020 - acc: 0.8717
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3010 - acc: 0.8719
2048/4713 [============>.................] - ETA: 1s - loss: 0.2968 - acc: 0.8726
2176/4713 [============>.................] - ETA: 1s - loss: 0.2983 - acc: 0.8727
2304/4713 [=============>................] - ETA: 1s - loss: 0.2970 - acc: 0.8711
2432/4713 [==============>...............] - ETA: 1s - loss: 0.2960 - acc: 0.8709
2560/4713 [===============>..............] - ETA: 1s - loss: 0.2933 - acc: 0.8719
2688/4713 [================>.............] - ETA: 1s - loss: 0.2923 - acc: 0.8702
2816/4713 [================>.............] - ETA: 1s - loss: 0.2911 - acc: 0.8725
2944/4713 [=================>............] - ETA: 1s - loss: 0.2893 - acc: 0.8723
3072/4713 [==================>...........] - ETA: 1s - loss: 0.2881 - acc: 0.8727
3200/4713 [===================>..........] - ETA: 1s - loss: 0.2893 - acc: 0.8719
3328/4713 [====================>.........] - ETA: 0s - loss: 0.2877 - acc: 0.8723
3456/4713 [====================>.........] - ETA: 0s - loss: 0.2868 - acc: 0.8736
3584/4713 [=====================>........] - ETA: 0s - loss: 0.2859 - acc: 0.8742
3712/4713 [======================>.......] - ETA: 0s - loss: 0.2860 - acc: 0.8739
3840/4713 [=======================>......] - ETA: 0s - loss: 0.2845 - acc: 0.8750
3968/4713 [========================>.....] - ETA: 0s - loss: 0.2822 - acc: 0.8768
4096/4713 [=========================>....] - ETA: 0s - loss: 0.2857 - acc: 0.8755
4224/4713 [=========================>....] - ETA: 0s - loss: 0.2844 - acc: 0.8757
4352/4713 [==========================>...] - ETA: 0s - loss: 0.2815 - acc: 0.8775
4480/4713 [===========================>..] - ETA: 0s - loss: 0.2814 - acc: 0.8770
4608/4713 [============================>.] - ETA: 0s - loss: 0.2806 - acc: 0.8770
4713/4713 [==============================] - 3s 659us/step - loss: 0.2815 - acc: 0.8759

Test accuracy: 87.57396449704143

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  255

choose_one :  252

F1score :  0.8752475247524752

AUC :  0.9442283153341011

Confusion Matrix
[[223  31]
 [ 32 221]]
True label 0
0.8779527559055118  
0.1220472440944882  
True label 1
0.12648221343873517  
0.8735177865612648  

Train_result {'loss': [0.2815163350398693], 'acc': [0.8758752384485269]}
Saved model to disk


15

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.1590 - acc: 0.9219
 128/4713 [..............................] - ETA: 4s - loss: 0.2236 - acc: 0.8906
 256/4713 [>.............................] - ETA: 3s - loss: 0.2338 - acc: 0.8867
 384/4713 [=>............................] - ETA: 3s - loss: 0.2581 - acc: 0.8802
 512/4713 [==>...........................] - ETA: 3s - loss: 0.2596 - acc: 0.8809
 640/4713 [===>..........................] - ETA: 2s - loss: 0.2612 - acc: 0.8766
 768/4713 [===>..........................] - ETA: 2s - loss: 0.2631 - acc: 0.8737
 896/4713 [====>.........................] - ETA: 2s - loss: 0.2710 - acc: 0.8728
1024/4713 [=====>........................] - ETA: 2s - loss: 0.2669 - acc: 0.8779
1152/4713 [======>.......................] - ETA: 2s - loss: 0.2706 - acc: 0.8759
1280/4713 [=======>......................] - ETA: 2s - loss: 0.2803 - acc: 0.8734
1408/4713 [=======>......................] - ETA: 2s - loss: 0.2743 - acc: 0.8757
1536/4713 [========>.....................] - ETA: 2s - loss: 0.2720 - acc: 0.8770
1664/4713 [=========>....................] - ETA: 2s - loss: 0.2769 - acc: 0.8756
1792/4713 [==========>...................] - ETA: 1s - loss: 0.2793 - acc: 0.8744
1920/4713 [===========>..................] - ETA: 1s - loss: 0.2848 - acc: 0.8724
2048/4713 [============>.................] - ETA: 1s - loss: 0.2843 - acc: 0.8740
2176/4713 [============>.................] - ETA: 1s - loss: 0.2869 - acc: 0.8741
2304/4713 [=============>................] - ETA: 1s - loss: 0.2877 - acc: 0.8754
2432/4713 [==============>...............] - ETA: 1s - loss: 0.2869 - acc: 0.8754
2560/4713 [===============>..............] - ETA: 1s - loss: 0.2870 - acc: 0.8762
2688/4713 [================>.............] - ETA: 1s - loss: 0.2910 - acc: 0.8772
2816/4713 [================>.............] - ETA: 1s - loss: 0.2905 - acc: 0.8768
2944/4713 [=================>............] - ETA: 1s - loss: 0.2906 - acc: 0.8764
3072/4713 [==================>...........] - ETA: 1s - loss: 0.2885 - acc: 0.8763
3200/4713 [===================>..........] - ETA: 0s - loss: 0.2880 - acc: 0.8769
3328/4713 [====================>.........] - ETA: 0s - loss: 0.2871 - acc: 0.8774
3456/4713 [====================>.........] - ETA: 0s - loss: 0.2867 - acc: 0.8779
3584/4713 [=====================>........] - ETA: 0s - loss: 0.2858 - acc: 0.8789
3712/4713 [======================>.......] - ETA: 0s - loss: 0.2832 - acc: 0.8796
3840/4713 [=======================>......] - ETA: 0s - loss: 0.2814 - acc: 0.8807
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2816 - acc: 0.8801
3968/4713 [========================>.....] - ETA: 0s - loss: 0.2825 - acc: 0.8793
4096/4713 [=========================>....] - ETA: 0s - loss: 0.2843 - acc: 0.8779
4224/4713 [=========================>....] - ETA: 0s - loss: 0.2871 - acc: 0.8762
4352/4713 [==========================>...] - ETA: 0s - loss: 0.2859 - acc: 0.8766
4480/4713 [===========================>..] - ETA: 0s - loss: 0.2879 - acc: 0.8750
4608/4713 [============================>.] - ETA: 0s - loss: 0.2881 - acc: 0.8757
4713/4713 [==============================] - 3s 655us/step - loss: 0.2873 - acc: 0.8759

Test accuracy: 87.77120315581854

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  230

choose_one :  277

F1score :  0.8830188679245283

AUC :  0.9428744825869099

Confusion Matrix
[[211  43]
 [ 19 234]]
True label 0
0.8307086614173228  
0.16929133858267717  
True label 1
0.07509881422924901  
0.924901185770751  

Train_result {'loss': [0.2872853125454437], 'acc': [0.8758752386761703]}
Saved model to disk


[[85.00986193293886, 1], [85.60157790927022, 2], [85.4043392504931, 3], [86.19329388560158, 4], [86.98224852071006, 5], [85.99605522682445, 6], [86.58777120315581, 7], [87.3767258382643, 8], [87.3767258382643, 9], [87.57396449704143, 10], [87.57396449704143, 11], [86.98224852071006, 12], [87.77120315581854, 13], [87.57396449704143, 14], [87.77120315581854, 15]]
max accuracy :  [87.77120315581854, 15]
