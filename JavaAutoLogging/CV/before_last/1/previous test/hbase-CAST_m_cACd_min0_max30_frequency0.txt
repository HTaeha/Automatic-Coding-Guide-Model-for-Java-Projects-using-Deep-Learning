Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
/home/2014313303/taeha/JavaAutoLogging/model.py:154: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor("ou..., inputs=[<tf.Tenso...)`
  model = Model(input=[input1, input2, input3, input4], output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-10 02:58:40.698984: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-10 02:58:40.715930: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099840000 Hz
2019-09-10 02:58:40.721555: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x177a9bb0 executing computations on platform Host. Devices:
2019-09-10 02:58:40.721592: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Standard data
zero :  39451
one :  9019

First data
zero :  39451
one :  9019

Second data
zero :  39451
one :  9019

Third data
zero :  39451
one :  9019

4th data
zero :  39451
one :  9019

hbase-code
After set document size of train data, the number of zero and one label data :  23525 1507
After set document size of test data, the number of zero and one label data :  2614 166

Sentence length Average : 13

Under 10 : 9590
Over 10, Under 30 : 18222
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

After balance out data.
hbase-code

Sentence length Average : 14

Under 10 : 1039
Over 10, Under 30 : 2309
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

hbase-AST
After set document size of train data, the number of zero and one label data :  23525 1507
After set document size of test data, the number of zero and one label data :  2614 166
After balance out data.
hbase-AST

Sentence length Average : 9

Under 10 : 2145
Over 10, Under 30 : 1168
Over 30, Under 100 : 25
Over 100, Under 150 : 3
Over 150, Under 200 : 2
Over 200, Under 400 : 3
Over 400 : 2

hbase-CAST
After set document size of train data, the number of zero and one label data :  23525 1507
After set document size of test data, the number of zero and one label data :  2614 166
After balance out data.
hbase-CAST

Sentence length Average : 23

Under 10 : 923
Over 10, Under 30 : 1585
Over 30, Under 100 : 823
Over 100, Under 150 : 2
Over 150, Under 200 : 1
Over 200, Under 400 : 9
Over 400 : 5

hbase-depth_num
After set document size of train data, the number of zero and one label data :  23525 1507
After set document size of test data, the number of zero and one label data :  2614 166
After balance out data.
hbase-depth_num

Sentence length Average : 9

Under 10 : 2145
Over 10, Under 30 : 1168
Over 30, Under 100 : 25
Over 100, Under 150 : 3
Over 150, Under 200 : 2
Over 200, Under 400 : 3
Over 400 : 2

Count model parameter.
Get a short summary of each layer dimensions and parameters.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 30, 200)      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 60, 200)      0                                            
__________________________________________________________________________________________________
masking_1 (Masking)             (None, 30, 200)      0           input_1[0][0]                    
__________________________________________________________________________________________________
masking_2 (Masking)             (None, 60, 200)      0           input_2[0][0]                    
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 90, 200)      0                                            
__________________________________________________________________________________________________
forwards_1 (LSTM)               (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
backwords_1 (LSTM)              (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
forwards_2 (LSTM)               (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
backwards_2 (LSTM)              (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
masking_3 (Masking)             (None, 90, 200)      0           input_3[0][0]                    
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 60, 200)      0                                            
__________________________________________________________________________________________________
after_dp_forward_1 (Dropout)    (None, 64)           0           forwards_1[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_1 (Dropout)   (None, 64)           0           backwords_1[0][0]                
__________________________________________________________________________________________________
after_dp_forward_2 (Dropout)    (None, 64)           0           forwards_2[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_2 (Dropout)   (None, 64)           0           backwards_2[0][0]                
__________________________________________________________________________________________________
forwards_3 (LSTM)               (None, 64)           67840       masking_3[0][0]                  
__________________________________________________________________________________________________
backwards_3 (LSTM)              (None, 64)           67840       masking_3[0][0]                  
__________________________________________________________________________________________________
masking_4 (Masking)             (None, 60, 200)      0           input_4[0][0]                    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128)          0           after_dp_forward_1[0][0]         
                                                                 after_dp_backward_1[0][0]        
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 128)          0           after_dp_forward_2[0][0]         
                                                                 after_dp_backward_2[0][0]        
__________________________________________________________________________________________________
after_dp_forward_3 (Dropout)    (None, 64)           0           forwards_3[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_3 (Dropout)   (None, 64)           0           backwards_3[0][0]                
__________________________________________________________________________________________________
forwards_4 (LSTM)               (None, 64)           67840       masking_4[0][0]                  
__________________________________________________________________________________________________
backwards_4 (LSTM)              (None, 64)           67840       masking_4[0][0]                  
__________________________________________________________________________________________________
after_dp_1 (Dropout)            (None, 128)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
after_dp_2 (Dropout)            (None, 128)          0           concatenate_2[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 128)          0           after_dp_forward_3[0][0]         
                                                                 after_dp_backward_3[0][0]        
__________________________________________________________________________________________________
after_dp_forward_4 (Dropout)    (None, 64)           0           forwards_4[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_4 (Dropout)   (None, 64)           0           backwards_4[0][0]                
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 256)          0           after_dp_1[0][0]                 
                                                                 after_dp_2[0][0]                 
__________________________________________________________________________________________________
after_dp_3 (Dropout)            (None, 128)          0           concatenate_3[0][0]              
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 128)          0           after_dp_forward_4[0][0]         
                                                                 after_dp_backward_4[0][0]        
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 384)          0           concatenate_5[0][0]              
                                                                 after_dp_3[0][0]                 
__________________________________________________________________________________________________
after_dp_4 (Dropout)            (None, 128)          0           concatenate_4[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 512)          0           concatenate_6[0][0]              
                                                                 after_dp_4[0][0]                 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          262656      concatenate_7[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 768)          393984      dense_1[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 512)          393728      dense_2[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 256)          131328      dense_3[0][0]                    
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 128)          32896       dense_4[0][0]                    
__________________________________________________________________________________________________
output (Dense)                  (None, 2)            258         dense_5[0][0]                    
==================================================================================================
Total params: 1,757,570
Trainable params: 1,757,570
Non-trainable params: 0
__________________________________________________________________________________________________
1

Epoch 1/1

  64/3015 [..............................] - ETA: 5:56 - loss: 0.7009 - acc: 0.4531
 128/3015 [>.............................] - ETA: 2:58 - loss: 0.6774 - acc: 0.5547
 192/3015 [>.............................] - ETA: 1:58 - loss: 0.6717 - acc: 0.5781
 256/3015 [=>............................] - ETA: 1:28 - loss: 0.6807 - acc: 0.5664
 320/3015 [==>...........................] - ETA: 1:10 - loss: 0.6619 - acc: 0.6156
 384/3015 [==>...........................] - ETA: 58s - loss: 0.6462 - acc: 0.6328 
 448/3015 [===>..........................] - ETA: 49s - loss: 0.6312 - acc: 0.6473
 512/3015 [====>.........................] - ETA: 43s - loss: 0.6273 - acc: 0.6484
 576/3015 [====>.........................] - ETA: 39s - loss: 0.6028 - acc: 0.6753
 640/3015 [=====>........................] - ETA: 35s - loss: 0.6083 - acc: 0.6734
 704/3015 [======>.......................] - ETA: 32s - loss: 0.5958 - acc: 0.6847
 768/3015 [======>.......................] - ETA: 29s - loss: 0.5830 - acc: 0.6953
 832/3015 [=======>......................] - ETA: 27s - loss: 0.5595 - acc: 0.7103
 896/3015 [=======>......................] - ETA: 25s - loss: 0.5381 - acc: 0.7254
 960/3015 [========>.....................] - ETA: 23s - loss: 0.5285 - acc: 0.7302
1024/3015 [=========>....................] - ETA: 21s - loss: 0.5120 - acc: 0.7402
1088/3015 [=========>....................] - ETA: 19s - loss: 0.5079 - acc: 0.7454
1152/3015 [==========>...................] - ETA: 18s - loss: 0.5057 - acc: 0.7465
1216/3015 [===========>..................] - ETA: 17s - loss: 0.5061 - acc: 0.7492
1280/3015 [===========>..................] - ETA: 15s - loss: 0.4946 - acc: 0.7562
1344/3015 [============>.................] - ETA: 14s - loss: 0.4890 - acc: 0.7604
1408/3015 [=============>................] - ETA: 13s - loss: 0.4820 - acc: 0.7656
1472/3015 [=============>................] - ETA: 12s - loss: 0.4743 - acc: 0.7683
1536/3015 [==============>...............] - ETA: 11s - loss: 0.4679 - acc: 0.7715
1600/3015 [==============>...............] - ETA: 11s - loss: 0.4639 - acc: 0.7738
1664/3015 [===============>..............] - ETA: 10s - loss: 0.4585 - acc: 0.7782
1728/3015 [================>.............] - ETA: 9s - loss: 0.4545 - acc: 0.7818 
1792/3015 [================>.............] - ETA: 8s - loss: 0.4557 - acc: 0.7818
1856/3015 [=================>............] - ETA: 8s - loss: 0.4506 - acc: 0.7861
1920/3015 [==================>...........] - ETA: 7s - loss: 0.4501 - acc: 0.7859
1984/3015 [==================>...........] - ETA: 7s - loss: 0.4454 - acc: 0.7878
2048/3015 [===================>..........] - ETA: 6s - loss: 0.4445 - acc: 0.7886
2112/3015 [====================>.........] - ETA: 6s - loss: 0.4426 - acc: 0.7888
2176/3015 [====================>.........] - ETA: 5s - loss: 0.4370 - acc: 0.7923
2240/3015 [=====================>........] - ETA: 5s - loss: 0.4347 - acc: 0.7929
2304/3015 [=====================>........] - ETA: 4s - loss: 0.4278 - acc: 0.7956
2368/3015 [======================>.......] - ETA: 4s - loss: 0.4234 - acc: 0.7986
2432/3015 [=======================>......] - ETA: 3s - loss: 0.4205 - acc: 0.8010
2496/3015 [=======================>......] - ETA: 3s - loss: 0.4163 - acc: 0.8041
2560/3015 [========================>.....] - ETA: 2s - loss: 0.4116 - acc: 0.8066
2624/3015 [=========================>....] - ETA: 2s - loss: 0.4099 - acc: 0.8079
2688/3015 [=========================>....] - ETA: 1s - loss: 0.4110 - acc: 0.8077
2752/3015 [==========================>...] - ETA: 1s - loss: 0.4101 - acc: 0.8078
2816/3015 [===========================>..] - ETA: 1s - loss: 0.4158 - acc: 0.8058
2880/3015 [===========================>..] - ETA: 0s - loss: 0.4122 - acc: 0.8069
2944/3015 [============================>.] - ETA: 0s - loss: 0.4105 - acc: 0.8077
3008/3015 [============================>.] - ETA: 0s - loss: 0.4081 - acc: 0.8095
3015/3015 [==============================] - 17s 6ms/step - loss: 0.4078 - acc: 0.8096

Test accuracy: 87.08708708708708

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  180

choose_one :  153

F1score :  0.8652037617554859

AUC :  0.9544765889906933

Confusion Matrix
[[152  15]
 [ 28 138]]
True label 0
0.9101796407185628  
0.08982035928143713  
True label 1
0.1686746987951807  
0.8313253012048193  

Train_result {'loss': [0.4077732522096207], 'acc': [0.8096185738174476]}
Saved model to disk


2

Epoch 1/1

  64/3015 [..............................] - ETA: 9s - loss: 0.3534 - acc: 0.8594
 128/3015 [>.............................] - ETA: 8s - loss: 0.2864 - acc: 0.8906
 192/3015 [>.............................] - ETA: 8s - loss: 0.3158 - acc: 0.8646
 256/3015 [=>............................] - ETA: 7s - loss: 0.3133 - acc: 0.8594
 320/3015 [==>...........................] - ETA: 7s - loss: 0.3265 - acc: 0.8562
 384/3015 [==>...........................] - ETA: 7s - loss: 0.3388 - acc: 0.8464
 448/3015 [===>..........................] - ETA: 6s - loss: 0.3581 - acc: 0.8371
 512/3015 [====>.........................] - ETA: 6s - loss: 0.3458 - acc: 0.8418
 576/3015 [====>.........................] - ETA: 6s - loss: 0.3367 - acc: 0.8455
 640/3015 [=====>........................] - ETA: 6s - loss: 0.3311 - acc: 0.8469
 704/3015 [======>.......................] - ETA: 6s - loss: 0.3358 - acc: 0.8452
 768/3015 [======>.......................] - ETA: 6s - loss: 0.3257 - acc: 0.8490
 832/3015 [=======>......................] - ETA: 6s - loss: 0.3211 - acc: 0.8522
 896/3015 [=======>......................] - ETA: 6s - loss: 0.3248 - acc: 0.8493
 960/3015 [========>.....................] - ETA: 6s - loss: 0.3193 - acc: 0.8510
1024/3015 [=========>....................] - ETA: 6s - loss: 0.3168 - acc: 0.8545
1088/3015 [=========>....................] - ETA: 6s - loss: 0.3103 - acc: 0.8575
1152/3015 [==========>...................] - ETA: 6s - loss: 0.3095 - acc: 0.8602
1216/3015 [===========>..................] - ETA: 5s - loss: 0.3091 - acc: 0.8594
1280/3015 [===========>..................] - ETA: 5s - loss: 0.3072 - acc: 0.8625
1344/3015 [============>.................] - ETA: 5s - loss: 0.3111 - acc: 0.8624
1408/3015 [=============>................] - ETA: 5s - loss: 0.3163 - acc: 0.8608
1472/3015 [=============>................] - ETA: 4s - loss: 0.3169 - acc: 0.8594
1536/3015 [==============>...............] - ETA: 4s - loss: 0.3132 - acc: 0.8613
1600/3015 [==============>...............] - ETA: 4s - loss: 0.3117 - acc: 0.8631
1664/3015 [===============>..............] - ETA: 4s - loss: 0.3099 - acc: 0.8642
1728/3015 [================>.............] - ETA: 3s - loss: 0.3126 - acc: 0.8628
1792/3015 [================>.............] - ETA: 3s - loss: 0.3117 - acc: 0.8622
1856/3015 [=================>............] - ETA: 3s - loss: 0.3078 - acc: 0.8653
1920/3015 [==================>...........] - ETA: 3s - loss: 0.3101 - acc: 0.8646
1984/3015 [==================>...........] - ETA: 3s - loss: 0.3081 - acc: 0.8664
2048/3015 [===================>..........] - ETA: 2s - loss: 0.3036 - acc: 0.8682
2112/3015 [====================>.........] - ETA: 2s - loss: 0.2998 - acc: 0.8703
2176/3015 [====================>.........] - ETA: 2s - loss: 0.2962 - acc: 0.8727
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2965 - acc: 0.8719
2304/3015 [=====================>........] - ETA: 2s - loss: 0.2993 - acc: 0.8715
2368/3015 [======================>.......] - ETA: 2s - loss: 0.2985 - acc: 0.8725
2432/3015 [=======================>......] - ETA: 1s - loss: 0.2987 - acc: 0.8721
2496/3015 [=======================>......] - ETA: 1s - loss: 0.2999 - acc: 0.8714
2560/3015 [========================>.....] - ETA: 1s - loss: 0.3010 - acc: 0.8715
2624/3015 [=========================>....] - ETA: 1s - loss: 0.2978 - acc: 0.8731
2688/3015 [=========================>....] - ETA: 1s - loss: 0.2967 - acc: 0.8724
2752/3015 [==========================>...] - ETA: 0s - loss: 0.2934 - acc: 0.8739
2816/3015 [===========================>..] - ETA: 0s - loss: 0.2924 - acc: 0.8754
2880/3015 [===========================>..] - ETA: 0s - loss: 0.2910 - acc: 0.8750
2944/3015 [============================>.] - ETA: 0s - loss: 0.2946 - acc: 0.8743
3008/3015 [============================>.] - ETA: 0s - loss: 0.2939 - acc: 0.8743
3015/3015 [==============================] - 9s 3ms/step - loss: 0.2935 - acc: 0.8746

Test accuracy: 89.7897897897898

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  155

choose_one :  178

F1score :  0.9011627906976745

AUC :  0.9587331361373638

Confusion Matrix
[[144  23]
 [ 11 155]]
True label 0
0.8622754491017964  
0.1377245508982036  
True label 1
0.06626506024096386  
0.9337349397590361  

Train_result {'loss': [0.2935247808398299], 'acc': [0.8746268656716418]}
Saved model to disk


3

Epoch 1/1

  64/3015 [..............................] - ETA: 12s - loss: 0.3224 - acc: 0.8125
 128/3015 [>.............................] - ETA: 10s - loss: 0.2684 - acc: 0.8672
 192/3015 [>.............................] - ETA: 9s - loss: 0.2419 - acc: 0.8802 
 256/3015 [=>............................] - ETA: 10s - loss: 0.2575 - acc: 0.8672
 320/3015 [==>...........................] - ETA: 9s - loss: 0.2516 - acc: 0.8750 
 384/3015 [==>...........................] - ETA: 9s - loss: 0.2790 - acc: 0.8620
 448/3015 [===>..........................] - ETA: 8s - loss: 0.2792 - acc: 0.8638
 512/3015 [====>.........................] - ETA: 7s - loss: 0.2832 - acc: 0.8652
 576/3015 [====>.........................] - ETA: 7s - loss: 0.2734 - acc: 0.8733
 640/3015 [=====>........................] - ETA: 7s - loss: 0.2733 - acc: 0.8766
 704/3015 [======>.......................] - ETA: 6s - loss: 0.2668 - acc: 0.8793
 768/3015 [======>.......................] - ETA: 6s - loss: 0.2687 - acc: 0.8828
 832/3015 [=======>......................] - ETA: 6s - loss: 0.2657 - acc: 0.8810
 896/3015 [=======>......................] - ETA: 5s - loss: 0.2798 - acc: 0.8783
 960/3015 [========>.....................] - ETA: 5s - loss: 0.2812 - acc: 0.8760
1024/3015 [=========>....................] - ETA: 5s - loss: 0.2828 - acc: 0.8740
1088/3015 [=========>....................] - ETA: 5s - loss: 0.2797 - acc: 0.8759
1152/3015 [==========>...................] - ETA: 5s - loss: 0.2845 - acc: 0.8741
1216/3015 [===========>..................] - ETA: 5s - loss: 0.2870 - acc: 0.8725
1280/3015 [===========>..................] - ETA: 5s - loss: 0.2842 - acc: 0.8727
1344/3015 [============>.................] - ETA: 5s - loss: 0.2835 - acc: 0.8728
1408/3015 [=============>................] - ETA: 5s - loss: 0.2853 - acc: 0.8707
1472/3015 [=============>................] - ETA: 4s - loss: 0.2832 - acc: 0.8716
1536/3015 [==============>...............] - ETA: 4s - loss: 0.2882 - acc: 0.8717
1600/3015 [==============>...............] - ETA: 4s - loss: 0.2921 - acc: 0.8712
1664/3015 [===============>..............] - ETA: 4s - loss: 0.2952 - acc: 0.8696
1728/3015 [================>.............] - ETA: 4s - loss: 0.2943 - acc: 0.8704
1792/3015 [================>.............] - ETA: 3s - loss: 0.2898 - acc: 0.8733
1856/3015 [=================>............] - ETA: 3s - loss: 0.2909 - acc: 0.8723
1920/3015 [==================>...........] - ETA: 3s - loss: 0.2892 - acc: 0.8714
1984/3015 [==================>...........] - ETA: 3s - loss: 0.2867 - acc: 0.8725
2048/3015 [===================>..........] - ETA: 2s - loss: 0.2857 - acc: 0.8721
2112/3015 [====================>.........] - ETA: 2s - loss: 0.2816 - acc: 0.8741
2176/3015 [====================>.........] - ETA: 2s - loss: 0.2823 - acc: 0.8750
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2854 - acc: 0.8732
2304/3015 [=====================>........] - ETA: 2s - loss: 0.2837 - acc: 0.8737
2368/3015 [======================>.......] - ETA: 1s - loss: 0.2795 - acc: 0.8754
2432/3015 [=======================>......] - ETA: 1s - loss: 0.2785 - acc: 0.8762
2496/3015 [=======================>......] - ETA: 1s - loss: 0.2759 - acc: 0.8766
2560/3015 [========================>.....] - ETA: 1s - loss: 0.2755 - acc: 0.8766
2624/3015 [=========================>....] - ETA: 1s - loss: 0.2737 - acc: 0.8773
2688/3015 [=========================>....] - ETA: 1s - loss: 0.2739 - acc: 0.8776
2752/3015 [==========================>...] - ETA: 0s - loss: 0.2758 - acc: 0.8757
2816/3015 [===========================>..] - ETA: 0s - loss: 0.2757 - acc: 0.8764
2880/3015 [===========================>..] - ETA: 0s - loss: 0.2767 - acc: 0.8764
2944/3015 [============================>.] - ETA: 0s - loss: 0.2755 - acc: 0.8770
3008/3015 [============================>.] - ETA: 0s - loss: 0.2746 - acc: 0.8777
3015/3015 [==============================] - 9s 3ms/step - loss: 0.2744 - acc: 0.8779

Test accuracy: 88.28828828828829

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  142

choose_one :  191

F1score :  0.8907563025210085

AUC :  0.9644686530553351

Confusion Matrix
[[135  32]
 [  7 159]]
True label 0
0.8083832335329342  
0.19161676646706588  
True label 1
0.04216867469879518  
0.9578313253012049  

Train_result {'loss': [0.27443073729476325], 'acc': [0.8779436152570481]}
Saved model to disk


4

Epoch 1/1

  64/3015 [..............................] - ETA: 14s - loss: 0.2910 - acc: 0.9062
 128/3015 [>.............................] - ETA: 16s - loss: 0.2445 - acc: 0.8906
 192/3015 [>.............................] - ETA: 14s - loss: 0.2408 - acc: 0.8854
 256/3015 [=>............................] - ETA: 13s - loss: 0.2320 - acc: 0.8906
 320/3015 [==>...........................] - ETA: 12s - loss: 0.2167 - acc: 0.9031
 384/3015 [==>...........................] - ETA: 11s - loss: 0.2174 - acc: 0.9036
 448/3015 [===>..........................] - ETA: 10s - loss: 0.2139 - acc: 0.8996
 512/3015 [====>.........................] - ETA: 10s - loss: 0.2310 - acc: 0.8984
 576/3015 [====>.........................] - ETA: 10s - loss: 0.2150 - acc: 0.9045
 640/3015 [=====>........................] - ETA: 9s - loss: 0.2197 - acc: 0.9000 
 704/3015 [======>.......................] - ETA: 8s - loss: 0.2289 - acc: 0.8963
 768/3015 [======>.......................] - ETA: 8s - loss: 0.2303 - acc: 0.8984
 832/3015 [=======>......................] - ETA: 7s - loss: 0.2320 - acc: 0.8966
 896/3015 [=======>......................] - ETA: 7s - loss: 0.2227 - acc: 0.9018
 960/3015 [========>.....................] - ETA: 7s - loss: 0.2213 - acc: 0.9000
1024/3015 [=========>....................] - ETA: 6s - loss: 0.2187 - acc: 0.9004
1088/3015 [=========>....................] - ETA: 6s - loss: 0.2200 - acc: 0.9017
1152/3015 [==========>...................] - ETA: 6s - loss: 0.2250 - acc: 0.8993
1216/3015 [===========>..................] - ETA: 5s - loss: 0.2247 - acc: 0.8988
1280/3015 [===========>..................] - ETA: 5s - loss: 0.2267 - acc: 0.8992
1344/3015 [============>.................] - ETA: 5s - loss: 0.2262 - acc: 0.8996
1408/3015 [=============>................] - ETA: 5s - loss: 0.2312 - acc: 0.8977
1472/3015 [=============>................] - ETA: 5s - loss: 0.2306 - acc: 0.8988
1536/3015 [==============>...............] - ETA: 5s - loss: 0.2305 - acc: 0.8984
1600/3015 [==============>...............] - ETA: 4s - loss: 0.2328 - acc: 0.8956
1664/3015 [===============>..............] - ETA: 4s - loss: 0.2337 - acc: 0.8960
1728/3015 [================>.............] - ETA: 4s - loss: 0.2332 - acc: 0.8976
1792/3015 [================>.............] - ETA: 4s - loss: 0.2325 - acc: 0.8979
1856/3015 [=================>............] - ETA: 3s - loss: 0.2362 - acc: 0.8976
1920/3015 [==================>...........] - ETA: 3s - loss: 0.2358 - acc: 0.8984
1984/3015 [==================>...........] - ETA: 3s - loss: 0.2355 - acc: 0.8982
2048/3015 [===================>..........] - ETA: 3s - loss: 0.2403 - acc: 0.8960
2112/3015 [====================>.........] - ETA: 2s - loss: 0.2398 - acc: 0.8973
2176/3015 [====================>.........] - ETA: 2s - loss: 0.2398 - acc: 0.8975
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2383 - acc: 0.8991
2304/3015 [=====================>........] - ETA: 2s - loss: 0.2352 - acc: 0.9010
2368/3015 [======================>.......] - ETA: 2s - loss: 0.2360 - acc: 0.9020
2432/3015 [=======================>......] - ETA: 1s - loss: 0.2425 - acc: 0.9005
2496/3015 [=======================>......] - ETA: 1s - loss: 0.2421 - acc: 0.9014
2560/3015 [========================>.....] - ETA: 1s - loss: 0.2421 - acc: 0.9020
2624/3015 [=========================>....] - ETA: 1s - loss: 0.2411 - acc: 0.9021
2688/3015 [=========================>....] - ETA: 1s - loss: 0.2416 - acc: 0.9018
2752/3015 [==========================>...] - ETA: 0s - loss: 0.2411 - acc: 0.9015
2816/3015 [===========================>..] - ETA: 0s - loss: 0.2404 - acc: 0.9009
2880/3015 [===========================>..] - ETA: 0s - loss: 0.2400 - acc: 0.9007
2944/3015 [============================>.] - ETA: 0s - loss: 0.2414 - acc: 0.9001
3008/3015 [============================>.] - ETA: 0s - loss: 0.2413 - acc: 0.9003
3015/3015 [==============================] - 10s 3ms/step - loss: 0.2411 - acc: 0.9005

Test accuracy: 90.69069069069069

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  160

choose_one :  173

F1score :  0.9085545722713864

AUC :  0.966164057427314

Confusion Matrix
[[148  19]
 [ 12 154]]
True label 0
0.8862275449101796  
0.11377245508982035  
True label 1
0.07228915662650602  
0.927710843373494  

Train_result {'loss': [0.2410944679433829], 'acc': [0.900497512437811]}
Saved model to disk


5

Epoch 1/1

  64/3015 [..............................] - ETA: 9s - loss: 0.2225 - acc: 0.8750
 128/3015 [>.............................] - ETA: 8s - loss: 0.2700 - acc: 0.8672
 192/3015 [>.............................] - ETA: 7s - loss: 0.2243 - acc: 0.8958
 256/3015 [=>............................] - ETA: 7s - loss: 0.2161 - acc: 0.8945
 320/3015 [==>...........................] - ETA: 8s - loss: 0.1899 - acc: 0.9125
 384/3015 [==>...........................] - ETA: 8s - loss: 0.1946 - acc: 0.9167
 448/3015 [===>..........................] - ETA: 8s - loss: 0.1979 - acc: 0.9152
 512/3015 [====>.........................] - ETA: 8s - loss: 0.2169 - acc: 0.9102
 576/3015 [====>.........................] - ETA: 8s - loss: 0.2027 - acc: 0.9167
 640/3015 [=====>........................] - ETA: 8s - loss: 0.2029 - acc: 0.9156
 704/3015 [======>.......................] - ETA: 7s - loss: 0.1968 - acc: 0.9190
 768/3015 [======>.......................] - ETA: 7s - loss: 0.2025 - acc: 0.9206
 832/3015 [=======>......................] - ETA: 7s - loss: 0.2034 - acc: 0.9207
 896/3015 [=======>......................] - ETA: 7s - loss: 0.2012 - acc: 0.9219
 960/3015 [========>.....................] - ETA: 6s - loss: 0.2066 - acc: 0.9229
1024/3015 [=========>....................] - ETA: 6s - loss: 0.2058 - acc: 0.9209
1088/3015 [=========>....................] - ETA: 6s - loss: 0.2057 - acc: 0.9210
1152/3015 [==========>...................] - ETA: 5s - loss: 0.2045 - acc: 0.9193
1216/3015 [===========>..................] - ETA: 5s - loss: 0.2096 - acc: 0.9161
1280/3015 [===========>..................] - ETA: 5s - loss: 0.2139 - acc: 0.9133
1344/3015 [============>.................] - ETA: 5s - loss: 0.2189 - acc: 0.9115
1408/3015 [=============>................] - ETA: 4s - loss: 0.2244 - acc: 0.9084
1472/3015 [=============>................] - ETA: 4s - loss: 0.2252 - acc: 0.9090
1536/3015 [==============>...............] - ETA: 4s - loss: 0.2219 - acc: 0.9102
1600/3015 [==============>...............] - ETA: 4s - loss: 0.2272 - acc: 0.9069
1664/3015 [===============>..............] - ETA: 4s - loss: 0.2247 - acc: 0.9093
1728/3015 [================>.............] - ETA: 4s - loss: 0.2253 - acc: 0.9091
1792/3015 [================>.............] - ETA: 3s - loss: 0.2238 - acc: 0.9107
1856/3015 [=================>............] - ETA: 3s - loss: 0.2225 - acc: 0.9106
1920/3015 [==================>...........] - ETA: 3s - loss: 0.2219 - acc: 0.9109
1984/3015 [==================>...........] - ETA: 3s - loss: 0.2193 - acc: 0.9118
2048/3015 [===================>..........] - ETA: 3s - loss: 0.2174 - acc: 0.9126
2112/3015 [====================>.........] - ETA: 2s - loss: 0.2147 - acc: 0.9134
2176/3015 [====================>.........] - ETA: 2s - loss: 0.2160 - acc: 0.9127
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2154 - acc: 0.9125
2304/3015 [=====================>........] - ETA: 2s - loss: 0.2166 - acc: 0.9115
2368/3015 [======================>.......] - ETA: 2s - loss: 0.2133 - acc: 0.9126
2432/3015 [=======================>......] - ETA: 1s - loss: 0.2189 - acc: 0.9116
2496/3015 [=======================>......] - ETA: 1s - loss: 0.2183 - acc: 0.9119
2560/3015 [========================>.....] - ETA: 1s - loss: 0.2212 - acc: 0.9109
2624/3015 [=========================>....] - ETA: 1s - loss: 0.2186 - acc: 0.9123
2688/3015 [=========================>....] - ETA: 1s - loss: 0.2233 - acc: 0.9107
2752/3015 [==========================>...] - ETA: 0s - loss: 0.2234 - acc: 0.9110
2816/3015 [===========================>..] - ETA: 0s - loss: 0.2239 - acc: 0.9105
2880/3015 [===========================>..] - ETA: 0s - loss: 0.2238 - acc: 0.9111
2944/3015 [============================>.] - ETA: 0s - loss: 0.2230 - acc: 0.9117
3008/3015 [============================>.] - ETA: 0s - loss: 0.2240 - acc: 0.9112
3015/3015 [==============================] - 10s 3ms/step - loss: 0.2242 - acc: 0.9111

Test accuracy: 90.69069069069069

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  162

choose_one :  171

F1score :  0.9080118694362017

AUC :  0.9662362022942068

Confusion Matrix
[[149  18]
 [ 13 153]]
True label 0
0.8922155688622755  
0.10778443113772455  
True label 1
0.0783132530120482  
0.9216867469879518  

Train_result {'loss': [0.2241862684636567], 'acc': [0.9111111111308805]}
Saved model to disk


6

Epoch 1/1

  64/3015 [..............................] - ETA: 9s - loss: 0.1796 - acc: 0.9375
 128/3015 [>.............................] - ETA: 8s - loss: 0.2682 - acc: 0.9062
 192/3015 [>.............................] - ETA: 7s - loss: 0.2335 - acc: 0.9167
 256/3015 [=>............................] - ETA: 7s - loss: 0.2018 - acc: 0.9258
 320/3015 [==>...........................] - ETA: 7s - loss: 0.2067 - acc: 0.9219
 384/3015 [==>...........................] - ETA: 6s - loss: 0.2078 - acc: 0.9167
 448/3015 [===>..........................] - ETA: 6s - loss: 0.2135 - acc: 0.9129
 512/3015 [====>.........................] - ETA: 6s - loss: 0.2220 - acc: 0.9102
 576/3015 [====>.........................] - ETA: 6s - loss: 0.2157 - acc: 0.9167
 640/3015 [=====>........................] - ETA: 5s - loss: 0.2052 - acc: 0.9203
 704/3015 [======>.......................] - ETA: 5s - loss: 0.1979 - acc: 0.9233
 768/3015 [======>.......................] - ETA: 5s - loss: 0.2052 - acc: 0.9219
 832/3015 [=======>......................] - ETA: 6s - loss: 0.2071 - acc: 0.9219
 896/3015 [=======>......................] - ETA: 6s - loss: 0.2002 - acc: 0.9241
 960/3015 [========>.....................] - ETA: 6s - loss: 0.1989 - acc: 0.9250
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1978 - acc: 0.9238
1088/3015 [=========>....................] - ETA: 5s - loss: 0.1919 - acc: 0.9256
1152/3015 [==========>...................] - ETA: 5s - loss: 0.1950 - acc: 0.9253
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1945 - acc: 0.9243
1280/3015 [===========>..................] - ETA: 5s - loss: 0.2051 - acc: 0.9180
1344/3015 [============>.................] - ETA: 5s - loss: 0.2045 - acc: 0.9182
1408/3015 [=============>................] - ETA: 5s - loss: 0.2070 - acc: 0.9169
1472/3015 [=============>................] - ETA: 4s - loss: 0.2077 - acc: 0.9158
1536/3015 [==============>...............] - ETA: 4s - loss: 0.2089 - acc: 0.9160
1600/3015 [==============>...............] - ETA: 4s - loss: 0.2103 - acc: 0.9163
1664/3015 [===============>..............] - ETA: 4s - loss: 0.2110 - acc: 0.9165
1728/3015 [================>.............] - ETA: 3s - loss: 0.2116 - acc: 0.9155
1792/3015 [================>.............] - ETA: 3s - loss: 0.2087 - acc: 0.9169
1856/3015 [=================>............] - ETA: 3s - loss: 0.2071 - acc: 0.9165
1920/3015 [==================>...........] - ETA: 3s - loss: 0.2100 - acc: 0.9156
1984/3015 [==================>...........] - ETA: 3s - loss: 0.2133 - acc: 0.9148
2048/3015 [===================>..........] - ETA: 2s - loss: 0.2123 - acc: 0.9146
2112/3015 [====================>.........] - ETA: 2s - loss: 0.2138 - acc: 0.9119
2176/3015 [====================>.........] - ETA: 2s - loss: 0.2138 - acc: 0.9122
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2133 - acc: 0.9125
2304/3015 [=====================>........] - ETA: 2s - loss: 0.2113 - acc: 0.9128
2368/3015 [======================>.......] - ETA: 2s - loss: 0.2092 - acc: 0.9134
2432/3015 [=======================>......] - ETA: 1s - loss: 0.2092 - acc: 0.9128
2496/3015 [=======================>......] - ETA: 1s - loss: 0.2079 - acc: 0.9131
2560/3015 [========================>.....] - ETA: 1s - loss: 0.2068 - acc: 0.9137
2624/3015 [=========================>....] - ETA: 1s - loss: 0.2064 - acc: 0.9135
2688/3015 [=========================>....] - ETA: 1s - loss: 0.2043 - acc: 0.9144
2752/3015 [==========================>...] - ETA: 0s - loss: 0.2087 - acc: 0.9139
2816/3015 [===========================>..] - ETA: 0s - loss: 0.2065 - acc: 0.9148
2880/3015 [===========================>..] - ETA: 0s - loss: 0.2054 - acc: 0.9160
2944/3015 [============================>.] - ETA: 0s - loss: 0.2077 - acc: 0.9147
3008/3015 [============================>.] - ETA: 0s - loss: 0.2072 - acc: 0.9156
3015/3015 [==============================] - 9s 3ms/step - loss: 0.2068 - acc: 0.9158

Test accuracy: 90.69069069069069

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  162

choose_one :  171

F1score :  0.9080118694362017

AUC :  0.9628814659836953

Confusion Matrix
[[149  18]
 [ 13 153]]
True label 0
0.8922155688622755  
0.10778443113772455  
True label 1
0.0783132530120482  
0.9216867469879518  

Train_result {'loss': [0.20677714392073315], 'acc': [0.9157545605306799]}
Saved model to disk


7

Epoch 1/1

  64/3015 [..............................] - ETA: 11s - loss: 0.1173 - acc: 0.9375
 128/3015 [>.............................] - ETA: 11s - loss: 0.1532 - acc: 0.9297
 192/3015 [>.............................] - ETA: 10s - loss: 0.1549 - acc: 0.9323
 256/3015 [=>............................] - ETA: 9s - loss: 0.1573 - acc: 0.9336 
 320/3015 [==>...........................] - ETA: 10s - loss: 0.1494 - acc: 0.9344
 384/3015 [==>...........................] - ETA: 10s - loss: 0.1719 - acc: 0.9297
 448/3015 [===>..........................] - ETA: 9s - loss: 0.1700 - acc: 0.9308 
 512/3015 [====>.........................] - ETA: 8s - loss: 0.1630 - acc: 0.9336
 576/3015 [====>.........................] - ETA: 8s - loss: 0.1613 - acc: 0.9323
 640/3015 [=====>........................] - ETA: 7s - loss: 0.1666 - acc: 0.9297
 704/3015 [======>.......................] - ETA: 7s - loss: 0.1824 - acc: 0.9247
 768/3015 [======>.......................] - ETA: 7s - loss: 0.1738 - acc: 0.9297
 832/3015 [=======>......................] - ETA: 6s - loss: 0.1735 - acc: 0.9303
 896/3015 [=======>......................] - ETA: 6s - loss: 0.1786 - acc: 0.9308
 960/3015 [========>.....................] - ETA: 6s - loss: 0.1865 - acc: 0.9281
1024/3015 [=========>....................] - ETA: 5s - loss: 0.1915 - acc: 0.9258
1088/3015 [=========>....................] - ETA: 5s - loss: 0.1930 - acc: 0.9246
1152/3015 [==========>...................] - ETA: 5s - loss: 0.1929 - acc: 0.9227
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1987 - acc: 0.9202
1280/3015 [===========>..................] - ETA: 5s - loss: 0.2007 - acc: 0.9195
1344/3015 [============>.................] - ETA: 5s - loss: 0.2002 - acc: 0.9196
1408/3015 [=============>................] - ETA: 5s - loss: 0.2008 - acc: 0.9205
1472/3015 [=============>................] - ETA: 5s - loss: 0.2029 - acc: 0.9198
1536/3015 [==============>...............] - ETA: 4s - loss: 0.2035 - acc: 0.9186
1600/3015 [==============>...............] - ETA: 4s - loss: 0.2071 - acc: 0.9169
1664/3015 [===============>..............] - ETA: 4s - loss: 0.2051 - acc: 0.9183
1728/3015 [================>.............] - ETA: 4s - loss: 0.2044 - acc: 0.9184
1792/3015 [================>.............] - ETA: 4s - loss: 0.2063 - acc: 0.9174
1856/3015 [=================>............] - ETA: 3s - loss: 0.2052 - acc: 0.9165
1920/3015 [==================>...........] - ETA: 3s - loss: 0.2052 - acc: 0.9156
1984/3015 [==================>...........] - ETA: 3s - loss: 0.2035 - acc: 0.9163
2048/3015 [===================>..........] - ETA: 3s - loss: 0.2042 - acc: 0.9160
2112/3015 [====================>.........] - ETA: 2s - loss: 0.2053 - acc: 0.9148
2176/3015 [====================>.........] - ETA: 2s - loss: 0.2038 - acc: 0.9150
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2025 - acc: 0.9152
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1997 - acc: 0.9167
2368/3015 [======================>.......] - ETA: 1s - loss: 0.2029 - acc: 0.9151
2432/3015 [=======================>......] - ETA: 1s - loss: 0.2005 - acc: 0.9161
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1981 - acc: 0.9171
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1984 - acc: 0.9164
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1980 - acc: 0.9158
2688/3015 [=========================>....] - ETA: 1s - loss: 0.2024 - acc: 0.9141
2752/3015 [==========================>...] - ETA: 0s - loss: 0.2007 - acc: 0.9146
2816/3015 [===========================>..] - ETA: 0s - loss: 0.2013 - acc: 0.9134
2880/3015 [===========================>..] - ETA: 0s - loss: 0.2014 - acc: 0.9139
2944/3015 [============================>.] - ETA: 0s - loss: 0.2020 - acc: 0.9144
3008/3015 [============================>.] - ETA: 0s - loss: 0.2025 - acc: 0.9139
3015/3015 [==============================] - 10s 3ms/step - loss: 0.2022 - acc: 0.9141

Test accuracy: 90.39039039039038

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  155

choose_one :  178

F1score :  0.9069767441860466

AUC :  0.9668133612293486

Confusion Matrix
[[145  22]
 [ 10 156]]
True label 0
0.8682634730538922  
0.1317365269461078  
True label 1
0.060240963855421686  
0.9397590361445783  

Train_result {'loss': [0.20220195196729593], 'acc': [0.9140961857379768]}
Saved model to disk


8

Epoch 1/1

  64/3015 [..............................] - ETA: 8s - loss: 0.1657 - acc: 0.9688
 128/3015 [>.............................] - ETA: 9s - loss: 0.1644 - acc: 0.9453
 192/3015 [>.............................] - ETA: 11s - loss: 0.2155 - acc: 0.9323
 256/3015 [=>............................] - ETA: 12s - loss: 0.1879 - acc: 0.9375
 320/3015 [==>...........................] - ETA: 11s - loss: 0.1789 - acc: 0.9375
 384/3015 [==>...........................] - ETA: 11s - loss: 0.1810 - acc: 0.9323
 448/3015 [===>..........................] - ETA: 10s - loss: 0.1807 - acc: 0.9330
 512/3015 [====>.........................] - ETA: 10s - loss: 0.1809 - acc: 0.9336
 576/3015 [====>.........................] - ETA: 9s - loss: 0.1828 - acc: 0.9288 
 640/3015 [=====>........................] - ETA: 9s - loss: 0.1753 - acc: 0.9297
 704/3015 [======>.......................] - ETA: 8s - loss: 0.1731 - acc: 0.9290
 768/3015 [======>.......................] - ETA: 8s - loss: 0.1789 - acc: 0.9297
 832/3015 [=======>......................] - ETA: 7s - loss: 0.1778 - acc: 0.9279
 896/3015 [=======>......................] - ETA: 7s - loss: 0.1851 - acc: 0.9275
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1817 - acc: 0.9271
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1844 - acc: 0.9248
1088/3015 [=========>....................] - ETA: 6s - loss: 0.1847 - acc: 0.9256
1152/3015 [==========>...................] - ETA: 6s - loss: 0.1841 - acc: 0.9227
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1805 - acc: 0.9252
1280/3015 [===========>..................] - ETA: 5s - loss: 0.1795 - acc: 0.9250
1344/3015 [============>.................] - ETA: 5s - loss: 0.1881 - acc: 0.9211
1408/3015 [=============>................] - ETA: 5s - loss: 0.1900 - acc: 0.9219
1472/3015 [=============>................] - ETA: 5s - loss: 0.1896 - acc: 0.9219
1536/3015 [==============>...............] - ETA: 5s - loss: 0.1893 - acc: 0.9206
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1886 - acc: 0.9206
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1855 - acc: 0.9219
1728/3015 [================>.............] - ETA: 4s - loss: 0.1832 - acc: 0.9236
1792/3015 [================>.............] - ETA: 4s - loss: 0.1814 - acc: 0.9247
1856/3015 [=================>............] - ETA: 4s - loss: 0.1784 - acc: 0.9251
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1757 - acc: 0.9260
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1744 - acc: 0.9269
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1779 - acc: 0.9272
2112/3015 [====================>.........] - ETA: 3s - loss: 0.1763 - acc: 0.9280
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1768 - acc: 0.9288
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1758 - acc: 0.9286
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1779 - acc: 0.9275
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1771 - acc: 0.9269
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1773 - acc: 0.9264
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1782 - acc: 0.9259
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1759 - acc: 0.9273
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1756 - acc: 0.9280
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1738 - acc: 0.9289
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1749 - acc: 0.9288
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1769 - acc: 0.9286
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1791 - acc: 0.9288
2944/3015 [============================>.] - ETA: 0s - loss: 0.1790 - acc: 0.9283
3008/3015 [============================>.] - ETA: 0s - loss: 0.1801 - acc: 0.9285
3015/3015 [==============================] - 10s 3ms/step - loss: 0.1799 - acc: 0.9287

Test accuracy: 88.28828828828829

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  140

choose_one :  193

F1score :  0.8913649025069638

AUC :  0.967354447731044

Confusion Matrix
[[134  33]
 [  6 160]]
True label 0
0.8023952095808383  
0.19760479041916168  
True label 1
0.03614457831325301  
0.963855421686747  

Train_result {'loss': [0.17985391045239435], 'acc': [0.9286898839137645]}
Saved model to disk


9

Epoch 1/1

  64/3015 [..............................] - ETA: 8s - loss: 0.1393 - acc: 0.9375
 128/3015 [>.............................] - ETA: 8s - loss: 0.1680 - acc: 0.9219
 192/3015 [>.............................] - ETA: 8s - loss: 0.1942 - acc: 0.9062
 256/3015 [=>............................] - ETA: 10s - loss: 0.1721 - acc: 0.9141
 320/3015 [==>...........................] - ETA: 10s - loss: 0.1978 - acc: 0.9000
 384/3015 [==>...........................] - ETA: 10s - loss: 0.1843 - acc: 0.9141
 448/3015 [===>..........................] - ETA: 9s - loss: 0.1881 - acc: 0.9152 
 512/3015 [====>.........................] - ETA: 9s - loss: 0.1839 - acc: 0.9199
 576/3015 [====>.........................] - ETA: 8s - loss: 0.1849 - acc: 0.9167
 640/3015 [=====>........................] - ETA: 9s - loss: 0.1803 - acc: 0.9203
 704/3015 [======>.......................] - ETA: 8s - loss: 0.1781 - acc: 0.9205
 768/3015 [======>.......................] - ETA: 8s - loss: 0.1732 - acc: 0.9219
 832/3015 [=======>......................] - ETA: 7s - loss: 0.1704 - acc: 0.9207
 896/3015 [=======>......................] - ETA: 7s - loss: 0.1812 - acc: 0.9141
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1776 - acc: 0.9156
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1719 - acc: 0.9189
1088/3015 [=========>....................] - ETA: 6s - loss: 0.1697 - acc: 0.9210
1152/3015 [==========>...................] - ETA: 6s - loss: 0.1719 - acc: 0.9184
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1716 - acc: 0.9178
1280/3015 [===========>..................] - ETA: 5s - loss: 0.1750 - acc: 0.9148
1344/3015 [============>.................] - ETA: 5s - loss: 0.1819 - acc: 0.9137
1408/3015 [=============>................] - ETA: 5s - loss: 0.1848 - acc: 0.9119
1472/3015 [=============>................] - ETA: 4s - loss: 0.1854 - acc: 0.9144
1536/3015 [==============>...............] - ETA: 4s - loss: 0.1872 - acc: 0.9141
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1846 - acc: 0.9156
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1838 - acc: 0.9147
1728/3015 [================>.............] - ETA: 4s - loss: 0.1808 - acc: 0.9167
1792/3015 [================>.............] - ETA: 4s - loss: 0.1867 - acc: 0.9163
1856/3015 [=================>............] - ETA: 3s - loss: 0.1859 - acc: 0.9165
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1833 - acc: 0.9187
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1812 - acc: 0.9199
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1786 - acc: 0.9209
2112/3015 [====================>.........] - ETA: 2s - loss: 0.1767 - acc: 0.9219
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1754 - acc: 0.9219
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1768 - acc: 0.9223
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1761 - acc: 0.9219
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1764 - acc: 0.9215
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1752 - acc: 0.9223
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1733 - acc: 0.9231
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1742 - acc: 0.9219
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1729 - acc: 0.9226
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1739 - acc: 0.9219
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1719 - acc: 0.9230
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1710 - acc: 0.9229
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1746 - acc: 0.9219
2944/3015 [============================>.] - ETA: 0s - loss: 0.1744 - acc: 0.9222
3008/3015 [============================>.] - ETA: 0s - loss: 0.1731 - acc: 0.9235
3015/3015 [==============================] - 10s 3ms/step - loss: 0.1729 - acc: 0.9237

Test accuracy: 90.69069069069069

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  158

choose_one :  175

F1score :  0.909090909090909

AUC :  0.9655868984921723

Confusion Matrix
[[147  20]
 [ 11 155]]
True label 0
0.8802395209580839  
0.11976047904191617  
True label 1
0.06626506024096386  
0.9337349397590361  

Train_result {'loss': [0.1729290404994887], 'acc': [0.9237147595356551]}
Saved model to disk


10

Epoch 1/1

  64/3015 [..............................] - ETA: 8s - loss: 0.1080 - acc: 0.9688
 128/3015 [>.............................] - ETA: 8s - loss: 0.1303 - acc: 0.9375
 192/3015 [>.............................] - ETA: 7s - loss: 0.1546 - acc: 0.9323
 256/3015 [=>............................] - ETA: 7s - loss: 0.1275 - acc: 0.9453
 320/3015 [==>...........................] - ETA: 7s - loss: 0.1216 - acc: 0.9469
 384/3015 [==>...........................] - ETA: 7s - loss: 0.1121 - acc: 0.9531
 448/3015 [===>..........................] - ETA: 7s - loss: 0.1425 - acc: 0.9442
 512/3015 [====>.........................] - ETA: 7s - loss: 0.1409 - acc: 0.9453
 576/3015 [====>.........................] - ETA: 7s - loss: 0.1377 - acc: 0.9462
 640/3015 [=====>........................] - ETA: 7s - loss: 0.1320 - acc: 0.9484
 704/3015 [======>.......................] - ETA: 7s - loss: 0.1339 - acc: 0.9474
 768/3015 [======>.......................] - ETA: 7s - loss: 0.1395 - acc: 0.9492
 832/3015 [=======>......................] - ETA: 7s - loss: 0.1432 - acc: 0.9471
 896/3015 [=======>......................] - ETA: 7s - loss: 0.1507 - acc: 0.9420
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1596 - acc: 0.9396
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1664 - acc: 0.9375
1088/3015 [=========>....................] - ETA: 6s - loss: 0.1683 - acc: 0.9338
1152/3015 [==========>...................] - ETA: 6s - loss: 0.1688 - acc: 0.9323
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1652 - acc: 0.9334
1280/3015 [===========>..................] - ETA: 5s - loss: 0.1654 - acc: 0.9344
1344/3015 [============>.................] - ETA: 5s - loss: 0.1653 - acc: 0.9338
1408/3015 [=============>................] - ETA: 5s - loss: 0.1651 - acc: 0.9332
1472/3015 [=============>................] - ETA: 4s - loss: 0.1674 - acc: 0.9334
1536/3015 [==============>...............] - ETA: 4s - loss: 0.1677 - acc: 0.9342
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1700 - acc: 0.9319
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1658 - acc: 0.9345
1728/3015 [================>.............] - ETA: 3s - loss: 0.1632 - acc: 0.9358
1792/3015 [================>.............] - ETA: 3s - loss: 0.1642 - acc: 0.9353
1856/3015 [=================>............] - ETA: 3s - loss: 0.1678 - acc: 0.9332
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1687 - acc: 0.9333
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1683 - acc: 0.9330
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1664 - acc: 0.9336
2112/3015 [====================>.........] - ETA: 2s - loss: 0.1675 - acc: 0.9337
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1707 - acc: 0.9334
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1687 - acc: 0.9335
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1678 - acc: 0.9336
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1669 - acc: 0.9341
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1656 - acc: 0.9350
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1658 - acc: 0.9359
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1639 - acc: 0.9363
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1629 - acc: 0.9360
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1631 - acc: 0.9360
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1623 - acc: 0.9357
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1640 - acc: 0.9343
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1626 - acc: 0.9344
2944/3015 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9341
3008/3015 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9335
3015/3015 [==============================] - 9s 3ms/step - loss: 0.1650 - acc: 0.9337

Test accuracy: 90.39039039039038

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  163

choose_one :  170

F1score :  0.9047619047619048

AUC :  0.9694105764374865

Confusion Matrix
[[149  18]
 [ 14 152]]
True label 0
0.8922155688622755  
0.10778443113772455  
True label 1
0.08433734939759036  
0.9156626506024096  

Train_result {'loss': [0.16504856110774413], 'acc': [0.9336650082918739]}
Saved model to disk


11

Epoch 1/1

  64/3015 [..............................] - ETA: 9s - loss: 0.1256 - acc: 0.9531
 128/3015 [>.............................] - ETA: 8s - loss: 0.1164 - acc: 0.9688
 192/3015 [>.............................] - ETA: 8s - loss: 0.1671 - acc: 0.9479
 256/3015 [=>............................] - ETA: 7s - loss: 0.1653 - acc: 0.9453
 320/3015 [==>...........................] - ETA: 7s - loss: 0.1657 - acc: 0.9469
 384/3015 [==>...........................] - ETA: 7s - loss: 0.1621 - acc: 0.9453
 448/3015 [===>..........................] - ETA: 6s - loss: 0.1660 - acc: 0.9420
 512/3015 [====>.........................] - ETA: 6s - loss: 0.1646 - acc: 0.9395
 576/3015 [====>.........................] - ETA: 6s - loss: 0.1555 - acc: 0.9444
 640/3015 [=====>........................] - ETA: 6s - loss: 0.1537 - acc: 0.9437
 704/3015 [======>.......................] - ETA: 6s - loss: 0.1472 - acc: 0.9460
 768/3015 [======>.......................] - ETA: 5s - loss: 0.1452 - acc: 0.9453
 832/3015 [=======>......................] - ETA: 5s - loss: 0.1429 - acc: 0.9483
 896/3015 [=======>......................] - ETA: 5s - loss: 0.1459 - acc: 0.9475
 960/3015 [========>.....................] - ETA: 6s - loss: 0.1417 - acc: 0.9479
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1428 - acc: 0.9453
1088/3015 [=========>....................] - ETA: 5s - loss: 0.1408 - acc: 0.9458
1152/3015 [==========>...................] - ETA: 5s - loss: 0.1386 - acc: 0.9453
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1396 - acc: 0.9441
1280/3015 [===========>..................] - ETA: 5s - loss: 0.1417 - acc: 0.9445
1344/3015 [============>.................] - ETA: 5s - loss: 0.1539 - acc: 0.9382
1408/3015 [=============>................] - ETA: 5s - loss: 0.1483 - acc: 0.9403
1472/3015 [=============>................] - ETA: 4s - loss: 0.1516 - acc: 0.9389
1536/3015 [==============>...............] - ETA: 4s - loss: 0.1486 - acc: 0.9395
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1499 - acc: 0.9394
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1480 - acc: 0.9405
1728/3015 [================>.............] - ETA: 3s - loss: 0.1474 - acc: 0.9410
1792/3015 [================>.............] - ETA: 3s - loss: 0.1487 - acc: 0.9403
1856/3015 [=================>............] - ETA: 3s - loss: 0.1468 - acc: 0.9418
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1481 - acc: 0.9411
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1472 - acc: 0.9420
2048/3015 [===================>..........] - ETA: 2s - loss: 0.1490 - acc: 0.9414
2112/3015 [====================>.........] - ETA: 2s - loss: 0.1491 - acc: 0.9413
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1501 - acc: 0.9407
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1481 - acc: 0.9420
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1471 - acc: 0.9423
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1461 - acc: 0.9421
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1488 - acc: 0.9404
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1508 - acc: 0.9395
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1490 - acc: 0.9402
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1499 - acc: 0.9402
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1507 - acc: 0.9397
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1492 - acc: 0.9404
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1491 - acc: 0.9403
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1492 - acc: 0.9399
2944/3015 [============================>.] - ETA: 0s - loss: 0.1536 - acc: 0.9378
3008/3015 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9365
3015/3015 [==============================] - 9s 3ms/step - loss: 0.1549 - acc: 0.9367

Test accuracy: 89.7897897897898

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  157

choose_one :  176

F1score :  0.9005847953216374

AUC :  0.9675708823317222

Confusion Matrix
[[145  22]
 [ 12 154]]
True label 0
0.8682634730538922  
0.1317365269461078  
True label 1
0.07228915662650602  
0.927710843373494  

Train_result {'loss': [0.15489031642576553], 'acc': [0.9366500829187396]}
Saved model to disk


12

Epoch 1/1

  64/3015 [..............................] - ETA: 10s - loss: 0.0909 - acc: 0.9844
 128/3015 [>.............................] - ETA: 9s - loss: 0.1290 - acc: 0.9688 
 192/3015 [>.............................] - ETA: 9s - loss: 0.1489 - acc: 0.9531
 256/3015 [=>............................] - ETA: 10s - loss: 0.1602 - acc: 0.9453
 320/3015 [==>...........................] - ETA: 9s - loss: 0.1702 - acc: 0.9406 
 384/3015 [==>...........................] - ETA: 8s - loss: 0.1650 - acc: 0.9375
 448/3015 [===>..........................] - ETA: 8s - loss: 0.1602 - acc: 0.9397
 512/3015 [====>.........................] - ETA: 7s - loss: 0.1591 - acc: 0.9375
 576/3015 [====>.........................] - ETA: 7s - loss: 0.1529 - acc: 0.9392
 640/3015 [=====>........................] - ETA: 7s - loss: 0.1470 - acc: 0.9406
 704/3015 [======>.......................] - ETA: 6s - loss: 0.1447 - acc: 0.9418
 768/3015 [======>.......................] - ETA: 6s - loss: 0.1380 - acc: 0.9440
 832/3015 [=======>......................] - ETA: 6s - loss: 0.1384 - acc: 0.9423
 896/3015 [=======>......................] - ETA: 5s - loss: 0.1411 - acc: 0.9420
 960/3015 [========>.....................] - ETA: 5s - loss: 0.1430 - acc: 0.9406
1024/3015 [=========>....................] - ETA: 5s - loss: 0.1433 - acc: 0.9404
1088/3015 [=========>....................] - ETA: 5s - loss: 0.1517 - acc: 0.9366
1152/3015 [==========>...................] - ETA: 5s - loss: 0.1579 - acc: 0.9366
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1549 - acc: 0.9383
1280/3015 [===========>..................] - ETA: 5s - loss: 0.1515 - acc: 0.9398
1344/3015 [============>.................] - ETA: 5s - loss: 0.1511 - acc: 0.9382
1408/3015 [=============>................] - ETA: 5s - loss: 0.1508 - acc: 0.9389
1472/3015 [=============>................] - ETA: 5s - loss: 0.1486 - acc: 0.9395
1536/3015 [==============>...............] - ETA: 4s - loss: 0.1459 - acc: 0.9408
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1457 - acc: 0.9413
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1441 - acc: 0.9417
1728/3015 [================>.............] - ETA: 4s - loss: 0.1450 - acc: 0.9410
1792/3015 [================>.............] - ETA: 3s - loss: 0.1478 - acc: 0.9397
1856/3015 [=================>............] - ETA: 3s - loss: 0.1470 - acc: 0.9397
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1463 - acc: 0.9401
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1469 - acc: 0.9400
2048/3015 [===================>..........] - ETA: 2s - loss: 0.1506 - acc: 0.9395
2112/3015 [====================>.........] - ETA: 2s - loss: 0.1507 - acc: 0.9394
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1488 - acc: 0.9407
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1493 - acc: 0.9415
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1489 - acc: 0.9410
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1469 - acc: 0.9417
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1480 - acc: 0.9408
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1466 - acc: 0.9415
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1460 - acc: 0.9410
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1475 - acc: 0.9402
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1466 - acc: 0.9405
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1455 - acc: 0.9411
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1434 - acc: 0.9418
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1414 - acc: 0.9427
2944/3015 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9429
3008/3015 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9435
3015/3015 [==============================] - 10s 3ms/step - loss: 0.1405 - acc: 0.9436

Test accuracy: 89.4894894894895

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  174

choose_one :  159

F1score :  0.8923076923076924

AUC :  0.968364475867542

Confusion Matrix
[[153  14]
 [ 21 145]]
True label 0
0.9161676646706587  
0.08383233532934131  
True label 1
0.12650602409638553  
0.8734939759036144  

Train_result {'loss': [0.14052074191162045], 'acc': [0.9436152570480929]}
Saved model to disk


13

Epoch 1/1

  64/3015 [..............................] - ETA: 17s - loss: 0.0757 - acc: 0.9531
 128/3015 [>.............................] - ETA: 14s - loss: 0.1056 - acc: 0.9609
 192/3015 [>.............................] - ETA: 14s - loss: 0.1059 - acc: 0.9531
 256/3015 [=>............................] - ETA: 12s - loss: 0.1313 - acc: 0.9492
 320/3015 [==>...........................] - ETA: 11s - loss: 0.1471 - acc: 0.9406
 384/3015 [==>...........................] - ETA: 10s - loss: 0.1377 - acc: 0.9479
 448/3015 [===>..........................] - ETA: 10s - loss: 0.1378 - acc: 0.9487
 512/3015 [====>.........................] - ETA: 10s - loss: 0.1311 - acc: 0.9531
 576/3015 [====>.........................] - ETA: 9s - loss: 0.1430 - acc: 0.9462 
 640/3015 [=====>........................] - ETA: 8s - loss: 0.1462 - acc: 0.9469
 704/3015 [======>.......................] - ETA: 8s - loss: 0.1399 - acc: 0.9489
 768/3015 [======>.......................] - ETA: 7s - loss: 0.1357 - acc: 0.9505
 832/3015 [=======>......................] - ETA: 7s - loss: 0.1311 - acc: 0.9519
 896/3015 [=======>......................] - ETA: 7s - loss: 0.1313 - acc: 0.9509
 960/3015 [========>.....................] - ETA: 6s - loss: 0.1257 - acc: 0.9531
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1248 - acc: 0.9521
1088/3015 [=========>....................] - ETA: 6s - loss: 0.1243 - acc: 0.9513
1152/3015 [==========>...................] - ETA: 5s - loss: 0.1218 - acc: 0.9523
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1189 - acc: 0.9523
1280/3015 [===========>..................] - ETA: 5s - loss: 0.1200 - acc: 0.9531
1344/3015 [============>.................] - ETA: 5s - loss: 0.1256 - acc: 0.9494
1408/3015 [=============>................] - ETA: 5s - loss: 0.1251 - acc: 0.9482
1472/3015 [=============>................] - ETA: 5s - loss: 0.1249 - acc: 0.9477
1536/3015 [==============>...............] - ETA: 4s - loss: 0.1330 - acc: 0.9453
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1362 - acc: 0.9444
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1390 - acc: 0.9441
1728/3015 [================>.............] - ETA: 4s - loss: 0.1382 - acc: 0.9433
1792/3015 [================>.............] - ETA: 4s - loss: 0.1375 - acc: 0.9431
1856/3015 [=================>............] - ETA: 3s - loss: 0.1400 - acc: 0.9423
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1401 - acc: 0.9422
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1414 - acc: 0.9425
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1402 - acc: 0.9434
2112/3015 [====================>.........] - ETA: 2s - loss: 0.1404 - acc: 0.9422
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1407 - acc: 0.9416
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1394 - acc: 0.9429
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1410 - acc: 0.9423
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1409 - acc: 0.9434
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1408 - acc: 0.9428
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1408 - acc: 0.9427
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1398 - acc: 0.9434
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1386 - acc: 0.9440
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1379 - acc: 0.9442
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1372 - acc: 0.9444
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1377 - acc: 0.9442
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1367 - acc: 0.9444
2944/3015 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9443
3008/3015 [============================>.] - ETA: 0s - loss: 0.1349 - acc: 0.9448
3015/3015 [==============================] - 10s 3ms/step - loss: 0.1354 - acc: 0.9443

Test accuracy: 90.39039039039038

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  151

choose_one :  182

F1score :  0.9080459770114944

AUC :  0.968869489935791

Confusion Matrix
[[143  24]
 [  8 158]]
True label 0
0.8562874251497006  
0.1437125748502994  
True label 1
0.04819277108433735  
0.9518072289156626  

Train_result {'loss': [0.13544005712071067], 'acc': [0.9442786070047129]}
Saved model to disk


14

Epoch 1/1

  64/3015 [..............................] - ETA: 9s - loss: 0.0938 - acc: 0.9688
 128/3015 [>.............................] - ETA: 7s - loss: 0.1645 - acc: 0.9375
 192/3015 [>.............................] - ETA: 7s - loss: 0.1439 - acc: 0.9427
 256/3015 [=>............................] - ETA: 7s - loss: 0.1451 - acc: 0.9414
 320/3015 [==>...........................] - ETA: 7s - loss: 0.1343 - acc: 0.9437
 384/3015 [==>...........................] - ETA: 8s - loss: 0.1288 - acc: 0.9453
 448/3015 [===>..........................] - ETA: 9s - loss: 0.1225 - acc: 0.9509
 512/3015 [====>.........................] - ETA: 9s - loss: 0.1178 - acc: 0.9512
 576/3015 [====>.........................] - ETA: 8s - loss: 0.1115 - acc: 0.9531
 640/3015 [=====>........................] - ETA: 8s - loss: 0.1137 - acc: 0.9531
 704/3015 [======>.......................] - ETA: 8s - loss: 0.1117 - acc: 0.9531
 768/3015 [======>.......................] - ETA: 8s - loss: 0.1125 - acc: 0.9544
 832/3015 [=======>......................] - ETA: 7s - loss: 0.1133 - acc: 0.9555
 896/3015 [=======>......................] - ETA: 7s - loss: 0.1096 - acc: 0.9576
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1120 - acc: 0.9583
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1154 - acc: 0.9570
1088/3015 [=========>....................] - ETA: 6s - loss: 0.1143 - acc: 0.9550
1152/3015 [==========>...................] - ETA: 6s - loss: 0.1224 - acc: 0.9531
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1207 - acc: 0.9523
1280/3015 [===========>..................] - ETA: 5s - loss: 0.1199 - acc: 0.9531
1344/3015 [============>.................] - ETA: 5s - loss: 0.1239 - acc: 0.9516
1408/3015 [=============>................] - ETA: 4s - loss: 0.1213 - acc: 0.9517
1472/3015 [=============>................] - ETA: 4s - loss: 0.1226 - acc: 0.9518
1536/3015 [==============>...............] - ETA: 4s - loss: 0.1236 - acc: 0.9505
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1254 - acc: 0.9494
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1256 - acc: 0.9483
1728/3015 [================>.............] - ETA: 4s - loss: 0.1257 - acc: 0.9479
1792/3015 [================>.............] - ETA: 4s - loss: 0.1250 - acc: 0.9475
1856/3015 [=================>............] - ETA: 3s - loss: 0.1237 - acc: 0.9488
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1223 - acc: 0.9495
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1205 - acc: 0.9501
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1244 - acc: 0.9487
2112/3015 [====================>.........] - ETA: 2s - loss: 0.1268 - acc: 0.9484
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1276 - acc: 0.9485
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1289 - acc: 0.9478
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1281 - acc: 0.9484
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1291 - acc: 0.9476
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1305 - acc: 0.9474
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1302 - acc: 0.9479
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1324 - acc: 0.9465
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1325 - acc: 0.9466
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1326 - acc: 0.9464
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1314 - acc: 0.9473
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1308 - acc: 0.9482
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1302 - acc: 0.9479
2944/3015 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9480
3008/3015 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9471
3015/3015 [==============================] - 10s 3ms/step - loss: 0.1315 - acc: 0.9473

Test accuracy: 90.990990990991

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  171

choose_one :  162

F1score :  0.9085365853658537

AUC :  0.9708174013418945

Confusion Matrix
[[154  13]
 [ 17 149]]
True label 0
0.9221556886227545  
0.07784431137724551  
True label 1
0.10240963855421686  
0.8975903614457831  

Train_result {'loss': [0.13152906374996573], 'acc': [0.9472636815920398]}
Saved model to disk


15

Epoch 1/1

  64/3015 [..............................] - ETA: 9s - loss: 0.1360 - acc: 0.9219
 128/3015 [>.............................] - ETA: 8s - loss: 0.1240 - acc: 0.9453
 192/3015 [>.............................] - ETA: 7s - loss: 0.1184 - acc: 0.9531
 256/3015 [=>............................] - ETA: 7s - loss: 0.1128 - acc: 0.9531
 320/3015 [==>...........................] - ETA: 7s - loss: 0.1182 - acc: 0.9469
 384/3015 [==>...........................] - ETA: 6s - loss: 0.1088 - acc: 0.9531
 448/3015 [===>..........................] - ETA: 6s - loss: 0.0979 - acc: 0.9576
 512/3015 [====>.........................] - ETA: 6s - loss: 0.1110 - acc: 0.9551
 576/3015 [====>.........................] - ETA: 6s - loss: 0.1288 - acc: 0.9514
 640/3015 [=====>........................] - ETA: 5s - loss: 0.1275 - acc: 0.9531
 704/3015 [======>.......................] - ETA: 5s - loss: 0.1270 - acc: 0.9503
 768/3015 [======>.......................] - ETA: 5s - loss: 0.1273 - acc: 0.9518
 832/3015 [=======>......................] - ETA: 6s - loss: 0.1259 - acc: 0.9519
 896/3015 [=======>......................] - ETA: 6s - loss: 0.1312 - acc: 0.9498
 960/3015 [========>.....................] - ETA: 6s - loss: 0.1386 - acc: 0.9469
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1353 - acc: 0.9482
1088/3015 [=========>....................] - ETA: 5s - loss: 0.1314 - acc: 0.9494
1152/3015 [==========>...................] - ETA: 5s - loss: 0.1355 - acc: 0.9462
1216/3015 [===========>..................] - ETA: 5s - loss: 0.1329 - acc: 0.9482
1280/3015 [===========>..................] - ETA: 5s - loss: 0.1305 - acc: 0.9492
1344/3015 [============>.................] - ETA: 5s - loss: 0.1301 - acc: 0.9501
1408/3015 [=============>................] - ETA: 5s - loss: 0.1283 - acc: 0.9503
1472/3015 [=============>................] - ETA: 4s - loss: 0.1256 - acc: 0.9511
1536/3015 [==============>...............] - ETA: 4s - loss: 0.1262 - acc: 0.9492
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1246 - acc: 0.9500
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1227 - acc: 0.9507
1728/3015 [================>.............] - ETA: 3s - loss: 0.1191 - acc: 0.9525
1792/3015 [================>.............] - ETA: 3s - loss: 0.1172 - acc: 0.9531
1856/3015 [=================>............] - ETA: 3s - loss: 0.1157 - acc: 0.9542
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1164 - acc: 0.9531
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1203 - acc: 0.9516
2048/3015 [===================>..........] - ETA: 2s - loss: 0.1194 - acc: 0.9521
2112/3015 [====================>.........] - ETA: 2s - loss: 0.1212 - acc: 0.9512
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1208 - acc: 0.9508
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1239 - acc: 0.9509
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1220 - acc: 0.9523
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1237 - acc: 0.9514
2432/3015 [=======================>......] - ETA: 1s - loss: 0.1273 - acc: 0.9502
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1265 - acc: 0.9507
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1281 - acc: 0.9504
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1289 - acc: 0.9501
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1273 - acc: 0.9509
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1271 - acc: 0.9509
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1253 - acc: 0.9517
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1258 - acc: 0.9514
2944/3015 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9514
3008/3015 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9521
3015/3015 [==============================] - 9s 3ms/step - loss: 0.1239 - acc: 0.9522

Test accuracy: 91.8918918918919

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  168

choose_one :  165

F1score :  0.918429003021148

AUC :  0.9685448380347739

Confusion Matrix
[[154  13]
 [ 14 152]]
True label 0
0.9221556886227545  
0.07784431137724551  
True label 1
0.08433734939759036  
0.9156626506024096  

Train_result {'loss': [0.12394531298139956], 'acc': [0.9522388059701492]}
Saved model to disk


[[87.08708708708708, 1], [89.7897897897898, 2], [88.28828828828829, 3], [90.69069069069069, 4], [90.69069069069069, 5], [90.69069069069069, 6], [90.39039039039038, 7], [88.28828828828829, 8], [90.69069069069069, 9], [90.39039039039038, 10], [89.7897897897898, 11], [89.4894894894895, 12], [90.39039039039038, 13], [90.990990990991, 14], [91.8918918918919, 15]]
max accuracy :  [91.8918918918919, 15]
