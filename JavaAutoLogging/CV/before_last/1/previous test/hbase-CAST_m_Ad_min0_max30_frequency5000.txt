Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
/home/2014313303/taeha/JavaAutoLogging/model.py:53: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor("ou...)`
  model = Model(input=[input1, input2], output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-08 04:03:52.039639: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-08 04:03:52.047505: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100085000 Hz
2019-09-08 04:03:52.050087: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0xd312a90 executing computations on platform Host. Devices:
2019-09-08 04:03:52.050127: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Standard data
zero :  39451
one :  9019

First data
zero :  39451
one :  9019

Second data
zero :  39451
one :  9019

hbase-AST
After set document size of train data, the number of zero and one label data :  27718 2356
After set document size of test data, the number of zero and one label data :  3087 253

Sentence length Average : 9

Under 10 : 21693
Over 10, Under 30 : 11721
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

After balance out data.
hbase-AST

Sentence length Average : 11

Under 10 : 2794
Over 10, Under 30 : 2426
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

hbase-depth_num
After set document size of train data, the number of zero and one label data :  27718 2356
After set document size of test data, the number of zero and one label data :  3087 253
After balance out data.
hbase-depth_num

Sentence length Average : 11

Under 10 : 2794
Over 10, Under 30 : 2426
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

Count model parameter.
Get a short summary of each layer dimensions and parameters.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 30, 200)      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 30, 200)      0                                            
__________________________________________________________________________________________________
masking_1 (Masking)             (None, 30, 200)      0           input_1[0][0]                    
__________________________________________________________________________________________________
masking_2 (Masking)             (None, 30, 200)      0           input_2[0][0]                    
__________________________________________________________________________________________________
forwards_1 (LSTM)               (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
backwords_1 (LSTM)              (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
forwards_2 (LSTM)               (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
backwards_2 (LSTM)              (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
after_dp_forward_1 (Dropout)    (None, 64)           0           forwards_1[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_1 (Dropout)   (None, 64)           0           backwords_1[0][0]                
__________________________________________________________________________________________________
after_dp_forward_2 (Dropout)    (None, 64)           0           forwards_2[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_2 (Dropout)   (None, 64)           0           backwards_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128)          0           after_dp_forward_1[0][0]         
                                                                 after_dp_backward_1[0][0]        
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 128)          0           after_dp_forward_2[0][0]         
                                                                 after_dp_backward_2[0][0]        
__________________________________________________________________________________________________
after_dp_1 (Dropout)            (None, 128)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
after_dp_2 (Dropout)            (None, 128)          0           concatenate_2[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 256)          0           after_dp_1[0][0]                 
                                                                 after_dp_2[0][0]                 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 256)          65792       concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 128)          32896       dense_1[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 64)           8256        dense_2[0][0]                    
__________________________________________________________________________________________________
output (Dense)                  (None, 2)            130         dense_3[0][0]                    
==================================================================================================
Total params: 378,434
Trainable params: 378,434
Non-trainable params: 0
__________________________________________________________________________________________________
1

Epoch 1/1

  64/4713 [..............................] - ETA: 3:55 - loss: 0.6982 - acc: 0.5312
 128/4713 [..............................] - ETA: 1:58 - loss: 0.6834 - acc: 0.5391
 192/4713 [>.............................] - ETA: 1:18 - loss: 0.6926 - acc: 0.5260
 320/4713 [=>............................] - ETA: 47s - loss: 0.6800 - acc: 0.5531 
 448/4713 [=>............................] - ETA: 33s - loss: 0.6874 - acc: 0.5446
 576/4713 [==>...........................] - ETA: 26s - loss: 0.6734 - acc: 0.5833
 704/4713 [===>..........................] - ETA: 21s - loss: 0.6627 - acc: 0.6136
 832/4713 [====>.........................] - ETA: 17s - loss: 0.6512 - acc: 0.6334
 960/4713 [=====>........................] - ETA: 15s - loss: 0.6397 - acc: 0.6479
1088/4713 [=====>........................] - ETA: 13s - loss: 0.6247 - acc: 0.6618
1216/4713 [======>.......................] - ETA: 11s - loss: 0.6198 - acc: 0.6653
1344/4713 [=======>......................] - ETA: 10s - loss: 0.6065 - acc: 0.6786
1472/4713 [========>.....................] - ETA: 9s - loss: 0.6001 - acc: 0.6861 
1600/4713 [=========>....................] - ETA: 8s - loss: 0.5901 - acc: 0.6931
1728/4713 [=========>....................] - ETA: 7s - loss: 0.5802 - acc: 0.7002
1792/4713 [==========>...................] - ETA: 7s - loss: 0.5806 - acc: 0.6998
1920/4713 [===========>..................] - ETA: 6s - loss: 0.5656 - acc: 0.7099
2048/4713 [============>.................] - ETA: 6s - loss: 0.5588 - acc: 0.7139
2176/4713 [============>.................] - ETA: 5s - loss: 0.5471 - acc: 0.7215
2304/4713 [=============>................] - ETA: 5s - loss: 0.5395 - acc: 0.7266
2432/4713 [==============>...............] - ETA: 4s - loss: 0.5341 - acc: 0.7311
2560/4713 [===============>..............] - ETA: 4s - loss: 0.5274 - acc: 0.7359
2688/4713 [================>.............] - ETA: 3s - loss: 0.5215 - acc: 0.7388
2816/4713 [================>.............] - ETA: 3s - loss: 0.5193 - acc: 0.7411
2944/4713 [=================>............] - ETA: 3s - loss: 0.5118 - acc: 0.7456
3072/4713 [==================>...........] - ETA: 2s - loss: 0.5100 - acc: 0.7474
3200/4713 [===================>..........] - ETA: 2s - loss: 0.5140 - acc: 0.7475
3328/4713 [====================>.........] - ETA: 2s - loss: 0.5162 - acc: 0.7464
3456/4713 [====================>.........] - ETA: 2s - loss: 0.5143 - acc: 0.7480
3584/4713 [=====================>........] - ETA: 1s - loss: 0.5105 - acc: 0.7520
3712/4713 [======================>.......] - ETA: 1s - loss: 0.5082 - acc: 0.7538
3840/4713 [=======================>......] - ETA: 1s - loss: 0.5027 - acc: 0.7576
3968/4713 [========================>.....] - ETA: 1s - loss: 0.5015 - acc: 0.7583
4096/4713 [=========================>....] - ETA: 0s - loss: 0.4967 - acc: 0.7612
4224/4713 [=========================>....] - ETA: 0s - loss: 0.4922 - acc: 0.7642
4352/4713 [==========================>...] - ETA: 0s - loss: 0.4876 - acc: 0.7668
4480/4713 [===========================>..] - ETA: 0s - loss: 0.4843 - acc: 0.7692
4608/4713 [============================>.] - ETA: 0s - loss: 0.4817 - acc: 0.7715
4713/4713 [==============================] - 6s 1ms/step - loss: 0.4778 - acc: 0.7740

Test accuracy: 83.82642998027613

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  232

choose_one :  275

F1score :  0.8446969696969698

AUC :  0.9235706949674769

Confusion Matrix
[[202  52]
 [ 30 223]]
True label 0
0.7952755905511811  
0.2047244094488189  
True label 1
0.11857707509881422  
0.8814229249011858  

Train_result {'acc': [0.7740292808899777], 'loss': [0.47777167149797106]}
Saved model to disk


2

Epoch 1/1

  64/4713 [..............................] - ETA: 5s - loss: 0.3168 - acc: 0.8594
 192/4713 [>.............................] - ETA: 4s - loss: 0.4053 - acc: 0.8125
 320/4713 [=>............................] - ETA: 3s - loss: 0.3812 - acc: 0.8219
 448/4713 [=>............................] - ETA: 3s - loss: 0.3771 - acc: 0.8214
 576/4713 [==>...........................] - ETA: 3s - loss: 0.3671 - acc: 0.8229
 704/4713 [===>..........................] - ETA: 3s - loss: 0.3841 - acc: 0.8139
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3690 - acc: 0.8281
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3739 - acc: 0.8250
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3748 - acc: 0.8263
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3754 - acc: 0.8257
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3755 - acc: 0.8266
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3774 - acc: 0.8274
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3785 - acc: 0.8300
1728/4713 [=========>....................] - ETA: 2s - loss: 0.3762 - acc: 0.8322
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3806 - acc: 0.8303
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3795 - acc: 0.8322
2112/4713 [============>.................] - ETA: 1s - loss: 0.3800 - acc: 0.8314
2240/4713 [=============>................] - ETA: 1s - loss: 0.3838 - acc: 0.8295
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3799 - acc: 0.8311
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3844 - acc: 0.8265
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3840 - acc: 0.8274
2752/4713 [================>.............] - ETA: 1s - loss: 0.3837 - acc: 0.8281
2880/4713 [=================>............] - ETA: 1s - loss: 0.3830 - acc: 0.8281
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3823 - acc: 0.8285
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3793 - acc: 0.8297
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3784 - acc: 0.8297
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3776 - acc: 0.8296
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3804 - acc: 0.8284
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3789 - acc: 0.8300
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3772 - acc: 0.8318
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3726 - acc: 0.8345
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3734 - acc: 0.8338
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3729 - acc: 0.8341
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3739 - acc: 0.8333
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3745 - acc: 0.8320
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3750 - acc: 0.8325
4672/4713 [============================>.] - ETA: 0s - loss: 0.3738 - acc: 0.8343
4713/4713 [==============================] - 3s 658us/step - loss: 0.3735 - acc: 0.8341

Test accuracy: 86.19329388560158

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  252

choose_one :  255

F1score :  0.8622047244094487

AUC :  0.930643303974355

Confusion Matrix
[[218  36]
 [ 34 219]]
True label 0
0.8582677165354331  
0.14173228346456693  
True label 1
0.13438735177865613  
0.8656126482213439  

Train_result {'acc': [0.8340759601735674], 'loss': [0.3734612167197733]}
Saved model to disk


3

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.3222 - acc: 0.7812
 192/4713 [>.............................] - ETA: 3s - loss: 0.3033 - acc: 0.8490
 320/4713 [=>............................] - ETA: 3s - loss: 0.3824 - acc: 0.8250
 448/4713 [=>............................] - ETA: 3s - loss: 0.3644 - acc: 0.8371
 576/4713 [==>...........................] - ETA: 3s - loss: 0.3697 - acc: 0.8333
 704/4713 [===>..........................] - ETA: 2s - loss: 0.3596 - acc: 0.8423
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3619 - acc: 0.8365
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3649 - acc: 0.8406
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3546 - acc: 0.8465
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3480 - acc: 0.8495
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3416 - acc: 0.8549
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3536 - acc: 0.8478
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3509 - acc: 0.8481
1728/4713 [=========>....................] - ETA: 2s - loss: 0.3465 - acc: 0.8530
1856/4713 [==========>...................] - ETA: 2s - loss: 0.3523 - acc: 0.8502
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3559 - acc: 0.8483
2112/4713 [============>.................] - ETA: 1s - loss: 0.3535 - acc: 0.8494
2240/4713 [=============>................] - ETA: 1s - loss: 0.3526 - acc: 0.8504
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3563 - acc: 0.8492
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3556 - acc: 0.8494
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3544 - acc: 0.8498
2752/4713 [================>.............] - ETA: 1s - loss: 0.3529 - acc: 0.8507
2880/4713 [=================>............] - ETA: 1s - loss: 0.3519 - acc: 0.8514
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3521 - acc: 0.8511
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3511 - acc: 0.8530
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3520 - acc: 0.8514
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3526 - acc: 0.8505
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3531 - acc: 0.8511
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3553 - acc: 0.8501
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3542 - acc: 0.8498
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3540 - acc: 0.8496
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3555 - acc: 0.8475
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3556 - acc: 0.8478
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3564 - acc: 0.8477
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3569 - acc: 0.8471
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3563 - acc: 0.8468
4672/4713 [============================>.] - ETA: 0s - loss: 0.3535 - acc: 0.8482
4713/4713 [==============================] - 3s 670us/step - loss: 0.3524 - acc: 0.8489

Test accuracy: 84.81262327416174

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  259

choose_one :  248

F1score :  0.8463073852295409

AUC :  0.9353894992374965

Confusion Matrix
[[218  36]
 [ 41 212]]
True label 0
0.8582677165354331  
0.14173228346456693  
True label 1
0.16205533596837945  
0.8379446640316206  

Train_result {'acc': [0.8489284957388569], 'loss': [0.3524128182625381]}
Saved model to disk


4

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2760 - acc: 0.8906
 128/4713 [..............................] - ETA: 4s - loss: 0.2986 - acc: 0.8828
 256/4713 [>.............................] - ETA: 3s - loss: 0.3299 - acc: 0.8555
 384/4713 [=>............................] - ETA: 3s - loss: 0.3346 - acc: 0.8490
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3241 - acc: 0.8613
 640/4713 [===>..........................] - ETA: 3s - loss: 0.3278 - acc: 0.8609
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3402 - acc: 0.8529
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3398 - acc: 0.8504
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3325 - acc: 0.8555
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3375 - acc: 0.8516
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3456 - acc: 0.8484
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3491 - acc: 0.8473
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3503 - acc: 0.8457
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3458 - acc: 0.8492
1792/4713 [==========>...................] - ETA: 1s - loss: 0.3414 - acc: 0.8532
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3434 - acc: 0.8521
2048/4713 [============>.................] - ETA: 1s - loss: 0.3407 - acc: 0.8530
2176/4713 [============>.................] - ETA: 1s - loss: 0.3375 - acc: 0.8543
2304/4713 [=============>................] - ETA: 1s - loss: 0.3503 - acc: 0.8503
2432/4713 [==============>...............] - ETA: 1s - loss: 0.3505 - acc: 0.8491
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3475 - acc: 0.8504
2688/4713 [================>.............] - ETA: 1s - loss: 0.3493 - acc: 0.8486
2816/4713 [================>.............] - ETA: 1s - loss: 0.3494 - acc: 0.8498
2944/4713 [=================>............] - ETA: 1s - loss: 0.3503 - acc: 0.8485
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3511 - acc: 0.8490
3200/4713 [===================>..........] - ETA: 0s - loss: 0.3505 - acc: 0.8484
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3502 - acc: 0.8483
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3490 - acc: 0.8481
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3461 - acc: 0.8513
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3463 - acc: 0.8518
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3469 - acc: 0.8508
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3497 - acc: 0.8493
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3486 - acc: 0.8496
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3470 - acc: 0.8506
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3468 - acc: 0.8505
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3486 - acc: 0.8496
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3467 - acc: 0.8504
4672/4713 [============================>.] - ETA: 0s - loss: 0.3452 - acc: 0.8504
4713/4713 [==============================] - 3s 655us/step - loss: 0.3448 - acc: 0.8502

Test accuracy: 86.3905325443787

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  249

choose_one :  258

F1score :  0.8649706457925636

AUC :  0.9328607886464785

Confusion Matrix
[[217  37]
 [ 32 221]]
True label 0
0.8543307086614174  
0.14566929133858267  
True label 1
0.12648221343873517  
0.8735177865612648  

Train_result {'acc': [0.8502015699860702], 'loss': [0.34475565602919517]}
Saved model to disk


5

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.3956 - acc: 0.7969
 128/4713 [..............................] - ETA: 3s - loss: 0.2833 - acc: 0.8594
 256/4713 [>.............................] - ETA: 3s - loss: 0.2894 - acc: 0.8672
 384/4713 [=>............................] - ETA: 3s - loss: 0.3380 - acc: 0.8464
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3293 - acc: 0.8535
 640/4713 [===>..........................] - ETA: 2s - loss: 0.3702 - acc: 0.8406
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3749 - acc: 0.8385
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3699 - acc: 0.8393
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3501 - acc: 0.8516
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3498 - acc: 0.8490
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3456 - acc: 0.8523
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3381 - acc: 0.8565
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3416 - acc: 0.8561
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3453 - acc: 0.8522
1792/4713 [==========>...................] - ETA: 1s - loss: 0.3443 - acc: 0.8516
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3432 - acc: 0.8536
2048/4713 [============>.................] - ETA: 1s - loss: 0.3417 - acc: 0.8540
2176/4713 [============>.................] - ETA: 1s - loss: 0.3367 - acc: 0.8557
2304/4713 [=============>................] - ETA: 1s - loss: 0.3379 - acc: 0.8537
2432/4713 [==============>...............] - ETA: 1s - loss: 0.3387 - acc: 0.8528
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3355 - acc: 0.8535
2688/4713 [================>.............] - ETA: 1s - loss: 0.3367 - acc: 0.8519
2816/4713 [================>.............] - ETA: 1s - loss: 0.3397 - acc: 0.8509
2944/4713 [=================>............] - ETA: 1s - loss: 0.3389 - acc: 0.8522
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3386 - acc: 0.8506
3200/4713 [===================>..........] - ETA: 1s - loss: 0.3357 - acc: 0.8519
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3318 - acc: 0.8528
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3308 - acc: 0.8533
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3275 - acc: 0.8557
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3276 - acc: 0.8559
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3312 - acc: 0.8547
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3308 - acc: 0.8551
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3298 - acc: 0.8555
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3342 - acc: 0.8544
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3363 - acc: 0.8536
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3352 - acc: 0.8540
4608/4713 [============================>.] - ETA: 0s - loss: 0.3363 - acc: 0.8531
4713/4713 [==============================] - 3s 655us/step - loss: 0.3375 - acc: 0.8519

Test accuracy: 86.58777120315581

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  216

choose_one :  291

F1score :  0.8749999999999999

AUC :  0.9366810868009088

Confusion Matrix
[[201  53]
 [ 15 238]]
True label 0
0.7913385826771654  
0.20866141732283464  
True label 1
0.05928853754940711  
0.9407114624505929  

Train_result {'acc': [0.8518990029100904], 'loss': [0.33751763452422257]}
Saved model to disk


6

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2123 - acc: 0.9375
 192/4713 [>.............................] - ETA: 3s - loss: 0.2649 - acc: 0.9062
 320/4713 [=>............................] - ETA: 3s - loss: 0.3027 - acc: 0.8719
 448/4713 [=>............................] - ETA: 3s - loss: 0.3149 - acc: 0.8728
 576/4713 [==>...........................] - ETA: 3s - loss: 0.3081 - acc: 0.8767
 704/4713 [===>..........................] - ETA: 2s - loss: 0.3196 - acc: 0.8679
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3148 - acc: 0.8678
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3268 - acc: 0.8635
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3439 - acc: 0.8548
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3308 - acc: 0.8610
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3230 - acc: 0.8646
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3246 - acc: 0.8614
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3209 - acc: 0.8656
1728/4713 [=========>....................] - ETA: 2s - loss: 0.3178 - acc: 0.8663
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3200 - acc: 0.8648
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3171 - acc: 0.8644
2112/4713 [============>.................] - ETA: 1s - loss: 0.3200 - acc: 0.8641
2240/4713 [=============>................] - ETA: 1s - loss: 0.3210 - acc: 0.8634
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3168 - acc: 0.8649
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3171 - acc: 0.8642
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3165 - acc: 0.8628
2752/4713 [================>.............] - ETA: 1s - loss: 0.3172 - acc: 0.8634
2880/4713 [=================>............] - ETA: 1s - loss: 0.3192 - acc: 0.8642
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3182 - acc: 0.8644
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3192 - acc: 0.8648
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3191 - acc: 0.8643
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3189 - acc: 0.8638
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3177 - acc: 0.8642
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3165 - acc: 0.8651
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3186 - acc: 0.8652
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3165 - acc: 0.8663
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3175 - acc: 0.8661
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3190 - acc: 0.8651
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3188 - acc: 0.8654
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3198 - acc: 0.8648
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3188 - acc: 0.8651
4672/4713 [============================>.] - ETA: 0s - loss: 0.3180 - acc: 0.8658
4713/4713 [==============================] - 3s 637us/step - loss: 0.3202 - acc: 0.8648

Test accuracy: 86.78500986193293

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  225

choose_one :  282

F1score :  0.8747663551401869

AUC :  0.9355606734928885

Confusion Matrix
[[206  48]
 [ 19 234]]
True label 0
0.8110236220472441  
0.1889763779527559  
True label 1
0.07509881422924901  
0.924901185770751  

Train_result {'acc': [0.8648419265354512], 'loss': [0.3202085702656536]}
Saved model to disk


7

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2027 - acc: 0.9062
 128/4713 [..............................] - ETA: 3s - loss: 0.2472 - acc: 0.8906
 256/4713 [>.............................] - ETA: 3s - loss: 0.2889 - acc: 0.8672
 384/4713 [=>............................] - ETA: 3s - loss: 0.3181 - acc: 0.8594
 448/4713 [=>............................] - ETA: 3s - loss: 0.3132 - acc: 0.8638
 576/4713 [==>...........................] - ETA: 3s - loss: 0.3014 - acc: 0.8733
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2968 - acc: 0.8736
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3005 - acc: 0.8738
 960/4713 [=====>........................] - ETA: 2s - loss: 0.2908 - acc: 0.8781
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2862 - acc: 0.8796
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2846 - acc: 0.8799
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2809 - acc: 0.8795
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2861 - acc: 0.8777
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2871 - acc: 0.8769
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2963 - acc: 0.8750
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3027 - acc: 0.8723
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3032 - acc: 0.8715
2112/4713 [============>.................] - ETA: 1s - loss: 0.3020 - acc: 0.8703
2240/4713 [=============>................] - ETA: 1s - loss: 0.3011 - acc: 0.8692
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3016 - acc: 0.8678
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3077 - acc: 0.8638
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3108 - acc: 0.8624
2752/4713 [================>.............] - ETA: 1s - loss: 0.3090 - acc: 0.8645
2880/4713 [=================>............] - ETA: 1s - loss: 0.3116 - acc: 0.8646
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3130 - acc: 0.8644
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3135 - acc: 0.8642
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3147 - acc: 0.8631
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3162 - acc: 0.8632
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3166 - acc: 0.8636
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3164 - acc: 0.8629
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3151 - acc: 0.8639
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3146 - acc: 0.8645
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3156 - acc: 0.8638
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3166 - acc: 0.8632
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3145 - acc: 0.8647
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3140 - acc: 0.8650
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3148 - acc: 0.8651
4672/4713 [============================>.] - ETA: 0s - loss: 0.3154 - acc: 0.8647
4713/4713 [==============================] - 3s 648us/step - loss: 0.3165 - acc: 0.8642

Test accuracy: 86.78500986193293

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  215

choose_one :  292

F1score :  0.8770642201834863

AUC :  0.9387663004575021

Confusion Matrix
[[201  53]
 [ 14 239]]
True label 0
0.7913385826771654  
0.20866141732283464  
True label 1
0.05533596837944664  
0.9446640316205533  

Train_result {'acc': [0.8642053894118445], 'loss': [0.31646186290413564]}
Saved model to disk


8

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2207 - acc: 0.8906
 128/4713 [..............................] - ETA: 4s - loss: 0.2582 - acc: 0.8750
 256/4713 [>.............................] - ETA: 3s - loss: 0.2774 - acc: 0.8711
 384/4713 [=>............................] - ETA: 3s - loss: 0.2613 - acc: 0.8828
 512/4713 [==>...........................] - ETA: 3s - loss: 0.2902 - acc: 0.8789
 576/4713 [==>...........................] - ETA: 3s - loss: 0.2821 - acc: 0.8802
 704/4713 [===>..........................] - ETA: 2s - loss: 0.3064 - acc: 0.8651
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3276 - acc: 0.8582
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3236 - acc: 0.8615
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3238 - acc: 0.8612
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3270 - acc: 0.8594
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3205 - acc: 0.8586
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3217 - acc: 0.8587
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3137 - acc: 0.8619
1728/4713 [=========>....................] - ETA: 1s - loss: 0.3184 - acc: 0.8605
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3151 - acc: 0.8626
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3119 - acc: 0.8629
2112/4713 [============>.................] - ETA: 1s - loss: 0.3129 - acc: 0.8632
2240/4713 [=============>................] - ETA: 1s - loss: 0.3120 - acc: 0.8652
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3110 - acc: 0.8670
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3110 - acc: 0.8666
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3096 - acc: 0.8670
2752/4713 [================>.............] - ETA: 1s - loss: 0.3097 - acc: 0.8656
2880/4713 [=================>............] - ETA: 1s - loss: 0.3078 - acc: 0.8670
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3098 - acc: 0.8664
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3144 - acc: 0.8651
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3154 - acc: 0.8652
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3134 - acc: 0.8667
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3148 - acc: 0.8668
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3158 - acc: 0.8651
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3136 - acc: 0.8652
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3135 - acc: 0.8655
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3132 - acc: 0.8656
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3127 - acc: 0.8661
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3130 - acc: 0.8647
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3138 - acc: 0.8644
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3132 - acc: 0.8640
4672/4713 [============================>.] - ETA: 0s - loss: 0.3123 - acc: 0.8643
4713/4713 [==============================] - 3s 632us/step - loss: 0.3140 - acc: 0.8640

Test accuracy: 87.17948717948718

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  235

choose_one :  272

F1score :  0.8761904761904762

AUC :  0.9363620802340419

Confusion Matrix
[[212  42]
 [ 23 230]]
True label 0
0.8346456692913385  
0.16535433070866143  
True label 1
0.09090909090909091  
0.9090909090909091  

Train_result {'acc': [0.863993210130352], 'loss': [0.3140074816348066]}
Saved model to disk


9

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.3187 - acc: 0.8281
 192/4713 [>.............................] - ETA: 3s - loss: 0.2895 - acc: 0.8750
 320/4713 [=>............................] - ETA: 3s - loss: 0.2840 - acc: 0.8750
 448/4713 [=>............................] - ETA: 3s - loss: 0.2974 - acc: 0.8705
 576/4713 [==>...........................] - ETA: 3s - loss: 0.2798 - acc: 0.8802
 704/4713 [===>..........................] - ETA: 2s - loss: 0.3003 - acc: 0.8679
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2985 - acc: 0.8714
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3034 - acc: 0.8719
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3063 - acc: 0.8713
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3123 - acc: 0.8668
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3132 - acc: 0.8638
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3100 - acc: 0.8648
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3058 - acc: 0.8681
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2993 - acc: 0.8727
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2981 - acc: 0.8728
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3081 - acc: 0.8705
2112/4713 [============>.................] - ETA: 1s - loss: 0.3080 - acc: 0.8688
2240/4713 [=============>................] - ETA: 1s - loss: 0.3042 - acc: 0.8705
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3056 - acc: 0.8712
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3042 - acc: 0.8718
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3077 - acc: 0.8708
2752/4713 [================>.............] - ETA: 1s - loss: 0.3052 - acc: 0.8717
2880/4713 [=================>............] - ETA: 1s - loss: 0.3077 - acc: 0.8712
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3088 - acc: 0.8720
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3105 - acc: 0.8709
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3088 - acc: 0.8710
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3100 - acc: 0.8709
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3114 - acc: 0.8699
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3085 - acc: 0.8712
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3089 - acc: 0.8713
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3071 - acc: 0.8722
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3078 - acc: 0.8720
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3080 - acc: 0.8726
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3085 - acc: 0.8727
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3064 - acc: 0.8736
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3056 - acc: 0.8739
4672/4713 [============================>.] - ETA: 0s - loss: 0.3054 - acc: 0.8737
4713/4713 [==============================] - 3s 652us/step - loss: 0.3054 - acc: 0.8735

Test accuracy: 87.57396449704143

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  237

choose_one :  270

F1score :  0.8795411089866157

AUC :  0.9395910491425725

Confusion Matrix
[[214  40]
 [ 23 230]]
True label 0
0.84251968503937  
0.15748031496062992  
True label 1
0.09090909090909091  
0.9090909090909091  

Train_result {'acc': [0.8735412690079493], 'loss': [0.30537525530759885]}
Saved model to disk


10

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.3166 - acc: 0.8906
 192/4713 [>.............................] - ETA: 3s - loss: 0.2717 - acc: 0.8750
 320/4713 [=>............................] - ETA: 3s - loss: 0.2974 - acc: 0.8562
 448/4713 [=>............................] - ETA: 3s - loss: 0.2861 - acc: 0.8616
 576/4713 [==>...........................] - ETA: 2s - loss: 0.3158 - acc: 0.8524
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2920 - acc: 0.8665
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2938 - acc: 0.8666
 960/4713 [=====>........................] - ETA: 2s - loss: 0.2990 - acc: 0.8604
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2993 - acc: 0.8612
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3061 - acc: 0.8602
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3008 - acc: 0.8646
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2977 - acc: 0.8668
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2983 - acc: 0.8675
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2946 - acc: 0.8686
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2942 - acc: 0.8675
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2984 - acc: 0.8664
2112/4713 [============>.................] - ETA: 1s - loss: 0.2980 - acc: 0.8651
2240/4713 [=============>................] - ETA: 1s - loss: 0.2951 - acc: 0.8679
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2953 - acc: 0.8678
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2942 - acc: 0.8694
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2916 - acc: 0.8697
2752/4713 [================>.............] - ETA: 1s - loss: 0.2918 - acc: 0.8681
2880/4713 [=================>............] - ETA: 1s - loss: 0.2941 - acc: 0.8656
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3003 - acc: 0.8644
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2975 - acc: 0.8645
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3002 - acc: 0.8646
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3015 - acc: 0.8644
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3017 - acc: 0.8648
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3022 - acc: 0.8651
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3039 - acc: 0.8647
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3044 - acc: 0.8655
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3065 - acc: 0.8646
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3054 - acc: 0.8654
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3044 - acc: 0.8652
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3015 - acc: 0.8668
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3025 - acc: 0.8664
4672/4713 [============================>.] - ETA: 0s - loss: 0.3020 - acc: 0.8669
4713/4713 [==============================] - 3s 636us/step - loss: 0.3011 - acc: 0.8670

Test accuracy: 86.78500986193293

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  233

choose_one :  274

F1score :  0.8728652751423149

AUC :  0.9360586349631197

Confusion Matrix
[[210  44]
 [ 23 230]]
True label 0
0.8267716535433071  
0.1732283464566929  
True label 1
0.09090909090909091  
0.9090909090909091  

Train_result {'acc': [0.8669637173521728], 'loss': [0.3011251089901978]}
Saved model to disk


11

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2839 - acc: 0.9375
 192/4713 [>.............................] - ETA: 3s - loss: 0.2646 - acc: 0.9219
 320/4713 [=>............................] - ETA: 3s - loss: 0.2598 - acc: 0.9125
 448/4713 [=>............................] - ETA: 3s - loss: 0.2789 - acc: 0.8973
 576/4713 [==>...........................] - ETA: 3s - loss: 0.2893 - acc: 0.8958
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2848 - acc: 0.8920
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2921 - acc: 0.8858
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3022 - acc: 0.8812
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2949 - acc: 0.8814
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2986 - acc: 0.8791
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2946 - acc: 0.8802
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2924 - acc: 0.8804
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2933 - acc: 0.8800
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2900 - acc: 0.8785
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2915 - acc: 0.8798
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2861 - acc: 0.8816
2112/4713 [============>.................] - ETA: 1s - loss: 0.2891 - acc: 0.8797
2240/4713 [=============>................] - ETA: 1s - loss: 0.2900 - acc: 0.8772
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2896 - acc: 0.8767
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2875 - acc: 0.8770
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2893 - acc: 0.8777
2752/4713 [================>.............] - ETA: 1s - loss: 0.2895 - acc: 0.8768
2880/4713 [=================>............] - ETA: 1s - loss: 0.2926 - acc: 0.8757
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2947 - acc: 0.8757
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2941 - acc: 0.8769
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2943 - acc: 0.8762
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2960 - acc: 0.8744
3520/4713 [=====================>........] - ETA: 0s - loss: 0.2947 - acc: 0.8753
3648/4713 [======================>.......] - ETA: 0s - loss: 0.2933 - acc: 0.8764
3776/4713 [=======================>......] - ETA: 0s - loss: 0.2957 - acc: 0.8739
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2946 - acc: 0.8745
4032/4713 [========================>.....] - ETA: 0s - loss: 0.2960 - acc: 0.8733
4160/4713 [=========================>....] - ETA: 0s - loss: 0.2943 - acc: 0.8733
4288/4713 [==========================>...] - ETA: 0s - loss: 0.2920 - acc: 0.8748
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2927 - acc: 0.8759
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2914 - acc: 0.8763
4672/4713 [============================>.] - ETA: 0s - loss: 0.2939 - acc: 0.8748
4713/4713 [==============================] - 3s 635us/step - loss: 0.2943 - acc: 0.8746

Test accuracy: 87.77120315581854

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  254

choose_one :  253

F1score :  0.8774703557312253

AUC :  0.9397622233979646

Confusion Matrix
[[223  31]
 [ 31 222]]
True label 0
0.8779527559055118  
0.1220472440944882  
True label 1
0.1225296442687747  
0.8774703557312253  

Train_result {'acc': [0.8746021644036632], 'loss': [0.2943223227165622]}
Saved model to disk


12

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2586 - acc: 0.9062
 192/4713 [>.............................] - ETA: 3s - loss: 0.3108 - acc: 0.8646
 320/4713 [=>............................] - ETA: 3s - loss: 0.2969 - acc: 0.8750
 448/4713 [=>............................] - ETA: 3s - loss: 0.2751 - acc: 0.8817
 576/4713 [==>...........................] - ETA: 3s - loss: 0.2723 - acc: 0.8802
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2799 - acc: 0.8793
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2834 - acc: 0.8750
 960/4713 [=====>........................] - ETA: 2s - loss: 0.2938 - acc: 0.8719
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2907 - acc: 0.8741
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2857 - acc: 0.8783
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2853 - acc: 0.8780
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2897 - acc: 0.8750
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2943 - acc: 0.8738
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2950 - acc: 0.8738
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2968 - acc: 0.8723
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2990 - acc: 0.8695
2048/4713 [============>.................] - ETA: 1s - loss: 0.2983 - acc: 0.8691
2176/4713 [============>.................] - ETA: 1s - loss: 0.3029 - acc: 0.8681
2304/4713 [=============>................] - ETA: 1s - loss: 0.2998 - acc: 0.8702
2432/4713 [==============>...............] - ETA: 1s - loss: 0.2955 - acc: 0.8717
2560/4713 [===============>..............] - ETA: 1s - loss: 0.2942 - acc: 0.8734
2688/4713 [================>.............] - ETA: 1s - loss: 0.2932 - acc: 0.8735
2816/4713 [================>.............] - ETA: 1s - loss: 0.2924 - acc: 0.8736
2944/4713 [=================>............] - ETA: 1s - loss: 0.2958 - acc: 0.8723
3072/4713 [==================>...........] - ETA: 1s - loss: 0.2956 - acc: 0.8730
3200/4713 [===================>..........] - ETA: 1s - loss: 0.2924 - acc: 0.8744
3328/4713 [====================>.........] - ETA: 0s - loss: 0.2922 - acc: 0.8741
3456/4713 [====================>.........] - ETA: 0s - loss: 0.2929 - acc: 0.8753
3584/4713 [=====================>........] - ETA: 0s - loss: 0.2934 - acc: 0.8753
3712/4713 [======================>.......] - ETA: 0s - loss: 0.2945 - acc: 0.8750
3840/4713 [=======================>......] - ETA: 0s - loss: 0.2933 - acc: 0.8755
3968/4713 [========================>.....] - ETA: 0s - loss: 0.2948 - acc: 0.8747
4096/4713 [=========================>....] - ETA: 0s - loss: 0.2946 - acc: 0.8743
4224/4713 [=========================>....] - ETA: 0s - loss: 0.2937 - acc: 0.8743
4352/4713 [==========================>...] - ETA: 0s - loss: 0.2946 - acc: 0.8732
4480/4713 [===========================>..] - ETA: 0s - loss: 0.2942 - acc: 0.8737
4608/4713 [============================>.] - ETA: 0s - loss: 0.2933 - acc: 0.8746
4713/4713 [==============================] - 3s 655us/step - loss: 0.2918 - acc: 0.8755

Test accuracy: 86.19329388560158

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  256

choose_one :  251

F1score :  0.8611111111111112

AUC :  0.9399333976533566

Confusion Matrix
[[220  34]
 [ 36 217]]
True label 0
0.8661417322834646  
0.13385826771653545  
True label 1
0.1422924901185771  
0.857707509881423  

Train_result {'acc': [0.8754508805178848], 'loss': [0.2918112626721746]}
Saved model to disk


13

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2716 - acc: 0.8750
 192/4713 [>.............................] - ETA: 3s - loss: 0.2775 - acc: 0.8698
 320/4713 [=>............................] - ETA: 3s - loss: 0.2917 - acc: 0.8719
 448/4713 [=>............................] - ETA: 3s - loss: 0.2954 - acc: 0.8750
 576/4713 [==>...........................] - ETA: 2s - loss: 0.2876 - acc: 0.8802
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2839 - acc: 0.8778
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2768 - acc: 0.8798
 960/4713 [=====>........................] - ETA: 2s - loss: 0.2806 - acc: 0.8812
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2879 - acc: 0.8759
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2916 - acc: 0.8758
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2920 - acc: 0.8743
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2994 - acc: 0.8709
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2928 - acc: 0.8719
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2913 - acc: 0.8738
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2889 - acc: 0.8739
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2930 - acc: 0.8715
2112/4713 [============>.................] - ETA: 1s - loss: 0.2888 - acc: 0.8745
2240/4713 [=============>................] - ETA: 1s - loss: 0.2863 - acc: 0.8750
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2857 - acc: 0.8750
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2821 - acc: 0.8758
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2860 - acc: 0.8735
2752/4713 [================>.............] - ETA: 1s - loss: 0.2884 - acc: 0.8739
2880/4713 [=================>............] - ETA: 1s - loss: 0.2857 - acc: 0.8750
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2881 - acc: 0.8727
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2902 - acc: 0.8718
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2912 - acc: 0.8729
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2903 - acc: 0.8729
3520/4713 [=====================>........] - ETA: 0s - loss: 0.2917 - acc: 0.8716
3648/4713 [======================>.......] - ETA: 0s - loss: 0.2919 - acc: 0.8728
3776/4713 [=======================>......] - ETA: 0s - loss: 0.2915 - acc: 0.8729
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2918 - acc: 0.8730
3968/4713 [========================>.....] - ETA: 0s - loss: 0.2918 - acc: 0.8735
4096/4713 [=========================>....] - ETA: 0s - loss: 0.2913 - acc: 0.8738
4224/4713 [=========================>....] - ETA: 0s - loss: 0.2899 - acc: 0.8745
4352/4713 [==========================>...] - ETA: 0s - loss: 0.2925 - acc: 0.8732
4480/4713 [===========================>..] - ETA: 0s - loss: 0.2927 - acc: 0.8725
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2915 - acc: 0.8726
4672/4713 [============================>.] - ETA: 0s - loss: 0.2910 - acc: 0.8731
4713/4713 [==============================] - 3s 660us/step - loss: 0.2916 - acc: 0.8731

Test accuracy: 87.77120315581854

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  248

choose_one :  259

F1score :  0.87890625

AUC :  0.9433413214652516

Confusion Matrix
[[220  34]
 [ 28 225]]
True label 0
0.8661417322834646  
0.13385826771653545  
True label 1
0.11067193675889328  
0.8893280632411067  

Train_result {'acc': [0.873116910647314], 'loss': [0.29158725126796836]}
Saved model to disk


14

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2757 - acc: 0.8906
 128/4713 [..............................] - ETA: 4s - loss: 0.3076 - acc: 0.8594
 256/4713 [>.............................] - ETA: 3s - loss: 0.2990 - acc: 0.8711
 384/4713 [=>............................] - ETA: 3s - loss: 0.3090 - acc: 0.8750
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3320 - acc: 0.8613
 640/4713 [===>..........................] - ETA: 3s - loss: 0.3356 - acc: 0.8578
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3381 - acc: 0.8516
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3157 - acc: 0.8650
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3158 - acc: 0.8691
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3099 - acc: 0.8724
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3035 - acc: 0.8742
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3011 - acc: 0.8757
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3029 - acc: 0.8717
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3013 - acc: 0.8726
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2990 - acc: 0.8744
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3020 - acc: 0.8739
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2971 - acc: 0.8750
2112/4713 [============>.................] - ETA: 1s - loss: 0.2970 - acc: 0.8755
2240/4713 [=============>................] - ETA: 1s - loss: 0.2961 - acc: 0.8763
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2969 - acc: 0.8758
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2963 - acc: 0.8766
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2943 - acc: 0.8761
2752/4713 [================>.............] - ETA: 1s - loss: 0.2938 - acc: 0.8750
2880/4713 [=================>............] - ETA: 1s - loss: 0.2936 - acc: 0.8757
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2901 - acc: 0.8777
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2932 - acc: 0.8766
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2928 - acc: 0.8768
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2917 - acc: 0.8777
3520/4713 [=====================>........] - ETA: 0s - loss: 0.2930 - acc: 0.8778
3648/4713 [======================>.......] - ETA: 0s - loss: 0.2933 - acc: 0.8775
3776/4713 [=======================>......] - ETA: 0s - loss: 0.2930 - acc: 0.8774
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2899 - acc: 0.8788
4032/4713 [========================>.....] - ETA: 0s - loss: 0.2880 - acc: 0.8805
4160/4713 [=========================>....] - ETA: 0s - loss: 0.2894 - acc: 0.8796
4288/4713 [==========================>...] - ETA: 0s - loss: 0.2863 - acc: 0.8811
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2852 - acc: 0.8811
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2849 - acc: 0.8814
4672/4713 [============================>.] - ETA: 0s - loss: 0.2864 - acc: 0.8812
4713/4713 [==============================] - 3s 661us/step - loss: 0.2863 - acc: 0.8812

Test accuracy: 87.96844181459566

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  227

choose_one :  280

F1score :  0.8855534709193246

AUC :  0.9377470355731226

Confusion Matrix
[[210  44]
 [ 17 236]]
True label 0
0.8267716535433071  
0.1732283464566929  
True label 1
0.06719367588932806  
0.932806324110672  

Train_result {'acc': [0.8811797156547402], 'loss': [0.2862561640088381]}
Saved model to disk


15

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2005 - acc: 0.9062
 128/4713 [..............................] - ETA: 4s - loss: 0.2647 - acc: 0.8594
 256/4713 [>.............................] - ETA: 3s - loss: 0.2570 - acc: 0.8828
 320/4713 [=>............................] - ETA: 3s - loss: 0.2827 - acc: 0.8750
 448/4713 [=>............................] - ETA: 3s - loss: 0.2587 - acc: 0.8862
 576/4713 [==>...........................] - ETA: 3s - loss: 0.2673 - acc: 0.8802
 704/4713 [===>..........................] - ETA: 3s - loss: 0.2565 - acc: 0.8864
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2738 - acc: 0.8774
 960/4713 [=====>........................] - ETA: 2s - loss: 0.2679 - acc: 0.8844
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2755 - acc: 0.8787
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2754 - acc: 0.8775
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2792 - acc: 0.8750
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2756 - acc: 0.8784
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2766 - acc: 0.8781
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2825 - acc: 0.8762
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2859 - acc: 0.8755
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2876 - acc: 0.8765
2112/4713 [============>.................] - ETA: 1s - loss: 0.2847 - acc: 0.8783
2240/4713 [=============>................] - ETA: 1s - loss: 0.2884 - acc: 0.8777
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2854 - acc: 0.8796
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2874 - acc: 0.8766
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2896 - acc: 0.8765
2752/4713 [================>.............] - ETA: 1s - loss: 0.2886 - acc: 0.8772
2880/4713 [=================>............] - ETA: 1s - loss: 0.2880 - acc: 0.8767
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2886 - acc: 0.8750
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2855 - acc: 0.8766
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2865 - acc: 0.8759
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2870 - acc: 0.8750
3520/4713 [=====================>........] - ETA: 0s - loss: 0.2855 - acc: 0.8759
3648/4713 [======================>.......] - ETA: 0s - loss: 0.2827 - acc: 0.8777
3776/4713 [=======================>......] - ETA: 0s - loss: 0.2821 - acc: 0.8776
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2805 - acc: 0.8794
4032/4713 [========================>.....] - ETA: 0s - loss: 0.2831 - acc: 0.8775
4160/4713 [=========================>....] - ETA: 0s - loss: 0.2847 - acc: 0.8764
4288/4713 [==========================>...] - ETA: 0s - loss: 0.2859 - acc: 0.8771
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2856 - acc: 0.8777
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2861 - acc: 0.8783
4672/4713 [============================>.] - ETA: 0s - loss: 0.2849 - acc: 0.8784
4713/4713 [==============================] - 3s 643us/step - loss: 0.2848 - acc: 0.8786

Test accuracy: 88.3629191321499

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  237

choose_one :  270

F1score :  0.887189292543021

AUC :  0.9402290622763063

Confusion Matrix
[[216  38]
 [ 21 232]]
True label 0
0.8503937007874016  
0.14960629921259844  
True label 1
0.08300395256916997  
0.9169960474308301  

Train_result {'acc': [0.878633566502677], 'loss': [0.2847699303865281]}
Saved model to disk


[[83.82642998027613, 1], [86.19329388560158, 2], [84.81262327416174, 3], [86.3905325443787, 4], [86.58777120315581, 5], [86.78500986193293, 6], [86.78500986193293, 7], [87.17948717948718, 8], [87.57396449704143, 9], [86.78500986193293, 10], [87.77120315581854, 11], [86.19329388560158, 12], [87.77120315581854, 13], [87.96844181459566, 14], [88.3629191321499, 15]]
max accuracy :  [88.3629191321499, 15]
