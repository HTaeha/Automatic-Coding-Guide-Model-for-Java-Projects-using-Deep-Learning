Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
/home/2014313303/taeha/JavaAutoLogging/model.py:53: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor("ou...)`
  model = Model(input=[input1, input2], output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-08 03:57:15.979537: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-08 03:57:15.989781: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100085000 Hz
2019-09-08 03:57:15.992303: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0xc18e0c0 executing computations on platform Host. Devices:
2019-09-08 03:57:15.992343: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Standard data
zero :  39451
one :  9019

First data
zero :  39451
one :  9019

Second data
zero :  39451
one :  9019

hbase-AST
After set document size of train data, the number of zero and one label data :  27718 2356
After set document size of test data, the number of zero and one label data :  3087 253

Sentence length Average : 9

Under 10 : 21693
Over 10, Under 30 : 11721
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

After balance out data.
hbase-AST

Sentence length Average : 11

Under 10 : 2794
Over 10, Under 30 : 2426
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

hbase-depth_num
After set document size of train data, the number of zero and one label data :  27718 2356
After set document size of test data, the number of zero and one label data :  3087 253
After balance out data.
hbase-depth_num

Sentence length Average : 11

Under 10 : 2794
Over 10, Under 30 : 2426
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

Count model parameter.
Get a short summary of each layer dimensions and parameters.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 30, 200)      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 30, 200)      0                                            
__________________________________________________________________________________________________
masking_1 (Masking)             (None, 30, 200)      0           input_1[0][0]                    
__________________________________________________________________________________________________
masking_2 (Masking)             (None, 30, 200)      0           input_2[0][0]                    
__________________________________________________________________________________________________
forwards_1 (LSTM)               (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
backwords_1 (LSTM)              (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
forwards_2 (LSTM)               (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
backwards_2 (LSTM)              (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
after_dp_forward_1 (Dropout)    (None, 64)           0           forwards_1[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_1 (Dropout)   (None, 64)           0           backwords_1[0][0]                
__________________________________________________________________________________________________
after_dp_forward_2 (Dropout)    (None, 64)           0           forwards_2[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_2 (Dropout)   (None, 64)           0           backwards_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128)          0           after_dp_forward_1[0][0]         
                                                                 after_dp_backward_1[0][0]        
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 128)          0           after_dp_forward_2[0][0]         
                                                                 after_dp_backward_2[0][0]        
__________________________________________________________________________________________________
after_dp_1 (Dropout)            (None, 128)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
after_dp_2 (Dropout)            (None, 128)          0           concatenate_2[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 256)          0           after_dp_1[0][0]                 
                                                                 after_dp_2[0][0]                 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 256)          65792       concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 128)          32896       dense_1[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 64)           8256        dense_2[0][0]                    
__________________________________________________________________________________________________
output (Dense)                  (None, 2)            130         dense_3[0][0]                    
==================================================================================================
Total params: 378,434
Trainable params: 378,434
Non-trainable params: 0
__________________________________________________________________________________________________
1

Epoch 1/1

  64/4713 [..............................] - ETA: 3:51 - loss: 0.7065 - acc: 0.4688
 128/4713 [..............................] - ETA: 1:56 - loss: 0.7149 - acc: 0.5156
 256/4713 [>.............................] - ETA: 58s - loss: 0.7113 - acc: 0.5234 
 384/4713 [=>............................] - ETA: 38s - loss: 0.6964 - acc: 0.5599
 512/4713 [==>...........................] - ETA: 28s - loss: 0.6911 - acc: 0.5801
 640/4713 [===>..........................] - ETA: 22s - loss: 0.6792 - acc: 0.6062
 768/4713 [===>..........................] - ETA: 18s - loss: 0.6694 - acc: 0.6250
 896/4713 [====>.........................] - ETA: 16s - loss: 0.6514 - acc: 0.6529
1024/4713 [=====>........................] - ETA: 13s - loss: 0.6409 - acc: 0.6631
1152/4713 [======>.......................] - ETA: 12s - loss: 0.6277 - acc: 0.6701
1280/4713 [=======>......................] - ETA: 10s - loss: 0.6266 - acc: 0.6719
1408/4713 [=======>......................] - ETA: 9s - loss: 0.6113 - acc: 0.6854 
1536/4713 [========>.....................] - ETA: 8s - loss: 0.5980 - acc: 0.6986
1664/4713 [=========>....................] - ETA: 7s - loss: 0.5911 - acc: 0.7049
1792/4713 [==========>...................] - ETA: 7s - loss: 0.5895 - acc: 0.7048
1920/4713 [===========>..................] - ETA: 6s - loss: 0.5774 - acc: 0.7125
2048/4713 [============>.................] - ETA: 5s - loss: 0.5678 - acc: 0.7178
2176/4713 [============>.................] - ETA: 5s - loss: 0.5552 - acc: 0.7252
2304/4713 [=============>................] - ETA: 4s - loss: 0.5472 - acc: 0.7313
2432/4713 [==============>...............] - ETA: 4s - loss: 0.5395 - acc: 0.7356
2560/4713 [===============>..............] - ETA: 4s - loss: 0.5311 - acc: 0.7398
2688/4713 [================>.............] - ETA: 3s - loss: 0.5227 - acc: 0.7444
2816/4713 [================>.............] - ETA: 3s - loss: 0.5201 - acc: 0.7464
2944/4713 [=================>............] - ETA: 3s - loss: 0.5123 - acc: 0.7510
3072/4713 [==================>...........] - ETA: 2s - loss: 0.5106 - acc: 0.7533
3200/4713 [===================>..........] - ETA: 2s - loss: 0.5143 - acc: 0.7525
3328/4713 [====================>.........] - ETA: 2s - loss: 0.5164 - acc: 0.7518
3456/4713 [====================>.........] - ETA: 2s - loss: 0.5148 - acc: 0.7523
3584/4713 [=====================>........] - ETA: 1s - loss: 0.5115 - acc: 0.7545
3712/4713 [======================>.......] - ETA: 1s - loss: 0.5093 - acc: 0.7565
3840/4713 [=======================>......] - ETA: 1s - loss: 0.5045 - acc: 0.7594
3968/4713 [========================>.....] - ETA: 1s - loss: 0.5028 - acc: 0.7611
4096/4713 [=========================>....] - ETA: 0s - loss: 0.4989 - acc: 0.7642
4224/4713 [=========================>....] - ETA: 0s - loss: 0.4940 - acc: 0.7675
4352/4713 [==========================>...] - ETA: 0s - loss: 0.4903 - acc: 0.7688
4480/4713 [===========================>..] - ETA: 0s - loss: 0.4873 - acc: 0.7710
4608/4713 [============================>.] - ETA: 0s - loss: 0.4830 - acc: 0.7728
4713/4713 [==============================] - 6s 1ms/step - loss: 0.4798 - acc: 0.7745

Test accuracy: 85.00986193293886

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  260

choose_one :  247

F1score :  0.848

AUC :  0.9238118950546201

Confusion Matrix
[[219  35]
 [ 41 212]]
True label 0
0.8622047244094488  
0.1377952755905512  
True label 1
0.16205533596837945  
0.8379446640316206  

Train_result {'loss': [0.47980143740352693], 'acc': [0.7744536388206199]}
Saved model to disk


2

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2697 - acc: 0.8750
 192/4713 [>.............................] - ETA: 3s - loss: 0.3588 - acc: 0.8542
 320/4713 [=>............................] - ETA: 3s - loss: 0.3474 - acc: 0.8438
 448/4713 [=>............................] - ETA: 3s - loss: 0.3575 - acc: 0.8393
 576/4713 [==>...........................] - ETA: 3s - loss: 0.3491 - acc: 0.8368
 704/4713 [===>..........................] - ETA: 2s - loss: 0.3632 - acc: 0.8324
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3576 - acc: 0.8365
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3656 - acc: 0.8292
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3659 - acc: 0.8318
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3704 - acc: 0.8306
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3764 - acc: 0.8266
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3774 - acc: 0.8261
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3784 - acc: 0.8269
1728/4713 [=========>....................] - ETA: 2s - loss: 0.3732 - acc: 0.8310
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3763 - acc: 0.8308
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3763 - acc: 0.8332
2112/4713 [============>.................] - ETA: 1s - loss: 0.3747 - acc: 0.8348
2240/4713 [=============>................] - ETA: 1s - loss: 0.3757 - acc: 0.8344
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3717 - acc: 0.8361
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3753 - acc: 0.8325
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3739 - acc: 0.8346
2752/4713 [================>.............] - ETA: 1s - loss: 0.3728 - acc: 0.8354
2880/4713 [=================>............] - ETA: 1s - loss: 0.3703 - acc: 0.8365
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3693 - acc: 0.8371
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3665 - acc: 0.8399
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3652 - acc: 0.8398
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3658 - acc: 0.8381
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3676 - acc: 0.8372
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3667 - acc: 0.8372
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3658 - acc: 0.8379
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3608 - acc: 0.8404
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3625 - acc: 0.8388
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3619 - acc: 0.8387
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3630 - acc: 0.8382
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3641 - acc: 0.8376
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3657 - acc: 0.8367
4672/4713 [============================>.] - ETA: 0s - loss: 0.3656 - acc: 0.8367
4713/4713 [==============================] - 3s 653us/step - loss: 0.3649 - acc: 0.8370

Test accuracy: 85.60157790927022

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  267

choose_one :  240

F1score :  0.8519269776876267

AUC :  0.9316236656188728

Confusion Matrix
[[224  30]
 [ 43 210]]
True label 0
0.8818897637795275  
0.11811023622047244  
True label 1
0.16996047430830039  
0.8300395256916996  

Train_result {'loss': [0.36489950247233827], 'acc': [0.8370464671930385]}
Saved model to disk


3

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.3197 - acc: 0.8594
 192/4713 [>.............................] - ETA: 3s - loss: 0.3104 - acc: 0.8750
 320/4713 [=>............................] - ETA: 3s - loss: 0.3752 - acc: 0.8406
 448/4713 [=>............................] - ETA: 3s - loss: 0.3571 - acc: 0.8482
 576/4713 [==>...........................] - ETA: 3s - loss: 0.3638 - acc: 0.8455
 704/4713 [===>..........................] - ETA: 3s - loss: 0.3556 - acc: 0.8480
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3570 - acc: 0.8510
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3620 - acc: 0.8500
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3511 - acc: 0.8557
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3448 - acc: 0.8569
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3381 - acc: 0.8616
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3477 - acc: 0.8567
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3413 - acc: 0.8575
1728/4713 [=========>....................] - ETA: 2s - loss: 0.3349 - acc: 0.8600
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3407 - acc: 0.8572
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3417 - acc: 0.8558
2112/4713 [============>.................] - ETA: 1s - loss: 0.3397 - acc: 0.8570
2240/4713 [=============>................] - ETA: 1s - loss: 0.3400 - acc: 0.8558
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3458 - acc: 0.8526
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3455 - acc: 0.8510
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3459 - acc: 0.8514
2752/4713 [================>.............] - ETA: 1s - loss: 0.3460 - acc: 0.8499
2880/4713 [=================>............] - ETA: 1s - loss: 0.3442 - acc: 0.8517
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3449 - acc: 0.8517
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3432 - acc: 0.8530
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3438 - acc: 0.8526
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3442 - acc: 0.8523
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3454 - acc: 0.8517
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3485 - acc: 0.8503
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3479 - acc: 0.8504
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3474 - acc: 0.8507
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3487 - acc: 0.8504
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3495 - acc: 0.8502
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3497 - acc: 0.8503
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3501 - acc: 0.8494
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3487 - acc: 0.8506
4672/4713 [============================>.] - ETA: 0s - loss: 0.3463 - acc: 0.8512
4713/4713 [==============================] - 3s 653us/step - loss: 0.3450 - acc: 0.8521

Test accuracy: 86.78500986193293

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  271

choose_one :  236

F1score :  0.8629856850715746

AUC :  0.9382683389872709

Confusion Matrix
[[229  25]
 [ 42 211]]
True label 0
0.9015748031496063  
0.0984251968503937  
True label 1
0.16600790513833993  
0.83399209486166  

Train_result {'loss': [0.3450339212460349], 'acc': [0.8521111817236491]}
Saved model to disk


4

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2875 - acc: 0.8594
 192/4713 [>.............................] - ETA: 3s - loss: 0.3171 - acc: 0.8542
 320/4713 [=>............................] - ETA: 3s - loss: 0.3410 - acc: 0.8375
 448/4713 [=>............................] - ETA: 3s - loss: 0.3344 - acc: 0.8482
 576/4713 [==>...........................] - ETA: 3s - loss: 0.3214 - acc: 0.8542
 704/4713 [===>..........................] - ETA: 2s - loss: 0.3427 - acc: 0.8466
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3365 - acc: 0.8522
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3381 - acc: 0.8531
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3391 - acc: 0.8520
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3428 - acc: 0.8503
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3522 - acc: 0.8445
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3545 - acc: 0.8410
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3503 - acc: 0.8450
1728/4713 [=========>....................] - ETA: 2s - loss: 0.3472 - acc: 0.8478
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3435 - acc: 0.8486
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3413 - acc: 0.8493
2112/4713 [============>.................] - ETA: 1s - loss: 0.3410 - acc: 0.8485
2240/4713 [=============>................] - ETA: 1s - loss: 0.3427 - acc: 0.8460
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3441 - acc: 0.8442
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3400 - acc: 0.8470
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3367 - acc: 0.8483
2752/4713 [================>.............] - ETA: 1s - loss: 0.3374 - acc: 0.8485
2880/4713 [=================>............] - ETA: 1s - loss: 0.3391 - acc: 0.8483
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3376 - acc: 0.8491
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3393 - acc: 0.8492
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3385 - acc: 0.8496
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3374 - acc: 0.8499
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3336 - acc: 0.8514
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3316 - acc: 0.8536
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3332 - acc: 0.8525
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3346 - acc: 0.8514
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3346 - acc: 0.8502
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3350 - acc: 0.8505
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3327 - acc: 0.8517
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3355 - acc: 0.8503
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3331 - acc: 0.8510
4672/4713 [============================>.] - ETA: 0s - loss: 0.3333 - acc: 0.8500
4713/4713 [==============================] - 3s 660us/step - loss: 0.3327 - acc: 0.8500

Test accuracy: 85.99605522682445

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  263

choose_one :  244

F1score :  0.8571428571428571

AUC :  0.9348526345274034

Confusion Matrix
[[223  31]
 [ 40 213]]
True label 0
0.8779527559055118  
0.1220472440944882  
True label 1
0.15810276679841898  
0.841897233201581  

Train_result {'loss': [0.3327393979434878], 'acc': [0.8499893912230989]}
Saved model to disk


5

Epoch 1/1

  64/4713 [..............................] - ETA: 3s - loss: 0.3256 - acc: 0.8906
 192/4713 [>.............................] - ETA: 3s - loss: 0.2685 - acc: 0.9062
 320/4713 [=>............................] - ETA: 3s - loss: 0.2908 - acc: 0.8938
 448/4713 [=>............................] - ETA: 3s - loss: 0.3257 - acc: 0.8705
 576/4713 [==>...........................] - ETA: 3s - loss: 0.3255 - acc: 0.8715
 704/4713 [===>..........................] - ETA: 2s - loss: 0.3509 - acc: 0.8622
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3679 - acc: 0.8462
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3501 - acc: 0.8542
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3399 - acc: 0.8566
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3375 - acc: 0.8577
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3329 - acc: 0.8594
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3313 - acc: 0.8607
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3361 - acc: 0.8581
1728/4713 [=========>....................] - ETA: 1s - loss: 0.3321 - acc: 0.8582
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3293 - acc: 0.8583
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3329 - acc: 0.8569
2112/4713 [============>.................] - ETA: 1s - loss: 0.3288 - acc: 0.8580
2240/4713 [=============>................] - ETA: 1s - loss: 0.3297 - acc: 0.8576
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3340 - acc: 0.8526
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3326 - acc: 0.8522
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3306 - acc: 0.8518
2752/4713 [================>.............] - ETA: 1s - loss: 0.3316 - acc: 0.8510
2880/4713 [=================>............] - ETA: 1s - loss: 0.3391 - acc: 0.8497
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3366 - acc: 0.8501
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3338 - acc: 0.8504
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3324 - acc: 0.8511
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3297 - acc: 0.8523
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3291 - acc: 0.8534
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3261 - acc: 0.8542
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3293 - acc: 0.8530
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3316 - acc: 0.8525
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3311 - acc: 0.8537
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3333 - acc: 0.8529
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3372 - acc: 0.8505
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3368 - acc: 0.8510
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3356 - acc: 0.8519
4672/4713 [============================>.] - ETA: 0s - loss: 0.3352 - acc: 0.8519
4713/4713 [==============================] - 3s 639us/step - loss: 0.3362 - acc: 0.8506

Test accuracy: 86.98224852071006

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  222

choose_one :  285

F1score :  0.8773234200743495

AUC :  0.9380349195480999

Confusion Matrix
[[205  49]
 [ 17 236]]
True label 0
0.8070866141732284  
0.19291338582677164  
True label 1
0.06719367588932806  
0.932806324110672  

Train_result {'loss': [0.3361618161302652], 'acc': [0.8506259281190621]}
Saved model to disk


6

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2067 - acc: 0.9375
 128/4713 [..............................] - ETA: 4s - loss: 0.2299 - acc: 0.8984
 256/4713 [>.............................] - ETA: 3s - loss: 0.2826 - acc: 0.8594
 384/4713 [=>............................] - ETA: 3s - loss: 0.2941 - acc: 0.8620
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3113 - acc: 0.8574
 640/4713 [===>..........................] - ETA: 2s - loss: 0.3156 - acc: 0.8562
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3131 - acc: 0.8594
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3063 - acc: 0.8661
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3184 - acc: 0.8573
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3393 - acc: 0.8502
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3276 - acc: 0.8553
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3252 - acc: 0.8562
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3215 - acc: 0.8537
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3257 - acc: 0.8516
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3209 - acc: 0.8528
1792/4713 [==========>...................] - ETA: 2s - loss: 0.3231 - acc: 0.8516
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3225 - acc: 0.8526
2048/4713 [============>.................] - ETA: 1s - loss: 0.3241 - acc: 0.8521
2176/4713 [============>.................] - ETA: 1s - loss: 0.3255 - acc: 0.8516
2304/4713 [=============>................] - ETA: 1s - loss: 0.3232 - acc: 0.8537
2432/4713 [==============>...............] - ETA: 1s - loss: 0.3210 - acc: 0.8557
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3203 - acc: 0.8559
2688/4713 [================>.............] - ETA: 1s - loss: 0.3226 - acc: 0.8560
2816/4713 [================>.............] - ETA: 1s - loss: 0.3219 - acc: 0.8569
2944/4713 [=================>............] - ETA: 1s - loss: 0.3213 - acc: 0.8573
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3210 - acc: 0.8577
3200/4713 [===================>..........] - ETA: 1s - loss: 0.3216 - acc: 0.8588
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3208 - acc: 0.8585
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3214 - acc: 0.8588
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3185 - acc: 0.8608
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3178 - acc: 0.8613
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3185 - acc: 0.8617
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3181 - acc: 0.8632
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3186 - acc: 0.8628
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3172 - acc: 0.8632
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3166 - acc: 0.8631
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3175 - acc: 0.8627
4608/4713 [============================>.] - ETA: 0s - loss: 0.3160 - acc: 0.8628
4713/4713 [==============================] - 3s 657us/step - loss: 0.3180 - acc: 0.8623

Test accuracy: 86.98224852071006

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  254

choose_one :  253

F1score :  0.8695652173913043

AUC :  0.9397155395101304

Confusion Matrix
[[221  33]
 [ 33 220]]
True label 0
0.8700787401574803  
0.12992125984251968  
True label 1
0.13043478260869565  
0.8695652173913043  

Train_result {'loss': [0.3179621172133409], 'acc': [0.8622957774972096]}
Saved model to disk


7

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.1979 - acc: 0.9062
 192/4713 [>.............................] - ETA: 3s - loss: 0.2441 - acc: 0.9062
 320/4713 [=>............................] - ETA: 3s - loss: 0.2626 - acc: 0.8969
 448/4713 [=>............................] - ETA: 3s - loss: 0.2927 - acc: 0.8683
 576/4713 [==>...........................] - ETA: 3s - loss: 0.2824 - acc: 0.8854
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2874 - acc: 0.8821
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2905 - acc: 0.8786
 960/4713 [=====>........................] - ETA: 2s - loss: 0.2826 - acc: 0.8833
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2756 - acc: 0.8906
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2800 - acc: 0.8849
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2763 - acc: 0.8832
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2803 - acc: 0.8791
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2776 - acc: 0.8812
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2905 - acc: 0.8756
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2966 - acc: 0.8728
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2967 - acc: 0.8730
2112/4713 [============>.................] - ETA: 1s - loss: 0.2960 - acc: 0.8722
2240/4713 [=============>................] - ETA: 1s - loss: 0.2934 - acc: 0.8728
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2934 - acc: 0.8720
2432/4713 [==============>...............] - ETA: 1s - loss: 0.2923 - acc: 0.8725
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2965 - acc: 0.8698
2560/4713 [===============>..............] - ETA: 1s - loss: 0.2976 - acc: 0.8699
2688/4713 [================>.............] - ETA: 1s - loss: 0.2960 - acc: 0.8702
2816/4713 [================>.............] - ETA: 1s - loss: 0.3020 - acc: 0.8675
2944/4713 [=================>............] - ETA: 1s - loss: 0.3006 - acc: 0.8689
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3021 - acc: 0.8680
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3022 - acc: 0.8677
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3029 - acc: 0.8664
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3050 - acc: 0.8653
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3054 - acc: 0.8651
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3061 - acc: 0.8635
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3061 - acc: 0.8631
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3065 - acc: 0.8622
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3087 - acc: 0.8609
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3095 - acc: 0.8603
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3078 - acc: 0.8615
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3073 - acc: 0.8623
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3071 - acc: 0.8623
4608/4713 [============================>.] - ETA: 0s - loss: 0.3104 - acc: 0.8618
4713/4713 [==============================] - 3s 673us/step - loss: 0.3099 - acc: 0.8623

Test accuracy: 87.96844181459566

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  239

choose_one :  268

F1score :  0.8829174664107485

AUC :  0.9419408048302262

Confusion Matrix
[[216  38]
 [ 23 230]]
True label 0
0.8503937007874016  
0.14960629921259844  
True label 1
0.09090909090909091  
0.9090909090909091  

Train_result {'loss': [0.30991137169385297], 'acc': [0.8622957778133811]}
Saved model to disk


8

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2107 - acc: 0.9062
 192/4713 [>.............................] - ETA: 3s - loss: 0.3169 - acc: 0.8594
 320/4713 [=>............................] - ETA: 3s - loss: 0.2723 - acc: 0.8938
 448/4713 [=>............................] - ETA: 3s - loss: 0.2807 - acc: 0.8884
 576/4713 [==>...........................] - ETA: 2s - loss: 0.2755 - acc: 0.8924
 704/4713 [===>..........................] - ETA: 2s - loss: 0.3055 - acc: 0.8750
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3277 - acc: 0.8594
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3194 - acc: 0.8625
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3176 - acc: 0.8612
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3177 - acc: 0.8618
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3121 - acc: 0.8609
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3114 - acc: 0.8635
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3042 - acc: 0.8675
1728/4713 [=========>....................] - ETA: 2s - loss: 0.3100 - acc: 0.8663
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3064 - acc: 0.8685
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3035 - acc: 0.8705
2112/4713 [============>.................] - ETA: 1s - loss: 0.3026 - acc: 0.8712
2240/4713 [=============>................] - ETA: 1s - loss: 0.3033 - acc: 0.8714
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3047 - acc: 0.8712
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3047 - acc: 0.8706
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3036 - acc: 0.8704
2752/4713 [================>.............] - ETA: 1s - loss: 0.3047 - acc: 0.8692
2880/4713 [=================>............] - ETA: 1s - loss: 0.3029 - acc: 0.8701
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3055 - acc: 0.8687
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3088 - acc: 0.8670
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3100 - acc: 0.8655
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3089 - acc: 0.8656
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3095 - acc: 0.8659
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3107 - acc: 0.8646
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3081 - acc: 0.8660
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3072 - acc: 0.8659
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3066 - acc: 0.8659
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3058 - acc: 0.8665
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3055 - acc: 0.8658
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3049 - acc: 0.8660
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3046 - acc: 0.8652
4608/4713 [============================>.] - ETA: 0s - loss: 0.3034 - acc: 0.8661
4713/4713 [==============================] - 3s 646us/step - loss: 0.3053 - acc: 0.8661

Test accuracy: 87.3767258382643

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  252

choose_one :  255

F1score :  0.8740157480314961

AUC :  0.9440727023746538

Confusion Matrix
[[221  33]
 [ 31 222]]
True label 0
0.8700787401574803  
0.12992125984251968  
True label 1
0.1225296442687747  
0.8774703557312253  

Train_result {'loss': [0.3053269394764899], 'acc': [0.86611500092178]}
Saved model to disk


9

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2515 - acc: 0.8750
 192/4713 [>.............................] - ETA: 3s - loss: 0.2804 - acc: 0.8750
 320/4713 [=>............................] - ETA: 3s - loss: 0.2648 - acc: 0.8750
 448/4713 [=>............................] - ETA: 3s - loss: 0.2838 - acc: 0.8728
 576/4713 [==>...........................] - ETA: 3s - loss: 0.2688 - acc: 0.8819
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2996 - acc: 0.8707
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2954 - acc: 0.8738
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3011 - acc: 0.8729
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3053 - acc: 0.8722
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3133 - acc: 0.8684
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3138 - acc: 0.8661
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3088 - acc: 0.8682
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3049 - acc: 0.8719
1728/4713 [=========>....................] - ETA: 1s - loss: 0.2983 - acc: 0.8744
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2973 - acc: 0.8750
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3073 - acc: 0.8710
2112/4713 [============>.................] - ETA: 1s - loss: 0.3081 - acc: 0.8688
2240/4713 [=============>................] - ETA: 1s - loss: 0.3074 - acc: 0.8688
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3092 - acc: 0.8704
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3074 - acc: 0.8706
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3104 - acc: 0.8697
2752/4713 [================>.............] - ETA: 1s - loss: 0.3078 - acc: 0.8706
2880/4713 [=================>............] - ETA: 1s - loss: 0.3090 - acc: 0.8694
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3082 - acc: 0.8713
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3091 - acc: 0.8709
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3067 - acc: 0.8722
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3087 - acc: 0.8718
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3096 - acc: 0.8710
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3065 - acc: 0.8728
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3064 - acc: 0.8726
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3045 - acc: 0.8732
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3046 - acc: 0.8733
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3039 - acc: 0.8733
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3039 - acc: 0.8736
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3012 - acc: 0.8745
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3003 - acc: 0.8752
4672/4713 [============================>.] - ETA: 0s - loss: 0.3002 - acc: 0.8752
4713/4713 [==============================] - 3s 635us/step - loss: 0.3004 - acc: 0.8744

Test accuracy: 86.58777120315581

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  258

choose_one :  249

F1score :  0.8645418326693226

AUC :  0.9429056051787994

Confusion Matrix
[[222  32]
 [ 36 217]]
True label 0
0.8740157480314961  
0.12598425196850394  
True label 1
0.1422924901185771  
0.857707509881423  

Train_result {'loss': [0.30036637901551605], 'acc': [0.8743899848945272]}
Saved model to disk


10

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2503 - acc: 0.9062
 128/4713 [..............................] - ETA: 4s - loss: 0.2685 - acc: 0.8594
 256/4713 [>.............................] - ETA: 3s - loss: 0.2731 - acc: 0.8594
 384/4713 [=>............................] - ETA: 3s - loss: 0.2760 - acc: 0.8672
 448/4713 [=>............................] - ETA: 3s - loss: 0.2681 - acc: 0.8661
 576/4713 [==>...........................] - ETA: 3s - loss: 0.3022 - acc: 0.8559
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2829 - acc: 0.8679
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2870 - acc: 0.8690
 960/4713 [=====>........................] - ETA: 2s - loss: 0.2983 - acc: 0.8625
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2970 - acc: 0.8631
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3025 - acc: 0.8643
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2982 - acc: 0.8646
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2939 - acc: 0.8689
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2966 - acc: 0.8681
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2909 - acc: 0.8709
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2888 - acc: 0.8712
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2949 - acc: 0.8690
2112/4713 [============>.................] - ETA: 1s - loss: 0.2949 - acc: 0.8670
2240/4713 [=============>................] - ETA: 1s - loss: 0.2923 - acc: 0.8688
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2931 - acc: 0.8691
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2921 - acc: 0.8710
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2903 - acc: 0.8716
2752/4713 [================>.............] - ETA: 1s - loss: 0.2905 - acc: 0.8725
2880/4713 [=================>............] - ETA: 1s - loss: 0.2924 - acc: 0.8712
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2982 - acc: 0.8700
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2952 - acc: 0.8712
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2985 - acc: 0.8713
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3024 - acc: 0.8700
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3022 - acc: 0.8702
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3018 - acc: 0.8706
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3022 - acc: 0.8708
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3032 - acc: 0.8701
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3044 - acc: 0.8698
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3027 - acc: 0.8712
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3013 - acc: 0.8715
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2982 - acc: 0.8736
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2996 - acc: 0.8735
4672/4713 [============================>.] - ETA: 0s - loss: 0.2992 - acc: 0.8737
4713/4713 [==============================] - 3s 650us/step - loss: 0.2982 - acc: 0.8735

Test accuracy: 87.77120315581854

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  246

choose_one :  261

F1score :  0.8793774319066148

AUC :  0.9440260184868196

Confusion Matrix
[[219  35]
 [ 27 226]]
True label 0
0.8622047244094488  
0.1377952755905512  
True label 1
0.1067193675889328  
0.8932806324110671  

Train_result {'loss': [0.29820152697304164], 'acc': [0.8735412690079493]}
Saved model to disk


11

Epoch 1/1

  64/4713 [..............................] - ETA: 5s - loss: 0.2759 - acc: 0.9375
 128/4713 [..............................] - ETA: 4s - loss: 0.2171 - acc: 0.9375
 256/4713 [>.............................] - ETA: 3s - loss: 0.2543 - acc: 0.8984
 384/4713 [=>............................] - ETA: 3s - loss: 0.2275 - acc: 0.9062
 512/4713 [==>...........................] - ETA: 3s - loss: 0.2645 - acc: 0.9004
 640/4713 [===>..........................] - ETA: 3s - loss: 0.2619 - acc: 0.9000
 768/4713 [===>..........................] - ETA: 2s - loss: 0.2640 - acc: 0.9010
 896/4713 [====>.........................] - ETA: 2s - loss: 0.2706 - acc: 0.8951
1024/4713 [=====>........................] - ETA: 2s - loss: 0.2787 - acc: 0.8906
1152/4713 [======>.......................] - ETA: 2s - loss: 0.2764 - acc: 0.8915
1280/4713 [=======>......................] - ETA: 2s - loss: 0.2787 - acc: 0.8898
1408/4713 [=======>......................] - ETA: 2s - loss: 0.2740 - acc: 0.8899
1536/4713 [========>.....................] - ETA: 2s - loss: 0.2767 - acc: 0.8867
1664/4713 [=========>....................] - ETA: 2s - loss: 0.2744 - acc: 0.8876
1792/4713 [==========>...................] - ETA: 1s - loss: 0.2776 - acc: 0.8862
1920/4713 [===========>..................] - ETA: 1s - loss: 0.2743 - acc: 0.8875
2048/4713 [============>.................] - ETA: 1s - loss: 0.2730 - acc: 0.8867
2176/4713 [============>.................] - ETA: 1s - loss: 0.2789 - acc: 0.8842
2304/4713 [=============>................] - ETA: 1s - loss: 0.2796 - acc: 0.8837
2432/4713 [==============>...............] - ETA: 1s - loss: 0.2800 - acc: 0.8832
2560/4713 [===============>..............] - ETA: 1s - loss: 0.2811 - acc: 0.8840
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2830 - acc: 0.8838
2752/4713 [================>.............] - ETA: 1s - loss: 0.2830 - acc: 0.8826
2880/4713 [=================>............] - ETA: 1s - loss: 0.2857 - acc: 0.8806
2944/4713 [=================>............] - ETA: 1s - loss: 0.2869 - acc: 0.8784
3072/4713 [==================>...........] - ETA: 1s - loss: 0.2905 - acc: 0.8766
3200/4713 [===================>..........] - ETA: 0s - loss: 0.2895 - acc: 0.8775
3328/4713 [====================>.........] - ETA: 0s - loss: 0.2916 - acc: 0.8762
3456/4713 [====================>.........] - ETA: 0s - loss: 0.2923 - acc: 0.8750
3584/4713 [=====================>........] - ETA: 0s - loss: 0.2911 - acc: 0.8761
3712/4713 [======================>.......] - ETA: 0s - loss: 0.2914 - acc: 0.8755
3840/4713 [=======================>......] - ETA: 0s - loss: 0.2919 - acc: 0.8753
3968/4713 [========================>.....] - ETA: 0s - loss: 0.2941 - acc: 0.8742
4096/4713 [=========================>....] - ETA: 0s - loss: 0.2918 - acc: 0.8748
4224/4713 [=========================>....] - ETA: 0s - loss: 0.2900 - acc: 0.8752
4352/4713 [==========================>...] - ETA: 0s - loss: 0.2880 - acc: 0.8755
4480/4713 [===========================>..] - ETA: 0s - loss: 0.2894 - acc: 0.8757
4608/4713 [============================>.] - ETA: 0s - loss: 0.2885 - acc: 0.8759
4713/4713 [==============================] - 3s 645us/step - loss: 0.2906 - acc: 0.8750

Test accuracy: 86.78500986193293

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  249

choose_one :  258

F1score :  0.8688845401174168

AUC :  0.940586972083035

Confusion Matrix
[[218  36]
 [ 31 222]]
True label 0
0.8582677165354331  
0.14173228346456693  
True label 1
0.1225296442687747  
0.8774703557312253  

Train_result {'loss': [0.2906013237122338], 'acc': [0.8750265223595991]}
Saved model to disk


12

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2699 - acc: 0.8750
 192/4713 [>.............................] - ETA: 3s - loss: 0.3383 - acc: 0.8542
 320/4713 [=>............................] - ETA: 3s - loss: 0.3105 - acc: 0.8656
 448/4713 [=>............................] - ETA: 3s - loss: 0.2848 - acc: 0.8750
 576/4713 [==>...........................] - ETA: 3s - loss: 0.2816 - acc: 0.8698
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2821 - acc: 0.8722
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2821 - acc: 0.8714
 960/4713 [=====>........................] - ETA: 2s - loss: 0.2898 - acc: 0.8729
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2825 - acc: 0.8741
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2768 - acc: 0.8758
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2758 - acc: 0.8780
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2748 - acc: 0.8784
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2783 - acc: 0.8769
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2823 - acc: 0.8744
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2881 - acc: 0.8728
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2902 - acc: 0.8705
2112/4713 [============>.................] - ETA: 1s - loss: 0.2947 - acc: 0.8665
2240/4713 [=============>................] - ETA: 1s - loss: 0.2939 - acc: 0.8683
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2901 - acc: 0.8699
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2878 - acc: 0.8718
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2882 - acc: 0.8712
2752/4713 [================>.............] - ETA: 1s - loss: 0.2869 - acc: 0.8721
2880/4713 [=================>............] - ETA: 1s - loss: 0.2888 - acc: 0.8712
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2892 - acc: 0.8720
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2897 - acc: 0.8712
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2875 - acc: 0.8722
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2879 - acc: 0.8715
3520/4713 [=====================>........] - ETA: 0s - loss: 0.2867 - acc: 0.8730
3648/4713 [======================>.......] - ETA: 0s - loss: 0.2900 - acc: 0.8712
3776/4713 [=======================>......] - ETA: 0s - loss: 0.2872 - acc: 0.8724
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2893 - acc: 0.8717
4032/4713 [========================>.....] - ETA: 0s - loss: 0.2890 - acc: 0.8715
4160/4713 [=========================>....] - ETA: 0s - loss: 0.2876 - acc: 0.8719
4288/4713 [==========================>...] - ETA: 0s - loss: 0.2874 - acc: 0.8722
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2889 - acc: 0.8709
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2883 - acc: 0.8710
4672/4713 [============================>.] - ETA: 0s - loss: 0.2868 - acc: 0.8720
4713/4713 [==============================] - 3s 652us/step - loss: 0.2870 - acc: 0.8721

Test accuracy: 86.19329388560158

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  256

choose_one :  251

F1score :  0.8611111111111112

AUC :  0.9422675920450655

Confusion Matrix
[[220  34]
 [ 36 217]]
True label 0
0.8661417322834646  
0.13385826771653545  
True label 1
0.1422924901185771  
0.857707509881423  

Train_result {'loss': [0.2870451353257967], 'acc': [0.8720560152516]}
Saved model to disk


13

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2716 - acc: 0.8906
 128/4713 [..............................] - ETA: 4s - loss: 0.3040 - acc: 0.8594
 256/4713 [>.............................] - ETA: 3s - loss: 0.2640 - acc: 0.8906
 384/4713 [=>............................] - ETA: 3s - loss: 0.2998 - acc: 0.8698
 512/4713 [==>...........................] - ETA: 3s - loss: 0.2854 - acc: 0.8711
 640/4713 [===>..........................] - ETA: 3s - loss: 0.2783 - acc: 0.8766
 768/4713 [===>..........................] - ETA: 2s - loss: 0.2670 - acc: 0.8828
 896/4713 [====>.........................] - ETA: 2s - loss: 0.2699 - acc: 0.8817
1024/4713 [=====>........................] - ETA: 2s - loss: 0.2658 - acc: 0.8818
1152/4713 [======>.......................] - ETA: 2s - loss: 0.2833 - acc: 0.8741
1280/4713 [=======>......................] - ETA: 2s - loss: 0.2800 - acc: 0.8742
1408/4713 [=======>......................] - ETA: 2s - loss: 0.2841 - acc: 0.8707
1536/4713 [========>.....................] - ETA: 2s - loss: 0.2867 - acc: 0.8737
1664/4713 [=========>....................] - ETA: 2s - loss: 0.2873 - acc: 0.8744
1792/4713 [==========>...................] - ETA: 2s - loss: 0.2808 - acc: 0.8767
1920/4713 [===========>..................] - ETA: 1s - loss: 0.2851 - acc: 0.8745
2048/4713 [============>.................] - ETA: 1s - loss: 0.2883 - acc: 0.8735
2176/4713 [============>.................] - ETA: 1s - loss: 0.2819 - acc: 0.8764
2240/4713 [=============>................] - ETA: 1s - loss: 0.2836 - acc: 0.8750
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2843 - acc: 0.8746
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2794 - acc: 0.8774
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2827 - acc: 0.8761
2752/4713 [================>.............] - ETA: 1s - loss: 0.2822 - acc: 0.8757
2880/4713 [=================>............] - ETA: 1s - loss: 0.2796 - acc: 0.8771
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2805 - acc: 0.8773
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2833 - acc: 0.8756
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2839 - acc: 0.8762
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2826 - acc: 0.8771
3520/4713 [=====================>........] - ETA: 0s - loss: 0.2840 - acc: 0.8761
3648/4713 [======================>.......] - ETA: 0s - loss: 0.2837 - acc: 0.8764
3776/4713 [=======================>......] - ETA: 0s - loss: 0.2822 - acc: 0.8763
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2823 - acc: 0.8760
4032/4713 [========================>.....] - ETA: 0s - loss: 0.2803 - acc: 0.8777
4160/4713 [=========================>....] - ETA: 0s - loss: 0.2805 - acc: 0.8774
4288/4713 [==========================>...] - ETA: 0s - loss: 0.2826 - acc: 0.8759
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2826 - acc: 0.8752
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2819 - acc: 0.8754
4672/4713 [============================>.] - ETA: 0s - loss: 0.2823 - acc: 0.8750
4713/4713 [==============================] - 3s 652us/step - loss: 0.2829 - acc: 0.8750

Test accuracy: 88.3629191321499

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  251

choose_one :  256

F1score :  0.8840864440078585

AUC :  0.946671438797423

Confusion Matrix
[[223  31]
 [ 28 225]]
True label 0
0.8779527559055118  
0.1220472440944882  
True label 1
0.11067193675889328  
0.8893280632411067  

Train_result {'loss': [0.28287758266700697], 'acc': [0.8750265223595991]}
Saved model to disk


14

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2863 - acc: 0.8906
 128/4713 [..............................] - ETA: 3s - loss: 0.3028 - acc: 0.8672
 256/4713 [>.............................] - ETA: 3s - loss: 0.2918 - acc: 0.8750
 384/4713 [=>............................] - ETA: 3s - loss: 0.2997 - acc: 0.8750
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3294 - acc: 0.8574
 640/4713 [===>..........................] - ETA: 2s - loss: 0.3315 - acc: 0.8516
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3325 - acc: 0.8490
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3138 - acc: 0.8627
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3153 - acc: 0.8643
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3110 - acc: 0.8672
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3042 - acc: 0.8688
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3020 - acc: 0.8700
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3050 - acc: 0.8659
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3058 - acc: 0.8666
1792/4713 [==========>...................] - ETA: 1s - loss: 0.3040 - acc: 0.8694
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3022 - acc: 0.8703
2048/4713 [============>.................] - ETA: 1s - loss: 0.2987 - acc: 0.8721
2176/4713 [============>.................] - ETA: 1s - loss: 0.2996 - acc: 0.8722
2304/4713 [=============>................] - ETA: 1s - loss: 0.2978 - acc: 0.8724
2432/4713 [==============>...............] - ETA: 1s - loss: 0.2950 - acc: 0.8734
2560/4713 [===============>..............] - ETA: 1s - loss: 0.2915 - acc: 0.8742
2688/4713 [================>.............] - ETA: 1s - loss: 0.2912 - acc: 0.8739
2816/4713 [================>.............] - ETA: 1s - loss: 0.2895 - acc: 0.8757
2944/4713 [=================>............] - ETA: 1s - loss: 0.2879 - acc: 0.8753
3072/4713 [==================>...........] - ETA: 1s - loss: 0.2873 - acc: 0.8760
3200/4713 [===================>..........] - ETA: 0s - loss: 0.2885 - acc: 0.8744
3328/4713 [====================>.........] - ETA: 0s - loss: 0.2872 - acc: 0.8753
3456/4713 [====================>.........] - ETA: 0s - loss: 0.2863 - acc: 0.8759
3584/4713 [=====================>........] - ETA: 0s - loss: 0.2855 - acc: 0.8764
3712/4713 [======================>.......] - ETA: 0s - loss: 0.2849 - acc: 0.8761
3840/4713 [=======================>......] - ETA: 0s - loss: 0.2835 - acc: 0.8758
3968/4713 [========================>.....] - ETA: 0s - loss: 0.2807 - acc: 0.8780
4096/4713 [=========================>....] - ETA: 0s - loss: 0.2827 - acc: 0.8770
4224/4713 [=========================>....] - ETA: 0s - loss: 0.2813 - acc: 0.8771
4352/4713 [==========================>...] - ETA: 0s - loss: 0.2788 - acc: 0.8784
4480/4713 [===========================>..] - ETA: 0s - loss: 0.2782 - acc: 0.8783
4608/4713 [============================>.] - ETA: 0s - loss: 0.2781 - acc: 0.8783
4713/4713 [==============================] - 3s 646us/step - loss: 0.2790 - acc: 0.8778

Test accuracy: 86.78500986193293

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  263

choose_one :  244

F1score :  0.8651911468812876

AUC :  0.9461034514954405

Confusion Matrix
[[225  29]
 [ 38 215]]
True label 0
0.8858267716535433  
0.1141732283464567  
True label 1
0.15019762845849802  
0.849802371541502  

Train_result {'loss': [0.27901863305021846], 'acc': [0.8777848502746337]}
Saved model to disk


15

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.1538 - acc: 0.9375
 128/4713 [..............................] - ETA: 3s - loss: 0.2286 - acc: 0.8906
 256/4713 [>.............................] - ETA: 3s - loss: 0.2389 - acc: 0.9023
 384/4713 [=>............................] - ETA: 3s - loss: 0.2586 - acc: 0.8932
 512/4713 [==>...........................] - ETA: 3s - loss: 0.2638 - acc: 0.8906
 640/4713 [===>..........................] - ETA: 2s - loss: 0.2593 - acc: 0.8875
 768/4713 [===>..........................] - ETA: 2s - loss: 0.2588 - acc: 0.8841
 896/4713 [====>.........................] - ETA: 2s - loss: 0.2664 - acc: 0.8817
1024/4713 [=====>........................] - ETA: 2s - loss: 0.2638 - acc: 0.8848
1152/4713 [======>.......................] - ETA: 2s - loss: 0.2632 - acc: 0.8828
1280/4713 [=======>......................] - ETA: 2s - loss: 0.2735 - acc: 0.8812
1408/4713 [=======>......................] - ETA: 2s - loss: 0.2691 - acc: 0.8800
1536/4713 [========>.....................] - ETA: 2s - loss: 0.2699 - acc: 0.8802
1664/4713 [=========>....................] - ETA: 2s - loss: 0.2721 - acc: 0.8804
1792/4713 [==========>...................] - ETA: 2s - loss: 0.2738 - acc: 0.8795
1920/4713 [===========>..................] - ETA: 1s - loss: 0.2763 - acc: 0.8771
2048/4713 [============>.................] - ETA: 1s - loss: 0.2767 - acc: 0.8765
2176/4713 [============>.................] - ETA: 1s - loss: 0.2770 - acc: 0.8778
2304/4713 [=============>................] - ETA: 1s - loss: 0.2780 - acc: 0.8793
2432/4713 [==============>...............] - ETA: 1s - loss: 0.2779 - acc: 0.8787
2560/4713 [===============>..............] - ETA: 1s - loss: 0.2769 - acc: 0.8781
2688/4713 [================>.............] - ETA: 1s - loss: 0.2809 - acc: 0.8787
2816/4713 [================>.............] - ETA: 1s - loss: 0.2806 - acc: 0.8786
2944/4713 [=================>............] - ETA: 1s - loss: 0.2812 - acc: 0.8770
3072/4713 [==================>...........] - ETA: 1s - loss: 0.2810 - acc: 0.8760
3200/4713 [===================>..........] - ETA: 0s - loss: 0.2821 - acc: 0.8756
3328/4713 [====================>.........] - ETA: 0s - loss: 0.2807 - acc: 0.8762
3456/4713 [====================>.........] - ETA: 0s - loss: 0.2795 - acc: 0.8756
3584/4713 [=====================>........] - ETA: 0s - loss: 0.2789 - acc: 0.8753
3712/4713 [======================>.......] - ETA: 0s - loss: 0.2762 - acc: 0.8766
3840/4713 [=======================>......] - ETA: 0s - loss: 0.2752 - acc: 0.8779
3968/4713 [========================>.....] - ETA: 0s - loss: 0.2755 - acc: 0.8768
4096/4713 [=========================>....] - ETA: 0s - loss: 0.2767 - acc: 0.8760
4224/4713 [=========================>....] - ETA: 0s - loss: 0.2783 - acc: 0.8750
4352/4713 [==========================>...] - ETA: 0s - loss: 0.2780 - acc: 0.8752
4480/4713 [===========================>..] - ETA: 0s - loss: 0.2790 - acc: 0.8754
4608/4713 [============================>.] - ETA: 0s - loss: 0.2792 - acc: 0.8761
4713/4713 [==============================] - 3s 650us/step - loss: 0.2789 - acc: 0.8761

Test accuracy: 87.17948717948718

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  251

choose_one :  256

F1score :  0.8722986247544204

AUC :  0.9443605863496312

Confusion Matrix
[[220  34]
 [ 31 222]]
True label 0
0.8661417322834646  
0.13385826771653545  
True label 1
0.1225296442687747  
0.8774703557312253  

Train_result {'loss': [0.27891512713739885], 'acc': [0.8760874177553131]}
Saved model to disk


[[85.00986193293886, 1], [85.60157790927022, 2], [86.78500986193293, 3], [85.99605522682445, 4], [86.98224852071006, 5], [86.98224852071006, 6], [87.96844181459566, 7], [87.3767258382643, 8], [86.58777120315581, 9], [87.77120315581854, 10], [86.78500986193293, 11], [86.19329388560158, 12], [88.3629191321499, 13], [86.78500986193293, 14], [87.17948717948718, 15]]
max accuracy :  [88.3629191321499, 13]
