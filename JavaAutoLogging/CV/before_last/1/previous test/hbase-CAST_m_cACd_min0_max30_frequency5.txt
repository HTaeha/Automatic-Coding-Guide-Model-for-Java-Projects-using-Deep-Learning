Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
/home/2014313303/taeha/JavaAutoLogging/model.py:154: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor("ou..., inputs=[<tf.Tenso...)`
  model = Model(input=[input1, input2, input3, input4], output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-10 03:04:09.153278: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-10 03:04:09.161485: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099840000 Hz
2019-09-10 03:04:09.163435: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x172da840 executing computations on platform Host. Devices:
2019-09-10 03:04:09.163505: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Standard data
zero :  39451
one :  9019

First data
zero :  39451
one :  9019

Second data
zero :  39451
one :  9019

Third data
zero :  39451
one :  9019

4th data
zero :  39451
one :  9019

hbase-code
After set document size of train data, the number of zero and one label data :  23525 1507
After set document size of test data, the number of zero and one label data :  2614 166

Sentence length Average : 13

Under 10 : 9590
Over 10, Under 30 : 18222
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

After balance out data.
hbase-code

Sentence length Average : 14

Under 10 : 1039
Over 10, Under 30 : 2309
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

hbase-AST
After set document size of train data, the number of zero and one label data :  23525 1507
After set document size of test data, the number of zero and one label data :  2614 166
After balance out data.
hbase-AST

Sentence length Average : 9

Under 10 : 2145
Over 10, Under 30 : 1168
Over 30, Under 100 : 25
Over 100, Under 150 : 3
Over 150, Under 200 : 2
Over 200, Under 400 : 3
Over 400 : 2

hbase-CAST
After set document size of train data, the number of zero and one label data :  23525 1507
After set document size of test data, the number of zero and one label data :  2614 166
After balance out data.
hbase-CAST

Sentence length Average : 23

Under 10 : 923
Over 10, Under 30 : 1585
Over 30, Under 100 : 823
Over 100, Under 150 : 2
Over 150, Under 200 : 1
Over 200, Under 400 : 9
Over 400 : 5

hbase-depth_num
After set document size of train data, the number of zero and one label data :  23525 1507
After set document size of test data, the number of zero and one label data :  2614 166
After balance out data.
hbase-depth_num

Sentence length Average : 9

Under 10 : 2145
Over 10, Under 30 : 1168
Over 30, Under 100 : 25
Over 100, Under 150 : 3
Over 150, Under 200 : 2
Over 200, Under 400 : 3
Over 400 : 2

Count model parameter.
Get a short summary of each layer dimensions and parameters.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 30, 200)      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 60, 200)      0                                            
__________________________________________________________________________________________________
masking_1 (Masking)             (None, 30, 200)      0           input_1[0][0]                    
__________________________________________________________________________________________________
masking_2 (Masking)             (None, 60, 200)      0           input_2[0][0]                    
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 90, 200)      0                                            
__________________________________________________________________________________________________
forwards_1 (LSTM)               (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
backwords_1 (LSTM)              (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
forwards_2 (LSTM)               (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
backwards_2 (LSTM)              (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
masking_3 (Masking)             (None, 90, 200)      0           input_3[0][0]                    
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 60, 200)      0                                            
__________________________________________________________________________________________________
after_dp_forward_1 (Dropout)    (None, 64)           0           forwards_1[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_1 (Dropout)   (None, 64)           0           backwords_1[0][0]                
__________________________________________________________________________________________________
after_dp_forward_2 (Dropout)    (None, 64)           0           forwards_2[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_2 (Dropout)   (None, 64)           0           backwards_2[0][0]                
__________________________________________________________________________________________________
forwards_3 (LSTM)               (None, 64)           67840       masking_3[0][0]                  
__________________________________________________________________________________________________
backwards_3 (LSTM)              (None, 64)           67840       masking_3[0][0]                  
__________________________________________________________________________________________________
masking_4 (Masking)             (None, 60, 200)      0           input_4[0][0]                    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128)          0           after_dp_forward_1[0][0]         
                                                                 after_dp_backward_1[0][0]        
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 128)          0           after_dp_forward_2[0][0]         
                                                                 after_dp_backward_2[0][0]        
__________________________________________________________________________________________________
after_dp_forward_3 (Dropout)    (None, 64)           0           forwards_3[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_3 (Dropout)   (None, 64)           0           backwards_3[0][0]                
__________________________________________________________________________________________________
forwards_4 (LSTM)               (None, 64)           67840       masking_4[0][0]                  
__________________________________________________________________________________________________
backwards_4 (LSTM)              (None, 64)           67840       masking_4[0][0]                  
__________________________________________________________________________________________________
after_dp_1 (Dropout)            (None, 128)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
after_dp_2 (Dropout)            (None, 128)          0           concatenate_2[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 128)          0           after_dp_forward_3[0][0]         
                                                                 after_dp_backward_3[0][0]        
__________________________________________________________________________________________________
after_dp_forward_4 (Dropout)    (None, 64)           0           forwards_4[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_4 (Dropout)   (None, 64)           0           backwards_4[0][0]                
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 256)          0           after_dp_1[0][0]                 
                                                                 after_dp_2[0][0]                 
__________________________________________________________________________________________________
after_dp_3 (Dropout)            (None, 128)          0           concatenate_3[0][0]              
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 128)          0           after_dp_forward_4[0][0]         
                                                                 after_dp_backward_4[0][0]        
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 384)          0           concatenate_5[0][0]              
                                                                 after_dp_3[0][0]                 
__________________________________________________________________________________________________
after_dp_4 (Dropout)            (None, 128)          0           concatenate_4[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 512)          0           concatenate_6[0][0]              
                                                                 after_dp_4[0][0]                 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          262656      concatenate_7[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 768)          393984      dense_1[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 512)          393728      dense_2[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 256)          131328      dense_3[0][0]                    
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 128)          32896       dense_4[0][0]                    
__________________________________________________________________________________________________
output (Dense)                  (None, 2)            258         dense_5[0][0]                    
==================================================================================================
Total params: 1,757,570
Trainable params: 1,757,570
Non-trainable params: 0
__________________________________________________________________________________________________
1

Epoch 1/1

  64/3015 [..............................] - ETA: 6:18 - loss: 0.6959 - acc: 0.4688
 128/3015 [>.............................] - ETA: 3:12 - loss: 0.6733 - acc: 0.5469
 192/3015 [>.............................] - ETA: 2:08 - loss: 0.6720 - acc: 0.5521
 256/3015 [=>............................] - ETA: 1:35 - loss: 0.6703 - acc: 0.5469
 320/3015 [==>...........................] - ETA: 1:16 - loss: 0.6523 - acc: 0.5750
 384/3015 [==>...........................] - ETA: 1:03 - loss: 0.6406 - acc: 0.5807
 448/3015 [===>..........................] - ETA: 53s - loss: 0.6325 - acc: 0.6027 
 512/3015 [====>.........................] - ETA: 47s - loss: 0.6141 - acc: 0.6250
 576/3015 [====>.........................] - ETA: 42s - loss: 0.5961 - acc: 0.6389
 640/3015 [=====>........................] - ETA: 38s - loss: 0.6015 - acc: 0.6406
 704/3015 [======>.......................] - ETA: 34s - loss: 0.5880 - acc: 0.6548
 768/3015 [======>.......................] - ETA: 31s - loss: 0.5701 - acc: 0.6745
 832/3015 [=======>......................] - ETA: 29s - loss: 0.5450 - acc: 0.6935
 896/3015 [=======>......................] - ETA: 26s - loss: 0.5228 - acc: 0.7121
 960/3015 [========>.....................] - ETA: 24s - loss: 0.5144 - acc: 0.7208
1024/3015 [=========>....................] - ETA: 22s - loss: 0.4969 - acc: 0.7324
1088/3015 [=========>....................] - ETA: 20s - loss: 0.4934 - acc: 0.7371
1152/3015 [==========>...................] - ETA: 19s - loss: 0.4927 - acc: 0.7413
1216/3015 [===========>..................] - ETA: 18s - loss: 0.4910 - acc: 0.7434
1280/3015 [===========>..................] - ETA: 17s - loss: 0.4783 - acc: 0.7508
1344/3015 [============>.................] - ETA: 15s - loss: 0.4759 - acc: 0.7545
1408/3015 [=============>................] - ETA: 14s - loss: 0.4681 - acc: 0.7599
1472/3015 [=============>................] - ETA: 13s - loss: 0.4621 - acc: 0.7670
1536/3015 [==============>...............] - ETA: 13s - loss: 0.4577 - acc: 0.7708
1600/3015 [==============>...............] - ETA: 12s - loss: 0.4549 - acc: 0.7731
1664/3015 [===============>..............] - ETA: 11s - loss: 0.4519 - acc: 0.7752
1728/3015 [================>.............] - ETA: 10s - loss: 0.4476 - acc: 0.7795
1792/3015 [================>.............] - ETA: 9s - loss: 0.4497 - acc: 0.7785 
1856/3015 [=================>............] - ETA: 8s - loss: 0.4424 - acc: 0.7823
1920/3015 [==================>...........] - ETA: 8s - loss: 0.4377 - acc: 0.7844
1984/3015 [==================>...........] - ETA: 7s - loss: 0.4339 - acc: 0.7868
2048/3015 [===================>..........] - ETA: 7s - loss: 0.4295 - acc: 0.7905
2112/3015 [====================>.........] - ETA: 6s - loss: 0.4275 - acc: 0.7940
2176/3015 [====================>.........] - ETA: 6s - loss: 0.4211 - acc: 0.7973
2240/3015 [=====================>........] - ETA: 5s - loss: 0.4180 - acc: 0.7982
2304/3015 [=====================>........] - ETA: 5s - loss: 0.4129 - acc: 0.8008
2368/3015 [======================>.......] - ETA: 4s - loss: 0.4089 - acc: 0.8028
2432/3015 [=======================>......] - ETA: 3s - loss: 0.4072 - acc: 0.8047
2496/3015 [=======================>......] - ETA: 3s - loss: 0.4044 - acc: 0.8073
2560/3015 [========================>.....] - ETA: 3s - loss: 0.4015 - acc: 0.8098
2624/3015 [=========================>....] - ETA: 2s - loss: 0.3988 - acc: 0.8110
2688/3015 [=========================>....] - ETA: 2s - loss: 0.3992 - acc: 0.8106
2752/3015 [==========================>...] - ETA: 1s - loss: 0.3980 - acc: 0.8110
2816/3015 [===========================>..] - ETA: 1s - loss: 0.4016 - acc: 0.8097
2880/3015 [===========================>..] - ETA: 0s - loss: 0.3980 - acc: 0.8122
2944/3015 [============================>.] - ETA: 0s - loss: 0.3968 - acc: 0.8139
3008/3015 [============================>.] - ETA: 0s - loss: 0.3945 - acc: 0.8155
3015/3015 [==============================] - 19s 6ms/step - loss: 0.3941 - acc: 0.8159

Test accuracy: 87.08708708708708

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  144

choose_one :  189

F1score :  0.8788732394366198

AUC :  0.9535747781545344

Confusion Matrix
[[134  33]
 [ 10 156]]
True label 0
0.8023952095808383  
0.19760479041916168  
True label 1
0.060240963855421686  
0.9397590361445783  

Train_result {'loss': [0.39408358368114454], 'acc': [0.8159203980099502]}
Saved model to disk


2

Epoch 1/1

  64/3015 [..............................] - ETA: 19s - loss: 0.3033 - acc: 0.8906
 128/3015 [>.............................] - ETA: 14s - loss: 0.2479 - acc: 0.8984
 192/3015 [>.............................] - ETA: 11s - loss: 0.3175 - acc: 0.8698
 256/3015 [=>............................] - ETA: 11s - loss: 0.3199 - acc: 0.8672
 320/3015 [==>...........................] - ETA: 11s - loss: 0.3429 - acc: 0.8562
 384/3015 [==>...........................] - ETA: 10s - loss: 0.3474 - acc: 0.8542
 448/3015 [===>..........................] - ETA: 9s - loss: 0.3760 - acc: 0.8415 
 512/3015 [====>.........................] - ETA: 8s - loss: 0.3650 - acc: 0.8418
 576/3015 [====>.........................] - ETA: 8s - loss: 0.3531 - acc: 0.8472
 640/3015 [=====>........................] - ETA: 8s - loss: 0.3494 - acc: 0.8500
 704/3015 [======>.......................] - ETA: 8s - loss: 0.3435 - acc: 0.8551
 768/3015 [======>.......................] - ETA: 8s - loss: 0.3417 - acc: 0.8594
 832/3015 [=======>......................] - ETA: 8s - loss: 0.3343 - acc: 0.8642
 896/3015 [=======>......................] - ETA: 7s - loss: 0.3366 - acc: 0.8627
 960/3015 [========>.....................] - ETA: 7s - loss: 0.3298 - acc: 0.8635
1024/3015 [=========>....................] - ETA: 7s - loss: 0.3265 - acc: 0.8643
1088/3015 [=========>....................] - ETA: 7s - loss: 0.3206 - acc: 0.8676
1152/3015 [==========>...................] - ETA: 6s - loss: 0.3210 - acc: 0.8689
1216/3015 [===========>..................] - ETA: 6s - loss: 0.3184 - acc: 0.8725
1280/3015 [===========>..................] - ETA: 6s - loss: 0.3131 - acc: 0.8742
1344/3015 [============>.................] - ETA: 5s - loss: 0.3164 - acc: 0.8735
1408/3015 [=============>................] - ETA: 5s - loss: 0.3223 - acc: 0.8700
1472/3015 [=============>................] - ETA: 5s - loss: 0.3220 - acc: 0.8696
1536/3015 [==============>...............] - ETA: 5s - loss: 0.3177 - acc: 0.8711
1600/3015 [==============>...............] - ETA: 5s - loss: 0.3172 - acc: 0.8712
1664/3015 [===============>..............] - ETA: 5s - loss: 0.3145 - acc: 0.8738
1728/3015 [================>.............] - ETA: 4s - loss: 0.3136 - acc: 0.8750
1792/3015 [================>.............] - ETA: 4s - loss: 0.3114 - acc: 0.8750
1856/3015 [=================>............] - ETA: 4s - loss: 0.3070 - acc: 0.8766
1920/3015 [==================>...........] - ETA: 3s - loss: 0.3101 - acc: 0.8755
1984/3015 [==================>...........] - ETA: 3s - loss: 0.3093 - acc: 0.8755
2048/3015 [===================>..........] - ETA: 3s - loss: 0.3053 - acc: 0.8774
2112/3015 [====================>.........] - ETA: 3s - loss: 0.3020 - acc: 0.8793
2176/3015 [====================>.........] - ETA: 3s - loss: 0.2997 - acc: 0.8805
2240/3015 [=====================>........] - ETA: 2s - loss: 0.3008 - acc: 0.8795
2304/3015 [=====================>........] - ETA: 2s - loss: 0.3016 - acc: 0.8789
2368/3015 [======================>.......] - ETA: 2s - loss: 0.3020 - acc: 0.8784
2432/3015 [=======================>......] - ETA: 2s - loss: 0.3059 - acc: 0.8766
2496/3015 [=======================>......] - ETA: 1s - loss: 0.3072 - acc: 0.8762
2560/3015 [========================>.....] - ETA: 1s - loss: 0.3088 - acc: 0.8750
2624/3015 [=========================>....] - ETA: 1s - loss: 0.3064 - acc: 0.8761
2688/3015 [=========================>....] - ETA: 1s - loss: 0.3073 - acc: 0.8743
2752/3015 [==========================>...] - ETA: 0s - loss: 0.3056 - acc: 0.8739
2816/3015 [===========================>..] - ETA: 0s - loss: 0.3038 - acc: 0.8750
2880/3015 [===========================>..] - ETA: 0s - loss: 0.3033 - acc: 0.8740
2944/3015 [============================>.] - ETA: 0s - loss: 0.3062 - acc: 0.8730
3008/3015 [============================>.] - ETA: 0s - loss: 0.3055 - acc: 0.8737
3015/3015 [==============================] - 11s 4ms/step - loss: 0.3050 - acc: 0.8740

Test accuracy: 88.58858858858859

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  147

choose_one :  186

F1score :  0.8920454545454547

AUC :  0.9591660053387202

Confusion Matrix
[[138  29]
 [  9 157]]
True label 0
0.8263473053892215  
0.17365269461077845  
True label 1
0.05421686746987952  
0.9457831325301205  

Train_result {'loss': [0.3049977153440811], 'acc': [0.8739635157545605]}
Saved model to disk


3

Epoch 1/1

  64/3015 [..............................] - ETA: 18s - loss: 0.3124 - acc: 0.8594
 128/3015 [>.............................] - ETA: 16s - loss: 0.2698 - acc: 0.8906
 192/3015 [>.............................] - ETA: 13s - loss: 0.2461 - acc: 0.9062
 256/3015 [=>............................] - ETA: 11s - loss: 0.2683 - acc: 0.8867
 320/3015 [==>...........................] - ETA: 10s - loss: 0.2473 - acc: 0.8969
 384/3015 [==>...........................] - ETA: 10s - loss: 0.2738 - acc: 0.8906
 448/3015 [===>..........................] - ETA: 10s - loss: 0.2644 - acc: 0.8906
 512/3015 [====>.........................] - ETA: 9s - loss: 0.2638 - acc: 0.8867 
 576/3015 [====>.........................] - ETA: 8s - loss: 0.2546 - acc: 0.8889
 640/3015 [=====>........................] - ETA: 8s - loss: 0.2571 - acc: 0.8906
 704/3015 [======>.......................] - ETA: 7s - loss: 0.2504 - acc: 0.8949
 768/3015 [======>.......................] - ETA: 8s - loss: 0.2487 - acc: 0.8971
 832/3015 [=======>......................] - ETA: 8s - loss: 0.2434 - acc: 0.8990
 896/3015 [=======>......................] - ETA: 7s - loss: 0.2590 - acc: 0.8951
 960/3015 [========>.....................] - ETA: 7s - loss: 0.2583 - acc: 0.8938
1024/3015 [=========>....................] - ETA: 7s - loss: 0.2587 - acc: 0.8926
1088/3015 [=========>....................] - ETA: 7s - loss: 0.2562 - acc: 0.8952
1152/3015 [==========>...................] - ETA: 6s - loss: 0.2602 - acc: 0.8924
1216/3015 [===========>..................] - ETA: 6s - loss: 0.2638 - acc: 0.8914
1280/3015 [===========>..................] - ETA: 6s - loss: 0.2608 - acc: 0.8914
1344/3015 [============>.................] - ETA: 5s - loss: 0.2622 - acc: 0.8899
1408/3015 [=============>................] - ETA: 5s - loss: 0.2634 - acc: 0.8878
1472/3015 [=============>................] - ETA: 5s - loss: 0.2625 - acc: 0.8886
1536/3015 [==============>...............] - ETA: 5s - loss: 0.2667 - acc: 0.8874
1600/3015 [==============>...............] - ETA: 5s - loss: 0.2694 - acc: 0.8869
1664/3015 [===============>..............] - ETA: 4s - loss: 0.2741 - acc: 0.8852
1728/3015 [================>.............] - ETA: 4s - loss: 0.2754 - acc: 0.8843
1792/3015 [================>.............] - ETA: 4s - loss: 0.2733 - acc: 0.8856
1856/3015 [=================>............] - ETA: 4s - loss: 0.2738 - acc: 0.8842
1920/3015 [==================>...........] - ETA: 3s - loss: 0.2713 - acc: 0.8854
1984/3015 [==================>...........] - ETA: 3s - loss: 0.2709 - acc: 0.8856
2048/3015 [===================>..........] - ETA: 3s - loss: 0.2730 - acc: 0.8838
2112/3015 [====================>.........] - ETA: 3s - loss: 0.2690 - acc: 0.8859
2176/3015 [====================>.........] - ETA: 3s - loss: 0.2703 - acc: 0.8856
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2705 - acc: 0.8848
2304/3015 [=====================>........] - ETA: 2s - loss: 0.2687 - acc: 0.8850
2368/3015 [======================>.......] - ETA: 2s - loss: 0.2657 - acc: 0.8864
2432/3015 [=======================>......] - ETA: 2s - loss: 0.2632 - acc: 0.8869
2496/3015 [=======================>......] - ETA: 1s - loss: 0.2598 - acc: 0.8878
2560/3015 [========================>.....] - ETA: 1s - loss: 0.2591 - acc: 0.8879
2624/3015 [=========================>....] - ETA: 1s - loss: 0.2586 - acc: 0.8880
2688/3015 [=========================>....] - ETA: 1s - loss: 0.2605 - acc: 0.8876
2752/3015 [==========================>...] - ETA: 0s - loss: 0.2644 - acc: 0.8874
2816/3015 [===========================>..] - ETA: 0s - loss: 0.2638 - acc: 0.8878
2880/3015 [===========================>..] - ETA: 0s - loss: 0.2635 - acc: 0.8882
2944/3015 [============================>.] - ETA: 0s - loss: 0.2625 - acc: 0.8882
3008/3015 [============================>.] - ETA: 0s - loss: 0.2612 - acc: 0.8890
3015/3015 [==============================] - 11s 4ms/step - loss: 0.2612 - acc: 0.8889

Test accuracy: 90.09009009009009

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  156

choose_one :  177

F1score :  0.9037900874635568

AUC :  0.9627732486833562

Confusion Matrix
[[145  22]
 [ 11 155]]
True label 0
0.8682634730538922  
0.1317365269461078  
True label 1
0.06626506024096386  
0.9337349397590361  

Train_result {'loss': [0.26118681581063846], 'acc': [0.8888888889086582]}
Saved model to disk


4

Epoch 1/1

  64/3015 [..............................] - ETA: 18s - loss: 0.2778 - acc: 0.9219
 128/3015 [>.............................] - ETA: 15s - loss: 0.2396 - acc: 0.8984
 192/3015 [>.............................] - ETA: 14s - loss: 0.2208 - acc: 0.9115
 256/3015 [=>............................] - ETA: 13s - loss: 0.2187 - acc: 0.9062
 320/3015 [==>...........................] - ETA: 11s - loss: 0.2074 - acc: 0.9094
 384/3015 [==>...........................] - ETA: 11s - loss: 0.2128 - acc: 0.9115
 448/3015 [===>..........................] - ETA: 11s - loss: 0.2099 - acc: 0.9107
 512/3015 [====>.........................] - ETA: 10s - loss: 0.2247 - acc: 0.9062
 576/3015 [====>.........................] - ETA: 9s - loss: 0.2116 - acc: 0.9115 
 640/3015 [=====>........................] - ETA: 8s - loss: 0.2075 - acc: 0.9125
 704/3015 [======>.......................] - ETA: 8s - loss: 0.2172 - acc: 0.9091
 768/3015 [======>.......................] - ETA: 8s - loss: 0.2146 - acc: 0.9102
 832/3015 [=======>......................] - ETA: 8s - loss: 0.2157 - acc: 0.9087
 896/3015 [=======>......................] - ETA: 8s - loss: 0.2058 - acc: 0.9141
 960/3015 [========>.....................] - ETA: 7s - loss: 0.2079 - acc: 0.9146
1024/3015 [=========>....................] - ETA: 7s - loss: 0.2059 - acc: 0.9150
1088/3015 [=========>....................] - ETA: 7s - loss: 0.2082 - acc: 0.9136
1152/3015 [==========>...................] - ETA: 7s - loss: 0.2191 - acc: 0.9106
1216/3015 [===========>..................] - ETA: 6s - loss: 0.2166 - acc: 0.9112
1280/3015 [===========>..................] - ETA: 6s - loss: 0.2206 - acc: 0.9078
1344/3015 [============>.................] - ETA: 6s - loss: 0.2214 - acc: 0.9055
1408/3015 [=============>................] - ETA: 5s - loss: 0.2257 - acc: 0.9034
1472/3015 [=============>................] - ETA: 5s - loss: 0.2263 - acc: 0.9049
1536/3015 [==============>...............] - ETA: 5s - loss: 0.2281 - acc: 0.9017
1600/3015 [==============>...............] - ETA: 5s - loss: 0.2322 - acc: 0.9006
1664/3015 [===============>..............] - ETA: 5s - loss: 0.2317 - acc: 0.9008
1728/3015 [================>.............] - ETA: 4s - loss: 0.2325 - acc: 0.8999
1792/3015 [================>.............] - ETA: 4s - loss: 0.2315 - acc: 0.9012
1856/3015 [=================>............] - ETA: 4s - loss: 0.2347 - acc: 0.8998
1920/3015 [==================>...........] - ETA: 4s - loss: 0.2354 - acc: 0.8990
1984/3015 [==================>...........] - ETA: 3s - loss: 0.2329 - acc: 0.9002
2048/3015 [===================>..........] - ETA: 3s - loss: 0.2386 - acc: 0.8989
2112/3015 [====================>.........] - ETA: 3s - loss: 0.2394 - acc: 0.8996
2176/3015 [====================>.........] - ETA: 3s - loss: 0.2390 - acc: 0.8994
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2357 - acc: 0.9009
2304/3015 [=====================>........] - ETA: 2s - loss: 0.2329 - acc: 0.9023
2368/3015 [======================>.......] - ETA: 2s - loss: 0.2346 - acc: 0.9016
2432/3015 [=======================>......] - ETA: 2s - loss: 0.2402 - acc: 0.9001
2496/3015 [=======================>......] - ETA: 1s - loss: 0.2409 - acc: 0.8998
2560/3015 [========================>.....] - ETA: 1s - loss: 0.2399 - acc: 0.9004
2624/3015 [=========================>....] - ETA: 1s - loss: 0.2386 - acc: 0.9005
2688/3015 [=========================>....] - ETA: 1s - loss: 0.2387 - acc: 0.9010
2752/3015 [==========================>...] - ETA: 0s - loss: 0.2377 - acc: 0.9012
2816/3015 [===========================>..] - ETA: 0s - loss: 0.2357 - acc: 0.9027
2880/3015 [===========================>..] - ETA: 0s - loss: 0.2355 - acc: 0.9021
2944/3015 [============================>.] - ETA: 0s - loss: 0.2369 - acc: 0.9022
3008/3015 [============================>.] - ETA: 0s - loss: 0.2371 - acc: 0.9016
3015/3015 [==============================] - 11s 4ms/step - loss: 0.2371 - acc: 0.9018

Test accuracy: 91.29129129129129

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  168

choose_one :  165

F1score :  0.9123867069486404

AUC :  0.9664526368948849

Confusion Matrix
[[153  14]
 [ 15 151]]
True label 0
0.9161676646706587  
0.08383233532934131  
True label 1
0.09036144578313253  
0.9096385542168675  

Train_result {'loss': [0.2370504010326629], 'acc': [0.9018242122719735]}
Saved model to disk


5

Epoch 1/1

  64/3015 [..............................] - ETA: 12s - loss: 0.1958 - acc: 0.8906
 128/3015 [>.............................] - ETA: 13s - loss: 0.2033 - acc: 0.8984
 192/3015 [>.............................] - ETA: 13s - loss: 0.1938 - acc: 0.9062
 256/3015 [=>............................] - ETA: 12s - loss: 0.2012 - acc: 0.9023
 320/3015 [==>...........................] - ETA: 11s - loss: 0.1808 - acc: 0.9156
 384/3015 [==>...........................] - ETA: 11s - loss: 0.1943 - acc: 0.9141
 448/3015 [===>..........................] - ETA: 10s - loss: 0.1962 - acc: 0.9129
 512/3015 [====>.........................] - ETA: 9s - loss: 0.2161 - acc: 0.9062 
 576/3015 [====>.........................] - ETA: 9s - loss: 0.2097 - acc: 0.9080
 640/3015 [=====>........................] - ETA: 8s - loss: 0.2068 - acc: 0.9078
 704/3015 [======>.......................] - ETA: 8s - loss: 0.2009 - acc: 0.9091
 768/3015 [======>.......................] - ETA: 8s - loss: 0.2113 - acc: 0.9036
 832/3015 [=======>......................] - ETA: 8s - loss: 0.2145 - acc: 0.9014
 896/3015 [=======>......................] - ETA: 7s - loss: 0.2125 - acc: 0.9029
 960/3015 [========>.....................] - ETA: 7s - loss: 0.2099 - acc: 0.9073
1024/3015 [=========>....................] - ETA: 7s - loss: 0.2075 - acc: 0.9092
1088/3015 [=========>....................] - ETA: 6s - loss: 0.2056 - acc: 0.9108
1152/3015 [==========>...................] - ETA: 6s - loss: 0.2044 - acc: 0.9106
1216/3015 [===========>..................] - ETA: 6s - loss: 0.2099 - acc: 0.9112
1280/3015 [===========>..................] - ETA: 6s - loss: 0.2132 - acc: 0.9086
1344/3015 [============>.................] - ETA: 5s - loss: 0.2165 - acc: 0.9070
1408/3015 [=============>................] - ETA: 5s - loss: 0.2264 - acc: 0.9020
1472/3015 [=============>................] - ETA: 5s - loss: 0.2296 - acc: 0.9001
1536/3015 [==============>...............] - ETA: 5s - loss: 0.2253 - acc: 0.9023
1600/3015 [==============>...............] - ETA: 5s - loss: 0.2296 - acc: 0.9000
1664/3015 [===============>..............] - ETA: 4s - loss: 0.2268 - acc: 0.9026
1728/3015 [================>.............] - ETA: 4s - loss: 0.2273 - acc: 0.9016
1792/3015 [================>.............] - ETA: 4s - loss: 0.2282 - acc: 0.9018
1856/3015 [=================>............] - ETA: 4s - loss: 0.2271 - acc: 0.9019
1920/3015 [==================>...........] - ETA: 3s - loss: 0.2251 - acc: 0.9036
1984/3015 [==================>...........] - ETA: 3s - loss: 0.2238 - acc: 0.9027
2048/3015 [===================>..........] - ETA: 3s - loss: 0.2209 - acc: 0.9043
2112/3015 [====================>.........] - ETA: 3s - loss: 0.2179 - acc: 0.9053
2176/3015 [====================>.........] - ETA: 2s - loss: 0.2183 - acc: 0.9053
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2161 - acc: 0.9062
2304/3015 [=====================>........] - ETA: 2s - loss: 0.2168 - acc: 0.9058
2368/3015 [======================>.......] - ETA: 2s - loss: 0.2145 - acc: 0.9062
2432/3015 [=======================>......] - ETA: 2s - loss: 0.2178 - acc: 0.9054
2496/3015 [=======================>......] - ETA: 1s - loss: 0.2155 - acc: 0.9067
2560/3015 [========================>.....] - ETA: 1s - loss: 0.2173 - acc: 0.9059
2624/3015 [=========================>....] - ETA: 1s - loss: 0.2150 - acc: 0.9070
2688/3015 [=========================>....] - ETA: 1s - loss: 0.2192 - acc: 0.9055
2752/3015 [==========================>...] - ETA: 0s - loss: 0.2192 - acc: 0.9059
2816/3015 [===========================>..] - ETA: 0s - loss: 0.2197 - acc: 0.9055
2880/3015 [===========================>..] - ETA: 0s - loss: 0.2188 - acc: 0.9066
2944/3015 [============================>.] - ETA: 0s - loss: 0.2178 - acc: 0.9073
3008/3015 [============================>.] - ETA: 0s - loss: 0.2184 - acc: 0.9062
3015/3015 [==============================] - 11s 4ms/step - loss: 0.2183 - acc: 0.9061

Test accuracy: 91.29129129129129

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  164

choose_one :  169

F1score :  0.9134328358208955

AUC :  0.9676790996320612

Confusion Matrix
[[151  16]
 [ 13 153]]
True label 0
0.9041916167664671  
0.09580838323353294  
True label 1
0.0783132530120482  
0.9216867469879518  

Train_result {'loss': [0.21833318271743718], 'acc': [0.9061359867527711]}
Saved model to disk


6

Epoch 1/1

  64/3015 [..............................] - ETA: 15s - loss: 0.1993 - acc: 0.9375
 128/3015 [>.............................] - ETA: 13s - loss: 0.2394 - acc: 0.8984
 192/3015 [>.............................] - ETA: 12s - loss: 0.2100 - acc: 0.9167
 256/3015 [=>............................] - ETA: 12s - loss: 0.1767 - acc: 0.9297
 320/3015 [==>...........................] - ETA: 11s - loss: 0.1777 - acc: 0.9313
 384/3015 [==>...........................] - ETA: 10s - loss: 0.1853 - acc: 0.9271
 448/3015 [===>..........................] - ETA: 10s - loss: 0.1905 - acc: 0.9241
 512/3015 [====>.........................] - ETA: 9s - loss: 0.1968 - acc: 0.9199 
 576/3015 [====>.........................] - ETA: 9s - loss: 0.1931 - acc: 0.9271
 640/3015 [=====>........................] - ETA: 8s - loss: 0.1809 - acc: 0.9313
 704/3015 [======>.......................] - ETA: 8s - loss: 0.1714 - acc: 0.9347
 768/3015 [======>.......................] - ETA: 7s - loss: 0.1796 - acc: 0.9323
 832/3015 [=======>......................] - ETA: 7s - loss: 0.1925 - acc: 0.9291
 896/3015 [=======>......................] - ETA: 7s - loss: 0.1917 - acc: 0.9297
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1878 - acc: 0.9313
1024/3015 [=========>....................] - ETA: 7s - loss: 0.1861 - acc: 0.9297
1088/3015 [=========>....................] - ETA: 6s - loss: 0.1791 - acc: 0.9329
1152/3015 [==========>...................] - ETA: 6s - loss: 0.1826 - acc: 0.9280
1216/3015 [===========>..................] - ETA: 6s - loss: 0.1830 - acc: 0.9285
1280/3015 [===========>..................] - ETA: 6s - loss: 0.1909 - acc: 0.9258
1344/3015 [============>.................] - ETA: 5s - loss: 0.1895 - acc: 0.9271
1408/3015 [=============>................] - ETA: 5s - loss: 0.1955 - acc: 0.9254
1472/3015 [=============>................] - ETA: 5s - loss: 0.1944 - acc: 0.9253
1536/3015 [==============>...............] - ETA: 5s - loss: 0.1947 - acc: 0.9251
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1940 - acc: 0.9244
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1958 - acc: 0.9231
1728/3015 [================>.............] - ETA: 4s - loss: 0.1947 - acc: 0.9225
1792/3015 [================>.............] - ETA: 4s - loss: 0.1931 - acc: 0.9224
1856/3015 [=================>............] - ETA: 4s - loss: 0.1907 - acc: 0.9235
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1928 - acc: 0.9245
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1958 - acc: 0.9224
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1971 - acc: 0.9214
2112/3015 [====================>.........] - ETA: 3s - loss: 0.1992 - acc: 0.9205
2176/3015 [====================>.........] - ETA: 2s - loss: 0.2004 - acc: 0.9187
2240/3015 [=====================>........] - ETA: 2s - loss: 0.2007 - acc: 0.9179
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1986 - acc: 0.9193
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1971 - acc: 0.9202
2432/3015 [=======================>......] - ETA: 2s - loss: 0.1973 - acc: 0.9194
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1963 - acc: 0.9207
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1951 - acc: 0.9211
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1969 - acc: 0.9200
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1959 - acc: 0.9204
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1986 - acc: 0.9179
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1966 - acc: 0.9190
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1950 - acc: 0.9198
2944/3015 [============================>.] - ETA: 0s - loss: 0.1948 - acc: 0.9195
3008/3015 [============================>.] - ETA: 0s - loss: 0.1951 - acc: 0.9199
3015/3015 [==============================] - 11s 4ms/step - loss: 0.1949 - acc: 0.9201

Test accuracy: 89.7897897897898

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  149

choose_one :  184

F1score :  0.9028571428571429

AUC :  0.9667412163624558

Confusion Matrix
[[141  26]
 [  8 158]]
True label 0
0.844311377245509  
0.15568862275449102  
True label 1
0.04819277108433735  
0.9518072289156626  

Train_result {'loss': [0.1948567808020372], 'acc': [0.9200663349917081]}
Saved model to disk


7

Epoch 1/1

  64/3015 [..............................] - ETA: 9s - loss: 0.1399 - acc: 0.9531
 128/3015 [>.............................] - ETA: 8s - loss: 0.1566 - acc: 0.9453
 192/3015 [>.............................] - ETA: 10s - loss: 0.2050 - acc: 0.9219
 256/3015 [=>............................] - ETA: 10s - loss: 0.2035 - acc: 0.9219
 320/3015 [==>...........................] - ETA: 11s - loss: 0.1851 - acc: 0.9250
 384/3015 [==>...........................] - ETA: 10s - loss: 0.2072 - acc: 0.9219
 448/3015 [===>..........................] - ETA: 9s - loss: 0.1957 - acc: 0.9263 
 512/3015 [====>.........................] - ETA: 9s - loss: 0.1893 - acc: 0.9258
 576/3015 [====>.........................] - ETA: 9s - loss: 0.1872 - acc: 0.9219
 640/3015 [=====>........................] - ETA: 8s - loss: 0.1891 - acc: 0.9203
 704/3015 [======>.......................] - ETA: 8s - loss: 0.1983 - acc: 0.9190
 768/3015 [======>.......................] - ETA: 7s - loss: 0.1893 - acc: 0.9258
 832/3015 [=======>......................] - ETA: 7s - loss: 0.1879 - acc: 0.9231
 896/3015 [=======>......................] - ETA: 7s - loss: 0.1929 - acc: 0.9219
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1996 - acc: 0.9198
1024/3015 [=========>....................] - ETA: 7s - loss: 0.2040 - acc: 0.9180
1088/3015 [=========>....................] - ETA: 7s - loss: 0.2048 - acc: 0.9182
1152/3015 [==========>...................] - ETA: 6s - loss: 0.2037 - acc: 0.9175
1216/3015 [===========>..................] - ETA: 6s - loss: 0.2094 - acc: 0.9145
1280/3015 [===========>..................] - ETA: 6s - loss: 0.2093 - acc: 0.9141
1344/3015 [============>.................] - ETA: 6s - loss: 0.2061 - acc: 0.9159
1408/3015 [=============>................] - ETA: 5s - loss: 0.2043 - acc: 0.9190
1472/3015 [=============>................] - ETA: 5s - loss: 0.2046 - acc: 0.9192
1536/3015 [==============>...............] - ETA: 5s - loss: 0.2037 - acc: 0.9186
1600/3015 [==============>...............] - ETA: 4s - loss: 0.2047 - acc: 0.9181
1664/3015 [===============>..............] - ETA: 4s - loss: 0.2027 - acc: 0.9195
1728/3015 [================>.............] - ETA: 4s - loss: 0.2001 - acc: 0.9201
1792/3015 [================>.............] - ETA: 4s - loss: 0.2022 - acc: 0.9185
1856/3015 [=================>............] - ETA: 4s - loss: 0.2007 - acc: 0.9181
1920/3015 [==================>...........] - ETA: 4s - loss: 0.2024 - acc: 0.9177
1984/3015 [==================>...........] - ETA: 3s - loss: 0.2008 - acc: 0.9183
2048/3015 [===================>..........] - ETA: 3s - loss: 0.2015 - acc: 0.9180
2112/3015 [====================>.........] - ETA: 3s - loss: 0.2003 - acc: 0.9181
2176/3015 [====================>.........] - ETA: 3s - loss: 0.1983 - acc: 0.9187
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1984 - acc: 0.9174
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1960 - acc: 0.9188
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1984 - acc: 0.9172
2432/3015 [=======================>......] - ETA: 2s - loss: 0.1974 - acc: 0.9178
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1958 - acc: 0.9187
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1968 - acc: 0.9184
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1963 - acc: 0.9188
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1986 - acc: 0.9182
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1968 - acc: 0.9182
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1985 - acc: 0.9173
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1987 - acc: 0.9170
2944/3015 [============================>.] - ETA: 0s - loss: 0.1989 - acc: 0.9175
3008/3015 [============================>.] - ETA: 0s - loss: 0.1998 - acc: 0.9169
3015/3015 [==============================] - 11s 4ms/step - loss: 0.1996 - acc: 0.9171

Test accuracy: 89.4894894894895

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  144

choose_one :  189

F1score :  0.9014084507042253

AUC :  0.9685448380347739

Confusion Matrix
[[138  29]
 [  6 160]]
True label 0
0.8263473053892215  
0.17365269461077845  
True label 1
0.03614457831325301  
0.963855421686747  

Train_result {'loss': [0.1996424715737403], 'acc': [0.9170812603648425]}
Saved model to disk


8

Epoch 1/1

  64/3015 [..............................] - ETA: 9s - loss: 0.1715 - acc: 0.9062
 128/3015 [>.............................] - ETA: 11s - loss: 0.1565 - acc: 0.9219
 192/3015 [>.............................] - ETA: 11s - loss: 0.2114 - acc: 0.9219
 256/3015 [=>............................] - ETA: 11s - loss: 0.1791 - acc: 0.9375
 320/3015 [==>...........................] - ETA: 11s - loss: 0.1719 - acc: 0.9344
 384/3015 [==>...........................] - ETA: 10s - loss: 0.1748 - acc: 0.9297
 448/3015 [===>..........................] - ETA: 9s - loss: 0.1720 - acc: 0.9286 
 512/3015 [====>.........................] - ETA: 9s - loss: 0.1788 - acc: 0.9238
 576/3015 [====>.........................] - ETA: 9s - loss: 0.1851 - acc: 0.9253
 640/3015 [=====>........................] - ETA: 8s - loss: 0.1803 - acc: 0.9297
 704/3015 [======>.......................] - ETA: 8s - loss: 0.1822 - acc: 0.9290
 768/3015 [======>.......................] - ETA: 8s - loss: 0.1812 - acc: 0.9297
 832/3015 [=======>......................] - ETA: 7s - loss: 0.1788 - acc: 0.9315
 896/3015 [=======>......................] - ETA: 7s - loss: 0.1871 - acc: 0.9319
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1848 - acc: 0.9333
1024/3015 [=========>....................] - ETA: 7s - loss: 0.1870 - acc: 0.9316
1088/3015 [=========>....................] - ETA: 7s - loss: 0.1888 - acc: 0.9301
1152/3015 [==========>...................] - ETA: 7s - loss: 0.1908 - acc: 0.9280
1216/3015 [===========>..................] - ETA: 6s - loss: 0.1868 - acc: 0.9293
1280/3015 [===========>..................] - ETA: 6s - loss: 0.1885 - acc: 0.9297
1344/3015 [============>.................] - ETA: 6s - loss: 0.1940 - acc: 0.9256
1408/3015 [=============>................] - ETA: 5s - loss: 0.1940 - acc: 0.9261
1472/3015 [=============>................] - ETA: 5s - loss: 0.1955 - acc: 0.9246
1536/3015 [==============>...............] - ETA: 5s - loss: 0.1959 - acc: 0.9238
1600/3015 [==============>...............] - ETA: 5s - loss: 0.1958 - acc: 0.9237
1664/3015 [===============>..............] - ETA: 5s - loss: 0.1942 - acc: 0.9243
1728/3015 [================>.............] - ETA: 4s - loss: 0.1924 - acc: 0.9248
1792/3015 [================>.............] - ETA: 4s - loss: 0.1910 - acc: 0.9252
1856/3015 [=================>............] - ETA: 4s - loss: 0.1898 - acc: 0.9256
1920/3015 [==================>...........] - ETA: 4s - loss: 0.1870 - acc: 0.9266
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1855 - acc: 0.9269
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1864 - acc: 0.9258
2112/3015 [====================>.........] - ETA: 3s - loss: 0.1844 - acc: 0.9261
2176/3015 [====================>.........] - ETA: 3s - loss: 0.1850 - acc: 0.9251
2240/3015 [=====================>........] - ETA: 3s - loss: 0.1858 - acc: 0.9250
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1879 - acc: 0.9236
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1863 - acc: 0.9240
2432/3015 [=======================>......] - ETA: 2s - loss: 0.1852 - acc: 0.9239
2496/3015 [=======================>......] - ETA: 2s - loss: 0.1843 - acc: 0.9247
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1818 - acc: 0.9254
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1800 - acc: 0.9261
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1774 - acc: 0.9275
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1769 - acc: 0.9281
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1782 - acc: 0.9276
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1798 - acc: 0.9281
2944/3015 [============================>.] - ETA: 0s - loss: 0.1799 - acc: 0.9283
3008/3015 [============================>.] - ETA: 0s - loss: 0.1822 - acc: 0.9285
3015/3015 [==============================] - 12s 4ms/step - loss: 0.1820 - acc: 0.9284

Test accuracy: 89.7897897897898

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  141

choose_one :  192

F1score :  0.9050279329608939

AUC :  0.97016809753986

Confusion Matrix
[[137  30]
 [  4 162]]
True label 0
0.8203592814371258  
0.17964071856287425  
True label 1
0.024096385542168676  
0.9759036144578314  

Train_result {'loss': [0.18203500597730007], 'acc': [0.9283582089749932]}
Saved model to disk


9

Epoch 1/1

  64/3015 [..............................] - ETA: 14s - loss: 0.1386 - acc: 0.9219
 128/3015 [>.............................] - ETA: 12s - loss: 0.1816 - acc: 0.9062
 192/3015 [>.............................] - ETA: 11s - loss: 0.1900 - acc: 0.9062
 256/3015 [=>............................] - ETA: 10s - loss: 0.1699 - acc: 0.9102
 320/3015 [==>...........................] - ETA: 9s - loss: 0.1805 - acc: 0.9094 
 384/3015 [==>...........................] - ETA: 9s - loss: 0.1702 - acc: 0.9167
 448/3015 [===>..........................] - ETA: 9s - loss: 0.1770 - acc: 0.9196
 512/3015 [====>.........................] - ETA: 9s - loss: 0.1835 - acc: 0.9219
 576/3015 [====>.........................] - ETA: 8s - loss: 0.1882 - acc: 0.9167
 640/3015 [=====>........................] - ETA: 8s - loss: 0.1894 - acc: 0.9156
 704/3015 [======>.......................] - ETA: 7s - loss: 0.1879 - acc: 0.9190
 768/3015 [======>.......................] - ETA: 7s - loss: 0.1844 - acc: 0.9193
 832/3015 [=======>......................] - ETA: 7s - loss: 0.1836 - acc: 0.9207
 896/3015 [=======>......................] - ETA: 7s - loss: 0.1910 - acc: 0.9163
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1879 - acc: 0.9177
1024/3015 [=========>....................] - ETA: 7s - loss: 0.1843 - acc: 0.9199
1088/3015 [=========>....................] - ETA: 7s - loss: 0.1849 - acc: 0.9219
1152/3015 [==========>...................] - ETA: 6s - loss: 0.1865 - acc: 0.9219
1216/3015 [===========>..................] - ETA: 6s - loss: 0.1902 - acc: 0.9211
1280/3015 [===========>..................] - ETA: 6s - loss: 0.1959 - acc: 0.9195
1344/3015 [============>.................] - ETA: 5s - loss: 0.1992 - acc: 0.9196
1408/3015 [=============>................] - ETA: 5s - loss: 0.1984 - acc: 0.9197
1472/3015 [=============>................] - ETA: 5s - loss: 0.1988 - acc: 0.9212
1536/3015 [==============>...............] - ETA: 5s - loss: 0.1987 - acc: 0.9219
1600/3015 [==============>...............] - ETA: 5s - loss: 0.1942 - acc: 0.9244
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1943 - acc: 0.9249
1728/3015 [================>.............] - ETA: 4s - loss: 0.1905 - acc: 0.9265
1792/3015 [================>.............] - ETA: 4s - loss: 0.1912 - acc: 0.9263
1856/3015 [=================>............] - ETA: 4s - loss: 0.1898 - acc: 0.9273
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1865 - acc: 0.9281
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1847 - acc: 0.9289
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1821 - acc: 0.9292
2112/3015 [====================>.........] - ETA: 3s - loss: 0.1798 - acc: 0.9304
2176/3015 [====================>.........] - ETA: 3s - loss: 0.1793 - acc: 0.9301
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1768 - acc: 0.9313
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1799 - acc: 0.9301
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1824 - acc: 0.9291
2432/3015 [=======================>......] - ETA: 2s - loss: 0.1819 - acc: 0.9289
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1815 - acc: 0.9287
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1826 - acc: 0.9277
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1810 - acc: 0.9287
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1824 - acc: 0.9282
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1806 - acc: 0.9291
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1802 - acc: 0.9290
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1821 - acc: 0.9285
2944/3015 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9293
3008/3015 [============================>.] - ETA: 0s - loss: 0.1802 - acc: 0.9292
3015/3015 [==============================] - 11s 4ms/step - loss: 0.1800 - acc: 0.9294

Test accuracy: 90.09009009009009

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  142

choose_one :  191

F1score :  0.9075630252100841

AUC :  0.9699516629391819

Confusion Matrix
[[138  29]
 [  4 162]]
True label 0
0.8263473053892215  
0.17365269461077845  
True label 1
0.024096385542168676  
0.9759036144578314  

Train_result {'loss': [0.17997574368568994], 'acc': [0.9293532338308458]}
Saved model to disk


10

Epoch 1/1

  64/3015 [..............................] - ETA: 13s - loss: 0.1454 - acc: 0.9375
 128/3015 [>.............................] - ETA: 12s - loss: 0.1432 - acc: 0.9297
 192/3015 [>.............................] - ETA: 13s - loss: 0.1460 - acc: 0.9323
 256/3015 [=>............................] - ETA: 12s - loss: 0.1266 - acc: 0.9453
 320/3015 [==>...........................] - ETA: 11s - loss: 0.1267 - acc: 0.9469
 384/3015 [==>...........................] - ETA: 11s - loss: 0.1185 - acc: 0.9505
 448/3015 [===>..........................] - ETA: 10s - loss: 0.1397 - acc: 0.9442
 512/3015 [====>.........................] - ETA: 10s - loss: 0.1489 - acc: 0.9375
 576/3015 [====>.........................] - ETA: 9s - loss: 0.1572 - acc: 0.9358 
 640/3015 [=====>........................] - ETA: 8s - loss: 0.1571 - acc: 0.9344
 704/3015 [======>.......................] - ETA: 8s - loss: 0.1542 - acc: 0.9347
 768/3015 [======>.......................] - ETA: 9s - loss: 0.1655 - acc: 0.9336
 832/3015 [=======>......................] - ETA: 8s - loss: 0.1620 - acc: 0.9339
 896/3015 [=======>......................] - ETA: 8s - loss: 0.1642 - acc: 0.9319
 960/3015 [========>.....................] - ETA: 8s - loss: 0.1700 - acc: 0.9313
1024/3015 [=========>....................] - ETA: 8s - loss: 0.1781 - acc: 0.9287
1088/3015 [=========>....................] - ETA: 7s - loss: 0.1806 - acc: 0.9292
1152/3015 [==========>...................] - ETA: 7s - loss: 0.1784 - acc: 0.9297
1216/3015 [===========>..................] - ETA: 6s - loss: 0.1750 - acc: 0.9309
1280/3015 [===========>..................] - ETA: 6s - loss: 0.1733 - acc: 0.9328
1344/3015 [============>.................] - ETA: 6s - loss: 0.1729 - acc: 0.9323
1408/3015 [=============>................] - ETA: 6s - loss: 0.1725 - acc: 0.9318
1472/3015 [=============>................] - ETA: 5s - loss: 0.1749 - acc: 0.9307
1536/3015 [==============>...............] - ETA: 5s - loss: 0.1746 - acc: 0.9316
1600/3015 [==============>...............] - ETA: 5s - loss: 0.1758 - acc: 0.9325
1664/3015 [===============>..............] - ETA: 5s - loss: 0.1715 - acc: 0.9351
1728/3015 [================>.............] - ETA: 4s - loss: 0.1700 - acc: 0.9363
1792/3015 [================>.............] - ETA: 4s - loss: 0.1721 - acc: 0.9353
1856/3015 [=================>............] - ETA: 4s - loss: 0.1756 - acc: 0.9332
1920/3015 [==================>...........] - ETA: 4s - loss: 0.1755 - acc: 0.9333
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1760 - acc: 0.9325
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1730 - acc: 0.9341
2112/3015 [====================>.........] - ETA: 3s - loss: 0.1731 - acc: 0.9337
2176/3015 [====================>.........] - ETA: 3s - loss: 0.1758 - acc: 0.9324
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1743 - acc: 0.9330
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1743 - acc: 0.9332
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1746 - acc: 0.9333
2432/3015 [=======================>......] - ETA: 2s - loss: 0.1732 - acc: 0.9342
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1725 - acc: 0.9351
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1703 - acc: 0.9363
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1686 - acc: 0.9367
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1703 - acc: 0.9364
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1694 - acc: 0.9364
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1710 - acc: 0.9354
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1704 - acc: 0.9351
2944/3015 [============================>.] - ETA: 0s - loss: 0.1709 - acc: 0.9344
3008/3015 [============================>.] - ETA: 0s - loss: 0.1720 - acc: 0.9342
3015/3015 [==============================] - 11s 4ms/step - loss: 0.1716 - acc: 0.9343

Test accuracy: 91.29129129129129

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  154

choose_one :  179

F1score :  0.9159420289855071

AUC :  0.9714306327104828

Confusion Matrix
[[146  21]
 [  8 158]]
True label 0
0.874251497005988  
0.12574850299401197  
True label 1
0.04819277108433735  
0.9518072289156626  

Train_result {'loss': [0.17164097878074963], 'acc': [0.9343283582089552]}
Saved model to disk


11

Epoch 1/1

  64/3015 [..............................] - ETA: 12s - loss: 0.1441 - acc: 0.9375
 128/3015 [>.............................] - ETA: 11s - loss: 0.1022 - acc: 0.9688
 192/3015 [>.............................] - ETA: 11s - loss: 0.1637 - acc: 0.9375
 256/3015 [=>............................] - ETA: 10s - loss: 0.1454 - acc: 0.9414
 320/3015 [==>...........................] - ETA: 10s - loss: 0.1486 - acc: 0.9469
 384/3015 [==>...........................] - ETA: 9s - loss: 0.1459 - acc: 0.9401 
 448/3015 [===>..........................] - ETA: 9s - loss: 0.1759 - acc: 0.9308
 512/3015 [====>.........................] - ETA: 9s - loss: 0.1663 - acc: 0.9316
 576/3015 [====>.........................] - ETA: 8s - loss: 0.1599 - acc: 0.9340
 640/3015 [=====>........................] - ETA: 8s - loss: 0.1583 - acc: 0.9359
 704/3015 [======>.......................] - ETA: 7s - loss: 0.1522 - acc: 0.9389
 768/3015 [======>.......................] - ETA: 7s - loss: 0.1461 - acc: 0.9427
 832/3015 [=======>......................] - ETA: 7s - loss: 0.1406 - acc: 0.9459
 896/3015 [=======>......................] - ETA: 7s - loss: 0.1442 - acc: 0.9431
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1399 - acc: 0.9448
1024/3015 [=========>....................] - ETA: 6s - loss: 0.1394 - acc: 0.9434
1088/3015 [=========>....................] - ETA: 6s - loss: 0.1383 - acc: 0.9449
1152/3015 [==========>...................] - ETA: 6s - loss: 0.1348 - acc: 0.9470
1216/3015 [===========>..................] - ETA: 6s - loss: 0.1351 - acc: 0.9465
1280/3015 [===========>..................] - ETA: 6s - loss: 0.1385 - acc: 0.9461
1344/3015 [============>.................] - ETA: 5s - loss: 0.1510 - acc: 0.9405
1408/3015 [=============>................] - ETA: 5s - loss: 0.1469 - acc: 0.9418
1472/3015 [=============>................] - ETA: 5s - loss: 0.1505 - acc: 0.9395
1536/3015 [==============>...............] - ETA: 4s - loss: 0.1477 - acc: 0.9401
1600/3015 [==============>...............] - ETA: 4s - loss: 0.1476 - acc: 0.9400
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1473 - acc: 0.9399
1728/3015 [================>.............] - ETA: 4s - loss: 0.1471 - acc: 0.9404
1792/3015 [================>.............] - ETA: 4s - loss: 0.1480 - acc: 0.9397
1856/3015 [=================>............] - ETA: 4s - loss: 0.1471 - acc: 0.9407
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1493 - acc: 0.9391
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1482 - acc: 0.9400
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1498 - acc: 0.9385
2112/3015 [====================>.........] - ETA: 3s - loss: 0.1497 - acc: 0.9394
2176/3015 [====================>.........] - ETA: 2s - loss: 0.1475 - acc: 0.9403
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1460 - acc: 0.9406
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1462 - acc: 0.9401
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1443 - acc: 0.9405
2432/3015 [=======================>......] - ETA: 2s - loss: 0.1461 - acc: 0.9400
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1479 - acc: 0.9391
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1465 - acc: 0.9398
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1453 - acc: 0.9405
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1453 - acc: 0.9412
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1444 - acc: 0.9419
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1434 - acc: 0.9421
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1418 - acc: 0.9427
2944/3015 [============================>.] - ETA: 0s - loss: 0.1440 - acc: 0.9409
3008/3015 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9412
3015/3015 [==============================] - 11s 4ms/step - loss: 0.1436 - acc: 0.9413

Test accuracy: 90.69069069069069

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  142

choose_one :  191

F1score :  0.9131652661064426

AUC :  0.97135848784359

Confusion Matrix
[[139  28]
 [  3 163]]
True label 0
0.8323353293413174  
0.16766467065868262  
True label 1
0.018072289156626505  
0.9819277108433735  

Train_result {'loss': [0.14362780948232853], 'acc': [0.9412935323383085]}
Saved model to disk


12

Epoch 1/1

  64/3015 [..............................] - ETA: 12s - loss: 0.1171 - acc: 0.9531
 128/3015 [>.............................] - ETA: 13s - loss: 0.1811 - acc: 0.9375
 192/3015 [>.............................] - ETA: 12s - loss: 0.2181 - acc: 0.9271
 256/3015 [=>............................] - ETA: 12s - loss: 0.2045 - acc: 0.9297
 320/3015 [==>...........................] - ETA: 11s - loss: 0.1993 - acc: 0.9281
 384/3015 [==>...........................] - ETA: 10s - loss: 0.1932 - acc: 0.9245
 448/3015 [===>..........................] - ETA: 10s - loss: 0.1882 - acc: 0.9263
 512/3015 [====>.........................] - ETA: 10s - loss: 0.1912 - acc: 0.9199
 576/3015 [====>.........................] - ETA: 9s - loss: 0.1907 - acc: 0.9184 
 640/3015 [=====>........................] - ETA: 8s - loss: 0.1872 - acc: 0.9203
 704/3015 [======>.......................] - ETA: 8s - loss: 0.1860 - acc: 0.9219
 768/3015 [======>.......................] - ETA: 8s - loss: 0.1832 - acc: 0.9245
 832/3015 [=======>......................] - ETA: 8s - loss: 0.1790 - acc: 0.9267
 896/3015 [=======>......................] - ETA: 8s - loss: 0.1767 - acc: 0.9308
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1723 - acc: 0.9323
1024/3015 [=========>....................] - ETA: 7s - loss: 0.1739 - acc: 0.9297
1088/3015 [=========>....................] - ETA: 7s - loss: 0.1854 - acc: 0.9265
1152/3015 [==========>...................] - ETA: 7s - loss: 0.1827 - acc: 0.9262
1216/3015 [===========>..................] - ETA: 6s - loss: 0.1778 - acc: 0.9276
1280/3015 [===========>..................] - ETA: 6s - loss: 0.1734 - acc: 0.9289
1344/3015 [============>.................] - ETA: 6s - loss: 0.1700 - acc: 0.9301
1408/3015 [=============>................] - ETA: 5s - loss: 0.1703 - acc: 0.9297
1472/3015 [=============>................] - ETA: 5s - loss: 0.1699 - acc: 0.9314
1536/3015 [==============>...............] - ETA: 5s - loss: 0.1687 - acc: 0.9316
1600/3015 [==============>...............] - ETA: 5s - loss: 0.1667 - acc: 0.9319
1664/3015 [===============>..............] - ETA: 5s - loss: 0.1665 - acc: 0.9321
1728/3015 [================>.............] - ETA: 4s - loss: 0.1691 - acc: 0.9311
1792/3015 [================>.............] - ETA: 4s - loss: 0.1685 - acc: 0.9319
1856/3015 [=================>............] - ETA: 4s - loss: 0.1664 - acc: 0.9321
1920/3015 [==================>...........] - ETA: 4s - loss: 0.1653 - acc: 0.9323
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1662 - acc: 0.9315
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1694 - acc: 0.9312
2112/3015 [====================>.........] - ETA: 3s - loss: 0.1685 - acc: 0.9318
2176/3015 [====================>.........] - ETA: 3s - loss: 0.1659 - acc: 0.9329
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1663 - acc: 0.9330
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1656 - acc: 0.9327
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1654 - acc: 0.9333
2432/3015 [=======================>......] - ETA: 2s - loss: 0.1667 - acc: 0.9326
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1661 - acc: 0.9327
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1676 - acc: 0.9320
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1697 - acc: 0.9303
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1680 - acc: 0.9308
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1673 - acc: 0.9317
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1655 - acc: 0.9329
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1643 - acc: 0.9330
2944/3015 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9338
3008/3015 [============================>.] - ETA: 0s - loss: 0.1624 - acc: 0.9342
3015/3015 [==============================] - 11s 4ms/step - loss: 0.1622 - acc: 0.9343

Test accuracy: 90.39039039039038

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  159

choose_one :  174

F1score :  0.9058823529411766

AUC :  0.9714667051439291

Confusion Matrix
[[147  20]
 [ 12 154]]
True label 0
0.8802395209580839  
0.11976047904191617  
True label 1
0.07228915662650602  
0.927710843373494  

Train_result {'loss': [0.16224883814306798], 'acc': [0.9343283582089552]}
Saved model to disk


13

Epoch 1/1

  64/3015 [..............................] - ETA: 14s - loss: 0.0760 - acc: 0.9688
 128/3015 [>.............................] - ETA: 13s - loss: 0.0914 - acc: 0.9688
 192/3015 [>.............................] - ETA: 12s - loss: 0.0839 - acc: 0.9688
 256/3015 [=>............................] - ETA: 10s - loss: 0.1172 - acc: 0.9609
 320/3015 [==>...........................] - ETA: 10s - loss: 0.1101 - acc: 0.9656
 384/3015 [==>...........................] - ETA: 10s - loss: 0.1113 - acc: 0.9583
 448/3015 [===>..........................] - ETA: 9s - loss: 0.1181 - acc: 0.9576 
 512/3015 [====>.........................] - ETA: 9s - loss: 0.1341 - acc: 0.9570
 576/3015 [====>.........................] - ETA: 8s - loss: 0.1414 - acc: 0.9531
 640/3015 [=====>........................] - ETA: 8s - loss: 0.1436 - acc: 0.9531
 704/3015 [======>.......................] - ETA: 8s - loss: 0.1351 - acc: 0.9560
 768/3015 [======>.......................] - ETA: 8s - loss: 0.1300 - acc: 0.9583
 832/3015 [=======>......................] - ETA: 8s - loss: 0.1242 - acc: 0.9603
 896/3015 [=======>......................] - ETA: 8s - loss: 0.1241 - acc: 0.9587
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1197 - acc: 0.9604
1024/3015 [=========>....................] - ETA: 7s - loss: 0.1186 - acc: 0.9590
1088/3015 [=========>....................] - ETA: 7s - loss: 0.1155 - acc: 0.9605
1152/3015 [==========>...................] - ETA: 6s - loss: 0.1125 - acc: 0.9609
1216/3015 [===========>..................] - ETA: 6s - loss: 0.1097 - acc: 0.9613
1280/3015 [===========>..................] - ETA: 6s - loss: 0.1133 - acc: 0.9578
1344/3015 [============>.................] - ETA: 5s - loss: 0.1187 - acc: 0.9546
1408/3015 [=============>................] - ETA: 5s - loss: 0.1162 - acc: 0.9560
1472/3015 [=============>................] - ETA: 5s - loss: 0.1138 - acc: 0.9572
1536/3015 [==============>...............] - ETA: 5s - loss: 0.1162 - acc: 0.9564
1600/3015 [==============>...............] - ETA: 5s - loss: 0.1173 - acc: 0.9556
1664/3015 [===============>..............] - ETA: 5s - loss: 0.1204 - acc: 0.9537
1728/3015 [================>.............] - ETA: 4s - loss: 0.1185 - acc: 0.9537
1792/3015 [================>.............] - ETA: 4s - loss: 0.1185 - acc: 0.9537
1856/3015 [=================>............] - ETA: 4s - loss: 0.1180 - acc: 0.9537
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1204 - acc: 0.9536
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1221 - acc: 0.9531
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1216 - acc: 0.9536
2112/3015 [====================>.........] - ETA: 3s - loss: 0.1211 - acc: 0.9531
2176/3015 [====================>.........] - ETA: 3s - loss: 0.1209 - acc: 0.9531
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1202 - acc: 0.9536
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1230 - acc: 0.9514
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1229 - acc: 0.9519
2432/3015 [=======================>......] - ETA: 2s - loss: 0.1242 - acc: 0.9519
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1248 - acc: 0.9519
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1245 - acc: 0.9520
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1256 - acc: 0.9512
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1243 - acc: 0.9516
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1235 - acc: 0.9520
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1235 - acc: 0.9524
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1229 - acc: 0.9528
2944/3015 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9531
3008/3015 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9538
3015/3015 [==============================] - 11s 4ms/step - loss: 0.1224 - acc: 0.9532

Test accuracy: 91.29129129129129

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  154

choose_one :  179

F1score :  0.9159420289855071

AUC :  0.9714306327104827

Confusion Matrix
[[146  21]
 [  8 158]]
True label 0
0.874251497005988  
0.12574850299401197  
True label 1
0.04819277108433735  
0.9518072289156626  

Train_result {'loss': [0.12237806577192215], 'acc': [0.9532338308853099]}
Saved model to disk


14

Epoch 1/1

  64/3015 [..............................] - ETA: 16s - loss: 0.0991 - acc: 0.9844
 128/3015 [>.............................] - ETA: 15s - loss: 0.1405 - acc: 0.9688
 192/3015 [>.............................] - ETA: 13s - loss: 0.1261 - acc: 0.9688
 256/3015 [=>............................] - ETA: 12s - loss: 0.1389 - acc: 0.9531
 320/3015 [==>...........................] - ETA: 10s - loss: 0.1290 - acc: 0.9563
 384/3015 [==>...........................] - ETA: 11s - loss: 0.1401 - acc: 0.9557
 448/3015 [===>..........................] - ETA: 10s - loss: 0.1418 - acc: 0.9487
 512/3015 [====>.........................] - ETA: 9s - loss: 0.1377 - acc: 0.9512 
 576/3015 [====>.........................] - ETA: 9s - loss: 0.1280 - acc: 0.9549
 640/3015 [=====>........................] - ETA: 8s - loss: 0.1371 - acc: 0.9500
 704/3015 [======>.......................] - ETA: 8s - loss: 0.1513 - acc: 0.9418
 768/3015 [======>.......................] - ETA: 8s - loss: 0.1442 - acc: 0.9466
 832/3015 [=======>......................] - ETA: 8s - loss: 0.1462 - acc: 0.9459
 896/3015 [=======>......................] - ETA: 8s - loss: 0.1459 - acc: 0.9453
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1429 - acc: 0.9469
1024/3015 [=========>....................] - ETA: 7s - loss: 0.1498 - acc: 0.9443
1088/3015 [=========>....................] - ETA: 7s - loss: 0.1502 - acc: 0.9421
1152/3015 [==========>...................] - ETA: 7s - loss: 0.1578 - acc: 0.9401
1216/3015 [===========>..................] - ETA: 6s - loss: 0.1568 - acc: 0.9408
1280/3015 [===========>..................] - ETA: 6s - loss: 0.1548 - acc: 0.9406
1344/3015 [============>.................] - ETA: 6s - loss: 0.1593 - acc: 0.9375
1408/3015 [=============>................] - ETA: 5s - loss: 0.1568 - acc: 0.9396
1472/3015 [=============>................] - ETA: 5s - loss: 0.1562 - acc: 0.9402
1536/3015 [==============>...............] - ETA: 5s - loss: 0.1557 - acc: 0.9395
1600/3015 [==============>...............] - ETA: 5s - loss: 0.1564 - acc: 0.9406
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1561 - acc: 0.9399
1728/3015 [================>.............] - ETA: 4s - loss: 0.1564 - acc: 0.9398
1792/3015 [================>.............] - ETA: 4s - loss: 0.1576 - acc: 0.9397
1856/3015 [=================>............] - ETA: 4s - loss: 0.1534 - acc: 0.9418
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1527 - acc: 0.9417
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1496 - acc: 0.9425
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1521 - acc: 0.9404
2112/3015 [====================>.........] - ETA: 3s - loss: 0.1532 - acc: 0.9408
2176/3015 [====================>.........] - ETA: 3s - loss: 0.1519 - acc: 0.9403
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1520 - acc: 0.9402
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1509 - acc: 0.9405
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1500 - acc: 0.9405
2432/3015 [=======================>......] - ETA: 2s - loss: 0.1509 - acc: 0.9404
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1492 - acc: 0.9411
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1515 - acc: 0.9395
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1502 - acc: 0.9398
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1517 - acc: 0.9390
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1499 - acc: 0.9397
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1495 - acc: 0.9396
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1497 - acc: 0.9396
2944/3015 [============================>.] - ETA: 0s - loss: 0.1487 - acc: 0.9402
3008/3015 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9395
3015/3015 [==============================] - 11s 4ms/step - loss: 0.1497 - acc: 0.9396

Test accuracy: 91.29129129129129

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  160

choose_one :  173

F1score :  0.9144542772861357

AUC :  0.9712863429766972

Confusion Matrix
[[149  18]
 [ 11 155]]
True label 0
0.8922155688622755  
0.10778443113772455  
True label 1
0.06626506024096386  
0.9337349397590361  

Train_result {'loss': [0.14969474861945087], 'acc': [0.9396351575456053]}
Saved model to disk


15

Epoch 1/1

  64/3015 [..............................] - ETA: 11s - loss: 0.1388 - acc: 0.9688
 128/3015 [>.............................] - ETA: 10s - loss: 0.1538 - acc: 0.9609
 192/3015 [>.............................] - ETA: 11s - loss: 0.1421 - acc: 0.9635
 256/3015 [=>............................] - ETA: 10s - loss: 0.1404 - acc: 0.9609
 320/3015 [==>...........................] - ETA: 9s - loss: 0.1417 - acc: 0.9563 
 384/3015 [==>...........................] - ETA: 10s - loss: 0.1351 - acc: 0.9557
 448/3015 [===>..........................] - ETA: 9s - loss: 0.1292 - acc: 0.9598 
 512/3015 [====>.........................] - ETA: 8s - loss: 0.1324 - acc: 0.9551
 576/3015 [====>.........................] - ETA: 8s - loss: 0.1363 - acc: 0.9531
 640/3015 [=====>........................] - ETA: 8s - loss: 0.1308 - acc: 0.9547
 704/3015 [======>.......................] - ETA: 8s - loss: 0.1249 - acc: 0.9574
 768/3015 [======>.......................] - ETA: 8s - loss: 0.1297 - acc: 0.9544
 832/3015 [=======>......................] - ETA: 8s - loss: 0.1288 - acc: 0.9543
 896/3015 [=======>......................] - ETA: 7s - loss: 0.1344 - acc: 0.9531
 960/3015 [========>.....................] - ETA: 7s - loss: 0.1385 - acc: 0.9500
1024/3015 [=========>....................] - ETA: 7s - loss: 0.1358 - acc: 0.9512
1088/3015 [=========>....................] - ETA: 7s - loss: 0.1302 - acc: 0.9540
1152/3015 [==========>...................] - ETA: 6s - loss: 0.1363 - acc: 0.9505
1216/3015 [===========>..................] - ETA: 6s - loss: 0.1341 - acc: 0.9515
1280/3015 [===========>..................] - ETA: 6s - loss: 0.1329 - acc: 0.9516
1344/3015 [============>.................] - ETA: 6s - loss: 0.1354 - acc: 0.9501
1408/3015 [=============>................] - ETA: 5s - loss: 0.1333 - acc: 0.9510
1472/3015 [=============>................] - ETA: 5s - loss: 0.1302 - acc: 0.9524
1536/3015 [==============>...............] - ETA: 5s - loss: 0.1290 - acc: 0.9531
1600/3015 [==============>...............] - ETA: 5s - loss: 0.1297 - acc: 0.9537
1664/3015 [===============>..............] - ETA: 4s - loss: 0.1299 - acc: 0.9531
1728/3015 [================>.............] - ETA: 4s - loss: 0.1258 - acc: 0.9549
1792/3015 [================>.............] - ETA: 4s - loss: 0.1279 - acc: 0.9537
1856/3015 [=================>............] - ETA: 4s - loss: 0.1263 - acc: 0.9542
1920/3015 [==================>...........] - ETA: 3s - loss: 0.1258 - acc: 0.9536
1984/3015 [==================>...........] - ETA: 3s - loss: 0.1263 - acc: 0.9536
2048/3015 [===================>..........] - ETA: 3s - loss: 0.1236 - acc: 0.9546
2112/3015 [====================>.........] - ETA: 3s - loss: 0.1261 - acc: 0.9527
2176/3015 [====================>.........] - ETA: 3s - loss: 0.1271 - acc: 0.9522
2240/3015 [=====================>........] - ETA: 2s - loss: 0.1266 - acc: 0.9518
2304/3015 [=====================>........] - ETA: 2s - loss: 0.1276 - acc: 0.9514
2368/3015 [======================>.......] - ETA: 2s - loss: 0.1291 - acc: 0.9514
2432/3015 [=======================>......] - ETA: 2s - loss: 0.1300 - acc: 0.9511
2496/3015 [=======================>......] - ETA: 1s - loss: 0.1283 - acc: 0.9523
2560/3015 [========================>.....] - ETA: 1s - loss: 0.1290 - acc: 0.9516
2624/3015 [=========================>....] - ETA: 1s - loss: 0.1312 - acc: 0.9497
2688/3015 [=========================>....] - ETA: 1s - loss: 0.1295 - acc: 0.9505
2752/3015 [==========================>...] - ETA: 0s - loss: 0.1305 - acc: 0.9499
2816/3015 [===========================>..] - ETA: 0s - loss: 0.1287 - acc: 0.9510
2880/3015 [===========================>..] - ETA: 0s - loss: 0.1289 - acc: 0.9507
2944/3015 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9507
3008/3015 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9505
3015/3015 [==============================] - 11s 4ms/step - loss: 0.1296 - acc: 0.9506

Test accuracy: 90.69069069069069

data size :  3348

zero :  1675

one :  1673

train_zero :  1508

train_one :  1507

test_zero :  167

test_one :  166

choose_zero :  166

choose_one :  167

F1score :  0.906906906906907

AUC :  0.9703845321405382

Confusion Matrix
[[151  16]
 [ 15 151]]
True label 0
0.9041916167664671  
0.09580838323353294  
True label 1
0.09036144578313253  
0.9096385542168675  

Train_result {'loss': [0.1295893605849837], 'acc': [0.9505804311774461]}
Saved model to disk


[[87.08708708708708, 1], [88.58858858858859, 2], [90.09009009009009, 3], [91.29129129129129, 4], [91.29129129129129, 5], [89.7897897897898, 6], [89.4894894894895, 7], [89.7897897897898, 8], [90.09009009009009, 9], [91.29129129129129, 10], [90.69069069069069, 11], [90.39039039039038, 12], [91.29129129129129, 13], [91.29129129129129, 14], [90.69069069069069, 15]]
max accuracy :  [91.29129129129129, 14]
