Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
/home/2014313303/taeha/JavaAutoLogging/model.py:53: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor("ou...)`
  model = Model(input=[input1, input2], output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-08 04:01:41.342399: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-08 04:01:41.355428: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100085000 Hz
2019-09-08 04:01:41.357769: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0xdaaf050 executing computations on platform Host. Devices:
2019-09-08 04:01:41.357794: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Standard data
zero :  39451
one :  9019

First data
zero :  39451
one :  9019

Second data
zero :  39451
one :  9019

hbase-AST
After set document size of train data, the number of zero and one label data :  27718 2356
After set document size of test data, the number of zero and one label data :  3087 253

Sentence length Average : 9

Under 10 : 21693
Over 10, Under 30 : 11721
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

After balance out data.
hbase-AST

Sentence length Average : 11

Under 10 : 2794
Over 10, Under 30 : 2426
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

hbase-depth_num
After set document size of train data, the number of zero and one label data :  27718 2356
After set document size of test data, the number of zero and one label data :  3087 253
After balance out data.
hbase-depth_num

Sentence length Average : 11

Under 10 : 2794
Over 10, Under 30 : 2426
Over 30, Under 100 : 0
Over 100, Under 150 : 0
Over 150, Under 200 : 0
Over 200, Under 400 : 0
Over 400 : 0

Count model parameter.
Get a short summary of each layer dimensions and parameters.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 30, 200)      0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 30, 200)      0                                            
__________________________________________________________________________________________________
masking_1 (Masking)             (None, 30, 200)      0           input_1[0][0]                    
__________________________________________________________________________________________________
masking_2 (Masking)             (None, 30, 200)      0           input_2[0][0]                    
__________________________________________________________________________________________________
forwards_1 (LSTM)               (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
backwords_1 (LSTM)              (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
forwards_2 (LSTM)               (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
backwards_2 (LSTM)              (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
after_dp_forward_1 (Dropout)    (None, 64)           0           forwards_1[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_1 (Dropout)   (None, 64)           0           backwords_1[0][0]                
__________________________________________________________________________________________________
after_dp_forward_2 (Dropout)    (None, 64)           0           forwards_2[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_2 (Dropout)   (None, 64)           0           backwards_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128)          0           after_dp_forward_1[0][0]         
                                                                 after_dp_backward_1[0][0]        
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 128)          0           after_dp_forward_2[0][0]         
                                                                 after_dp_backward_2[0][0]        
__________________________________________________________________________________________________
after_dp_1 (Dropout)            (None, 128)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
after_dp_2 (Dropout)            (None, 128)          0           concatenate_2[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 256)          0           after_dp_1[0][0]                 
                                                                 after_dp_2[0][0]                 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 256)          65792       concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 128)          32896       dense_1[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 64)           8256        dense_2[0][0]                    
__________________________________________________________________________________________________
output (Dense)                  (None, 2)            130         dense_3[0][0]                    
==================================================================================================
Total params: 378,434
Trainable params: 378,434
Non-trainable params: 0
__________________________________________________________________________________________________
1

Epoch 1/1

  64/4713 [..............................] - ETA: 3:42 - loss: 0.6974 - acc: 0.5312
 192/4713 [>.............................] - ETA: 1:14 - loss: 0.6917 - acc: 0.5260
 320/4713 [=>............................] - ETA: 44s - loss: 0.6844 - acc: 0.5594 
 448/4713 [=>............................] - ETA: 31s - loss: 0.6823 - acc: 0.5625
 576/4713 [==>...........................] - ETA: 24s - loss: 0.6759 - acc: 0.5729
 704/4713 [===>..........................] - ETA: 19s - loss: 0.6619 - acc: 0.6080
 832/4713 [====>.........................] - ETA: 16s - loss: 0.6484 - acc: 0.6322
 960/4713 [=====>........................] - ETA: 14s - loss: 0.6328 - acc: 0.6500
1088/4713 [=====>........................] - ETA: 12s - loss: 0.6190 - acc: 0.6636
1216/4713 [======>.......................] - ETA: 10s - loss: 0.6157 - acc: 0.6711
1344/4713 [=======>......................] - ETA: 9s - loss: 0.5956 - acc: 0.6868 
1472/4713 [========>.....................] - ETA: 8s - loss: 0.5862 - acc: 0.6963
1600/4713 [=========>....................] - ETA: 7s - loss: 0.5834 - acc: 0.6994
1728/4713 [=========>....................] - ETA: 7s - loss: 0.5740 - acc: 0.7054
1856/4713 [==========>...................] - ETA: 6s - loss: 0.5702 - acc: 0.7107
1984/4713 [===========>..................] - ETA: 5s - loss: 0.5569 - acc: 0.7213
2112/4713 [============>.................] - ETA: 5s - loss: 0.5446 - acc: 0.7306
2240/4713 [=============>................] - ETA: 4s - loss: 0.5313 - acc: 0.7388
2368/4713 [==============>...............] - ETA: 4s - loss: 0.5222 - acc: 0.7449
2496/4713 [==============>...............] - ETA: 4s - loss: 0.5180 - acc: 0.7492
2624/4713 [===============>..............] - ETA: 3s - loss: 0.5130 - acc: 0.7504
2752/4713 [================>.............] - ETA: 3s - loss: 0.5079 - acc: 0.7547
2880/4713 [=================>............] - ETA: 3s - loss: 0.5044 - acc: 0.7569
3008/4713 [==================>...........] - ETA: 2s - loss: 0.5045 - acc: 0.7566
3136/4713 [==================>...........] - ETA: 2s - loss: 0.5024 - acc: 0.7577
3264/4713 [===================>..........] - ETA: 2s - loss: 0.5028 - acc: 0.7583
3392/4713 [====================>.........] - ETA: 2s - loss: 0.5034 - acc: 0.7583
3520/4713 [=====================>........] - ETA: 1s - loss: 0.5002 - acc: 0.7605
3648/4713 [======================>.......] - ETA: 1s - loss: 0.4986 - acc: 0.7623
3776/4713 [=======================>......] - ETA: 1s - loss: 0.4938 - acc: 0.7656
3904/4713 [=======================>......] - ETA: 1s - loss: 0.4913 - acc: 0.7666
4032/4713 [========================>.....] - ETA: 0s - loss: 0.4882 - acc: 0.7691
4160/4713 [=========================>....] - ETA: 0s - loss: 0.4833 - acc: 0.7726
4288/4713 [==========================>...] - ETA: 0s - loss: 0.4786 - acc: 0.7747
4416/4713 [===========================>..] - ETA: 0s - loss: 0.4738 - acc: 0.7783
4544/4713 [===========================>..] - ETA: 0s - loss: 0.4724 - acc: 0.7797
4672/4713 [============================>.] - ETA: 0s - loss: 0.4658 - acc: 0.7830
4713/4713 [==============================] - 6s 1ms/step - loss: 0.4659 - acc: 0.7832

Test accuracy: 84.41814595660749

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  225

choose_one :  282

F1score :  0.8523364485981307

AUC :  0.925865986119324

Confusion Matrix
[[200  54]
 [ 25 228]]
True label 0
0.7874015748031497  
0.2125984251968504  
True label 1
0.09881422924901186  
0.9011857707509882  

Train_result {'loss': [0.46593384639791385], 'acc': [0.7831529811792962]}
Saved model to disk


2

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.3694 - acc: 0.8281
 128/4713 [..............................] - ETA: 4s - loss: 0.4237 - acc: 0.8281
 256/4713 [>.............................] - ETA: 3s - loss: 0.3976 - acc: 0.8398
 384/4713 [=>............................] - ETA: 3s - loss: 0.3818 - acc: 0.8411
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3688 - acc: 0.8477
 640/4713 [===>..........................] - ETA: 3s - loss: 0.3861 - acc: 0.8391
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3711 - acc: 0.8464
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3741 - acc: 0.8438
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3755 - acc: 0.8393
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3815 - acc: 0.8330
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3806 - acc: 0.8346
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3786 - acc: 0.8363
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3817 - acc: 0.8311
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3830 - acc: 0.8302
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3868 - acc: 0.8294
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3812 - acc: 0.8347
1792/4713 [==========>...................] - ETA: 2s - loss: 0.3784 - acc: 0.8365
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3782 - acc: 0.8370
2048/4713 [============>.................] - ETA: 1s - loss: 0.3744 - acc: 0.8398
2176/4713 [============>.................] - ETA: 1s - loss: 0.3700 - acc: 0.8419
2304/4713 [=============>................] - ETA: 1s - loss: 0.3709 - acc: 0.8411
2432/4713 [==============>...............] - ETA: 1s - loss: 0.3742 - acc: 0.8396
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3709 - acc: 0.8410
2688/4713 [================>.............] - ETA: 1s - loss: 0.3720 - acc: 0.8393
2816/4713 [================>.............] - ETA: 1s - loss: 0.3691 - acc: 0.8413
2944/4713 [=================>............] - ETA: 1s - loss: 0.3663 - acc: 0.8434
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3686 - acc: 0.8424
3200/4713 [===================>..........] - ETA: 1s - loss: 0.3665 - acc: 0.8425
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3655 - acc: 0.8422
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3686 - acc: 0.8409
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3694 - acc: 0.8401
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3688 - acc: 0.8402
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3664 - acc: 0.8409
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3645 - acc: 0.8420
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3656 - acc: 0.8413
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3655 - acc: 0.8421
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3643 - acc: 0.8415
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3658 - acc: 0.8406
4608/4713 [============================>.] - ETA: 0s - loss: 0.3661 - acc: 0.8411
4713/4713 [==============================] - 3s 661us/step - loss: 0.3642 - acc: 0.8421

Test accuracy: 86.58777120315581

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  254

choose_one :  253

F1score :  0.8656126482213438

AUC :  0.9327907628147272

Confusion Matrix
[[220  34]
 [ 34 219]]
True label 0
0.8661417322834646  
0.13385826771653545  
True label 1
0.13438735177865613  
0.8656126482213439  

Train_result {'loss': [0.3641947947336614], 'acc': [0.8421387650924657]}
Saved model to disk


3

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2908 - acc: 0.8438
 192/4713 [>.............................] - ETA: 3s - loss: 0.2776 - acc: 0.8750
 320/4713 [=>............................] - ETA: 3s - loss: 0.3455 - acc: 0.8500
 448/4713 [=>............................] - ETA: 3s - loss: 0.3400 - acc: 0.8504
 576/4713 [==>...........................] - ETA: 3s - loss: 0.3518 - acc: 0.8455
 704/4713 [===>..........................] - ETA: 2s - loss: 0.3413 - acc: 0.8466
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3432 - acc: 0.8498
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3465 - acc: 0.8500
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3387 - acc: 0.8548
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3327 - acc: 0.8586
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3288 - acc: 0.8601
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3383 - acc: 0.8539
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3332 - acc: 0.8531
1728/4713 [=========>....................] - ETA: 2s - loss: 0.3286 - acc: 0.8559
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3364 - acc: 0.8518
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3388 - acc: 0.8498
2112/4713 [============>.................] - ETA: 1s - loss: 0.3370 - acc: 0.8504
2240/4713 [=============>................] - ETA: 1s - loss: 0.3362 - acc: 0.8504
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3408 - acc: 0.8476
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3407 - acc: 0.8486
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3417 - acc: 0.8483
2752/4713 [================>.............] - ETA: 1s - loss: 0.3400 - acc: 0.8496
2880/4713 [=================>............] - ETA: 1s - loss: 0.3383 - acc: 0.8510
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3377 - acc: 0.8514
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3370 - acc: 0.8524
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3376 - acc: 0.8536
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3379 - acc: 0.8535
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3391 - acc: 0.8537
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3416 - acc: 0.8514
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3416 - acc: 0.8509
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3413 - acc: 0.8502
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3431 - acc: 0.8490
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3437 - acc: 0.8483
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3439 - acc: 0.8486
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3458 - acc: 0.8474
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3450 - acc: 0.8484
4672/4713 [============================>.] - ETA: 0s - loss: 0.3421 - acc: 0.8497
4713/4713 [==============================] - 3s 655us/step - loss: 0.3408 - acc: 0.8504

Test accuracy: 86.3905325443787

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  261

choose_one :  246

F1score :  0.8617234468937877

AUC :  0.9370000933677757

Confusion Matrix
[[223  31]
 [ 38 215]]
True label 0
0.8779527559055118  
0.1220472440944882  
True label 1
0.15019762845849802  
0.849802371541502  

Train_result {'loss': [0.3408430847277086], 'acc': [0.8504137492928565]}
Saved model to disk


4

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2238 - acc: 0.9062
 128/4713 [..............................] - ETA: 4s - loss: 0.2603 - acc: 0.9062
 256/4713 [>.............................] - ETA: 3s - loss: 0.2937 - acc: 0.8633
 384/4713 [=>............................] - ETA: 3s - loss: 0.3222 - acc: 0.8594
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3209 - acc: 0.8672
 640/4713 [===>..........................] - ETA: 3s - loss: 0.3277 - acc: 0.8625
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3427 - acc: 0.8581
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3390 - acc: 0.8606
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3393 - acc: 0.8583
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3334 - acc: 0.8633
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3367 - acc: 0.8620
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3447 - acc: 0.8562
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3447 - acc: 0.8580
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3462 - acc: 0.8555
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3399 - acc: 0.8600
1792/4713 [==========>...................] - ETA: 2s - loss: 0.3368 - acc: 0.8610
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3368 - acc: 0.8604
2048/4713 [============>.................] - ETA: 1s - loss: 0.3335 - acc: 0.8628
2176/4713 [============>.................] - ETA: 1s - loss: 0.3336 - acc: 0.8621
2304/4713 [=============>................] - ETA: 1s - loss: 0.3441 - acc: 0.8589
2432/4713 [==============>...............] - ETA: 1s - loss: 0.3438 - acc: 0.8581
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3390 - acc: 0.8609
2688/4713 [================>.............] - ETA: 1s - loss: 0.3390 - acc: 0.8601
2816/4713 [================>.............] - ETA: 1s - loss: 0.3395 - acc: 0.8619
2944/4713 [=================>............] - ETA: 1s - loss: 0.3408 - acc: 0.8590
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3414 - acc: 0.8590
3200/4713 [===================>..........] - ETA: 1s - loss: 0.3407 - acc: 0.8600
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3399 - acc: 0.8603
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3392 - acc: 0.8591
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3369 - acc: 0.8610
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3363 - acc: 0.8621
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3370 - acc: 0.8604
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3391 - acc: 0.8604
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3382 - acc: 0.8608
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3369 - acc: 0.8617
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3376 - acc: 0.8610
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3385 - acc: 0.8607
4608/4713 [============================>.] - ETA: 0s - loss: 0.3364 - acc: 0.8620
4713/4713 [==============================] - 3s 655us/step - loss: 0.3359 - acc: 0.8614

Test accuracy: 85.99605522682445

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  261

choose_one :  246

F1score :  0.8577154308617234

AUC :  0.9333976533565714

Confusion Matrix
[[222  32]
 [ 39 214]]
True label 0
0.8740157480314961  
0.12598425196850394  
True label 1
0.1541501976284585  
0.8458498023715415  

Train_result {'loss': [0.33589876881203223], 'acc': [0.8614470612944601]}
Saved model to disk


5

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.3418 - acc: 0.8438
 128/4713 [..............................] - ETA: 4s - loss: 0.2607 - acc: 0.8906
 256/4713 [>.............................] - ETA: 3s - loss: 0.2805 - acc: 0.8867
 384/4713 [=>............................] - ETA: 3s - loss: 0.3208 - acc: 0.8724
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3131 - acc: 0.8711
 640/4713 [===>..........................] - ETA: 2s - loss: 0.3439 - acc: 0.8531
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3553 - acc: 0.8464
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3512 - acc: 0.8482
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3327 - acc: 0.8594
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3304 - acc: 0.8585
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3267 - acc: 0.8625
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3219 - acc: 0.8651
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3276 - acc: 0.8620
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3310 - acc: 0.8594
1792/4713 [==========>...................] - ETA: 1s - loss: 0.3288 - acc: 0.8605
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3281 - acc: 0.8615
2048/4713 [============>.................] - ETA: 1s - loss: 0.3266 - acc: 0.8623
2176/4713 [============>.................] - ETA: 1s - loss: 0.3235 - acc: 0.8644
2304/4713 [=============>................] - ETA: 1s - loss: 0.3259 - acc: 0.8620
2432/4713 [==============>...............] - ETA: 1s - loss: 0.3273 - acc: 0.8602
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3247 - acc: 0.8590
2688/4713 [================>.............] - ETA: 1s - loss: 0.3266 - acc: 0.8586
2816/4713 [================>.............] - ETA: 1s - loss: 0.3297 - acc: 0.8576
2944/4713 [=================>............] - ETA: 1s - loss: 0.3312 - acc: 0.8584
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3296 - acc: 0.8590
3200/4713 [===================>..........] - ETA: 0s - loss: 0.3271 - acc: 0.8597
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3228 - acc: 0.8612
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3239 - acc: 0.8608
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3197 - acc: 0.8633
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3190 - acc: 0.8640
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3234 - acc: 0.8628
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3238 - acc: 0.8624
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3221 - acc: 0.8635
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3262 - acc: 0.8615
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3280 - acc: 0.8603
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3274 - acc: 0.8605
4608/4713 [============================>.] - ETA: 0s - loss: 0.3280 - acc: 0.8596
4713/4713 [==============================] - 3s 634us/step - loss: 0.3283 - acc: 0.8595

Test accuracy: 87.17948717948718

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  219

choose_one :  288

F1score :  0.8798521256931607

AUC :  0.9361208801468988

Confusion Matrix
[[204  50]
 [ 15 238]]
True label 0
0.8031496062992126  
0.1968503937007874  
True label 1
0.05928853754940711  
0.9407114624505929  

Train_result {'loss': [0.3283070039779498], 'acc': [0.8595374494683533]}
Saved model to disk


6

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.1926 - acc: 0.9375
 128/4713 [..............................] - ETA: 4s - loss: 0.2303 - acc: 0.9062
 256/4713 [>.............................] - ETA: 3s - loss: 0.2762 - acc: 0.8711
 384/4713 [=>............................] - ETA: 3s - loss: 0.2846 - acc: 0.8802
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3010 - acc: 0.8730
 640/4713 [===>..........................] - ETA: 2s - loss: 0.3012 - acc: 0.8719
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3012 - acc: 0.8711
 896/4713 [====>.........................] - ETA: 2s - loss: 0.2979 - acc: 0.8750
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3267 - acc: 0.8633
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3219 - acc: 0.8646
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3169 - acc: 0.8680
1408/4713 [=======>......................] - ETA: 2s - loss: 0.3139 - acc: 0.8665
1536/4713 [========>.....................] - ETA: 2s - loss: 0.3185 - acc: 0.8639
1664/4713 [=========>....................] - ETA: 2s - loss: 0.3111 - acc: 0.8690
1792/4713 [==========>...................] - ETA: 1s - loss: 0.3143 - acc: 0.8677
1920/4713 [===========>..................] - ETA: 1s - loss: 0.3135 - acc: 0.8667
2048/4713 [============>.................] - ETA: 1s - loss: 0.3145 - acc: 0.8647
2176/4713 [============>.................] - ETA: 1s - loss: 0.3160 - acc: 0.8644
2304/4713 [=============>................] - ETA: 1s - loss: 0.3144 - acc: 0.8659
2432/4713 [==============>...............] - ETA: 1s - loss: 0.3131 - acc: 0.8664
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3130 - acc: 0.8652
2688/4713 [================>.............] - ETA: 1s - loss: 0.3170 - acc: 0.8642
2816/4713 [================>.............] - ETA: 1s - loss: 0.3145 - acc: 0.8668
2944/4713 [=================>............] - ETA: 1s - loss: 0.3149 - acc: 0.8662
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3144 - acc: 0.8662
3200/4713 [===================>..........] - ETA: 1s - loss: 0.3154 - acc: 0.8672
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3150 - acc: 0.8657
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3164 - acc: 0.8649
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3135 - acc: 0.8666
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3133 - acc: 0.8664
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3138 - acc: 0.8664
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3132 - acc: 0.8674
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3149 - acc: 0.8669
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3132 - acc: 0.8679
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3134 - acc: 0.8676
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3145 - acc: 0.8670
4608/4713 [============================>.] - ETA: 0s - loss: 0.3135 - acc: 0.8670
4713/4713 [==============================] - 3s 651us/step - loss: 0.3152 - acc: 0.8661

Test accuracy: 86.3905325443787

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  249

choose_one :  258

F1score :  0.8649706457925636

AUC :  0.9376147645575924

Confusion Matrix
[[217  37]
 [ 32 221]]
True label 0
0.8543307086614174  
0.14566929133858267  
True label 1
0.12648221343873517  
0.8735177865612648  

Train_result {'loss': [0.3151626699660807], 'acc': [0.8661150008079582]}
Saved model to disk


7

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2175 - acc: 0.9062
 192/4713 [>.............................] - ETA: 3s - loss: 0.2384 - acc: 0.8958
 320/4713 [=>............................] - ETA: 3s - loss: 0.2721 - acc: 0.8938
 448/4713 [=>............................] - ETA: 3s - loss: 0.3006 - acc: 0.8750
 576/4713 [==>...........................] - ETA: 3s - loss: 0.2843 - acc: 0.8889
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2887 - acc: 0.8864
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2946 - acc: 0.8834
 960/4713 [=====>........................] - ETA: 2s - loss: 0.2951 - acc: 0.8833
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2863 - acc: 0.8879
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2848 - acc: 0.8873
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2801 - acc: 0.8847
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2824 - acc: 0.8832
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2823 - acc: 0.8844
1728/4713 [=========>....................] - ETA: 1s - loss: 0.2933 - acc: 0.8785
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2994 - acc: 0.8728
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2994 - acc: 0.8720
2112/4713 [============>.................] - ETA: 1s - loss: 0.2993 - acc: 0.8703
2240/4713 [=============>................] - ETA: 1s - loss: 0.2980 - acc: 0.8696
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2975 - acc: 0.8687
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3034 - acc: 0.8650
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3052 - acc: 0.8655
2752/4713 [================>.............] - ETA: 1s - loss: 0.3056 - acc: 0.8652
2880/4713 [=================>............] - ETA: 1s - loss: 0.3091 - acc: 0.8642
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3096 - acc: 0.8644
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3103 - acc: 0.8654
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3116 - acc: 0.8646
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3134 - acc: 0.8641
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3143 - acc: 0.8648
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3149 - acc: 0.8635
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3142 - acc: 0.8628
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3147 - acc: 0.8627
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3161 - acc: 0.8624
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3166 - acc: 0.8623
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3146 - acc: 0.8636
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3143 - acc: 0.8637
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3156 - acc: 0.8629
4672/4713 [============================>.] - ETA: 0s - loss: 0.3160 - acc: 0.8626
4713/4713 [==============================] - 3s 639us/step - loss: 0.3170 - acc: 0.8623

Test accuracy: 86.98224852071006

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  234

choose_one :  273

F1score :  0.8745247148288973

AUC :  0.9420886371417012

Confusion Matrix
[[211  43]
 [ 23 230]]
True label 0
0.8307086614173228  
0.16929133858267717  
True label 1
0.09090909090909091  
0.9090909090909091  

Train_result {'loss': [0.31695036288787926], 'acc': [0.8622957774972096]}
Saved model to disk


8

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2644 - acc: 0.8594
 128/4713 [..............................] - ETA: 4s - loss: 0.2968 - acc: 0.8672
 256/4713 [>.............................] - ETA: 3s - loss: 0.3017 - acc: 0.8594
 384/4713 [=>............................] - ETA: 3s - loss: 0.2788 - acc: 0.8828
 512/4713 [==>...........................] - ETA: 3s - loss: 0.3000 - acc: 0.8789
 640/4713 [===>..........................] - ETA: 2s - loss: 0.3030 - acc: 0.8781
 768/4713 [===>..........................] - ETA: 2s - loss: 0.3263 - acc: 0.8672
 896/4713 [====>.........................] - ETA: 2s - loss: 0.3330 - acc: 0.8638
1024/4713 [=====>........................] - ETA: 2s - loss: 0.3329 - acc: 0.8613
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3257 - acc: 0.8655
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3220 - acc: 0.8656
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3213 - acc: 0.8631
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3214 - acc: 0.8641
1600/4713 [=========>....................] - ETA: 2s - loss: 0.3121 - acc: 0.8675
1728/4713 [=========>....................] - ETA: 2s - loss: 0.3159 - acc: 0.8669
1856/4713 [==========>...................] - ETA: 1s - loss: 0.3121 - acc: 0.8680
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3089 - acc: 0.8669
2112/4713 [============>.................] - ETA: 1s - loss: 0.3094 - acc: 0.8674
2240/4713 [=============>................] - ETA: 1s - loss: 0.3098 - acc: 0.8679
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3106 - acc: 0.8678
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3105 - acc: 0.8678
2560/4713 [===============>..............] - ETA: 1s - loss: 0.3096 - acc: 0.8680
2688/4713 [================>.............] - ETA: 1s - loss: 0.3072 - acc: 0.8679
2816/4713 [================>.............] - ETA: 1s - loss: 0.3073 - acc: 0.8686
2944/4713 [=================>............] - ETA: 1s - loss: 0.3100 - acc: 0.8668
3072/4713 [==================>...........] - ETA: 1s - loss: 0.3108 - acc: 0.8675
3200/4713 [===================>..........] - ETA: 1s - loss: 0.3168 - acc: 0.8641
3328/4713 [====================>.........] - ETA: 0s - loss: 0.3159 - acc: 0.8642
3456/4713 [====================>.........] - ETA: 0s - loss: 0.3156 - acc: 0.8646
3584/4713 [=====================>........] - ETA: 0s - loss: 0.3154 - acc: 0.8661
3712/4713 [======================>.......] - ETA: 0s - loss: 0.3158 - acc: 0.8656
3840/4713 [=======================>......] - ETA: 0s - loss: 0.3128 - acc: 0.8667
3968/4713 [========================>.....] - ETA: 0s - loss: 0.3123 - acc: 0.8669
4096/4713 [=========================>....] - ETA: 0s - loss: 0.3124 - acc: 0.8669
4224/4713 [=========================>....] - ETA: 0s - loss: 0.3121 - acc: 0.8665
4352/4713 [==========================>...] - ETA: 0s - loss: 0.3112 - acc: 0.8667
4480/4713 [===========================>..] - ETA: 0s - loss: 0.3118 - acc: 0.8667
4608/4713 [============================>.] - ETA: 0s - loss: 0.3104 - acc: 0.8670
4713/4713 [==============================] - 3s 660us/step - loss: 0.3124 - acc: 0.8668

Test accuracy: 87.17948717948718

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  251

choose_one :  256

F1score :  0.8722986247544204

AUC :  0.942065295197784

Confusion Matrix
[[220  34]
 [ 31 222]]
True label 0
0.8661417322834646  
0.13385826771653545  
True label 1
0.1225296442687747  
0.8774703557312253  

Train_result {'loss': [0.3123577962932429], 'acc': [0.866751538361558]}
Saved model to disk


9

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2662 - acc: 0.8594
 192/4713 [>.............................] - ETA: 3s - loss: 0.2789 - acc: 0.8802
 320/4713 [=>............................] - ETA: 3s - loss: 0.2585 - acc: 0.8875
 448/4713 [=>............................] - ETA: 3s - loss: 0.2793 - acc: 0.8817
 576/4713 [==>...........................] - ETA: 2s - loss: 0.2623 - acc: 0.8924
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2861 - acc: 0.8778
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2803 - acc: 0.8774
 960/4713 [=====>........................] - ETA: 2s - loss: 0.2924 - acc: 0.8708
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2997 - acc: 0.8667
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3059 - acc: 0.8660
1344/4713 [=======>......................] - ETA: 2s - loss: 0.3069 - acc: 0.8638
1472/4713 [========>.....................] - ETA: 2s - loss: 0.3031 - acc: 0.8655
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2996 - acc: 0.8662
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2934 - acc: 0.8704
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2936 - acc: 0.8723
1984/4713 [===========>..................] - ETA: 1s - loss: 0.3034 - acc: 0.8679
2112/4713 [============>.................] - ETA: 1s - loss: 0.3035 - acc: 0.8670
2240/4713 [=============>................] - ETA: 1s - loss: 0.3024 - acc: 0.8665
2368/4713 [==============>...............] - ETA: 1s - loss: 0.3058 - acc: 0.8674
2496/4713 [==============>...............] - ETA: 1s - loss: 0.3052 - acc: 0.8674
2624/4713 [===============>..............] - ETA: 1s - loss: 0.3077 - acc: 0.8666
2752/4713 [================>.............] - ETA: 1s - loss: 0.3047 - acc: 0.8677
2880/4713 [=================>............] - ETA: 1s - loss: 0.3058 - acc: 0.8677
3008/4713 [==================>...........] - ETA: 1s - loss: 0.3057 - acc: 0.8690
3136/4713 [==================>...........] - ETA: 1s - loss: 0.3070 - acc: 0.8686
3264/4713 [===================>..........] - ETA: 0s - loss: 0.3051 - acc: 0.8701
3392/4713 [====================>.........] - ETA: 0s - loss: 0.3066 - acc: 0.8700
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3077 - acc: 0.8702
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3050 - acc: 0.8720
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3057 - acc: 0.8708
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3042 - acc: 0.8722
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3039 - acc: 0.8723
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3034 - acc: 0.8724
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3027 - acc: 0.8731
4416/4713 [===========================>..] - ETA: 0s - loss: 0.3010 - acc: 0.8734
4544/4713 [===========================>..] - ETA: 0s - loss: 0.3014 - acc: 0.8732
4672/4713 [============================>.] - ETA: 0s - loss: 0.3013 - acc: 0.8731
4713/4713 [==============================] - 3s 638us/step - loss: 0.3014 - acc: 0.8729

Test accuracy: 86.3905325443787

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  259

choose_one :  248

F1score :  0.8622754491017963

AUC :  0.9419408048302262

Confusion Matrix
[[222  32]
 [ 37 216]]
True label 0
0.8740157480314961  
0.12598425196850394  
True label 1
0.14624505928853754  
0.8537549407114624  

Train_result {'loss': [0.3013688261635916], 'acc': [0.8729047317705209]}
Saved model to disk


10

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2597 - acc: 0.9062
 128/4713 [..............................] - ETA: 4s - loss: 0.2765 - acc: 0.8906
 256/4713 [>.............................] - ETA: 3s - loss: 0.2767 - acc: 0.8789
 384/4713 [=>............................] - ETA: 3s - loss: 0.2738 - acc: 0.8776
 512/4713 [==>...........................] - ETA: 3s - loss: 0.2912 - acc: 0.8770
 640/4713 [===>..........................] - ETA: 2s - loss: 0.2911 - acc: 0.8734
 768/4713 [===>..........................] - ETA: 2s - loss: 0.2856 - acc: 0.8789
 896/4713 [====>.........................] - ETA: 2s - loss: 0.2937 - acc: 0.8795
1024/4713 [=====>........................] - ETA: 2s - loss: 0.2993 - acc: 0.8750
1152/4713 [======>.......................] - ETA: 2s - loss: 0.3019 - acc: 0.8767
1280/4713 [=======>......................] - ETA: 2s - loss: 0.3014 - acc: 0.8789
1408/4713 [=======>......................] - ETA: 2s - loss: 0.2955 - acc: 0.8814
1536/4713 [========>.....................] - ETA: 2s - loss: 0.2945 - acc: 0.8809
1664/4713 [=========>....................] - ETA: 2s - loss: 0.2923 - acc: 0.8828
1792/4713 [==========>...................] - ETA: 1s - loss: 0.2898 - acc: 0.8834
1920/4713 [===========>..................] - ETA: 1s - loss: 0.2903 - acc: 0.8823
2048/4713 [============>.................] - ETA: 1s - loss: 0.2933 - acc: 0.8799
2176/4713 [============>.................] - ETA: 1s - loss: 0.2939 - acc: 0.8787
2304/4713 [=============>................] - ETA: 1s - loss: 0.2893 - acc: 0.8815
2432/4713 [==============>...............] - ETA: 1s - loss: 0.2885 - acc: 0.8820
2560/4713 [===============>..............] - ETA: 1s - loss: 0.2881 - acc: 0.8816
2688/4713 [================>.............] - ETA: 1s - loss: 0.2889 - acc: 0.8817
2816/4713 [================>.............] - ETA: 1s - loss: 0.2896 - acc: 0.8810
2944/4713 [=================>............] - ETA: 1s - loss: 0.2973 - acc: 0.8774
3072/4713 [==================>...........] - ETA: 1s - loss: 0.2974 - acc: 0.8770
3200/4713 [===================>..........] - ETA: 0s - loss: 0.2965 - acc: 0.8772
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2976 - acc: 0.8768
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2989 - acc: 0.8765
3520/4713 [=====================>........] - ETA: 0s - loss: 0.3005 - acc: 0.8764
3648/4713 [======================>.......] - ETA: 0s - loss: 0.3003 - acc: 0.8772
3776/4713 [=======================>......] - ETA: 0s - loss: 0.3014 - acc: 0.8763
3904/4713 [=======================>......] - ETA: 0s - loss: 0.3030 - acc: 0.8753
4032/4713 [========================>.....] - ETA: 0s - loss: 0.3047 - acc: 0.8740
4160/4713 [=========================>....] - ETA: 0s - loss: 0.3032 - acc: 0.8748
4288/4713 [==========================>...] - ETA: 0s - loss: 0.3017 - acc: 0.8752
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2987 - acc: 0.8766
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2995 - acc: 0.8763
4672/4713 [============================>.] - ETA: 0s - loss: 0.2983 - acc: 0.8761
4713/4713 [==============================] - 3s 636us/step - loss: 0.2978 - acc: 0.8763

Test accuracy: 86.58777120315581

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  248

choose_one :  259

F1score :  0.8671875

AUC :  0.9377236936292054

Confusion Matrix
[[217  37]
 [ 31 222]]
True label 0
0.8543307086614174  
0.14566929133858267  
True label 1
0.1225296442687747  
0.8774703557312253  

Train_result {'loss': [0.2977871236409348], 'acc': [0.8762995966321062]}
Saved model to disk


11

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2673 - acc: 0.9062
 128/4713 [..............................] - ETA: 4s - loss: 0.2332 - acc: 0.9219
 256/4713 [>.............................] - ETA: 3s - loss: 0.2718 - acc: 0.8750
 320/4713 [=>............................] - ETA: 3s - loss: 0.2621 - acc: 0.8844
 448/4713 [=>............................] - ETA: 3s - loss: 0.2708 - acc: 0.8817
 576/4713 [==>...........................] - ETA: 3s - loss: 0.2765 - acc: 0.8837
 704/4713 [===>..........................] - ETA: 3s - loss: 0.2764 - acc: 0.8821
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2785 - acc: 0.8822
 960/4713 [=====>........................] - ETA: 2s - loss: 0.2889 - acc: 0.8771
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2834 - acc: 0.8814
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2877 - acc: 0.8783
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2842 - acc: 0.8795
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2802 - acc: 0.8811
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2806 - acc: 0.8819
1728/4713 [=========>....................] - ETA: 2s - loss: 0.2780 - acc: 0.8814
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2793 - acc: 0.8820
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2751 - acc: 0.8841
2112/4713 [============>.................] - ETA: 1s - loss: 0.2787 - acc: 0.8830
2240/4713 [=============>................] - ETA: 1s - loss: 0.2827 - acc: 0.8821
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2829 - acc: 0.8809
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2818 - acc: 0.8822
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2851 - acc: 0.8811
2752/4713 [================>.............] - ETA: 1s - loss: 0.2847 - acc: 0.8815
2880/4713 [=================>............] - ETA: 1s - loss: 0.2880 - acc: 0.8799
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2918 - acc: 0.8790
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2913 - acc: 0.8807
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2919 - acc: 0.8796
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2948 - acc: 0.8782
3520/4713 [=====================>........] - ETA: 0s - loss: 0.2931 - acc: 0.8790
3648/4713 [======================>.......] - ETA: 0s - loss: 0.2928 - acc: 0.8797
3776/4713 [=======================>......] - ETA: 0s - loss: 0.2956 - acc: 0.8776
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2950 - acc: 0.8773
4032/4713 [========================>.....] - ETA: 0s - loss: 0.2968 - acc: 0.8757
4160/4713 [=========================>....] - ETA: 0s - loss: 0.2947 - acc: 0.8762
4288/4713 [==========================>...] - ETA: 0s - loss: 0.2931 - acc: 0.8769
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2936 - acc: 0.8770
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2924 - acc: 0.8781
4672/4713 [============================>.] - ETA: 0s - loss: 0.2942 - acc: 0.8763
4713/4713 [==============================] - 3s 658us/step - loss: 0.2940 - acc: 0.8765

Test accuracy: 86.58777120315581

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  256

choose_one :  251

F1score :  0.8650793650793651

AUC :  0.9436525473841462

Confusion Matrix
[[221  33]
 [ 35 218]]
True label 0
0.8700787401574803  
0.12992125984251968  
True label 1
0.1383399209486166  
0.8616600790513834  

Train_result {'loss': [0.2940274829030315], 'acc': [0.8765117757112489]}
Saved model to disk


12

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2610 - acc: 0.8906
 192/4713 [>.............................] - ETA: 3s - loss: 0.3325 - acc: 0.8542
 320/4713 [=>............................] - ETA: 3s - loss: 0.3030 - acc: 0.8750
 448/4713 [=>............................] - ETA: 3s - loss: 0.2820 - acc: 0.8817
 576/4713 [==>...........................] - ETA: 2s - loss: 0.2844 - acc: 0.8767
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2863 - acc: 0.8722
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2858 - acc: 0.8738
 960/4713 [=====>........................] - ETA: 2s - loss: 0.2912 - acc: 0.8719
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2861 - acc: 0.8732
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2803 - acc: 0.8783
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2771 - acc: 0.8802
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2766 - acc: 0.8818
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2802 - acc: 0.8800
1728/4713 [=========>....................] - ETA: 1s - loss: 0.2805 - acc: 0.8802
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2840 - acc: 0.8777
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2861 - acc: 0.8765
2112/4713 [============>.................] - ETA: 1s - loss: 0.2941 - acc: 0.8717
2240/4713 [=============>................] - ETA: 1s - loss: 0.2943 - acc: 0.8737
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2910 - acc: 0.8758
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2893 - acc: 0.8770
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2887 - acc: 0.8777
2752/4713 [================>.............] - ETA: 1s - loss: 0.2872 - acc: 0.8790
2880/4713 [=================>............] - ETA: 1s - loss: 0.2902 - acc: 0.8778
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2904 - acc: 0.8787
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2901 - acc: 0.8776
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2885 - acc: 0.8775
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2893 - acc: 0.8771
3520/4713 [=====================>........] - ETA: 0s - loss: 0.2889 - acc: 0.8784
3648/4713 [======================>.......] - ETA: 0s - loss: 0.2922 - acc: 0.8764
3776/4713 [=======================>......] - ETA: 0s - loss: 0.2903 - acc: 0.8766
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2915 - acc: 0.8758
4032/4713 [========================>.....] - ETA: 0s - loss: 0.2910 - acc: 0.8765
4160/4713 [=========================>....] - ETA: 0s - loss: 0.2898 - acc: 0.8762
4288/4713 [==========================>...] - ETA: 0s - loss: 0.2890 - acc: 0.8773
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2892 - acc: 0.8775
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2885 - acc: 0.8772
4672/4713 [============================>.] - ETA: 0s - loss: 0.2873 - acc: 0.8784
4713/4713 [==============================] - 3s 635us/step - loss: 0.2876 - acc: 0.8784

Test accuracy: 87.3767258382643

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  244

choose_one :  263

F1score :  0.875968992248062

AUC :  0.9436447667361738

Confusion Matrix
[[217  37]
 [ 27 226]]
True label 0
0.8543307086614174  
0.14566929133858267  
True label 1
0.1067193675889328  
0.8932806324110671  

Train_result {'loss': [0.28761661468153166], 'acc': [0.8784213876258838]}
Saved model to disk


13

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2693 - acc: 0.8750
 192/4713 [>.............................] - ETA: 3s - loss: 0.2523 - acc: 0.8854
 320/4713 [=>............................] - ETA: 3s - loss: 0.2893 - acc: 0.8719
 448/4713 [=>............................] - ETA: 3s - loss: 0.2965 - acc: 0.8705
 576/4713 [==>...........................] - ETA: 2s - loss: 0.2859 - acc: 0.8733
 704/4713 [===>..........................] - ETA: 2s - loss: 0.2826 - acc: 0.8764
 832/4713 [====>.........................] - ETA: 2s - loss: 0.2736 - acc: 0.8810
 960/4713 [=====>........................] - ETA: 2s - loss: 0.2771 - acc: 0.8802
1088/4713 [=====>........................] - ETA: 2s - loss: 0.2796 - acc: 0.8787
1216/4713 [======>.......................] - ETA: 2s - loss: 0.2885 - acc: 0.8750
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2865 - acc: 0.8743
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2955 - acc: 0.8723
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2885 - acc: 0.8769
1728/4713 [=========>....................] - ETA: 1s - loss: 0.2871 - acc: 0.8767
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2850 - acc: 0.8777
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2866 - acc: 0.8760
2112/4713 [============>.................] - ETA: 1s - loss: 0.2837 - acc: 0.8764
2240/4713 [=============>................] - ETA: 1s - loss: 0.2808 - acc: 0.8772
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2804 - acc: 0.8775
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2760 - acc: 0.8794
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2784 - acc: 0.8769
2752/4713 [================>.............] - ETA: 1s - loss: 0.2819 - acc: 0.8765
2880/4713 [=================>............] - ETA: 1s - loss: 0.2798 - acc: 0.8788
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2810 - acc: 0.8793
3136/4713 [==================>...........] - ETA: 1s - loss: 0.2821 - acc: 0.8804
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2831 - acc: 0.8808
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2825 - acc: 0.8809
3520/4713 [=====================>........] - ETA: 0s - loss: 0.2837 - acc: 0.8804
3648/4713 [======================>.......] - ETA: 0s - loss: 0.2852 - acc: 0.8808
3776/4713 [=======================>......] - ETA: 0s - loss: 0.2837 - acc: 0.8814
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2833 - acc: 0.8811
4032/4713 [========================>.....] - ETA: 0s - loss: 0.2826 - acc: 0.8824
4160/4713 [=========================>....] - ETA: 0s - loss: 0.2824 - acc: 0.8817
4288/4713 [==========================>...] - ETA: 0s - loss: 0.2841 - acc: 0.8804
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2838 - acc: 0.8804
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2829 - acc: 0.8805
4672/4713 [============================>.] - ETA: 0s - loss: 0.2826 - acc: 0.8810
4713/4713 [==============================] - 3s 637us/step - loss: 0.2833 - acc: 0.8810

Test accuracy: 87.77120315581854

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  258

choose_one :  249

F1score :  0.8764940239043825

AUC :  0.9443061218138247

Confusion Matrix
[[225  29]
 [ 33 220]]
True label 0
0.8858267716535433  
0.1141732283464567  
True label 1
0.13043478260869565  
0.8695652173913043  

Train_result {'loss': [0.28326585726982817], 'acc': [0.8809675365755975]}
Saved model to disk


14

Epoch 1/1

  64/4713 [..............................] - ETA: 4s - loss: 0.2490 - acc: 0.8906
 192/4713 [>.............................] - ETA: 3s - loss: 0.2647 - acc: 0.8854
 320/4713 [=>............................] - ETA: 3s - loss: 0.2798 - acc: 0.8750
 448/4713 [=>............................] - ETA: 3s - loss: 0.3125 - acc: 0.8616
 576/4713 [==>...........................] - ETA: 2s - loss: 0.3088 - acc: 0.8628
 704/4713 [===>..........................] - ETA: 2s - loss: 0.3283 - acc: 0.8537
 832/4713 [====>.........................] - ETA: 2s - loss: 0.3171 - acc: 0.8630
 960/4713 [=====>........................] - ETA: 2s - loss: 0.3083 - acc: 0.8688
1088/4713 [=====>........................] - ETA: 2s - loss: 0.3041 - acc: 0.8722
1216/4713 [======>.......................] - ETA: 2s - loss: 0.3017 - acc: 0.8717
1344/4713 [=======>......................] - ETA: 2s - loss: 0.2964 - acc: 0.8735
1472/4713 [========>.....................] - ETA: 2s - loss: 0.2973 - acc: 0.8716
1600/4713 [=========>....................] - ETA: 2s - loss: 0.2997 - acc: 0.8675
1728/4713 [=========>....................] - ETA: 1s - loss: 0.2976 - acc: 0.8698
1856/4713 [==========>...................] - ETA: 1s - loss: 0.2980 - acc: 0.8702
1984/4713 [===========>..................] - ETA: 1s - loss: 0.2945 - acc: 0.8710
2112/4713 [============>.................] - ETA: 1s - loss: 0.2933 - acc: 0.8717
2240/4713 [=============>................] - ETA: 1s - loss: 0.2934 - acc: 0.8714
2368/4713 [==============>...............] - ETA: 1s - loss: 0.2912 - acc: 0.8720
2496/4713 [==============>...............] - ETA: 1s - loss: 0.2908 - acc: 0.8722
2624/4713 [===============>..............] - ETA: 1s - loss: 0.2875 - acc: 0.8727
2752/4713 [================>.............] - ETA: 1s - loss: 0.2862 - acc: 0.8728
2880/4713 [=================>............] - ETA: 1s - loss: 0.2871 - acc: 0.8740
3008/4713 [==================>...........] - ETA: 1s - loss: 0.2823 - acc: 0.8763
3136/4713 [==================>...........] - ETA: 0s - loss: 0.2857 - acc: 0.8750
3264/4713 [===================>..........] - ETA: 0s - loss: 0.2847 - acc: 0.8753
3392/4713 [====================>.........] - ETA: 0s - loss: 0.2827 - acc: 0.8765
3520/4713 [=====================>........] - ETA: 0s - loss: 0.2845 - acc: 0.8767
3648/4713 [======================>.......] - ETA: 0s - loss: 0.2840 - acc: 0.8772
3776/4713 [=======================>......] - ETA: 0s - loss: 0.2828 - acc: 0.8779
3904/4713 [=======================>......] - ETA: 0s - loss: 0.2795 - acc: 0.8801
4032/4713 [========================>.....] - ETA: 0s - loss: 0.2774 - acc: 0.8812
4160/4713 [=========================>....] - ETA: 0s - loss: 0.2804 - acc: 0.8800
4288/4713 [==========================>...] - ETA: 0s - loss: 0.2784 - acc: 0.8811
4416/4713 [===========================>..] - ETA: 0s - loss: 0.2776 - acc: 0.8813
4544/4713 [===========================>..] - ETA: 0s - loss: 0.2774 - acc: 0.8807
4672/4713 [============================>.] - ETA: 0s - loss: 0.2787 - acc: 0.8814
4713/4713 [==============================] - 3s 625us/step - loss: 0.2795 - acc: 0.8814

Test accuracy: 86.98224852071006

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  260

choose_one :  247

F1score :  0.8680000000000001

AUC :  0.9462045999190813

Confusion Matrix
[[224  30]
 [ 36 217]]
True label 0
0.8818897637795275  
0.11811023622047244  
True label 1
0.1422924901185771  
0.857707509881423  

Train_result {'loss': [0.2795208863599422], 'acc': [0.881391894733883]}
Saved model to disk


15

Epoch 1/1

  64/4713 [..............................] - ETA: 3s - loss: 0.1495 - acc: 0.9688
 128/4713 [..............................] - ETA: 3s - loss: 0.2230 - acc: 0.9219
 256/4713 [>.............................] - ETA: 3s - loss: 0.2288 - acc: 0.9141
 384/4713 [=>............................] - ETA: 3s - loss: 0.2562 - acc: 0.9010
 512/4713 [==>...........................] - ETA: 3s - loss: 0.2575 - acc: 0.9023
 640/4713 [===>..........................] - ETA: 2s - loss: 0.2545 - acc: 0.8953
 768/4713 [===>..........................] - ETA: 2s - loss: 0.2536 - acc: 0.8932
 896/4713 [====>.........................] - ETA: 2s - loss: 0.2624 - acc: 0.8906
1024/4713 [=====>........................] - ETA: 2s - loss: 0.2611 - acc: 0.8896
1152/4713 [======>.......................] - ETA: 2s - loss: 0.2586 - acc: 0.8880
1280/4713 [=======>......................] - ETA: 2s - loss: 0.2655 - acc: 0.8859
1408/4713 [=======>......................] - ETA: 2s - loss: 0.2602 - acc: 0.8857
1536/4713 [========>.....................] - ETA: 2s - loss: 0.2621 - acc: 0.8835
1664/4713 [=========>....................] - ETA: 2s - loss: 0.2665 - acc: 0.8840
1792/4713 [==========>...................] - ETA: 1s - loss: 0.2663 - acc: 0.8828
1920/4713 [===========>..................] - ETA: 1s - loss: 0.2710 - acc: 0.8802
2048/4713 [============>.................] - ETA: 1s - loss: 0.2727 - acc: 0.8813
2176/4713 [============>.................] - ETA: 1s - loss: 0.2762 - acc: 0.8787
2304/4713 [=============>................] - ETA: 1s - loss: 0.2782 - acc: 0.8793
2432/4713 [==============>...............] - ETA: 1s - loss: 0.2792 - acc: 0.8799
2560/4713 [===============>..............] - ETA: 1s - loss: 0.2785 - acc: 0.8797
2688/4713 [================>.............] - ETA: 1s - loss: 0.2820 - acc: 0.8791
2816/4713 [================>.............] - ETA: 1s - loss: 0.2823 - acc: 0.8800
2944/4713 [=================>............] - ETA: 1s - loss: 0.2831 - acc: 0.8784
3072/4713 [==================>...........] - ETA: 1s - loss: 0.2813 - acc: 0.8792
3200/4713 [===================>..........] - ETA: 0s - loss: 0.2825 - acc: 0.8794
3328/4713 [====================>.........] - ETA: 0s - loss: 0.2828 - acc: 0.8789
3456/4713 [====================>.........] - ETA: 0s - loss: 0.2816 - acc: 0.8793
3584/4713 [=====================>........] - ETA: 0s - loss: 0.2811 - acc: 0.8800
3712/4713 [======================>.......] - ETA: 0s - loss: 0.2778 - acc: 0.8815
3840/4713 [=======================>......] - ETA: 0s - loss: 0.2763 - acc: 0.8823
3968/4713 [========================>.....] - ETA: 0s - loss: 0.2760 - acc: 0.8818
4096/4713 [=========================>....] - ETA: 0s - loss: 0.2772 - acc: 0.8806
4224/4713 [=========================>....] - ETA: 0s - loss: 0.2788 - acc: 0.8804
4352/4713 [==========================>...] - ETA: 0s - loss: 0.2774 - acc: 0.8810
4480/4713 [===========================>..] - ETA: 0s - loss: 0.2780 - acc: 0.8815
4608/4713 [============================>.] - ETA: 0s - loss: 0.2779 - acc: 0.8822
4713/4713 [==============================] - 3s 643us/step - loss: 0.2777 - acc: 0.8818

Test accuracy: 86.98224852071006

data size :  5220

zero :  2611

one :  2609

train_zero :  2357

train_one :  2356

test_zero :  254

test_one :  253

choose_zero :  236

choose_one :  271

F1score :  0.8740458015267175

AUC :  0.9410460303134045

Confusion Matrix
[[212  42]
 [ 24 229]]
True label 0
0.8346456692913385  
0.16535433070866143  
True label 1
0.09486166007905138  
0.9051383399209486  

Train_result {'loss': [0.2777338891544844], 'acc': [0.8818162530945184]}
Saved model to disk


[[84.41814595660749, 1], [86.58777120315581, 2], [86.3905325443787, 3], [85.99605522682445, 4], [87.17948717948718, 5], [86.3905325443787, 6], [86.98224852071006, 7], [87.17948717948718, 8], [86.3905325443787, 9], [86.58777120315581, 10], [86.58777120315581, 11], [87.3767258382643, 12], [87.77120315581854, 13], [86.98224852071006, 14], [86.98224852071006, 15]]
max accuracy :  [87.77120315581854, 13]
