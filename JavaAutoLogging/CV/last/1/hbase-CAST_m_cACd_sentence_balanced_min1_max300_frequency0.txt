Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
/home/2014313303/taeha/JavaAutoLogging/model.py:210: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor("ou..., inputs=[<tf.Tenso...)`
  model = Model(input=[input1, input2, input3, input4], output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-10-08 23:33:42.863928: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-08 23:33:42.875856: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099840000 Hz
2019-10-08 23:33:42.877635: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0xddf3d30 executing computations on platform Host. Devices:
2019-10-08 23:33:42.877676: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
First data
zero :  6384
one :  6438

Second data
zero :  6384
one :  6438

Third data
zero :  6384
one :  6438

4th data
zero :  6384
one :  6438

hbase-code
After set document size of train data, the number of zero and one label data :  5764 5776
After set document size of test data, the number of zero and one label data :  619 662

Sentence length Average : 77

Under 10 : 772
Over 10, Under 30 : 2109
Over 30, Under 100 : 6327
Over 100, Under 150 : 2039
Over 150, Under 200 : 868
Over 200, Under 400 : 706
Over 400 : 0

After balance out data.
hbase-code

Sentence length Average : 77

Under 10 : 772
Over 10, Under 30 : 2109
Over 30, Under 100 : 6327
Over 100, Under 150 : 2039
Over 150, Under 200 : 868
Over 200, Under 400 : 706
Over 400 : 0

300
hbase-AST
After set document size of train data, the number of zero and one label data :  5764 5776
After set document size of test data, the number of zero and one label data :  619 662
After balance out data.
hbase-AST

Sentence length Average : 58

Under 10 : 1713
Over 10, Under 30 : 2744
Over 30, Under 100 : 6088
Over 100, Under 150 : 1411
Over 150, Under 200 : 591
Over 200, Under 400 : 270
Over 400 : 4

704
hbase-CAST
After set document size of train data, the number of zero and one label data :  5764 5776
After set document size of test data, the number of zero and one label data :  619 662
After balance out data.
hbase-CAST

Sentence length Average : 120

Under 10 : 687
Over 10, Under 30 : 1410
Over 30, Under 100 : 4534
Over 100, Under 150 : 2370
Over 150, Under 200 : 1486
Over 200, Under 400 : 2076
Over 400 : 258

1050
hbase-depth_num
After set document size of train data, the number of zero and one label data :  5764 5776
After set document size of test data, the number of zero and one label data :  619 662
After balance out data.
hbase-depth_num

Sentence length Average : 58

Under 10 : 1713
Over 10, Under 30 : 2744
Over 30, Under 100 : 6088
Over 100, Under 150 : 1411
Over 150, Under 200 : 591
Over 200, Under 400 : 270
Over 400 : 4

704
Count model parameter.
Get a short summary of each layer dimensions and parameters.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 300, 200)     0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 704, 200)     0                                            
__________________________________________________________________________________________________
masking_1 (Masking)             (None, 300, 200)     0           input_1[0][0]                    
__________________________________________________________________________________________________
masking_2 (Masking)             (None, 704, 200)     0           input_2[0][0]                    
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1050, 200)    0                                            
__________________________________________________________________________________________________
forwards_1 (LSTM)               (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
backwords_1 (LSTM)              (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
forwards_2 (LSTM)               (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
backwards_2 (LSTM)              (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
masking_3 (Masking)             (None, 1050, 200)    0           input_3[0][0]                    
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 704, 200)     0                                            
__________________________________________________________________________________________________
after_dp_forward_1 (Dropout)    (None, 64)           0           forwards_1[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_1 (Dropout)   (None, 64)           0           backwords_1[0][0]                
__________________________________________________________________________________________________
after_dp_forward_2 (Dropout)    (None, 64)           0           forwards_2[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_2 (Dropout)   (None, 64)           0           backwards_2[0][0]                
__________________________________________________________________________________________________
forwards_3 (LSTM)               (None, 64)           67840       masking_3[0][0]                  
__________________________________________________________________________________________________
backwards_3 (LSTM)              (None, 64)           67840       masking_3[0][0]                  
__________________________________________________________________________________________________
masking_4 (Masking)             (None, 704, 200)     0           input_4[0][0]                    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128)          0           after_dp_forward_1[0][0]         
                                                                 after_dp_backward_1[0][0]        
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 128)          0           after_dp_forward_2[0][0]         
                                                                 after_dp_backward_2[0][0]        
__________________________________________________________________________________________________
after_dp_forward_3 (Dropout)    (None, 64)           0           forwards_3[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_3 (Dropout)   (None, 64)           0           backwards_3[0][0]                
__________________________________________________________________________________________________
forwards_4 (LSTM)               (None, 64)           67840       masking_4[0][0]                  
__________________________________________________________________________________________________
backwards_4 (LSTM)              (None, 64)           67840       masking_4[0][0]                  
__________________________________________________________________________________________________
after_dp_1 (Dropout)            (None, 128)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
after_dp_2 (Dropout)            (None, 128)          0           concatenate_2[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 128)          0           after_dp_forward_3[0][0]         
                                                                 after_dp_backward_3[0][0]        
__________________________________________________________________________________________________
after_dp_forward_4 (Dropout)    (None, 64)           0           forwards_4[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_4 (Dropout)   (None, 64)           0           backwards_4[0][0]                
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 256)          0           after_dp_1[0][0]                 
                                                                 after_dp_2[0][0]                 
__________________________________________________________________________________________________
after_dp_3 (Dropout)            (None, 128)          0           concatenate_3[0][0]              
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 128)          0           after_dp_forward_4[0][0]         
                                                                 after_dp_backward_4[0][0]        
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 384)          0           concatenate_5[0][0]              
                                                                 after_dp_3[0][0]                 
__________________________________________________________________________________________________
after_dp_4 (Dropout)            (None, 128)          0           concatenate_4[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 512)          0           concatenate_6[0][0]              
                                                                 after_dp_4[0][0]                 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          262656      concatenate_7[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 768)          393984      dense_1[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 512)          393728      dense_2[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 256)          131328      dense_3[0][0]                    
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 128)          32896       dense_4[0][0]                    
__________________________________________________________________________________________________
output (Dense)                  (None, 2)            258         dense_5[0][0]                    
==================================================================================================
Total params: 1,757,570
Trainable params: 1,757,570
Non-trainable params: 0
__________________________________________________________________________________________________
1

Epoch 1/1

   64/11540 [..............................] - ETA: 31:03 - loss: 0.7149 - acc: 0.4688
  128/11540 [..............................] - ETA: 19:03 - loss: 0.7007 - acc: 0.5156
  192/11540 [..............................] - ETA: 14:57 - loss: 0.7112 - acc: 0.4740
  256/11540 [..............................] - ETA: 12:46 - loss: 0.7428 - acc: 0.4805
  320/11540 [..............................] - ETA: 11:28 - loss: 0.7482 - acc: 0.4813
  384/11540 [..............................] - ETA: 10:33 - loss: 0.7377 - acc: 0.5000
  448/11540 [>.............................] - ETA: 9:55 - loss: 0.7328 - acc: 0.4888 
  512/11540 [>.............................] - ETA: 9:24 - loss: 0.7263 - acc: 0.5039
  576/11540 [>.............................] - ETA: 8:59 - loss: 0.7218 - acc: 0.5069
  640/11540 [>.............................] - ETA: 8:43 - loss: 0.7163 - acc: 0.5141
  704/11540 [>.............................] - ETA: 8:31 - loss: 0.7110 - acc: 0.5213
  768/11540 [>.............................] - ETA: 8:17 - loss: 0.7095 - acc: 0.5169
  832/11540 [=>............................] - ETA: 8:05 - loss: 0.7066 - acc: 0.5204
  896/11540 [=>............................] - ETA: 7:54 - loss: 0.7031 - acc: 0.5268
  960/11540 [=>............................] - ETA: 7:43 - loss: 0.6989 - acc: 0.5344
 1024/11540 [=>............................] - ETA: 7:35 - loss: 0.6938 - acc: 0.5449
 1088/11540 [=>............................] - ETA: 7:30 - loss: 0.6865 - acc: 0.5570
 1152/11540 [=>............................] - ETA: 7:23 - loss: 0.6816 - acc: 0.5642
 1216/11540 [==>...........................] - ETA: 7:16 - loss: 0.6767 - acc: 0.5732
 1280/11540 [==>...........................] - ETA: 7:09 - loss: 0.6722 - acc: 0.5797
 1344/11540 [==>...........................] - ETA: 7:04 - loss: 0.6656 - acc: 0.5893
 1408/11540 [==>...........................] - ETA: 6:59 - loss: 0.6642 - acc: 0.5930
 1472/11540 [==>...........................] - ETA: 6:56 - loss: 0.6602 - acc: 0.5965
 1536/11540 [==>...........................] - ETA: 6:51 - loss: 0.6598 - acc: 0.5996
 1600/11540 [===>..........................] - ETA: 6:47 - loss: 0.6512 - acc: 0.6069
 1664/11540 [===>..........................] - ETA: 6:43 - loss: 0.6482 - acc: 0.6130
 1728/11540 [===>..........................] - ETA: 6:39 - loss: 0.6464 - acc: 0.6146
 1792/11540 [===>..........................] - ETA: 6:35 - loss: 0.6389 - acc: 0.6233
 1856/11540 [===>..........................] - ETA: 6:32 - loss: 0.6339 - acc: 0.6272
 1920/11540 [===>..........................] - ETA: 6:27 - loss: 0.6335 - acc: 0.6281
 1984/11540 [====>.........................] - ETA: 6:22 - loss: 0.6280 - acc: 0.6326
 2048/11540 [====>.........................] - ETA: 6:19 - loss: 0.6248 - acc: 0.6367
 2112/11540 [====>.........................] - ETA: 6:16 - loss: 0.6200 - acc: 0.6411
 2176/11540 [====>.........................] - ETA: 6:12 - loss: 0.6155 - acc: 0.6466
 2240/11540 [====>.........................] - ETA: 6:09 - loss: 0.6118 - acc: 0.6509
 2304/11540 [====>.........................] - ETA: 6:06 - loss: 0.6113 - acc: 0.6528
 2368/11540 [=====>........................] - ETA: 6:03 - loss: 0.6092 - acc: 0.6550
 2432/11540 [=====>........................] - ETA: 5:59 - loss: 0.6048 - acc: 0.6591
 2496/11540 [=====>........................] - ETA: 5:56 - loss: 0.6041 - acc: 0.6607
 2560/11540 [=====>........................] - ETA: 5:53 - loss: 0.6007 - acc: 0.6641
 2624/11540 [=====>........................] - ETA: 5:49 - loss: 0.6007 - acc: 0.6635
 2688/11540 [=====>........................] - ETA: 5:47 - loss: 0.6001 - acc: 0.6659
 2752/11540 [======>.......................] - ETA: 5:44 - loss: 0.5977 - acc: 0.6697
 2816/11540 [======>.......................] - ETA: 5:41 - loss: 0.5959 - acc: 0.6705
 2880/11540 [======>.......................] - ETA: 5:38 - loss: 0.5935 - acc: 0.6733
 2944/11540 [======>.......................] - ETA: 5:35 - loss: 0.5907 - acc: 0.6773
 3008/11540 [======>.......................] - ETA: 5:32 - loss: 0.5892 - acc: 0.6799
 3072/11540 [======>.......................] - ETA: 5:28 - loss: 0.5855 - acc: 0.6829
 3136/11540 [=======>......................] - ETA: 5:25 - loss: 0.5869 - acc: 0.6837
 3200/11540 [=======>......................] - ETA: 5:22 - loss: 0.5841 - acc: 0.6859
 3264/11540 [=======>......................] - ETA: 5:19 - loss: 0.5844 - acc: 0.6860
 3328/11540 [=======>......................] - ETA: 5:16 - loss: 0.5811 - acc: 0.6884
 3392/11540 [=======>......................] - ETA: 5:13 - loss: 0.5815 - acc: 0.6893
 3456/11540 [=======>......................] - ETA: 5:10 - loss: 0.5809 - acc: 0.6907
 3520/11540 [========>.....................] - ETA: 5:08 - loss: 0.5790 - acc: 0.6923
 3584/11540 [========>.....................] - ETA: 5:05 - loss: 0.5772 - acc: 0.6942
 3648/11540 [========>.....................] - ETA: 5:03 - loss: 0.5770 - acc: 0.6933
 3712/11540 [========>.....................] - ETA: 5:00 - loss: 0.5764 - acc: 0.6940
 3776/11540 [========>.....................] - ETA: 4:58 - loss: 0.5744 - acc: 0.6957
 3840/11540 [========>.....................] - ETA: 4:55 - loss: 0.5714 - acc: 0.6982
 3904/11540 [=========>....................] - ETA: 4:52 - loss: 0.5694 - acc: 0.6993
 3968/11540 [=========>....................] - ETA: 4:49 - loss: 0.5664 - acc: 0.7014
 4032/11540 [=========>....................] - ETA: 4:47 - loss: 0.5653 - acc: 0.7024
 4096/11540 [=========>....................] - ETA: 4:44 - loss: 0.5636 - acc: 0.7026
 4160/11540 [=========>....................] - ETA: 4:42 - loss: 0.5608 - acc: 0.7048
 4224/11540 [=========>....................] - ETA: 4:39 - loss: 0.5594 - acc: 0.7062
 4288/11540 [==========>...................] - ETA: 4:36 - loss: 0.5585 - acc: 0.7078
 4352/11540 [==========>...................] - ETA: 4:34 - loss: 0.5573 - acc: 0.7093
 4416/11540 [==========>...................] - ETA: 4:31 - loss: 0.5563 - acc: 0.7095
 4480/11540 [==========>...................] - ETA: 4:29 - loss: 0.5532 - acc: 0.7114
 4544/11540 [==========>...................] - ETA: 4:26 - loss: 0.5515 - acc: 0.7126
 4608/11540 [==========>...................] - ETA: 4:24 - loss: 0.5495 - acc: 0.7144
 4672/11540 [===========>..................] - ETA: 4:21 - loss: 0.5491 - acc: 0.7151
 4736/11540 [===========>..................] - ETA: 4:18 - loss: 0.5475 - acc: 0.7156
 4800/11540 [===========>..................] - ETA: 4:15 - loss: 0.5451 - acc: 0.7173
 4864/11540 [===========>..................] - ETA: 4:13 - loss: 0.5446 - acc: 0.7175
 4928/11540 [===========>..................] - ETA: 4:10 - loss: 0.5439 - acc: 0.7181
 4992/11540 [===========>..................] - ETA: 4:08 - loss: 0.5422 - acc: 0.7198
 5056/11540 [============>.................] - ETA: 4:05 - loss: 0.5416 - acc: 0.7207
 5120/11540 [============>.................] - ETA: 4:03 - loss: 0.5406 - acc: 0.7205
 5184/11540 [============>.................] - ETA: 4:00 - loss: 0.5394 - acc: 0.7215
 5248/11540 [============>.................] - ETA: 3:58 - loss: 0.5394 - acc: 0.7214
 5312/11540 [============>.................] - ETA: 3:55 - loss: 0.5380 - acc: 0.7223
 5376/11540 [============>.................] - ETA: 3:53 - loss: 0.5379 - acc: 0.7225
 5440/11540 [=============>................] - ETA: 3:50 - loss: 0.5360 - acc: 0.7243
 5504/11540 [=============>................] - ETA: 3:48 - loss: 0.5355 - acc: 0.7244
 5568/11540 [=============>................] - ETA: 3:45 - loss: 0.5347 - acc: 0.7252
 5632/11540 [=============>................] - ETA: 3:43 - loss: 0.5343 - acc: 0.7262
 5696/11540 [=============>................] - ETA: 3:40 - loss: 0.5344 - acc: 0.7268
 5760/11540 [=============>................] - ETA: 3:38 - loss: 0.5329 - acc: 0.7280
 5824/11540 [==============>...............] - ETA: 3:35 - loss: 0.5326 - acc: 0.7284
 5888/11540 [==============>...............] - ETA: 3:32 - loss: 0.5317 - acc: 0.7286
 5952/11540 [==============>...............] - ETA: 3:29 - loss: 0.5308 - acc: 0.7292
 6016/11540 [==============>...............] - ETA: 3:27 - loss: 0.5302 - acc: 0.7302
 6080/11540 [==============>...............] - ETA: 3:24 - loss: 0.5303 - acc: 0.7301
 6144/11540 [==============>...............] - ETA: 3:22 - loss: 0.5296 - acc: 0.7306
 6208/11540 [===============>..............] - ETA: 3:20 - loss: 0.5292 - acc: 0.7313
 6272/11540 [===============>..............] - ETA: 3:18 - loss: 0.5285 - acc: 0.7315
 6336/11540 [===============>..............] - ETA: 3:15 - loss: 0.5269 - acc: 0.7328
 6400/11540 [===============>..............] - ETA: 3:13 - loss: 0.5267 - acc: 0.7328
 6464/11540 [===============>..............] - ETA: 3:11 - loss: 0.5258 - acc: 0.7330
 6528/11540 [===============>..............] - ETA: 3:08 - loss: 0.5254 - acc: 0.7336
 6592/11540 [================>.............] - ETA: 3:06 - loss: 0.5242 - acc: 0.7341
 6656/11540 [================>.............] - ETA: 3:03 - loss: 0.5226 - acc: 0.7348
 6720/11540 [================>.............] - ETA: 3:01 - loss: 0.5214 - acc: 0.7353
 6784/11540 [================>.............] - ETA: 2:59 - loss: 0.5202 - acc: 0.7363
 6848/11540 [================>.............] - ETA: 2:56 - loss: 0.5187 - acc: 0.7370
 6912/11540 [================>.............] - ETA: 2:54 - loss: 0.5178 - acc: 0.7373
 6976/11540 [=================>............] - ETA: 2:51 - loss: 0.5166 - acc: 0.7381
 7040/11540 [=================>............] - ETA: 2:49 - loss: 0.5161 - acc: 0.7386
 7104/11540 [=================>............] - ETA: 2:46 - loss: 0.5153 - acc: 0.7390
 7168/11540 [=================>............] - ETA: 2:44 - loss: 0.5159 - acc: 0.7386
 7232/11540 [=================>............] - ETA: 2:42 - loss: 0.5150 - acc: 0.7391
 7296/11540 [=================>............] - ETA: 2:39 - loss: 0.5144 - acc: 0.7399
 7360/11540 [==================>...........] - ETA: 2:37 - loss: 0.5138 - acc: 0.7404
 7424/11540 [==================>...........] - ETA: 2:34 - loss: 0.5137 - acc: 0.7403
 7488/11540 [==================>...........] - ETA: 2:32 - loss: 0.5129 - acc: 0.7412
 7552/11540 [==================>...........] - ETA: 2:30 - loss: 0.5127 - acc: 0.7410
 7616/11540 [==================>...........] - ETA: 2:27 - loss: 0.5120 - acc: 0.7408
 7680/11540 [==================>...........] - ETA: 2:25 - loss: 0.5123 - acc: 0.7411
 7744/11540 [===================>..........] - ETA: 2:22 - loss: 0.5114 - acc: 0.7415
 7808/11540 [===================>..........] - ETA: 2:20 - loss: 0.5100 - acc: 0.7423
 7872/11540 [===================>..........] - ETA: 2:17 - loss: 0.5113 - acc: 0.7420
 7936/11540 [===================>..........] - ETA: 2:15 - loss: 0.5111 - acc: 0.7422
 8000/11540 [===================>..........] - ETA: 2:13 - loss: 0.5098 - acc: 0.7428
 8064/11540 [===================>..........] - ETA: 2:10 - loss: 0.5090 - acc: 0.7433
 8128/11540 [====================>.........] - ETA: 2:08 - loss: 0.5095 - acc: 0.7432
 8192/11540 [====================>.........] - ETA: 2:06 - loss: 0.5091 - acc: 0.7440
 8256/11540 [====================>.........] - ETA: 2:03 - loss: 0.5100 - acc: 0.7435
 8320/11540 [====================>.........] - ETA: 2:01 - loss: 0.5097 - acc: 0.7434
 8384/11540 [====================>.........] - ETA: 1:58 - loss: 0.5094 - acc: 0.7437
 8448/11540 [====================>.........] - ETA: 1:56 - loss: 0.5093 - acc: 0.7435
 8512/11540 [=====================>........] - ETA: 1:53 - loss: 0.5083 - acc: 0.7444
 8576/11540 [=====================>........] - ETA: 1:51 - loss: 0.5081 - acc: 0.7443
 8640/11540 [=====================>........] - ETA: 1:49 - loss: 0.5076 - acc: 0.7441
 8704/11540 [=====================>........] - ETA: 1:46 - loss: 0.5065 - acc: 0.7451
 8768/11540 [=====================>........] - ETA: 1:44 - loss: 0.5068 - acc: 0.7448
 8832/11540 [=====================>........] - ETA: 1:42 - loss: 0.5064 - acc: 0.7450
 8896/11540 [======================>.......] - ETA: 1:39 - loss: 0.5055 - acc: 0.7455
 8960/11540 [======================>.......] - ETA: 1:37 - loss: 0.5044 - acc: 0.7458
 9024/11540 [======================>.......] - ETA: 1:34 - loss: 0.5030 - acc: 0.7468
 9088/11540 [======================>.......] - ETA: 1:32 - loss: 0.5037 - acc: 0.7465
 9152/11540 [======================>.......] - ETA: 1:29 - loss: 0.5032 - acc: 0.7463