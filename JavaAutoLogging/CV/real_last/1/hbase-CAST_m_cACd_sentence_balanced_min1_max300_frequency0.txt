Using TensorFlow backend.
First data
zero :  7657
one :  7650

Second data
zero :  7657
one :  7650

Third data
zero :  7657
one :  7650

4th data
zero :  7657
one :  7650

hbase-code
After set document size of train data, the number of zero and one label data :  6855 6922
After set document size of test data, the number of zero and one label data :  802 727

Sentence length Average : 80

Under 10 : 877
Over 10, Under 30 : 2523
Over 30, Under 100 : 7276
Over 100, Under 150 : 2508
Over 150, Under 200 : 1171
Over 200, Under 400 : 951
Over 400 : 0

After balance out data.
hbase-code

Sentence length Average : 80

Under 10 : 877
Over 10, Under 30 : 2523
Over 30, Under 100 : 7276
Over 100, Under 150 : 2508
Over 150, Under 200 : 1171
Over 200, Under 400 : 951
Over 400 : 0

300
hbase-AST
After set document size of train data, the number of zero and one label data :  6855 6922
After set document size of test data, the number of zero and one label data :  802 727
After balance out data.
hbase-AST

Sentence length Average : 60

Under 10 : 2072
Over 10, Under 30 : 3356
Over 30, Under 100 : 6944
Over 100, Under 150 : 1747
Over 150, Under 200 : 790
Over 200, Under 400 : 394
Over 400 : 3

704
hbase-CAST
After set document size of train data, the number of zero and one label data :  6855 6922
After set document size of test data, the number of zero and one label data :  802 727
After balance out data.
hbase-CAST

Sentence length Average : 142

Under 10 : 810
Over 10, Under 30 : 1621
Over 30, Under 100 : 4682
Over 100, Under 150 : 2519
Over 150, Under 200 : 1831
Over 200, Under 400 : 3118
Over 400 : 725

1433
hbase-depth_num
After set document size of train data, the number of zero and one label data :  6855 6922
After set document size of test data, the number of zero and one label data :  802 727
After balance out data.
hbase-depth_num

Sentence length Average : 60

Under 10 : 2072
Over 10, Under 30 : 3356
Over 30, Under 100 : 6944
Over 100, Under 150 : 1747
Over 150, Under 200 : 790
Over 200, Under 400 : 394
Over 400 : 3

704
Traceback (most recent call last):
  File "sentence_java_auto_logging.py", line 346, in <module>
    X_train4, Y_train4 = pr.create_deep_learning_input_data(train_data4, train_logging4, max_sentence_len4, embed_size_word2vec, vocabulary, wordvec_model)
  File "/home/2014313303/taeha/JavaAutoLogging/preprocessing_data.py", line 242, in create_deep_learning_input_data
    X = np.empty(shape=[len(data), max_sentence_len, embed_size_word2vec], dtype='float32')
MemoryError
