Using TensorFlow backend.
First data
zero :  10049
one :  10279

Second data
zero :  10049
one :  10279

Third data
zero :  10049
one :  10279

hbase-code
After set document size of train data, the number of zero and one label data :  44 56
After set document size of test data, the number of zero and one label data :  10005 10223

Sentence length Average : 44

Under 10 : 3104
Over 10, Under 30 : 7785
Over 30, Under 100 : 7330
Over 100, Under 150 : 1113
Over 150, Under 200 : 509
Over 200, Under 400 : 487
Over 400 : 0

After balance out data.
hbase-code

Sentence length Average : 44

Under 10 : 3104
Over 10, Under 30 : 7785
Over 30, Under 100 : 7330
Over 100, Under 150 : 1113
Over 150, Under 200 : 509
Over 200, Under 400 : 487
Over 400 : 0

300
hbase-AST
After set document size of train data, the number of zero and one label data :  44 56
After set document size of test data, the number of zero and one label data :  10005 10223
After balance out data.
hbase-AST

Sentence length Average : 30

Under 10 : 7492
Over 10, Under 30 : 6294
Over 30, Under 100 : 5232
Over 100, Under 150 : 774
Over 150, Under 200 : 347
Over 200, Under 400 : 186
Over 400 : 3

621
hbase-CAST
After set document size of train data, the number of zero and one label data :  44 56
After set document size of test data, the number of zero and one label data :  10005 10223
After balance out data.
hbase-CAST

Sentence length Average : 66

Under 10 : 1960
Over 10, Under 30 : 6663
Over 30, Under 100 : 7615
Over 100, Under 150 : 1826
Over 150, Under 200 : 842
Over 200, Under 400 : 1236
Over 400 : 186

697
Traceback (most recent call last):
  File "stacking.py", line 351, in <module>
    X_test3, Y_test3 = pr.create_deep_learning_input_data(test_data3, test_exception3, max_sentence_len3, embed_size_word2vec, vocabulary, wordvec_model)
  File "/home/2014313303/taeha/JavaAutoLogging/preprocessing_data.py", line 255, in create_deep_learning_input_data
    X = np.empty(shape=[len(data), max_sentence_len, embed_size_word2vec], dtype='float32')
MemoryError
