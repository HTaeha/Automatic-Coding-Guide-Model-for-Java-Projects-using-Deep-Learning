Using TensorFlow backend.
First data
zero :  12935
one :  12723

Second data
zero :  12935
one :  12723

Third data
zero :  12935
one :  12723

4th data
zero :  12935
one :  12723

guava-code
After set document size of train data, the number of zero and one label data :  11683 11410
After set document size of test data, the number of zero and one label data :  1252 1312

Sentence length Average : 34

Under 10 : 3292
Over 10, Under 30 : 11587
Over 30, Under 100 : 9592
Over 100, Under 150 : 822
Over 150, Under 200 : 263
Over 200, Under 400 : 101
Over 400 : 0

After balance out data.
guava-code

Sentence length Average : 34

Under 10 : 3292
Over 10, Under 30 : 11587
Over 30, Under 100 : 9592
Over 100, Under 150 : 822
Over 150, Under 200 : 263
Over 200, Under 400 : 101
Over 400 : 0

288
guava-AST
After set document size of train data, the number of zero and one label data :  11683 11410
After set document size of test data, the number of zero and one label data :  1252 1312
After balance out data.
guava-AST

Sentence length Average : 25

Under 10 : 7257
Over 10, Under 30 : 10886
Over 30, Under 100 : 6803
Over 100, Under 150 : 520
Over 150, Under 200 : 141
Over 200, Under 400 : 50
Over 400 : 0

286
Traceback (most recent call last):
  File "sentence_java_auto_logging.py", line 254, in <module>
    X_train2, Y_train2 = pr.create_deep_learning_input_data(train_data2, train_logging2, max_sentence_len2, embed_size_word2vec, vocabulary, wordvec_model)
  File "/home/2014313303/taeha/JavaAutoLogging/preprocessing_data.py", line 242, in create_deep_learning_input_data
    X = np.empty(shape=[len(data), max_sentence_len, embed_size_word2vec], dtype='float32')
MemoryError
