Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
sum_MLP.py:400: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor("de..., inputs=Tensor("in...)`
  model = Model(input=inputs, output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-08-21 14:38:43.484879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-21 14:38:43.490758: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099840000 Hz
2019-08-21 14:38:43.492413: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x8454e50 executing computations on platform Host. Devices:
2019-08-21 14:38:43.492435: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
zero : 
39451

one : 
9019
hbase-code
all data

Sentence length Average : 55

Under 10 : 8165
Over 10, Under 200 : 37669
Over 200, Under 400 : 2147
Over 400 : 489

hbase-code
updated_train_data

Sentence length Average : 50

Under 10 : 0
Over 10, Under 200 : 27203
Over 200, Under 400 : 820
Over 400 : 0


Test_zero:  2300
Train_zero:  20480
zero:  22780
Test_one:  797
Train_one:  7543
one:  8340

Count model parameter.
Get a short summary of each layer dimensions and parameters.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 200)               0         
_________________________________________________________________
masking_1 (Masking)          (None, 200)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              205824    
_________________________________________________________________
dropout_1 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
dropout_2 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 2050      
=================================================================
Total params: 1,257,474
Trainable params: 1,257,474
Non-trainable params: 0
_________________________________________________________________
1

Epoch 1/1

   64/15087 [..............................] - ETA: 51s - loss: 3.7571 - acc: 0.5312
  384/15087 [..............................] - ETA: 10s - loss: 6.8829 - acc: 0.5026
  768/15087 [>.............................] - ETA: 6s - loss: 7.2611 - acc: 0.5143 
 1152/15087 [=>............................] - ETA: 4s - loss: 7.3032 - acc: 0.5234
 1536/15087 [==>...........................] - ETA: 3s - loss: 7.3033 - acc: 0.5293
 1856/15087 [==>...........................] - ETA: 3s - loss: 7.2773 - acc: 0.5339
 2112/15087 [===>..........................] - ETA: 3s - loss: 7.4026 - acc: 0.5279
 2368/15087 [===>..........................] - ETA: 3s - loss: 7.5280 - acc: 0.5215
 2624/15087 [====>.........................] - ETA: 3s - loss: 7.5429 - acc: 0.5217
 2880/15087 [====>.........................] - ETA: 3s - loss: 7.5888 - acc: 0.5198
 3136/15087 [=====>........................] - ETA: 3s - loss: 7.6580 - acc: 0.5163
 3392/15087 [=====>........................] - ETA: 2s - loss: 7.6978 - acc: 0.5144
 3648/15087 [======>.......................] - ETA: 2s - loss: 7.7187 - acc: 0.5137
 3840/15087 [======>.......................] - ETA: 2s - loss: 7.7358 - acc: 0.5130
 3968/15087 [======>.......................] - ETA: 2s - loss: 7.7543 - acc: 0.5121
 4096/15087 [=======>......................] - ETA: 2s - loss: 7.7717 - acc: 0.5112
 4288/15087 [=======>......................] - ETA: 2s - loss: 7.7921 - acc: 0.5103
 4416/15087 [=======>......................] - ETA: 2s - loss: 7.7743 - acc: 0.5115
 4544/15087 [========>.....................] - ETA: 2s - loss: 7.7433 - acc: 0.5136
 4736/15087 [========>.....................] - ETA: 2s - loss: 7.7765 - acc: 0.5118
 4928/15087 [========>.....................] - ETA: 2s - loss: 7.7875 - acc: 0.5114
 5056/15087 [=========>....................] - ETA: 2s - loss: 7.7912 - acc: 0.5113
 5248/15087 [=========>....................] - ETA: 2s - loss: 7.8133 - acc: 0.5101
 5440/15087 [=========>....................] - ETA: 2s - loss: 7.8160 - acc: 0.5101
 5632/15087 [==========>...................] - ETA: 2s - loss: 7.8386 - acc: 0.5089
 5760/15087 [==========>...................] - ETA: 2s - loss: 7.8715 - acc: 0.5069
 6016/15087 [==========>...................] - ETA: 2s - loss: 7.8527 - acc: 0.5083
 6208/15087 [===========>..................] - ETA: 2s - loss: 7.8669 - acc: 0.5076
 6336/15087 [===========>..................] - ETA: 2s - loss: 7.8835 - acc: 0.5066
 6528/15087 [===========>..................] - ETA: 2s - loss: 7.8960 - acc: 0.5060
 6720/15087 [============>.................] - ETA: 2s - loss: 7.9055 - acc: 0.5055
 6976/15087 [============>.................] - ETA: 2s - loss: 7.9296 - acc: 0.5042
 7232/15087 [=============>................] - ETA: 2s - loss: 7.9297 - acc: 0.5043
 7488/15087 [=============>................] - ETA: 2s - loss: 7.9449 - acc: 0.5035
 7744/15087 [==============>...............] - ETA: 2s - loss: 7.9653 - acc: 0.5023
 8000/15087 [==============>...............] - ETA: 2s - loss: 7.9925 - acc: 0.5008
 8256/15087 [===============>..............] - ETA: 1s - loss: 8.0004 - acc: 0.5004
 8512/15087 [===============>..............] - ETA: 1s - loss: 8.0041 - acc: 0.5002
 8768/15087 [================>.............] - ETA: 1s - loss: 8.0186 - acc: 0.4994
 9024/15087 [================>.............] - ETA: 1s - loss: 8.0340 - acc: 0.4986
 9152/15087 [=================>............] - ETA: 1s - loss: 8.0185 - acc: 0.4996
 9280/15087 [=================>............] - ETA: 1s - loss: 8.0104 - acc: 0.5001
 9408/15087 [=================>............] - ETA: 1s - loss: 7.9990 - acc: 0.5009
 9536/15087 [=================>............] - ETA: 1s - loss: 7.9830 - acc: 0.5019
 9728/15087 [==================>...........] - ETA: 1s - loss: 7.9729 - acc: 0.5026
 9920/15087 [==================>...........] - ETA: 1s - loss: 7.9761 - acc: 0.5024
10176/15087 [===================>..........] - ETA: 1s - loss: 7.9862 - acc: 0.5019
10432/15087 [===================>..........] - ETA: 1s - loss: 7.9740 - acc: 0.5027
10688/15087 [====================>.........] - ETA: 1s - loss: 7.9715 - acc: 0.5029
10944/15087 [====================>.........] - ETA: 1s - loss: 7.9883 - acc: 0.5019
11136/15087 [=====================>........] - ETA: 1s - loss: 7.9924 - acc: 0.5017
11392/15087 [=====================>........] - ETA: 1s - loss: 7.9883 - acc: 0.5020
11648/15087 [======================>.......] - ETA: 0s - loss: 7.9677 - acc: 0.5033
11904/15087 [======================>.......] - ETA: 0s - loss: 7.9737 - acc: 0.5030
12160/15087 [=======================>......] - ETA: 0s - loss: 7.9729 - acc: 0.5031
12416/15087 [=======================>......] - ETA: 0s - loss: 7.9824 - acc: 0.5026
12672/15087 [========================>.....] - ETA: 0s - loss: 7.9865 - acc: 0.5024
12928/15087 [========================>.....] - ETA: 0s - loss: 8.0104 - acc: 0.5009
13184/15087 [=========================>....] - ETA: 0s - loss: 8.0175 - acc: 0.5005
13440/15087 [=========================>....] - ETA: 0s - loss: 8.0230 - acc: 0.5002
13696/15087 [==========================>...] - ETA: 0s - loss: 8.0296 - acc: 0.4999
13952/15087 [==========================>...] - ETA: 0s - loss: 8.0209 - acc: 0.5004
14208/15087 [===========================>..] - ETA: 0s - loss: 8.0193 - acc: 0.5006
14464/15087 [===========================>..] - ETA: 0s - loss: 8.0334 - acc: 0.4997
14720/15087 [============================>.] - ETA: 0s - loss: 8.0371 - acc: 0.4995
14976/15087 [============================>.] - ETA: 0s - loss: 8.0343 - acc: 0.4997
15087/15087 [==============================] - 4s 271us/step - loss: 8.0329 - acc: 0.4998

Test accuracy: 50.03134796238244

data size :  16682

zero :  8342

one :  8340

train_zero :  7544

train_one :  7543

test_zero :  798

test_one :  797

choose_zero :  1595

choose_one :  0

F1score :  0.0

AUC : 0.4213702386455474

Confusion Matrix
[[798   0]
 [797   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.032850688009667], 'acc': [0.4998342944296152]}
Saved model to disk



2

Epoch 1/1

   64/15087 [..............................] - ETA: 3s - loss: 6.0443 - acc: 0.6250
  320/15087 [..............................] - ETA: 3s - loss: 7.7568 - acc: 0.5188
  576/15087 [>.............................] - ETA: 3s - loss: 7.8632 - acc: 0.5122
  832/15087 [>.............................] - ETA: 3s - loss: 7.8266 - acc: 0.5144
 1024/15087 [=>............................] - ETA: 3s - loss: 7.8544 - acc: 0.5127
 1216/15087 [=>............................] - ETA: 3s - loss: 7.7409 - acc: 0.5197
 1472/15087 [=>............................] - ETA: 3s - loss: 7.9605 - acc: 0.5061
 1728/15087 [==>...........................] - ETA: 3s - loss: 8.0124 - acc: 0.5029
 1984/15087 [==>...........................] - ETA: 3s - loss: 8.0347 - acc: 0.5015
 2176/15087 [===>..........................] - ETA: 3s - loss: 8.0146 - acc: 0.5028
 2496/15087 [===>..........................] - ETA: 2s - loss: 7.9622 - acc: 0.5060
 2752/15087 [====>.........................] - ETA: 2s - loss: 8.0590 - acc: 0.5000
 2944/15087 [====>.........................] - ETA: 2s - loss: 8.0152 - acc: 0.5027
 3200/15087 [=====>........................] - ETA: 2s - loss: 7.9432 - acc: 0.5072
 3456/15087 [=====>........................] - ETA: 2s - loss: 7.9938 - acc: 0.5041
 3584/15087 [======>.......................] - ETA: 2s - loss: 8.0096 - acc: 0.5031
 3776/15087 [======>.......................] - ETA: 2s - loss: 8.0206 - acc: 0.5024
 3968/15087 [======>.......................] - ETA: 2s - loss: 7.9981 - acc: 0.5038
 4352/15087 [=======>......................] - ETA: 2s - loss: 7.9887 - acc: 0.5044
 4736/15087 [========>.....................] - ETA: 2s - loss: 8.0114 - acc: 0.5030
 5120/15087 [=========>....................] - ETA: 2s - loss: 8.0653 - acc: 0.4996
 5504/15087 [=========>....................] - ETA: 2s - loss: 8.0795 - acc: 0.4987
 5888/15087 [==========>...................] - ETA: 1s - loss: 8.0317 - acc: 0.5017
 6208/15087 [===========>..................] - ETA: 1s - loss: 8.0045 - acc: 0.5034
 6592/15087 [============>.................] - ETA: 1s - loss: 7.9759 - acc: 0.5052
 6784/15087 [============>.................] - ETA: 1s - loss: 8.0044 - acc: 0.5034
 7040/15087 [============>.................] - ETA: 1s - loss: 8.0316 - acc: 0.5017
 7296/15087 [=============>................] - ETA: 1s - loss: 8.0215 - acc: 0.5023
 7488/15087 [=============>................] - ETA: 1s - loss: 8.0418 - acc: 0.5011
 7744/15087 [==============>...............] - ETA: 1s - loss: 8.0465 - acc: 0.5008
 8000/15087 [==============>...............] - ETA: 1s - loss: 8.0913 - acc: 0.4979
 8256/15087 [===============>..............] - ETA: 1s - loss: 8.0786 - acc: 0.4987
 8512/15087 [===============>..............] - ETA: 1s - loss: 8.0894 - acc: 0.4980
 8768/15087 [================>.............] - ETA: 1s - loss: 8.0885 - acc: 0.4981
 9024/15087 [================>.............] - ETA: 1s - loss: 8.0859 - acc: 0.4982
 9280/15087 [=================>............] - ETA: 1s - loss: 8.0643 - acc: 0.4996
 9536/15087 [=================>............] - ETA: 1s - loss: 8.0523 - acc: 0.5003
 9792/15087 [==================>...........] - ETA: 1s - loss: 8.0410 - acc: 0.5010
10048/15087 [==================>...........] - ETA: 1s - loss: 8.0414 - acc: 0.5010
10176/15087 [===================>..........] - ETA: 1s - loss: 8.0638 - acc: 0.4996
10304/15087 [===================>..........] - ETA: 1s - loss: 8.0466 - acc: 0.5007
10432/15087 [===================>..........] - ETA: 1s - loss: 8.0421 - acc: 0.5010
10688/15087 [====================>.........] - ETA: 0s - loss: 8.0606 - acc: 0.4998
11072/15087 [=====================>........] - ETA: 0s - loss: 8.0416 - acc: 0.5010
11328/15087 [=====================>........] - ETA: 0s - loss: 8.0321 - acc: 0.5016
11648/15087 [======================>.......] - ETA: 0s - loss: 8.0425 - acc: 0.5009
11904/15087 [======================>.......] - ETA: 0s - loss: 8.0415 - acc: 0.5010
12224/15087 [=======================>......] - ETA: 0s - loss: 8.0459 - acc: 0.5007
12480/15087 [=======================>......] - ETA: 0s - loss: 8.0423 - acc: 0.5010
12736/15087 [========================>.....] - ETA: 0s - loss: 8.0414 - acc: 0.5010
12992/15087 [========================>.....] - ETA: 0s - loss: 8.0442 - acc: 0.5008
13248/15087 [=========================>....] - ETA: 0s - loss: 8.0457 - acc: 0.5008
13504/15087 [=========================>....] - ETA: 0s - loss: 8.0495 - acc: 0.5005
13760/15087 [==========================>...] - ETA: 0s - loss: 8.0696 - acc: 0.4993
14016/15087 [==========================>...] - ETA: 0s - loss: 8.0614 - acc: 0.4998
14272/15087 [===========================>..] - ETA: 0s - loss: 8.0613 - acc: 0.4998
14528/15087 [===========================>..] - ETA: 0s - loss: 8.0569 - acc: 0.5001
14848/15087 [============================>.] - ETA: 0s - loss: 8.0623 - acc: 0.4997
15087/15087 [==============================] - 3s 219us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03134796238244

data size :  16682

zero :  8342

one :  8340

train_zero :  7544

train_one :  7543

test_zero :  798

test_one :  797

choose_zero :  1595

choose_one :  0

F1score :  0.0

AUC : 0.44380713389496323

Confusion Matrix
[[798   0]
 [797   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.05854407470601], 'acc': [0.4999668588732807]}
Saved model to disk



3

Epoch 1/1

   64/15087 [..............................] - ETA: 3s - loss: 9.3183 - acc: 0.4219
  320/15087 [..............................] - ETA: 3s - loss: 7.8576 - acc: 0.5125
  576/15087 [>.............................] - ETA: 3s - loss: 8.0031 - acc: 0.5035
  832/15087 [>.............................] - ETA: 3s - loss: 8.2334 - acc: 0.4892
 1088/15087 [=>............................] - ETA: 3s - loss: 8.2220 - acc: 0.4899
 1344/15087 [=>............................] - ETA: 2s - loss: 8.3469 - acc: 0.4821
 1600/15087 [==>...........................] - ETA: 2s - loss: 8.3310 - acc: 0.4831
 1856/15087 [==>...........................] - ETA: 2s - loss: 8.1893 - acc: 0.4919
 2112/15087 [===>..........................] - ETA: 2s - loss: 8.1888 - acc: 0.4920
 2432/15087 [===>..........................] - ETA: 2s - loss: 8.1783 - acc: 0.4926
 2688/15087 [====>.........................] - ETA: 2s - loss: 8.0890 - acc: 0.4981
 2944/15087 [====>.........................] - ETA: 2s - loss: 8.0043 - acc: 0.5034
 3136/15087 [=====>........................] - ETA: 2s - loss: 8.0128 - acc: 0.5029
 3392/15087 [=====>........................] - ETA: 2s - loss: 8.0686 - acc: 0.4994
 3584/15087 [======>.......................] - ETA: 2s - loss: 8.0411 - acc: 0.5011
 3712/15087 [======>.......................] - ETA: 2s - loss: 8.0069 - acc: 0.5032
 3904/15087 [======>.......................] - ETA: 2s - loss: 7.9765 - acc: 0.5051
 4224/15087 [=======>......................] - ETA: 2s - loss: 8.0285 - acc: 0.5019
 4608/15087 [========>.....................] - ETA: 2s - loss: 7.9611 - acc: 0.5061
 4992/15087 [========>.....................] - ETA: 2s - loss: 8.0106 - acc: 0.5030
 5184/15087 [=========>....................] - ETA: 2s - loss: 8.0342 - acc: 0.5015
 5440/15087 [=========>....................] - ETA: 2s - loss: 8.0057 - acc: 0.5033
 5632/15087 [==========>...................] - ETA: 2s - loss: 7.9589 - acc: 0.5062
 5760/15087 [==========>...................] - ETA: 2s - loss: 7.9555 - acc: 0.5064
 5952/15087 [==========>...................] - ETA: 2s - loss: 7.9534 - acc: 0.5066
 6272/15087 [===========>..................] - ETA: 2s - loss: 7.9511 - acc: 0.5067
 6400/15087 [===========>..................] - ETA: 2s - loss: 7.9533 - acc: 0.5066
 6592/15087 [============>.................] - ETA: 2s - loss: 7.9612 - acc: 0.5061
 6784/15087 [============>.................] - ETA: 2s - loss: 7.9593 - acc: 0.5062
 6976/15087 [============>.................] - ETA: 1s - loss: 7.9712 - acc: 0.5054
 7168/15087 [=============>................] - ETA: 1s - loss: 7.9534 - acc: 0.5066
 7360/15087 [=============>................] - ETA: 1s - loss: 7.9495 - acc: 0.5068
 7616/15087 [==============>...............] - ETA: 1s - loss: 7.9553 - acc: 0.5064
 7808/15087 [==============>...............] - ETA: 1s - loss: 7.9662 - acc: 0.5058
 8000/15087 [==============>...............] - ETA: 1s - loss: 7.9684 - acc: 0.5056
 8192/15087 [===============>..............] - ETA: 1s - loss: 7.9626 - acc: 0.5060
 8448/15087 [===============>..............] - ETA: 1s - loss: 7.9961 - acc: 0.5039
 8640/15087 [================>.............] - ETA: 1s - loss: 8.0068 - acc: 0.5032
 8896/15087 [================>.............] - ETA: 1s - loss: 7.9993 - acc: 0.5037
 9152/15087 [=================>............] - ETA: 1s - loss: 7.9939 - acc: 0.5040
 9408/15087 [=================>............] - ETA: 1s - loss: 7.9991 - acc: 0.5037
 9664/15087 [==================>...........] - ETA: 1s - loss: 8.0040 - acc: 0.5034
 9856/15087 [==================>...........] - ETA: 1s - loss: 8.0165 - acc: 0.5026
10112/15087 [===================>..........] - ETA: 1s - loss: 8.0288 - acc: 0.5019
10240/15087 [===================>..........] - ETA: 1s - loss: 8.0197 - acc: 0.5024
10368/15087 [===================>..........] - ETA: 1s - loss: 8.0171 - acc: 0.5026
10560/15087 [===================>..........] - ETA: 1s - loss: 8.0133 - acc: 0.5028
10752/15087 [====================>.........] - ETA: 1s - loss: 8.0246 - acc: 0.5021
10944/15087 [====================>.........] - ETA: 1s - loss: 8.0311 - acc: 0.5017
11136/15087 [=====================>........] - ETA: 1s - loss: 8.0388 - acc: 0.5013
11392/15087 [=====================>........] - ETA: 0s - loss: 8.0336 - acc: 0.5016
11648/15087 [======================>.......] - ETA: 0s - loss: 8.0341 - acc: 0.5015
11904/15087 [======================>.......] - ETA: 0s - loss: 8.0306 - acc: 0.5018
12160/15087 [=======================>......] - ETA: 0s - loss: 8.0498 - acc: 0.5006
12416/15087 [=======================>......] - ETA: 0s - loss: 8.0603 - acc: 0.4999
12672/15087 [========================>.....] - ETA: 0s - loss: 8.0578 - acc: 0.5001
12928/15087 [========================>.....] - ETA: 0s - loss: 8.0553 - acc: 0.5002
13184/15087 [=========================>....] - ETA: 0s - loss: 8.0688 - acc: 0.4994
13440/15087 [=========================>....] - ETA: 0s - loss: 8.0734 - acc: 0.4991
13696/15087 [==========================>...] - ETA: 0s - loss: 8.0720 - acc: 0.4992
13952/15087 [==========================>...] - ETA: 0s - loss: 8.0706 - acc: 0.4993
14272/15087 [===========================>..] - ETA: 0s - loss: 8.0602 - acc: 0.4999
14592/15087 [============================>.] - ETA: 0s - loss: 8.0511 - acc: 0.5005
14912/15087 [============================>.] - ETA: 0s - loss: 8.0707 - acc: 0.4993
15087/15087 [==============================] - 4s 243us/step - loss: 8.0583 - acc: 0.5000

Test accuracy: 50.03134796238244

data size :  16682

zero :  8342

one :  8340

train_zero :  7544

train_one :  7543

test_zero :  798

test_one :  797

choose_zero :  1595

choose_one :  0

F1score :  0.0

AUC : 0.4374188293821128

Confusion Matrix
[[798   0]
 [797   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.05830790842157], 'acc': [0.500033141087212]}
Saved model to disk



4

Epoch 1/1

   64/15087 [..............................] - ETA: 4s - loss: 8.8146 - acc: 0.4531
  320/15087 [..............................] - ETA: 3s - loss: 7.6057 - acc: 0.5281
  576/15087 [>.............................] - ETA: 3s - loss: 7.8352 - acc: 0.5139
  832/15087 [>.............................] - ETA: 3s - loss: 7.8459 - acc: 0.5132
 1088/15087 [=>............................] - ETA: 3s - loss: 7.7331 - acc: 0.5202
 1344/15087 [=>............................] - ETA: 2s - loss: 7.7592 - acc: 0.5186
 1664/15087 [==>...........................] - ETA: 2s - loss: 7.8459 - acc: 0.5132
 1920/15087 [==>...........................] - ETA: 2s - loss: 7.7904 - acc: 0.5167
 2176/15087 [===>..........................] - ETA: 2s - loss: 7.8516 - acc: 0.5129
 2496/15087 [===>..........................] - ETA: 2s - loss: 7.9105 - acc: 0.5092
 2752/15087 [====>.........................] - ETA: 2s - loss: 7.8541 - acc: 0.5127
 3008/15087 [====>.........................] - ETA: 2s - loss: 7.8661 - acc: 0.5120
 3200/15087 [=====>........................] - ETA: 2s - loss: 7.8878 - acc: 0.5106
 3520/15087 [=====>........................] - ETA: 2s - loss: 7.8805 - acc: 0.5111
 3840/15087 [======>.......................] - ETA: 2s - loss: 7.9037 - acc: 0.5096
 4032/15087 [=======>......................] - ETA: 2s - loss: 7.9431 - acc: 0.5072
 4224/15087 [=======>......................] - ETA: 2s - loss: 7.9331 - acc: 0.5078
 4416/15087 [=======>......................] - ETA: 2s - loss: 7.9568 - acc: 0.5063
 4608/15087 [========>.....................] - ETA: 2s - loss: 7.9576 - acc: 0.5063
 4928/15087 [========>.....................] - ETA: 2s - loss: 7.9675 - acc: 0.5057
 5248/15087 [=========>....................] - ETA: 2s - loss: 7.9546 - acc: 0.5065
 5504/15087 [=========>....................] - ETA: 2s - loss: 7.9624 - acc: 0.5060
 5696/15087 [==========>...................] - ETA: 2s - loss: 7.9628 - acc: 0.5060
 5952/15087 [==========>...................] - ETA: 2s - loss: 7.9426 - acc: 0.5072
 6208/15087 [===========>..................] - ETA: 2s - loss: 7.9552 - acc: 0.5064
 6464/15087 [===========>..................] - ETA: 1s - loss: 7.9593 - acc: 0.5062
 6656/15087 [============>.................] - ETA: 1s - loss: 7.9937 - acc: 0.5041
 6784/15087 [============>.................] - ETA: 1s - loss: 7.9901 - acc: 0.5043
 6912/15087 [============>.................] - ETA: 1s - loss: 7.9751 - acc: 0.5052
 7040/15087 [============>.................] - ETA: 1s - loss: 7.9743 - acc: 0.5053
 7168/15087 [=============>................] - ETA: 1s - loss: 7.9848 - acc: 0.5046
 7360/15087 [=============>................] - ETA: 1s - loss: 7.9780 - acc: 0.5050
 7552/15087 [==============>...............] - ETA: 1s - loss: 7.9651 - acc: 0.5058
 7744/15087 [==============>...............] - ETA: 1s - loss: 7.9779 - acc: 0.5050
 7936/15087 [==============>...............] - ETA: 1s - loss: 7.9859 - acc: 0.5045
 8192/15087 [===============>..............] - ETA: 1s - loss: 7.9961 - acc: 0.5039
 8448/15087 [===============>..............] - ETA: 1s - loss: 7.9999 - acc: 0.5037
 8704/15087 [================>.............] - ETA: 1s - loss: 7.9868 - acc: 0.5045
 8960/15087 [================>.............] - ETA: 1s - loss: 8.0015 - acc: 0.5036
 9216/15087 [=================>............] - ETA: 1s - loss: 8.0031 - acc: 0.5035
 9472/15087 [=================>............] - ETA: 1s - loss: 8.0046 - acc: 0.5034
 9728/15087 [==================>...........] - ETA: 1s - loss: 8.0077 - acc: 0.5032
 9984/15087 [==================>...........] - ETA: 1s - loss: 8.0171 - acc: 0.5026
10240/15087 [===================>..........] - ETA: 1s - loss: 8.0339 - acc: 0.5016
10432/15087 [===================>..........] - ETA: 1s - loss: 8.0343 - acc: 0.5015
10624/15087 [====================>.........] - ETA: 1s - loss: 8.0302 - acc: 0.5018
10880/15087 [====================>.........] - ETA: 1s - loss: 8.0250 - acc: 0.5021
11200/15087 [=====================>........] - ETA: 0s - loss: 8.0519 - acc: 0.5004
11584/15087 [======================>.......] - ETA: 0s - loss: 8.0604 - acc: 0.4999
11840/15087 [======================>.......] - ETA: 0s - loss: 8.0509 - acc: 0.5005
12096/15087 [=======================>......] - ETA: 0s - loss: 8.0564 - acc: 0.5002
12352/15087 [=======================>......] - ETA: 0s - loss: 8.0512 - acc: 0.5005
12672/15087 [========================>.....] - ETA: 0s - loss: 8.0425 - acc: 0.5010
12928/15087 [========================>.....] - ETA: 0s - loss: 8.0379 - acc: 0.5013
13184/15087 [=========================>....] - ETA: 0s - loss: 8.0285 - acc: 0.5019
13504/15087 [=========================>....] - ETA: 0s - loss: 8.0352 - acc: 0.5015
13824/15087 [==========================>...] - ETA: 0s - loss: 8.0416 - acc: 0.5011
14080/15087 [==========================>...] - ETA: 0s - loss: 8.0556 - acc: 0.5002
14336/15087 [===========================>..] - ETA: 0s - loss: 8.0444 - acc: 0.5009
14656/15087 [============================>.] - ETA: 0s - loss: 8.0557 - acc: 0.5002
14976/15087 [============================>.] - ETA: 0s - loss: 8.0494 - acc: 0.5006
15087/15087 [==============================] - 4s 233us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03134796238244

data size :  16682

zero :  8342

one :  8340

train_zero :  7544

train_one :  7543

test_zero :  798

test_one :  797

choose_zero :  1595

choose_one :  0

F1score :  0.0

AUC : 0.475420829363245

Confusion Matrix
[[798   0]
 [797   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058514049578323], 'acc': [0.5000331411583251]}
Saved model to disk



5

Epoch 1/1

   64/15087 [..............................] - ETA: 3s - loss: 9.5701 - acc: 0.4062
  320/15087 [..............................] - ETA: 3s - loss: 8.4620 - acc: 0.4750
  640/15087 [>.............................] - ETA: 2s - loss: 8.2102 - acc: 0.4906
  960/15087 [>.............................] - ETA: 2s - loss: 8.1598 - acc: 0.4938
 1280/15087 [=>............................] - ETA: 2s - loss: 8.0842 - acc: 0.4984
 1600/15087 [==>...........................] - ETA: 2s - loss: 8.1296 - acc: 0.4956
 1920/15087 [==>...........................] - ETA: 2s - loss: 8.0926 - acc: 0.4979
 2240/15087 [===>..........................] - ETA: 2s - loss: 8.0519 - acc: 0.5004
 2560/15087 [====>.........................] - ETA: 2s - loss: 8.0968 - acc: 0.4977
 2880/15087 [====>.........................] - ETA: 2s - loss: 8.1374 - acc: 0.4951
 3136/15087 [=====>........................] - ETA: 2s - loss: 8.1310 - acc: 0.4955
 3456/15087 [=====>........................] - ETA: 2s - loss: 8.1337 - acc: 0.4954
 3776/15087 [======>.......................] - ETA: 2s - loss: 8.1487 - acc: 0.4944
 4096/15087 [=======>......................] - ETA: 2s - loss: 8.1377 - acc: 0.4951
 4352/15087 [=======>......................] - ETA: 2s - loss: 8.1479 - acc: 0.4945
 4608/15087 [========>.....................] - ETA: 2s - loss: 8.1535 - acc: 0.4941
 4864/15087 [========>.....................] - ETA: 2s - loss: 8.1717 - acc: 0.4930
 5056/15087 [=========>....................] - ETA: 2s - loss: 8.1515 - acc: 0.4943
 5312/15087 [=========>....................] - ETA: 2s - loss: 8.1440 - acc: 0.4947
 5568/15087 [==========>...................] - ETA: 2s - loss: 8.1777 - acc: 0.4926
 5952/15087 [==========>...................] - ETA: 1s - loss: 8.1809 - acc: 0.4924
 6336/15087 [===========>..................] - ETA: 1s - loss: 8.1532 - acc: 0.4942
 6720/15087 [============>.................] - ETA: 1s - loss: 8.1262 - acc: 0.4958
 7104/15087 [=============>................] - ETA: 1s - loss: 8.1407 - acc: 0.4949
 7360/15087 [=============>................] - ETA: 1s - loss: 8.1138 - acc: 0.4966
 7680/15087 [==============>...............] - ETA: 1s - loss: 8.1136 - acc: 0.4966
 7872/15087 [==============>...............] - ETA: 1s - loss: 8.1000 - acc: 0.4975
 8128/15087 [===============>..............] - ETA: 1s - loss: 8.0888 - acc: 0.4982
 8448/15087 [===============>..............] - ETA: 1s - loss: 8.0724 - acc: 0.4992
 8640/15087 [================>.............] - ETA: 1s - loss: 8.0702 - acc: 0.4993
 8896/15087 [================>.............] - ETA: 1s - loss: 8.0446 - acc: 0.5009
 9280/15087 [=================>............] - ETA: 1s - loss: 8.0747 - acc: 0.4990
 9600/15087 [==================>...........] - ETA: 1s - loss: 8.0758 - acc: 0.4990
 9920/15087 [==================>...........] - ETA: 1s - loss: 8.0834 - acc: 0.4985
10240/15087 [===================>..........] - ETA: 0s - loss: 8.0606 - acc: 0.4999
10496/15087 [===================>..........] - ETA: 0s - loss: 8.0637 - acc: 0.4997
10816/15087 [====================>.........] - ETA: 0s - loss: 8.0695 - acc: 0.4994
11136/15087 [=====================>........] - ETA: 0s - loss: 8.0779 - acc: 0.4988
11392/15087 [=====================>........] - ETA: 0s - loss: 8.0633 - acc: 0.4997
11712/15087 [======================>.......] - ETA: 0s - loss: 8.0673 - acc: 0.4995
12032/15087 [======================>.......] - ETA: 0s - loss: 8.0845 - acc: 0.4984
12288/15087 [=======================>......] - ETA: 0s - loss: 8.0669 - acc: 0.4995
12480/15087 [=======================>......] - ETA: 0s - loss: 8.0616 - acc: 0.4998
12672/15087 [========================>.....] - ETA: 0s - loss: 8.0540 - acc: 0.5003
12864/15087 [========================>.....] - ETA: 0s - loss: 8.0428 - acc: 0.5010
13056/15087 [========================>.....] - ETA: 0s - loss: 8.0344 - acc: 0.5015
13376/15087 [=========================>....] - ETA: 0s - loss: 8.0422 - acc: 0.5010
13760/15087 [==========================>...] - ETA: 0s - loss: 8.0298 - acc: 0.5018
14144/15087 [===========================>..] - ETA: 0s - loss: 8.0363 - acc: 0.5014
14400/15087 [===========================>..] - ETA: 0s - loss: 8.0490 - acc: 0.5006
14720/15087 [============================>.] - ETA: 0s - loss: 8.0569 - acc: 0.5001
14976/15087 [============================>.] - ETA: 0s - loss: 8.0515 - acc: 0.5005
15087/15087 [==============================] - 3s 202us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03134796238244

data size :  16682

zero :  8342

one :  8340

train_zero :  7544

train_one :  7543

test_zero :  798

test_one :  797

choose_zero :  1595

choose_one :  0

F1score :  0.0

AUC : 0.475420829363245

Confusion Matrix
[[798   0]
 [797   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058513578272185], 'acc': [0.5000331411188178]}
Saved model to disk



6

Epoch 1/1

   64/15087 [..............................] - ETA: 3s - loss: 8.5627 - acc: 0.4688
  320/15087 [..............................] - ETA: 3s - loss: 8.1094 - acc: 0.4969
  576/15087 [>.............................] - ETA: 2s - loss: 8.0590 - acc: 0.5000
  896/15087 [>.............................] - ETA: 2s - loss: 7.9511 - acc: 0.5067
 1216/15087 [=>............................] - ETA: 2s - loss: 7.8867 - acc: 0.5107
 1536/15087 [==>...........................] - ETA: 2s - loss: 7.9646 - acc: 0.5059
 1856/15087 [==>...........................] - ETA: 2s - loss: 8.0677 - acc: 0.4995
 2176/15087 [===>..........................] - ETA: 2s - loss: 8.0813 - acc: 0.4986
 2496/15087 [===>..........................] - ETA: 2s - loss: 8.0913 - acc: 0.4980
 2816/15087 [====>.........................] - ETA: 2s - loss: 8.1621 - acc: 0.4936
 3136/15087 [=====>........................] - ETA: 2s - loss: 8.2235 - acc: 0.4898
 3456/15087 [=====>........................] - ETA: 2s - loss: 8.2316 - acc: 0.4893
 3776/15087 [======>.......................] - ETA: 2s - loss: 8.2255 - acc: 0.4897
 4032/15087 [=======>......................] - ETA: 2s - loss: 8.2349 - acc: 0.4891
 4352/15087 [=======>......................] - ETA: 2s - loss: 8.1961 - acc: 0.4915
 4672/15087 [========>.....................] - ETA: 1s - loss: 8.2005 - acc: 0.4912
 4992/15087 [========>.....................] - ETA: 1s - loss: 8.2108 - acc: 0.4906
 5312/15087 [=========>....................] - ETA: 1s - loss: 8.2472 - acc: 0.4883
 5632/15087 [==========>...................] - ETA: 1s - loss: 8.2165 - acc: 0.4902
 5952/15087 [==========>...................] - ETA: 1s - loss: 8.2242 - acc: 0.4898
 6272/15087 [===========>..................] - ETA: 1s - loss: 8.2055 - acc: 0.4909
 6592/15087 [============>.................] - ETA: 1s - loss: 8.1984 - acc: 0.4914
 6912/15087 [============>.................] - ETA: 1s - loss: 8.2036 - acc: 0.4910
 7232/15087 [=============>................] - ETA: 1s - loss: 8.1816 - acc: 0.4924
 7360/15087 [=============>................] - ETA: 1s - loss: 8.1817 - acc: 0.4924
 7680/15087 [==============>...............] - ETA: 1s - loss: 8.1682 - acc: 0.4932
 8000/15087 [==============>...............] - ETA: 1s - loss: 8.1275 - acc: 0.4958
 8320/15087 [===============>..............] - ETA: 1s - loss: 8.1017 - acc: 0.4974
 8576/15087 [================>.............] - ETA: 1s - loss: 8.1173 - acc: 0.4964
 8832/15087 [================>.............] - ETA: 1s - loss: 8.1412 - acc: 0.4949
 9024/15087 [================>.............] - ETA: 1s - loss: 8.1376 - acc: 0.4951
 9280/15087 [=================>............] - ETA: 1s - loss: 8.1129 - acc: 0.4967
 9536/15087 [=================>............] - ETA: 1s - loss: 8.0912 - acc: 0.4980
 9728/15087 [==================>...........] - ETA: 1s - loss: 8.0839 - acc: 0.4985
 9856/15087 [==================>...........] - ETA: 1s - loss: 8.0868 - acc: 0.4983
10048/15087 [==================>...........] - ETA: 1s - loss: 8.0510 - acc: 0.5005
10240/15087 [===================>..........] - ETA: 1s - loss: 8.0339 - acc: 0.5016
10368/15087 [===================>..........] - ETA: 0s - loss: 8.0357 - acc: 0.5014
10560/15087 [===================>..........] - ETA: 0s - loss: 8.0239 - acc: 0.5022
10752/15087 [====================>.........] - ETA: 0s - loss: 8.0306 - acc: 0.5018
10944/15087 [====================>.........] - ETA: 0s - loss: 8.0296 - acc: 0.5018
11136/15087 [=====================>........] - ETA: 0s - loss: 8.0533 - acc: 0.5004
11328/15087 [=====================>........] - ETA: 0s - loss: 8.0662 - acc: 0.4996
11520/15087 [=====================>........] - ETA: 0s - loss: 8.0730 - acc: 0.4991
11712/15087 [======================>.......] - ETA: 0s - loss: 8.0632 - acc: 0.4997
11904/15087 [======================>.......] - ETA: 0s - loss: 8.0414 - acc: 0.5011
12224/15087 [=======================>......] - ETA: 0s - loss: 8.0604 - acc: 0.4999
12416/15087 [=======================>......] - ETA: 0s - loss: 8.0552 - acc: 0.5002
12672/15087 [========================>.....] - ETA: 0s - loss: 8.0603 - acc: 0.4999
12928/15087 [========================>.....] - ETA: 0s - loss: 8.0553 - acc: 0.5002
13248/15087 [=========================>....] - ETA: 0s - loss: 8.0262 - acc: 0.5020
13504/15087 [=========================>....] - ETA: 0s - loss: 8.0280 - acc: 0.5019
13824/15087 [==========================>...] - ETA: 0s - loss: 8.0147 - acc: 0.5027
14080/15087 [==========================>...] - ETA: 0s - loss: 8.0167 - acc: 0.5026
14336/15087 [===========================>..] - ETA: 0s - loss: 8.0208 - acc: 0.5024
14592/15087 [============================>.] - ETA: 0s - loss: 8.0314 - acc: 0.5017
14848/15087 [============================>.] - ETA: 0s - loss: 8.0417 - acc: 0.5011
15040/15087 [============================>.] - ETA: 0s - loss: 8.0580 - acc: 0.5001
15087/15087 [==============================] - 3s 224us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03134796238244

data size :  16682

zero :  8342

one :  8340

train_zero :  7544

train_one :  7543

test_zero :  798

test_one :  797

choose_zero :  1595

choose_one :  0

F1score :  0.0

AUC : 0.475420829363245

Confusion Matrix
[[798   0]
 [797   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058513596477143], 'acc': [0.5000331411188178]}
Saved model to disk



7

Epoch 1/1

   64/15087 [..............................] - ETA: 4s - loss: 10.5775 - acc: 0.3438
  320/15087 [..............................] - ETA: 3s - loss: 8.6131 - acc: 0.4656 
  512/15087 [>.............................] - ETA: 3s - loss: 7.9331 - acc: 0.5078
  832/15087 [>.............................] - ETA: 3s - loss: 8.3884 - acc: 0.4796
 1152/15087 [=>............................] - ETA: 2s - loss: 8.1150 - acc: 0.4965
 1472/15087 [=>............................] - ETA: 2s - loss: 8.1904 - acc: 0.4918
 1792/15087 [==>...........................] - ETA: 2s - loss: 8.3469 - acc: 0.4821
 2112/15087 [===>..........................] - ETA: 2s - loss: 8.3719 - acc: 0.4806
 2432/15087 [===>..........................] - ETA: 2s - loss: 8.3772 - acc: 0.4803
 2752/15087 [====>.........................] - ETA: 2s - loss: 8.4105 - acc: 0.4782
 3072/15087 [=====>........................] - ETA: 2s - loss: 8.3686 - acc: 0.4808
 3392/15087 [=====>........................] - ETA: 2s - loss: 8.3774 - acc: 0.4802
 3712/15087 [======>.......................] - ETA: 2s - loss: 8.3760 - acc: 0.4803
 4032/15087 [=======>......................] - ETA: 2s - loss: 8.3589 - acc: 0.4814
 4352/15087 [=======>......................] - ETA: 2s - loss: 8.3442 - acc: 0.4823
 4672/15087 [========>.....................] - ETA: 1s - loss: 8.3661 - acc: 0.4810
 4992/15087 [========>.....................] - ETA: 1s - loss: 8.3658 - acc: 0.4810
 5312/15087 [=========>....................] - ETA: 1s - loss: 8.3261 - acc: 0.4834
 5632/15087 [==========>...................] - ETA: 1s - loss: 8.2909 - acc: 0.4856
 5952/15087 [==========>...................] - ETA: 1s - loss: 8.2974 - acc: 0.4852
 6272/15087 [===========>..................] - ETA: 1s - loss: 8.3135 - acc: 0.4842
 6592/15087 [============>.................] - ETA: 1s - loss: 8.3305 - acc: 0.4832
 6912/15087 [============>.................] - ETA: 1s - loss: 8.3086 - acc: 0.4845
 7232/15087 [=============>................] - ETA: 1s - loss: 8.2663 - acc: 0.4871
 7552/15087 [==============>...............] - ETA: 1s - loss: 8.2405 - acc: 0.4887
 7872/15087 [==============>...............] - ETA: 1s - loss: 8.2474 - acc: 0.4883
 8192/15087 [===============>..............] - ETA: 1s - loss: 8.2204 - acc: 0.4900
 8512/15087 [===============>..............] - ETA: 1s - loss: 8.2105 - acc: 0.4906
 8832/15087 [================>.............] - ETA: 1s - loss: 8.2342 - acc: 0.4891
 9152/15087 [=================>............] - ETA: 1s - loss: 8.1929 - acc: 0.4917
 9472/15087 [=================>............] - ETA: 1s - loss: 8.1833 - acc: 0.4923
 9792/15087 [==================>...........] - ETA: 0s - loss: 8.1776 - acc: 0.4926
10112/15087 [===================>..........] - ETA: 0s - loss: 8.1754 - acc: 0.4928
10368/15087 [===================>..........] - ETA: 0s - loss: 8.1741 - acc: 0.4929
10624/15087 [====================>.........] - ETA: 0s - loss: 8.1577 - acc: 0.4939
10944/15087 [====================>.........] - ETA: 0s - loss: 8.1445 - acc: 0.4947
11264/15087 [=====================>........] - ETA: 0s - loss: 8.1292 - acc: 0.4956
11584/15087 [======================>.......] - ETA: 0s - loss: 8.1244 - acc: 0.4959
11776/15087 [======================>.......] - ETA: 0s - loss: 8.1165 - acc: 0.4964
12032/15087 [======================>.......] - ETA: 0s - loss: 8.1019 - acc: 0.4973
12224/15087 [=======================>......] - ETA: 0s - loss: 8.0960 - acc: 0.4977
12544/15087 [=======================>......] - ETA: 0s - loss: 8.1015 - acc: 0.4974
12864/15087 [========================>.....] - ETA: 0s - loss: 8.0891 - acc: 0.4981
12992/15087 [========================>.....] - ETA: 0s - loss: 8.0863 - acc: 0.4983
13184/15087 [=========================>....] - ETA: 0s - loss: 8.0749 - acc: 0.4990
13440/15087 [=========================>....] - ETA: 0s - loss: 8.0782 - acc: 0.4988
13632/15087 [==========================>...] - ETA: 0s - loss: 8.0673 - acc: 0.4995
13888/15087 [==========================>...] - ETA: 0s - loss: 8.0683 - acc: 0.4994
14272/15087 [===========================>..] - ETA: 0s - loss: 8.0681 - acc: 0.4994
14528/15087 [===========================>..] - ETA: 0s - loss: 8.0568 - acc: 0.5001
14784/15087 [============================>.] - ETA: 0s - loss: 8.0590 - acc: 0.5000
15087/15087 [==============================] - 3s 193us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03134796238244

data size :  16682

zero :  8342

one :  8340

train_zero :  7544

train_one :  7543

test_zero :  798

test_one :  797

choose_zero :  1595

choose_one :  0

F1score :  0.0

AUC : 0.475420829363245

Confusion Matrix
[[798   0]
 [797   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058513574985179], 'acc': [0.5000331410714091]}
Saved model to disk



8

Epoch 1/1

   64/15087 [..............................] - ETA: 4s - loss: 7.8072 - acc: 0.5156
  320/15087 [..............................] - ETA: 3s - loss: 7.2531 - acc: 0.5500
  576/15087 [>.............................] - ETA: 3s - loss: 7.5274 - acc: 0.5330
  704/15087 [>.............................] - ETA: 4s - loss: 7.6698 - acc: 0.5241
  896/15087 [>.............................] - ETA: 4s - loss: 7.8612 - acc: 0.5123
 1088/15087 [=>............................] - ETA: 4s - loss: 7.8220 - acc: 0.5147
 1472/15087 [=>............................] - ETA: 3s - loss: 7.7853 - acc: 0.5170
 1856/15087 [==>...........................] - ETA: 3s - loss: 7.7725 - acc: 0.5178
 2240/15087 [===>..........................] - ETA: 2s - loss: 7.8504 - acc: 0.5129
 2560/15087 [====>.........................] - ETA: 2s - loss: 7.8891 - acc: 0.5105
 2880/15087 [====>.........................] - ETA: 2s - loss: 7.9247 - acc: 0.5083
 3200/15087 [=====>........................] - ETA: 2s - loss: 7.9231 - acc: 0.5084
 3520/15087 [=====>........................] - ETA: 2s - loss: 7.9125 - acc: 0.5091
 3840/15087 [======>.......................] - ETA: 2s - loss: 7.9163 - acc: 0.5089
 4160/15087 [=======>......................] - ETA: 2s - loss: 8.0126 - acc: 0.5029
 4480/15087 [=======>......................] - ETA: 2s - loss: 7.9295 - acc: 0.5080
 4736/15087 [========>.....................] - ETA: 2s - loss: 7.9569 - acc: 0.5063
 5056/15087 [=========>....................] - ETA: 2s - loss: 8.0017 - acc: 0.5036
 5376/15087 [=========>....................] - ETA: 1s - loss: 7.9781 - acc: 0.5050
 5696/15087 [==========>...................] - ETA: 1s - loss: 8.0336 - acc: 0.5016
 6016/15087 [==========>...................] - ETA: 1s - loss: 8.0189 - acc: 0.5025
 6336/15087 [===========>..................] - ETA: 1s - loss: 8.0514 - acc: 0.5005
 6656/15087 [============>.................] - ETA: 1s - loss: 8.0566 - acc: 0.5002
 6976/15087 [============>.................] - ETA: 1s - loss: 8.0752 - acc: 0.4990
 7296/15087 [=============>................] - ETA: 1s - loss: 8.0149 - acc: 0.5027
 7616/15087 [==============>...............] - ETA: 1s - loss: 8.0210 - acc: 0.5024
 7936/15087 [==============>...............] - ETA: 1s - loss: 8.0306 - acc: 0.5018
 8256/15087 [===============>..............] - ETA: 1s - loss: 8.0278 - acc: 0.5019
 8576/15087 [================>.............] - ETA: 1s - loss: 8.0346 - acc: 0.5015
 8896/15087 [================>.............] - ETA: 1s - loss: 8.0264 - acc: 0.5020
 9216/15087 [=================>............] - ETA: 1s - loss: 8.0398 - acc: 0.5012
 9536/15087 [=================>............] - ETA: 1s - loss: 8.0371 - acc: 0.5014
 9856/15087 [==================>...........] - ETA: 0s - loss: 8.0492 - acc: 0.5006
10176/15087 [===================>..........] - ETA: 0s - loss: 8.0400 - acc: 0.5012
10496/15087 [===================>..........] - ETA: 0s - loss: 8.0422 - acc: 0.5010
10816/15087 [====================>.........] - ETA: 0s - loss: 8.0531 - acc: 0.5004
11136/15087 [=====================>........] - ETA: 0s - loss: 8.0663 - acc: 0.4996
11456/15087 [=====================>........] - ETA: 0s - loss: 8.0689 - acc: 0.4994
11776/15087 [======================>.......] - ETA: 0s - loss: 8.0604 - acc: 0.4999
12096/15087 [=======================>......] - ETA: 0s - loss: 8.0697 - acc: 0.4993
12416/15087 [=======================>......] - ETA: 0s - loss: 8.0746 - acc: 0.4990
12736/15087 [========================>.....] - ETA: 0s - loss: 8.0844 - acc: 0.4984
13056/15087 [========================>.....] - ETA: 0s - loss: 8.0714 - acc: 0.4992
13376/15087 [=========================>....] - ETA: 0s - loss: 8.0627 - acc: 0.4998
13696/15087 [==========================>...] - ETA: 0s - loss: 8.0461 - acc: 0.5008
14016/15087 [==========================>...] - ETA: 0s - loss: 8.0556 - acc: 0.5002
14336/15087 [===========================>..] - ETA: 0s - loss: 8.0523 - acc: 0.5004
14656/15087 [============================>.] - ETA: 0s - loss: 8.0579 - acc: 0.5001
14976/15087 [============================>.] - ETA: 0s - loss: 8.0569 - acc: 0.5001
15087/15087 [==============================] - 3s 185us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03134796238244

data size :  16682

zero :  8342

one :  8340

train_zero :  7544

train_one :  7543

test_zero :  798

test_one :  797

choose_zero :  1595

choose_one :  0

F1score :  0.0

AUC : 0.475420829363245

Confusion Matrix
[[798   0]
 [797   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.05851358453014], 'acc': [0.5000331411267193]}
Saved model to disk



9

Epoch 1/1

   64/15087 [..............................] - ETA: 5s - loss: 9.3183 - acc: 0.4219
  320/15087 [..............................] - ETA: 3s - loss: 9.0161 - acc: 0.4406
  704/15087 [>.............................] - ETA: 2s - loss: 8.3567 - acc: 0.4815
 1024/15087 [=>............................] - ETA: 2s - loss: 8.3581 - acc: 0.4814
 1280/15087 [=>............................] - ETA: 2s - loss: 8.2479 - acc: 0.4883
 1600/15087 [==>...........................] - ETA: 2s - loss: 8.3210 - acc: 0.4838
 1856/15087 [==>...........................] - ETA: 2s - loss: 8.1893 - acc: 0.4919
 2176/15087 [===>..........................] - ETA: 2s - loss: 8.0590 - acc: 0.5000
 2496/15087 [===>..........................] - ETA: 2s - loss: 8.0332 - acc: 0.5016
 2944/15087 [====>.........................] - ETA: 2s - loss: 8.0262 - acc: 0.5020
 3328/15087 [=====>........................] - ETA: 2s - loss: 8.0106 - acc: 0.5030
 3712/15087 [======>.......................] - ETA: 1s - loss: 7.9722 - acc: 0.5054
 4096/15087 [=======>......................] - ETA: 1s - loss: 7.9567 - acc: 0.5063
 4416/15087 [=======>......................] - ETA: 1s - loss: 7.9970 - acc: 0.5038
 4736/15087 [========>.....................] - ETA: 1s - loss: 8.0250 - acc: 0.5021
 4992/15087 [========>.....................] - ETA: 1s - loss: 8.0074 - acc: 0.5032
 5312/15087 [=========>....................] - ETA: 1s - loss: 7.9923 - acc: 0.5041
 5632/15087 [==========>...................] - ETA: 1s - loss: 7.9617 - acc: 0.5060
 5952/15087 [==========>...................] - ETA: 1s - loss: 7.9534 - acc: 0.5066
 6272/15087 [===========>..................] - ETA: 1s - loss: 7.9614 - acc: 0.5061
 6528/15087 [===========>..................] - ETA: 1s - loss: 7.9430 - acc: 0.5072
 6656/15087 [============>.................] - ETA: 1s - loss: 7.9477 - acc: 0.5069
 6784/15087 [============>.................] - ETA: 1s - loss: 7.9521 - acc: 0.5066
 6976/15087 [============>.................] - ETA: 1s - loss: 7.9505 - acc: 0.5067
 7232/15087 [=============>................] - ETA: 1s - loss: 7.9365 - acc: 0.5076
 7488/15087 [=============>................] - ETA: 1s - loss: 7.9299 - acc: 0.5080
 7744/15087 [==============>...............] - ETA: 1s - loss: 7.9550 - acc: 0.5065
 8000/15087 [==============>...............] - ETA: 1s - loss: 7.9563 - acc: 0.5064
 8320/15087 [===============>..............] - ETA: 1s - loss: 7.9564 - acc: 0.5064
 8640/15087 [================>.............] - ETA: 1s - loss: 7.9602 - acc: 0.5061
 8960/15087 [================>.............] - ETA: 1s - loss: 7.9547 - acc: 0.5065
 9280/15087 [=================>............] - ETA: 1s - loss: 7.9705 - acc: 0.5055
 9600/15087 [==================>...........] - ETA: 1s - loss: 7.9768 - acc: 0.5051
 9920/15087 [==================>...........] - ETA: 1s - loss: 7.9892 - acc: 0.5043
10240/15087 [===================>..........] - ETA: 0s - loss: 7.9835 - acc: 0.5047
10560/15087 [===================>..........] - ETA: 0s - loss: 7.9675 - acc: 0.5057
10880/15087 [====================>.........] - ETA: 0s - loss: 7.9524 - acc: 0.5066
11200/15087 [=====================>........] - ETA: 0s - loss: 7.9785 - acc: 0.5050
11520/15087 [=====================>........] - ETA: 0s - loss: 7.9933 - acc: 0.5041
11840/15087 [======================>.......] - ETA: 0s - loss: 7.9842 - acc: 0.5046
12160/15087 [=======================>......] - ETA: 0s - loss: 7.9994 - acc: 0.5037
12480/15087 [=======================>......] - ETA: 0s - loss: 8.0177 - acc: 0.5026
12800/15087 [========================>.....] - ETA: 0s - loss: 8.0112 - acc: 0.5030
13120/15087 [=========================>....] - ETA: 0s - loss: 8.0296 - acc: 0.5018
13440/15087 [=========================>....] - ETA: 0s - loss: 8.0435 - acc: 0.5010
13760/15087 [==========================>...] - ETA: 0s - loss: 8.0368 - acc: 0.5014
14080/15087 [==========================>...] - ETA: 0s - loss: 8.0316 - acc: 0.5017
14400/15087 [===========================>..] - ETA: 0s - loss: 8.0445 - acc: 0.5009
14720/15087 [============================>.] - ETA: 0s - loss: 8.0569 - acc: 0.5001
15040/15087 [============================>.] - ETA: 0s - loss: 8.0558 - acc: 0.5002
15087/15087 [==============================] - 3s 186us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03134796238244

data size :  16682

zero :  8342

one :  8340

train_zero :  7544

train_one :  7543

test_zero :  798

test_one :  797

choose_zero :  1595

choose_one :  0

F1score :  0.0

AUC : 0.475420829363245

Confusion Matrix
[[798   0]
 [797   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058513602924732], 'acc': [0.5000331411346207]}
Saved model to disk



10

Epoch 1/1

   64/15087 [..............................] - ETA: 3s - loss: 8.5627 - acc: 0.4688
  320/15087 [..............................] - ETA: 3s - loss: 8.5124 - acc: 0.4719
  640/15087 [>.............................] - ETA: 2s - loss: 8.2353 - acc: 0.4891
  832/15087 [>.............................] - ETA: 3s - loss: 8.2140 - acc: 0.4904
 1152/15087 [=>............................] - ETA: 2s - loss: 8.3948 - acc: 0.4792
 1472/15087 [=>............................] - ETA: 2s - loss: 8.2561 - acc: 0.4878
 1664/15087 [==>...........................] - ETA: 2s - loss: 8.1365 - acc: 0.4952
 1856/15087 [==>...........................] - ETA: 3s - loss: 8.1459 - acc: 0.4946
 2048/15087 [===>..........................] - ETA: 3s - loss: 8.0748 - acc: 0.4990
 2176/15087 [===>..........................] - ETA: 3s - loss: 8.1183 - acc: 0.4963
 2368/15087 [===>..........................] - ETA: 3s - loss: 8.0931 - acc: 0.4979
 2560/15087 [====>.........................] - ETA: 3s - loss: 8.1598 - acc: 0.4938
 2688/15087 [====>.........................] - ETA: 3s - loss: 8.1430 - acc: 0.4948
 2880/15087 [====>.........................] - ETA: 3s - loss: 8.1766 - acc: 0.4927
 3072/15087 [=====>........................] - ETA: 3s - loss: 8.1955 - acc: 0.4915
 3392/15087 [=====>........................] - ETA: 3s - loss: 8.0686 - acc: 0.4994
 3584/15087 [======>.......................] - ETA: 3s - loss: 8.0231 - acc: 0.5022
 3776/15087 [======>.......................] - ETA: 3s - loss: 8.0590 - acc: 0.5000
 4032/15087 [=======>......................] - ETA: 2s - loss: 8.0830 - acc: 0.4985
 4288/15087 [=======>......................] - ETA: 2s - loss: 8.0440 - acc: 0.5009
 4544/15087 [========>.....................] - ETA: 2s - loss: 8.0626 - acc: 0.4998
 4864/15087 [========>.....................] - ETA: 2s - loss: 8.0458 - acc: 0.5008
 5120/15087 [=========>....................] - ETA: 2s - loss: 8.0339 - acc: 0.5016
 5440/15087 [=========>....................] - ETA: 2s - loss: 8.0057 - acc: 0.5033
 5824/15087 [==========>...................] - ETA: 2s - loss: 7.9982 - acc: 0.5038
 6208/15087 [===========>..................] - ETA: 2s - loss: 8.0071 - acc: 0.5032
 6528/15087 [===========>..................] - ETA: 2s - loss: 8.0344 - acc: 0.5015
 6848/15087 [============>.................] - ETA: 1s - loss: 8.0143 - acc: 0.5028
 7104/15087 [=============>................] - ETA: 1s - loss: 8.0046 - acc: 0.5034
 7424/15087 [=============>................] - ETA: 1s - loss: 8.0113 - acc: 0.5030
 7744/15087 [==============>...............] - ETA: 1s - loss: 7.9904 - acc: 0.5043
 8000/15087 [==============>...............] - ETA: 1s - loss: 8.0288 - acc: 0.5019
 8320/15087 [===============>..............] - ETA: 1s - loss: 8.0281 - acc: 0.5019
 8512/15087 [===============>..............] - ETA: 1s - loss: 8.0363 - acc: 0.5014
 8704/15087 [================>.............] - ETA: 1s - loss: 8.0405 - acc: 0.5011
 8832/15087 [================>.............] - ETA: 1s - loss: 8.0536 - acc: 0.5003
 8960/15087 [================>.............] - ETA: 1s - loss: 8.0554 - acc: 0.5002
 9216/15087 [=================>............] - ETA: 1s - loss: 8.0433 - acc: 0.5010
 9472/15087 [=================>............] - ETA: 1s - loss: 8.0505 - acc: 0.5005
 9664/15087 [==================>...........] - ETA: 1s - loss: 8.0457 - acc: 0.5008
 9920/15087 [==================>...........] - ETA: 1s - loss: 8.0331 - acc: 0.5016
10240/15087 [===================>..........] - ETA: 1s - loss: 8.0244 - acc: 0.5021
10496/15087 [===================>..........] - ETA: 1s - loss: 8.0329 - acc: 0.5016
10816/15087 [====================>.........] - ETA: 0s - loss: 8.0278 - acc: 0.5019
11136/15087 [=====================>........] - ETA: 0s - loss: 8.0417 - acc: 0.5011
11392/15087 [=====================>........] - ETA: 0s - loss: 8.0322 - acc: 0.5017
11648/15087 [======================>.......] - ETA: 0s - loss: 8.0452 - acc: 0.5009
11968/15087 [======================>.......] - ETA: 0s - loss: 8.0442 - acc: 0.5009
12224/15087 [=======================>......] - ETA: 0s - loss: 8.0380 - acc: 0.5013
12544/15087 [=======================>......] - ETA: 0s - loss: 8.0411 - acc: 0.5011
12864/15087 [========================>.....] - ETA: 0s - loss: 8.0403 - acc: 0.5012
13184/15087 [=========================>....] - ETA: 0s - loss: 8.0211 - acc: 0.5024
13504/15087 [=========================>....] - ETA: 0s - loss: 8.0125 - acc: 0.5029
13824/15087 [==========================>...] - ETA: 0s - loss: 8.0042 - acc: 0.5034
14144/15087 [===========================>..] - ETA: 0s - loss: 8.0123 - acc: 0.5029
14464/15087 [===========================>..] - ETA: 0s - loss: 8.0223 - acc: 0.5023
14784/15087 [============================>.] - ETA: 0s - loss: 8.0242 - acc: 0.5022
15087/15087 [==============================] - 3s 218us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03134796238244

data size :  16682

zero :  8342

one :  8340

train_zero :  7544

train_one :  7543

test_zero :  798

test_one :  797

choose_zero :  1595

choose_one :  0

F1score :  0.0

AUC : 0.475420829363245

Confusion Matrix
[[798   0]
 [797   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058513597772983], 'acc': [0.5000331411109163]}
Saved model to disk



11

Epoch 1/1

   64/15087 [..............................] - ETA: 3s - loss: 7.8072 - acc: 0.5156
  384/15087 [..............................] - ETA: 2s - loss: 7.8492 - acc: 0.5130
  704/15087 [>.............................] - ETA: 2s - loss: 7.6240 - acc: 0.5270
 1024/15087 [=>............................] - ETA: 2s - loss: 7.8072 - acc: 0.5156
 1344/15087 [=>............................] - ETA: 2s - loss: 8.0710 - acc: 0.4993
 1664/15087 [==>...........................] - ETA: 2s - loss: 8.0590 - acc: 0.5000
 1984/15087 [==>...........................] - ETA: 2s - loss: 7.9616 - acc: 0.5060
 2304/15087 [===>..........................] - ETA: 2s - loss: 8.0381 - acc: 0.5013
 2624/15087 [====>.........................] - ETA: 2s - loss: 8.0590 - acc: 0.5000
 2944/15087 [====>.........................] - ETA: 2s - loss: 8.0645 - acc: 0.4997
 3136/15087 [=====>........................] - ETA: 2s - loss: 8.1361 - acc: 0.4952
 3456/15087 [=====>........................] - ETA: 2s - loss: 8.1290 - acc: 0.4957
 3776/15087 [======>.......................] - ETA: 2s - loss: 8.1444 - acc: 0.4947
 4096/15087 [=======>......................] - ETA: 2s - loss: 8.0669 - acc: 0.4995
 4288/15087 [=======>......................] - ETA: 2s - loss: 8.0666 - acc: 0.4995
 4480/15087 [=======>......................] - ETA: 2s - loss: 8.0554 - acc: 0.5002
 4672/15087 [========>.....................] - ETA: 2s - loss: 8.1142 - acc: 0.4966
 4864/15087 [========>.....................] - ETA: 2s - loss: 8.1054 - acc: 0.4971
 5120/15087 [=========>....................] - ETA: 2s - loss: 8.0842 - acc: 0.4984
 5312/15087 [=========>....................] - ETA: 2s - loss: 8.1076 - acc: 0.4970
 5504/15087 [=========>....................] - ETA: 2s - loss: 8.1147 - acc: 0.4965
 5760/15087 [==========>...................] - ETA: 2s - loss: 8.1178 - acc: 0.4964
 5952/15087 [==========>...................] - ETA: 2s - loss: 8.1430 - acc: 0.4948
 6208/15087 [===========>..................] - ETA: 1s - loss: 8.1525 - acc: 0.4942
 6528/15087 [===========>..................] - ETA: 1s - loss: 8.1603 - acc: 0.4937
 6912/15087 [============>.................] - ETA: 1s - loss: 8.1477 - acc: 0.4945
 7232/15087 [=============>................] - ETA: 1s - loss: 8.1549 - acc: 0.4941
 7488/15087 [=============>................] - ETA: 1s - loss: 8.1172 - acc: 0.4964
 7744/15087 [==============>...............] - ETA: 1s - loss: 8.1194 - acc: 0.4963
 7936/15087 [==============>...............] - ETA: 1s - loss: 8.1058 - acc: 0.4971
 8128/15087 [===============>..............] - ETA: 1s - loss: 8.0769 - acc: 0.4989
 8384/15087 [===============>..............] - ETA: 1s - loss: 8.0917 - acc: 0.4980
 8640/15087 [================>.............] - ETA: 1s - loss: 8.1150 - acc: 0.4965
 8832/15087 [================>.............] - ETA: 1s - loss: 8.1284 - acc: 0.4957
 9088/15087 [=================>............] - ETA: 1s - loss: 8.1176 - acc: 0.4964
 9344/15087 [=================>............] - ETA: 1s - loss: 8.1108 - acc: 0.4968
 9664/15087 [==================>...........] - ETA: 1s - loss: 8.1191 - acc: 0.4963
 9984/15087 [==================>...........] - ETA: 1s - loss: 8.0962 - acc: 0.4977
10240/15087 [===================>..........] - ETA: 1s - loss: 8.0842 - acc: 0.4984
10560/15087 [===================>..........] - ETA: 1s - loss: 8.0713 - acc: 0.4992
10880/15087 [====================>.........] - ETA: 0s - loss: 8.0665 - acc: 0.4995
11200/15087 [=====================>........] - ETA: 0s - loss: 8.0706 - acc: 0.4993
11456/15087 [=====================>........] - ETA: 0s - loss: 8.0844 - acc: 0.4984
11776/15087 [======================>.......] - ETA: 0s - loss: 8.1152 - acc: 0.4965
11904/15087 [======================>.......] - ETA: 0s - loss: 8.1119 - acc: 0.4967
12096/15087 [=======================>......] - ETA: 0s - loss: 8.1190 - acc: 0.4963
12352/15087 [=======================>......] - ETA: 0s - loss: 8.1086 - acc: 0.4969
12672/15087 [========================>.....] - ETA: 0s - loss: 8.1176 - acc: 0.4964
13056/15087 [========================>.....] - ETA: 0s - loss: 8.1072 - acc: 0.4970
13376/15087 [=========================>....] - ETA: 0s - loss: 8.0856 - acc: 0.4984
13824/15087 [==========================>...] - ETA: 0s - loss: 8.0719 - acc: 0.4992
14208/15087 [===========================>..] - ETA: 0s - loss: 8.0568 - acc: 0.5001
14528/15087 [===========================>..] - ETA: 0s - loss: 8.0590 - acc: 0.5000
14848/15087 [============================>.] - ETA: 0s - loss: 8.0590 - acc: 0.5000
15087/15087 [==============================] - 3s 212us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03134796238244

data size :  16682

zero :  8342

one :  8340

train_zero :  7544

train_one :  7543

test_zero :  798

test_one :  797

choose_zero :  1595

choose_one :  0

F1score :  0.0

AUC : 0.475420829363245

Confusion Matrix
[[798   0]
 [797   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.05851357922036], 'acc': [0.5000331410793105]}
Saved model to disk



12

Epoch 1/1

   64/15087 [..............................] - ETA: 3s - loss: 7.8072 - acc: 0.5156
  320/15087 [..............................] - ETA: 3s - loss: 7.8072 - acc: 0.5156
  640/15087 [>.............................] - ETA: 2s - loss: 8.1598 - acc: 0.4938
  960/15087 [>.............................] - ETA: 2s - loss: 8.0926 - acc: 0.4979
 1280/15087 [=>............................] - ETA: 2s - loss: 8.0339 - acc: 0.5016
 1600/15087 [==>...........................] - ETA: 2s - loss: 8.0691 - acc: 0.4994
 1920/15087 [==>...........................] - ETA: 2s - loss: 8.2773 - acc: 0.4865
 2240/15087 [===>..........................] - ETA: 2s - loss: 8.1814 - acc: 0.4924
 2560/15087 [====>.........................] - ETA: 2s - loss: 8.1850 - acc: 0.4922
 2880/15087 [====>.........................] - ETA: 2s - loss: 8.1430 - acc: 0.4948
 3200/15087 [=====>........................] - ETA: 2s - loss: 8.1497 - acc: 0.4944
 3520/15087 [=====>........................] - ETA: 2s - loss: 8.2056 - acc: 0.4909
 3840/15087 [======>.......................] - ETA: 1s - loss: 8.1850 - acc: 0.4922
 4160/15087 [=======>......................] - ETA: 1s - loss: 8.1094 - acc: 0.4969
 4480/15087 [=======>......................] - ETA: 1s - loss: 8.0806 - acc: 0.4987
 4800/15087 [========>.....................] - ETA: 1s - loss: 8.1027 - acc: 0.4973
 5120/15087 [=========>....................] - ETA: 1s - loss: 8.1220 - acc: 0.4961
 5440/15087 [=========>....................] - ETA: 1s - loss: 8.1035 - acc: 0.4972
 5760/15087 [==========>...................] - ETA: 1s - loss: 8.0562 - acc: 0.5002
 6080/15087 [===========>..................] - ETA: 1s - loss: 8.0564 - acc: 0.5002
 6400/15087 [===========>..................] - ETA: 1s - loss: 8.0691 - acc: 0.4994
 6720/15087 [============>.................] - ETA: 1s - loss: 8.0710 - acc: 0.4993
 7040/15087 [============>.................] - ETA: 1s - loss: 8.0728 - acc: 0.4991
 7360/15087 [=============>................] - ETA: 1s - loss: 8.1160 - acc: 0.4965
 7616/15087 [==============>...............] - ETA: 1s - loss: 8.1437 - acc: 0.4947
 7936/15087 [==============>...............] - ETA: 1s - loss: 8.1322 - acc: 0.4955
 8256/15087 [===============>..............] - ETA: 1s - loss: 8.1196 - acc: 0.4962
 8448/15087 [===============>..............] - ETA: 1s - loss: 8.1239 - acc: 0.4960
 8640/15087 [================>.............] - ETA: 1s - loss: 8.1430 - acc: 0.4948
 8832/15087 [================>.............] - ETA: 1s - loss: 8.1576 - acc: 0.4939
 9024/15087 [================>.............] - ETA: 1s - loss: 8.1698 - acc: 0.4931
 9216/15087 [=================>............] - ETA: 1s - loss: 8.1412 - acc: 0.4949
 9472/15087 [=================>............] - ETA: 1s - loss: 8.1203 - acc: 0.4962
 9728/15087 [==================>...........] - ETA: 1s - loss: 8.0922 - acc: 0.4979
10112/15087 [===================>..........] - ETA: 0s - loss: 8.0766 - acc: 0.4989
10496/15087 [===================>..........] - ETA: 0s - loss: 8.0974 - acc: 0.4976
10880/15087 [====================>.........] - ETA: 0s - loss: 8.0724 - acc: 0.4992
11264/15087 [=====================>........] - ETA: 0s - loss: 8.0633 - acc: 0.4997
11584/15087 [======================>.......] - ETA: 0s - loss: 8.0716 - acc: 0.4992
11904/15087 [======================>.......] - ETA: 0s - loss: 8.0685 - acc: 0.4994
12288/15087 [=======================>......] - ETA: 0s - loss: 8.0761 - acc: 0.4989
12736/15087 [========================>.....] - ETA: 0s - loss: 8.0603 - acc: 0.4999
13120/15087 [=========================>....] - ETA: 0s - loss: 8.0689 - acc: 0.4994
13440/15087 [=========================>....] - ETA: 0s - loss: 8.0674 - acc: 0.4995
13632/15087 [==========================>...] - ETA: 0s - loss: 8.0673 - acc: 0.4995
13952/15087 [==========================>...] - ETA: 0s - loss: 8.0463 - acc: 0.5008
14336/15087 [===========================>..] - ETA: 0s - loss: 8.0602 - acc: 0.4999
14592/15087 [============================>.] - ETA: 0s - loss: 8.0624 - acc: 0.4998
14912/15087 [============================>.] - ETA: 0s - loss: 8.0666 - acc: 0.4995
15087/15087 [==============================] - 3s 182us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03134796238244

data size :  16682

zero :  8342

one :  8340

train_zero :  7544

train_one :  7543

test_zero :  798

test_one :  797

choose_zero :  1595

choose_one :  0

F1score :  0.0

AUC : 0.475420829363245

Confusion Matrix
[[798   0]
 [797   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.05851357422664], 'acc': [0.5000331411188178]}
Saved model to disk



13

Epoch 1/1

   64/15087 [..............................] - ETA: 3s - loss: 9.5701 - acc: 0.4062
  320/15087 [..............................] - ETA: 3s - loss: 8.1094 - acc: 0.4969
  576/15087 [>.............................] - ETA: 3s - loss: 8.1150 - acc: 0.4965
  832/15087 [>.............................] - ETA: 3s - loss: 7.9234 - acc: 0.5084
 1088/15087 [=>............................] - ETA: 3s - loss: 8.1035 - acc: 0.4972
 1408/15087 [=>............................] - ETA: 2s - loss: 8.1048 - acc: 0.4972
 1728/15087 [==>...........................] - ETA: 2s - loss: 8.2269 - acc: 0.4896
 2048/15087 [===>..........................] - ETA: 2s - loss: 8.2165 - acc: 0.4902
 2368/15087 [===>..........................] - ETA: 2s - loss: 8.1884 - acc: 0.4920
 2688/15087 [====>.........................] - ETA: 2s - loss: 8.1430 - acc: 0.4948
 3008/15087 [====>.........................] - ETA: 2s - loss: 8.1930 - acc: 0.4917
 3328/15087 [=====>........................] - ETA: 2s - loss: 8.1995 - acc: 0.4913
 3648/15087 [======>.......................] - ETA: 2s - loss: 8.1474 - acc: 0.4945
 3968/15087 [======>.......................] - ETA: 2s - loss: 8.1240 - acc: 0.4960
 4288/15087 [=======>......................] - ETA: 2s - loss: 8.0966 - acc: 0.4977
 4608/15087 [========>.....................] - ETA: 1s - loss: 8.0975 - acc: 0.4976
 4928/15087 [========>.....................] - ETA: 1s - loss: 8.1081 - acc: 0.4970
 5248/15087 [=========>....................] - ETA: 1s - loss: 8.0713 - acc: 0.4992
 5568/15087 [==========>...................] - ETA: 1s - loss: 8.0851 - acc: 0.4984
 5888/15087 [==========>...................] - ETA: 1s - loss: 8.0590 - acc: 0.5000
 6208/15087 [===========>..................] - ETA: 1s - loss: 8.0513 - acc: 0.5005
 6528/15087 [===========>..................] - ETA: 1s - loss: 8.0516 - acc: 0.5005
 6848/15087 [============>.................] - ETA: 1s - loss: 8.0308 - acc: 0.5018
 7168/15087 [=============>................] - ETA: 1s - loss: 8.0096 - acc: 0.5031
 7488/15087 [=============>................] - ETA: 1s - loss: 7.9988 - acc: 0.5037
 7808/15087 [==============>...............] - ETA: 1s - loss: 8.0116 - acc: 0.5029
 8128/15087 [===============>..............] - ETA: 1s - loss: 8.0174 - acc: 0.5026
 8448/15087 [===============>..............] - ETA: 1s - loss: 8.0037 - acc: 0.5034
 8768/15087 [================>.............] - ETA: 1s - loss: 8.0315 - acc: 0.5017
 9088/15087 [=================>............] - ETA: 1s - loss: 8.0395 - acc: 0.5012
 9408/15087 [=================>............] - ETA: 1s - loss: 8.0522 - acc: 0.5004
 9728/15087 [==================>...........] - ETA: 0s - loss: 8.0325 - acc: 0.5016
10048/15087 [==================>...........] - ETA: 0s - loss: 8.0510 - acc: 0.5005
10368/15087 [===================>..........] - ETA: 0s - loss: 8.0653 - acc: 0.4996
10688/15087 [====================>.........] - ETA: 0s - loss: 8.0696 - acc: 0.4993
11008/15087 [====================>.........] - ETA: 0s - loss: 8.0605 - acc: 0.4999
11328/15087 [=====================>........] - ETA: 0s - loss: 8.0647 - acc: 0.4996
11648/15087 [======================>.......] - ETA: 0s - loss: 8.0757 - acc: 0.4990
11968/15087 [======================>.......] - ETA: 0s - loss: 8.0752 - acc: 0.4990
12288/15087 [=======================>......] - ETA: 0s - loss: 8.0932 - acc: 0.4979
12608/15087 [========================>.....] - ETA: 0s - loss: 8.0987 - acc: 0.4975
12928/15087 [========================>.....] - ETA: 0s - loss: 8.0902 - acc: 0.4981
13248/15087 [=========================>....] - ETA: 0s - loss: 8.0773 - acc: 0.4989
13568/15087 [=========================>....] - ETA: 0s - loss: 8.0852 - acc: 0.4984
13888/15087 [==========================>...] - ETA: 0s - loss: 8.0846 - acc: 0.4984
14208/15087 [===========================>..] - ETA: 0s - loss: 8.0625 - acc: 0.4998
14464/15087 [===========================>..] - ETA: 0s - loss: 8.0579 - acc: 0.5001
14912/15087 [============================>.] - ETA: 0s - loss: 8.0558 - acc: 0.5002
15087/15087 [==============================] - 3s 174us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03134796238244

data size :  16682

zero :  8342

one :  8340

train_zero :  7544

train_one :  7543

test_zero :  798

test_one :  797

choose_zero :  1595

choose_one :  0

F1score :  0.0

AUC : 0.475420829363245

Confusion Matrix
[[798   0]
 [797   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058513610636554], 'acc': [0.5000331411188178]}
Saved model to disk



14

Epoch 1/1

   64/15087 [..............................] - ETA: 6s - loss: 7.5554 - acc: 0.5312
  256/15087 [..............................] - ETA: 5s - loss: 7.9331 - acc: 0.5078
  448/15087 [..............................] - ETA: 4s - loss: 7.8792 - acc: 0.5112
  640/15087 [>.............................] - ETA: 4s - loss: 7.8576 - acc: 0.5125
  896/15087 [>.............................] - ETA: 4s - loss: 7.9691 - acc: 0.5056
 1152/15087 [=>............................] - ETA: 3s - loss: 8.0870 - acc: 0.4983
 1408/15087 [=>............................] - ETA: 3s - loss: 8.1163 - acc: 0.4964
 1728/15087 [==>...........................] - ETA: 3s - loss: 8.1337 - acc: 0.4954
 2048/15087 [===>..........................] - ETA: 3s - loss: 8.0433 - acc: 0.5010
 2368/15087 [===>..........................] - ETA: 3s - loss: 8.0454 - acc: 0.5008
 2688/15087 [====>.........................] - ETA: 2s - loss: 8.0471 - acc: 0.5007
 3008/15087 [====>.........................] - ETA: 2s - loss: 8.0537 - acc: 0.5003
 3328/15087 [=====>........................] - ETA: 2s - loss: 8.0445 - acc: 0.5009
 3648/15087 [======>.......................] - ETA: 2s - loss: 7.9972 - acc: 0.5038
 3904/15087 [======>.......................] - ETA: 2s - loss: 7.9930 - acc: 0.5041
 4096/15087 [=======>......................] - ETA: 2s - loss: 7.9607 - acc: 0.5061
 4224/15087 [=======>......................] - ETA: 2s - loss: 7.9637 - acc: 0.5059
 4352/15087 [=======>......................] - ETA: 2s - loss: 7.9850 - acc: 0.5046
 4544/15087 [========>.....................] - ETA: 2s - loss: 7.9775 - acc: 0.5051
 4736/15087 [========>.....................] - ETA: 2s - loss: 7.9433 - acc: 0.5072
 4928/15087 [========>.....................] - ETA: 2s - loss: 7.9740 - acc: 0.5053
 5184/15087 [=========>....................] - ETA: 2s - loss: 7.9875 - acc: 0.5044
 5440/15087 [=========>....................] - ETA: 2s - loss: 8.0265 - acc: 0.5020
 5760/15087 [==========>...................] - ETA: 2s - loss: 8.0423 - acc: 0.5010
 6080/15087 [===========>..................] - ETA: 2s - loss: 8.0299 - acc: 0.5018
 6400/15087 [===========>..................] - ETA: 2s - loss: 8.0339 - acc: 0.5016
 6656/15087 [============>.................] - ETA: 1s - loss: 8.0542 - acc: 0.5003
 6976/15087 [============>.................] - ETA: 1s - loss: 8.0267 - acc: 0.5020
 7296/15087 [=============>................] - ETA: 1s - loss: 8.0414 - acc: 0.5011
 7616/15087 [==============>...............] - ETA: 1s - loss: 8.0379 - acc: 0.5013
 7936/15087 [==============>...............] - ETA: 1s - loss: 8.0530 - acc: 0.5004
 8256/15087 [===============>..............] - ETA: 1s - loss: 8.0376 - acc: 0.5013
 8576/15087 [================>.............] - ETA: 1s - loss: 8.0384 - acc: 0.5013
 8896/15087 [================>.............] - ETA: 1s - loss: 8.0446 - acc: 0.5009
 9216/15087 [=================>............] - ETA: 1s - loss: 8.0503 - acc: 0.5005
 9536/15087 [=================>............] - ETA: 1s - loss: 8.0743 - acc: 0.4991
 9856/15087 [==================>...........] - ETA: 1s - loss: 8.0787 - acc: 0.4988
10176/15087 [===================>..........] - ETA: 1s - loss: 8.0511 - acc: 0.5005
10496/15087 [===================>..........] - ETA: 0s - loss: 8.0437 - acc: 0.5010
10816/15087 [====================>.........] - ETA: 0s - loss: 8.0412 - acc: 0.5011
11136/15087 [=====================>........] - ETA: 0s - loss: 8.0446 - acc: 0.5009
11456/15087 [=====================>........] - ETA: 0s - loss: 8.0422 - acc: 0.5010
11776/15087 [======================>.......] - ETA: 0s - loss: 8.0344 - acc: 0.5015
12096/15087 [=======================>......] - ETA: 0s - loss: 8.0364 - acc: 0.5014
12416/15087 [=======================>......] - ETA: 0s - loss: 8.0435 - acc: 0.5010
12736/15087 [========================>.....] - ETA: 0s - loss: 8.0616 - acc: 0.4998
13056/15087 [========================>.....] - ETA: 0s - loss: 8.0714 - acc: 0.4992
13376/15087 [=========================>....] - ETA: 0s - loss: 8.0747 - acc: 0.4990
13696/15087 [==========================>...] - ETA: 0s - loss: 8.0802 - acc: 0.4987
14016/15087 [==========================>...] - ETA: 0s - loss: 8.0751 - acc: 0.4990
14336/15087 [===========================>..] - ETA: 0s - loss: 8.0635 - acc: 0.4997
14656/15087 [============================>.] - ETA: 0s - loss: 8.0634 - acc: 0.4997
14976/15087 [============================>.] - ETA: 0s - loss: 8.0623 - acc: 0.4998
15087/15087 [==============================] - 3s 195us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03134796238244

data size :  16682

zero :  8342

one :  8340

train_zero :  7544

train_one :  7543

test_zero :  798

test_one :  797

choose_zero :  1595

choose_one :  0

F1score :  0.0

AUC : 0.475420829363245

Confusion Matrix
[[798   0]
 [797   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.05851356853759], 'acc': [0.5000331411346207]}
Saved model to disk



15

Epoch 1/1

   64/15087 [..............................] - ETA: 9s - loss: 7.0517 - acc: 0.5625
  192/15087 [..............................] - ETA: 7s - loss: 7.3875 - acc: 0.5417
  448/15087 [..............................] - ETA: 5s - loss: 8.0590 - acc: 0.5000
  640/15087 [>.............................] - ETA: 4s - loss: 8.0590 - acc: 0.5000
  832/15087 [>.............................] - ETA: 4s - loss: 7.9041 - acc: 0.5096
 1088/15087 [=>............................] - ETA: 4s - loss: 7.8220 - acc: 0.5147
 1280/15087 [=>............................] - ETA: 3s - loss: 7.8702 - acc: 0.5117
 1536/15087 [==>...........................] - ETA: 3s - loss: 7.9436 - acc: 0.5072
 1664/15087 [==>...........................] - ETA: 3s - loss: 8.0397 - acc: 0.5012
 1856/15087 [==>...........................] - ETA: 4s - loss: 8.0417 - acc: 0.5011
 2048/15087 [===>..........................] - ETA: 4s - loss: 8.1535 - acc: 0.4941
 2240/15087 [===>..........................] - ETA: 3s - loss: 8.1310 - acc: 0.4955
 2368/15087 [===>..........................] - ETA: 3s - loss: 8.1135 - acc: 0.4966
 2624/15087 [====>.........................] - ETA: 3s - loss: 8.0775 - acc: 0.4989
 2816/15087 [====>.........................] - ETA: 3s - loss: 8.0190 - acc: 0.5025
 3008/15087 [====>.........................] - ETA: 3s - loss: 8.0376 - acc: 0.5013
 3264/15087 [=====>........................] - ETA: 3s - loss: 7.9850 - acc: 0.5046
 3456/15087 [=====>........................] - ETA: 3s - loss: 7.9891 - acc: 0.5043
 3776/15087 [======>.......................] - ETA: 3s - loss: 7.9651 - acc: 0.5058
 3968/15087 [======>.......................] - ETA: 3s - loss: 7.9941 - acc: 0.5040
 4224/15087 [=======>......................] - ETA: 3s - loss: 7.9560 - acc: 0.5064
 4544/15087 [========>.....................] - ETA: 2s - loss: 7.9207 - acc: 0.5086
 4800/15087 [========>.....................] - ETA: 2s - loss: 7.9717 - acc: 0.5054
 5120/15087 [=========>....................] - ETA: 2s - loss: 7.9489 - acc: 0.5068
 5376/15087 [=========>....................] - ETA: 2s - loss: 7.9931 - acc: 0.5041
 5696/15087 [==========>...................] - ETA: 2s - loss: 8.0138 - acc: 0.5028
 6016/15087 [==========>...................] - ETA: 2s - loss: 8.0430 - acc: 0.5010
 6336/15087 [===========>..................] - ETA: 2s - loss: 8.0031 - acc: 0.5035
 6656/15087 [============>.................] - ETA: 2s - loss: 8.0251 - acc: 0.5021
 6976/15087 [============>.................] - ETA: 1s - loss: 8.0221 - acc: 0.5023
 7296/15087 [=============>................] - ETA: 1s - loss: 8.0038 - acc: 0.5034
 7424/15087 [=============>................] - ETA: 1s - loss: 8.0135 - acc: 0.5028
 7616/15087 [==============>...............] - ETA: 1s - loss: 8.0188 - acc: 0.5025
 7936/15087 [==============>...............] - ETA: 1s - loss: 8.0347 - acc: 0.5015
 8256/15087 [===============>..............] - ETA: 1s - loss: 8.0278 - acc: 0.5019
 8640/15087 [================>.............] - ETA: 1s - loss: 8.0199 - acc: 0.5024
 9024/15087 [================>.............] - ETA: 1s - loss: 8.0251 - acc: 0.5021
 9408/15087 [=================>............] - ETA: 1s - loss: 8.0299 - acc: 0.5018
 9728/15087 [==================>...........] - ETA: 1s - loss: 8.0325 - acc: 0.5016
10048/15087 [==================>...........] - ETA: 1s - loss: 8.0109 - acc: 0.5030
10368/15087 [===================>..........] - ETA: 1s - loss: 8.0311 - acc: 0.5017
10688/15087 [====================>.........] - ETA: 0s - loss: 8.0485 - acc: 0.5007
11008/15087 [====================>.........] - ETA: 0s - loss: 8.0327 - acc: 0.5016
11328/15087 [=====================>........] - ETA: 0s - loss: 8.0221 - acc: 0.5023
11648/15087 [======================>.......] - ETA: 0s - loss: 8.0231 - acc: 0.5022
11968/15087 [======================>.......] - ETA: 0s - loss: 8.0388 - acc: 0.5013
12288/15087 [=======================>......] - ETA: 0s - loss: 8.0367 - acc: 0.5014
12608/15087 [========================>.....] - ETA: 0s - loss: 8.0642 - acc: 0.4997
12928/15087 [========================>.....] - ETA: 0s - loss: 8.0603 - acc: 0.4999
13248/15087 [=========================>....] - ETA: 0s - loss: 8.0627 - acc: 0.4998
13568/15087 [=========================>....] - ETA: 0s - loss: 8.0650 - acc: 0.4996
13888/15087 [==========================>...] - ETA: 0s - loss: 8.0660 - acc: 0.4996
14208/15087 [===========================>..] - ETA: 0s - loss: 8.0545 - acc: 0.5003
14528/15087 [===========================>..] - ETA: 0s - loss: 8.0613 - acc: 0.4999
14848/15087 [============================>.] - ETA: 0s - loss: 8.0536 - acc: 0.5003
15087/15087 [==============================] - 3s 205us/step - loss: 8.0585 - acc: 0.5000
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)

Test accuracy: 50.03134796238244

data size :  16682

zero :  8342

one :  8340

train_zero :  7544

train_one :  7543

test_zero :  798

test_one :  797

choose_zero :  1595

choose_one :  0

F1score :  0.0

AUC : 0.475420829363245

Confusion Matrix
[[798   0]
 [797   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058513607159913], 'acc': [0.5000331411425222]}
Saved model to disk



[[50.03134796238244, 1], [50.03134796238244, 2], [50.03134796238244, 3], [50.03134796238244, 4], [50.03134796238244, 5], [50.03134796238244, 6], [50.03134796238244, 7], [50.03134796238244, 8], [50.03134796238244, 9], [50.03134796238244, 10], [50.03134796238244, 11], [50.03134796238244, 12], [50.03134796238244, 13], [50.03134796238244, 14], [50.03134796238244, 15]]
max accuracy :  [50.03134796238244, 15]
