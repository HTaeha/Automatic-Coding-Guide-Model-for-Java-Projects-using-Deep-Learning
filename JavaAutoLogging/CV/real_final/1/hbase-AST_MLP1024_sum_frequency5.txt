Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
sum_MLP.py:400: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=inputs, output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-08-21 04:23:59.162674: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-21 04:23:59.173691: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100085000 Hz
2019-08-21 04:23:59.176090: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x6489ad0 executing computations on platform Host. Devices:
2019-08-21 04:23:59.176130: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
zero : 
39451

one : 
9019
hbase-AST
all data

Sentence length Average : 35

Under 10 : 21694
Over 10, Under 200 : 25475
Over 200, Under 400 : 1121
Over 400 : 180

hbase-AST
updated_train_data

Sentence length Average : 59

Under 10 : 0
Over 10, Under 200 : 22976
Over 200, Under 400 : 1162
Over 400 : 0


Test_zero:  1874
Train_zero:  16897
zero:  18771
Test_one:  764
Train_one:  7241
one:  8005

Count model parameter.
Get a short summary of each layer dimensions and parameters.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 200)               0         
_________________________________________________________________
masking_1 (Masking)          (None, 200)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              205824    
_________________________________________________________________
dropout_1 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
dropout_2 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 2050      
=================================================================
Total params: 1,257,474
Trainable params: 1,257,474
Non-trainable params: 0
_________________________________________________________________
1

Epoch 1/1

   64/14483 [..............................] - ETA: 1:30 - loss: 5.9440 - acc: 0.3750
  320/14483 [..............................] - ETA: 20s - loss: 6.8734 - acc: 0.5156 
  576/14483 [>.............................] - ETA: 12s - loss: 7.5930 - acc: 0.4965
  896/14483 [>.............................] - ETA: 8s - loss: 7.8134 - acc: 0.4944 
 1152/14483 [=>............................] - ETA: 7s - loss: 7.7001 - acc: 0.5061
 1472/14483 [==>...........................] - ETA: 6s - loss: 7.9971 - acc: 0.4912
 1792/14483 [==>...........................] - ETA: 5s - loss: 8.0262 - acc: 0.4916
 2112/14483 [===>..........................] - ETA: 4s - loss: 7.9014 - acc: 0.5009
 2432/14483 [====>.........................] - ETA: 4s - loss: 7.9354 - acc: 0.5000
 2752/14483 [====>.........................] - ETA: 3s - loss: 7.9908 - acc: 0.4975
 3072/14483 [=====>........................] - ETA: 3s - loss: 7.9349 - acc: 0.5016
 3392/14483 [======>.......................] - ETA: 3s - loss: 7.9419 - acc: 0.5018
 3712/14483 [======>.......................] - ETA: 3s - loss: 7.8912 - acc: 0.5054
 4032/14483 [=======>......................] - ETA: 3s - loss: 7.9325 - acc: 0.5032
 4352/14483 [========>.....................] - ETA: 2s - loss: 7.8928 - acc: 0.5060
 4672/14483 [========>.....................] - ETA: 2s - loss: 7.8584 - acc: 0.5081
 4992/14483 [=========>....................] - ETA: 2s - loss: 7.8939 - acc: 0.5062
 5312/14483 [==========>...................] - ETA: 2s - loss: 7.9038 - acc: 0.5058
 5632/14483 [==========>...................] - ETA: 2s - loss: 7.9184 - acc: 0.5051
 5952/14483 [===========>..................] - ETA: 2s - loss: 7.9368 - acc: 0.5042
 6272/14483 [===========>..................] - ETA: 2s - loss: 7.8865 - acc: 0.5075
 6592/14483 [============>.................] - ETA: 1s - loss: 7.8948 - acc: 0.5071
 6912/14483 [=============>................] - ETA: 1s - loss: 7.8791 - acc: 0.5082
 7232/14483 [=============>................] - ETA: 1s - loss: 7.8938 - acc: 0.5075
 7552/14483 [==============>...............] - ETA: 1s - loss: 7.9115 - acc: 0.5065
 7872/14483 [===============>..............] - ETA: 1s - loss: 7.9011 - acc: 0.5072
 8192/14483 [===============>..............] - ETA: 1s - loss: 7.9328 - acc: 0.5054
 8512/14483 [================>.............] - ETA: 1s - loss: 7.9167 - acc: 0.5065
 8832/14483 [=================>............] - ETA: 1s - loss: 7.9292 - acc: 0.5058
 9152/14483 [=================>............] - ETA: 1s - loss: 7.9320 - acc: 0.5057
 9472/14483 [==================>...........] - ETA: 1s - loss: 7.9499 - acc: 0.5046
 9792/14483 [===================>..........] - ETA: 1s - loss: 7.9400 - acc: 0.5053
10112/14483 [===================>..........] - ETA: 0s - loss: 7.9108 - acc: 0.5070
10432/14483 [====================>.........] - ETA: 0s - loss: 7.8797 - acc: 0.5088
10752/14483 [=====================>........] - ETA: 0s - loss: 7.8278 - acc: 0.5121
11072/14483 [=====================>........] - ETA: 0s - loss: 7.7899 - acc: 0.5142
11392/14483 [======================>.......] - ETA: 0s - loss: 7.7405 - acc: 0.5171
11712/14483 [=======================>......] - ETA: 0s - loss: 7.6754 - acc: 0.5210
12032/14483 [=======================>......] - ETA: 0s - loss: 7.6249 - acc: 0.5239
12352/14483 [========================>.....] - ETA: 0s - loss: 7.5769 - acc: 0.5268
12672/14483 [=========================>....] - ETA: 0s - loss: 7.5230 - acc: 0.5301
12992/14483 [=========================>....] - ETA: 0s - loss: 7.4715 - acc: 0.5333
13312/14483 [==========================>...] - ETA: 0s - loss: 7.4378 - acc: 0.5354
13632/14483 [===========================>..] - ETA: 0s - loss: 7.3910 - acc: 0.5383
13952/14483 [===========================>..] - ETA: 0s - loss: 7.3383 - acc: 0.5414
14272/14483 [============================>.] - ETA: 0s - loss: 7.2918 - acc: 0.5441
14483/14483 [==============================] - 3s 208us/step - loss: 7.2719 - acc: 0.5454

Test accuracy: 65.27141922825376

data size :  16012

zero :  8007

one :  8005

train_zero :  7242

train_one :  7241

test_zero :  765

test_one :  764

choose_zero :  686

choose_one :  843

F1score :  0.6695706285003112

AUC : 0.6571955309174281

Confusion Matrix
[[460 305]
 [226 538]]
True label 0
0.6013071895424836  
0.39869281045751637  
True label 1
0.29581151832460734  
0.7041884816753927  

Train_result {'loss': [7.271888281161027], 'acc': [0.5453980528854792]}
Saved model to disk



2

Epoch 1/1

   64/14483 [..............................] - ETA: 3s - loss: 5.3985 - acc: 0.6562
  320/14483 [..............................] - ETA: 3s - loss: 5.6986 - acc: 0.6438
  576/14483 [>.............................] - ETA: 2s - loss: 5.8167 - acc: 0.6337
  896/14483 [>.............................] - ETA: 2s - loss: 5.5710 - acc: 0.6496
 1216/14483 [=>............................] - ETA: 2s - loss: 5.6784 - acc: 0.6423
 1536/14483 [==>...........................] - ETA: 2s - loss: 5.8996 - acc: 0.6289
 1856/14483 [==>...........................] - ETA: 2s - loss: 5.9041 - acc: 0.6288
 2176/14483 [===>..........................] - ETA: 2s - loss: 5.8835 - acc: 0.6296
 2496/14483 [====>.........................] - ETA: 2s - loss: 5.8419 - acc: 0.6322
 2816/14483 [====>.........................] - ETA: 2s - loss: 5.8398 - acc: 0.6317
 3136/14483 [=====>........................] - ETA: 2s - loss: 5.8216 - acc: 0.6333
 3456/14483 [======>.......................] - ETA: 2s - loss: 5.7863 - acc: 0.6360
 3776/14483 [======>.......................] - ETA: 2s - loss: 5.8080 - acc: 0.6348
 4096/14483 [=======>......................] - ETA: 1s - loss: 5.8137 - acc: 0.6345
 4416/14483 [========>.....................] - ETA: 1s - loss: 5.8929 - acc: 0.6298
 4736/14483 [========>.....................] - ETA: 1s - loss: 5.8849 - acc: 0.6301
 5056/14483 [=========>....................] - ETA: 1s - loss: 5.9035 - acc: 0.6292
 5376/14483 [==========>...................] - ETA: 1s - loss: 5.8881 - acc: 0.6300
 5696/14483 [==========>...................] - ETA: 1s - loss: 5.8991 - acc: 0.6294
 6016/14483 [===========>..................] - ETA: 1s - loss: 5.9145 - acc: 0.6285
 6336/14483 [============>.................] - ETA: 1s - loss: 5.8867 - acc: 0.6302
 6656/14483 [============>.................] - ETA: 1s - loss: 5.9426 - acc: 0.6270
 6976/14483 [=============>................] - ETA: 1s - loss: 6.0219 - acc: 0.6220
 7296/14483 [==============>...............] - ETA: 1s - loss: 6.0327 - acc: 0.6213
 7616/14483 [==============>...............] - ETA: 1s - loss: 6.0441 - acc: 0.6207
 7936/14483 [===============>..............] - ETA: 1s - loss: 6.0337 - acc: 0.6213
 8256/14483 [================>.............] - ETA: 1s - loss: 6.0126 - acc: 0.6228
 8576/14483 [================>.............] - ETA: 1s - loss: 5.9857 - acc: 0.6245
 8896/14483 [=================>............] - ETA: 1s - loss: 5.9544 - acc: 0.6265
 9216/14483 [==================>...........] - ETA: 0s - loss: 5.9402 - acc: 0.6274
 9536/14483 [==================>...........] - ETA: 0s - loss: 5.9348 - acc: 0.6277
 9856/14483 [===================>..........] - ETA: 0s - loss: 5.9754 - acc: 0.6252
10176/14483 [====================>.........] - ETA: 0s - loss: 6.0097 - acc: 0.6231
10496/14483 [====================>.........] - ETA: 0s - loss: 6.0195 - acc: 0.6224
10816/14483 [=====================>........] - ETA: 0s - loss: 5.9949 - acc: 0.6241
11136/14483 [======================>.......] - ETA: 0s - loss: 5.9833 - acc: 0.6249
11456/14483 [======================>.......] - ETA: 0s - loss: 5.9787 - acc: 0.6251
11776/14483 [=======================>......] - ETA: 0s - loss: 6.0089 - acc: 0.6233
12096/14483 [========================>.....] - ETA: 0s - loss: 6.0259 - acc: 0.6222
12288/14483 [========================>.....] - ETA: 0s - loss: 6.0057 - acc: 0.6234
12544/14483 [========================>.....] - ETA: 0s - loss: 6.0104 - acc: 0.6231
12864/14483 [=========================>....] - ETA: 0s - loss: 6.0012 - acc: 0.6237
13184/14483 [==========================>...] - ETA: 0s - loss: 5.9904 - acc: 0.6244
13504/14483 [==========================>...] - ETA: 0s - loss: 5.9714 - acc: 0.6257
13824/14483 [===========================>..] - ETA: 0s - loss: 5.9545 - acc: 0.6268
14144/14483 [============================>.] - ETA: 0s - loss: 5.9531 - acc: 0.6270
14464/14483 [============================>.] - ETA: 0s - loss: 5.9547 - acc: 0.6269
14483/14483 [==============================] - 3s 195us/step - loss: 5.9535 - acc: 0.6270

Test accuracy: 65.729234793983

data size :  16012

zero :  8007

one :  8005

train_zero :  7242

train_one :  7241

test_zero :  765

test_one :  764

choose_zero :  431

choose_one :  1098

F1score :  0.7185821697099892

AUC : 0.6615636656058583

Confusion Matrix
[[336 429]
 [ 95 669]]
True label 0
0.4392156862745098  
0.5607843137254902  
True label 1
0.1243455497382199  
0.8756544502617801  

Train_result {'loss': [5.95352594903315], 'acc': [0.6270109784049174]}
Saved model to disk



3

Epoch 1/1

   64/14483 [..............................] - ETA: 3s - loss: 6.7998 - acc: 0.5781
  320/14483 [..............................] - ETA: 3s - loss: 5.6580 - acc: 0.6469
  576/14483 [>.............................] - ETA: 2s - loss: 5.5423 - acc: 0.6545
  832/14483 [>.............................] - ETA: 2s - loss: 5.3481 - acc: 0.6671
 1152/14483 [=>............................] - ETA: 2s - loss: 5.3037 - acc: 0.6701
 1472/14483 [==>...........................] - ETA: 2s - loss: 5.2981 - acc: 0.6698
 1792/14483 [==>...........................] - ETA: 2s - loss: 5.4280 - acc: 0.6607
 2112/14483 [===>..........................] - ETA: 2s - loss: 5.4311 - acc: 0.6605
 2432/14483 [====>.........................] - ETA: 2s - loss: 5.5533 - acc: 0.6525
 2752/14483 [====>.........................] - ETA: 2s - loss: 5.5714 - acc: 0.6512
 3008/14483 [=====>........................] - ETA: 2s - loss: 5.5260 - acc: 0.6543
 3328/14483 [=====>........................] - ETA: 2s - loss: 5.5113 - acc: 0.6553
 3648/14483 [======>.......................] - ETA: 2s - loss: 5.5272 - acc: 0.6546
 3968/14483 [=======>......................] - ETA: 2s - loss: 5.4910 - acc: 0.6568
 4288/14483 [=======>......................] - ETA: 1s - loss: 5.5011 - acc: 0.6560
 4608/14483 [========>.....................] - ETA: 1s - loss: 5.5224 - acc: 0.6547
 4928/14483 [=========>....................] - ETA: 1s - loss: 5.4811 - acc: 0.6575
 5248/14483 [=========>....................] - ETA: 1s - loss: 5.5170 - acc: 0.6551
 5568/14483 [==========>...................] - ETA: 1s - loss: 5.5301 - acc: 0.6545
 5888/14483 [===========>..................] - ETA: 1s - loss: 5.5415 - acc: 0.6537
 6208/14483 [===========>..................] - ETA: 1s - loss: 5.5155 - acc: 0.6554
 6528/14483 [============>.................] - ETA: 1s - loss: 5.5062 - acc: 0.6561
 6848/14483 [=============>................] - ETA: 1s - loss: 5.5330 - acc: 0.6544
 7168/14483 [=============>................] - ETA: 1s - loss: 5.5913 - acc: 0.6507
 7488/14483 [==============>...............] - ETA: 1s - loss: 5.5834 - acc: 0.6512
 7808/14483 [===============>..............] - ETA: 1s - loss: 5.5774 - acc: 0.6516
 8128/14483 [===============>..............] - ETA: 1s - loss: 5.6158 - acc: 0.6491
 8448/14483 [================>.............] - ETA: 1s - loss: 5.6270 - acc: 0.6484
 8768/14483 [=================>............] - ETA: 1s - loss: 5.6316 - acc: 0.6480
 9088/14483 [=================>............] - ETA: 0s - loss: 5.6318 - acc: 0.6481
 9408/14483 [==================>...........] - ETA: 0s - loss: 5.6396 - acc: 0.6476
 9728/14483 [===================>..........] - ETA: 0s - loss: 5.6248 - acc: 0.6486
10048/14483 [===================>..........] - ETA: 0s - loss: 5.6208 - acc: 0.6489
10368/14483 [====================>.........] - ETA: 0s - loss: 5.6135 - acc: 0.6493
10688/14483 [=====================>........] - ETA: 0s - loss: 5.6058 - acc: 0.6498
11008/14483 [=====================>........] - ETA: 0s - loss: 5.6184 - acc: 0.6491
11328/14483 [======================>.......] - ETA: 0s - loss: 5.6253 - acc: 0.6487
11648/14483 [=======================>......] - ETA: 0s - loss: 5.6273 - acc: 0.6485
11968/14483 [=======================>......] - ETA: 0s - loss: 5.6573 - acc: 0.6467
12288/14483 [========================>.....] - ETA: 0s - loss: 5.6817 - acc: 0.6452
12608/14483 [=========================>....] - ETA: 0s - loss: 5.6924 - acc: 0.6445
12928/14483 [=========================>....] - ETA: 0s - loss: 5.6889 - acc: 0.6447
13248/14483 [==========================>...] - ETA: 0s - loss: 5.6995 - acc: 0.6441
13568/14483 [===========================>..] - ETA: 0s - loss: 5.6995 - acc: 0.6441
13888/14483 [===========================>..] - ETA: 0s - loss: 5.7016 - acc: 0.6439
14208/14483 [============================>.] - ETA: 0s - loss: 5.6904 - acc: 0.6446
14483/14483 [==============================] - 3s 179us/step - loss: 5.6894 - acc: 0.6447

Test accuracy: 58.142576847612816

data size :  16012

zero :  8007

one :  8005

train_zero :  7242

train_one :  7241

test_zero :  765

test_one :  764

choose_zero :  1245

choose_one :  284

F1score :  0.3893129770992367

AUC : 0.5798600417479384

Confusion Matrix
[[685  80]
 [560 204]]
True label 0
0.8954248366013072  
0.10457516339869281  
True label 1
0.7329842931937173  
0.2670157068062827  

Train_result {'loss': [5.6893625222853865], 'acc': [0.6446868742622658]}
Saved model to disk



4

Epoch 1/1

   64/14483 [..............................] - ETA: 3s - loss: 6.7998 - acc: 0.5781
  320/14483 [..............................] - ETA: 3s - loss: 6.6799 - acc: 0.5813
  576/14483 [>.............................] - ETA: 2s - loss: 6.9850 - acc: 0.5642
  832/14483 [>.............................] - ETA: 2s - loss: 7.3155 - acc: 0.5445
 1152/14483 [=>............................] - ETA: 2s - loss: 7.5780 - acc: 0.5286
 1472/14483 [==>...........................] - ETA: 2s - loss: 7.4772 - acc: 0.5346
 1792/14483 [==>...........................] - ETA: 2s - loss: 7.4339 - acc: 0.5374
 2112/14483 [===>..........................] - ETA: 2s - loss: 7.1515 - acc: 0.5545
 2432/14483 [====>.........................] - ETA: 2s - loss: 6.8474 - acc: 0.5724
 2752/14483 [====>.........................] - ETA: 2s - loss: 6.5779 - acc: 0.5894
 3072/14483 [=====>........................] - ETA: 2s - loss: 6.4173 - acc: 0.5996
 3392/14483 [======>.......................] - ETA: 2s - loss: 6.4084 - acc: 0.5999
 3712/14483 [======>.......................] - ETA: 2s - loss: 6.3088 - acc: 0.6061
 4032/14483 [=======>......................] - ETA: 1s - loss: 6.2078 - acc: 0.6126
 4352/14483 [========>.....................] - ETA: 1s - loss: 6.1668 - acc: 0.6151
 4672/14483 [========>.....................] - ETA: 1s - loss: 6.1722 - acc: 0.6149
 4992/14483 [=========>....................] - ETA: 1s - loss: 6.1640 - acc: 0.6156
 5312/14483 [==========>...................] - ETA: 1s - loss: 6.1732 - acc: 0.6148
 5632/14483 [==========>...................] - ETA: 1s - loss: 6.1783 - acc: 0.6145
 5952/14483 [===========>..................] - ETA: 1s - loss: 6.1543 - acc: 0.6161
 6272/14483 [===========>..................] - ETA: 1s - loss: 6.1331 - acc: 0.6173
 6592/14483 [============>.................] - ETA: 1s - loss: 6.1159 - acc: 0.6185
 6912/14483 [=============>................] - ETA: 1s - loss: 6.1313 - acc: 0.6175
 7232/14483 [=============>................] - ETA: 1s - loss: 6.1052 - acc: 0.6192
 7552/14483 [==============>...............] - ETA: 1s - loss: 6.0450 - acc: 0.6230
 7872/14483 [===============>..............] - ETA: 1s - loss: 6.0332 - acc: 0.6237
 8192/14483 [===============>..............] - ETA: 1s - loss: 6.0388 - acc: 0.6234
 8512/14483 [================>.............] - ETA: 1s - loss: 6.0124 - acc: 0.6251
 8832/14483 [=================>............] - ETA: 1s - loss: 5.9788 - acc: 0.6272
 9152/14483 [=================>............] - ETA: 0s - loss: 6.0283 - acc: 0.6241
 9472/14483 [==================>...........] - ETA: 0s - loss: 6.1027 - acc: 0.6195
 9792/14483 [===================>..........] - ETA: 0s - loss: 6.1683 - acc: 0.6155
10112/14483 [===================>..........] - ETA: 0s - loss: 6.1867 - acc: 0.6144
10432/14483 [====================>.........] - ETA: 0s - loss: 6.2457 - acc: 0.6108
10752/14483 [=====================>........] - ETA: 0s - loss: 6.2944 - acc: 0.6078
11072/14483 [=====================>........] - ETA: 0s - loss: 6.3614 - acc: 0.6037
11392/14483 [======================>.......] - ETA: 0s - loss: 6.4156 - acc: 0.6003
11712/14483 [=======================>......] - ETA: 0s - loss: 6.4536 - acc: 0.5980
12032/14483 [=======================>......] - ETA: 0s - loss: 6.5070 - acc: 0.5947
12352/14483 [========================>.....] - ETA: 0s - loss: 6.5368 - acc: 0.5929
12672/14483 [=========================>....] - ETA: 0s - loss: 6.5854 - acc: 0.5900
12992/14483 [=========================>....] - ETA: 0s - loss: 6.6267 - acc: 0.5874
13312/14483 [==========================>...] - ETA: 0s - loss: 6.6280 - acc: 0.5873
13632/14483 [===========================>..] - ETA: 0s - loss: 6.5907 - acc: 0.5896
13952/14483 [===========================>..] - ETA: 0s - loss: 6.5840 - acc: 0.5900
14272/14483 [============================>.] - ETA: 0s - loss: 6.5583 - acc: 0.5916
14483/14483 [==============================] - 3s 176us/step - loss: 6.5486 - acc: 0.5921

Test accuracy: 56.703727926749515

data size :  16012

zero :  8007

one :  8005

train_zero :  7242

train_one :  7241

test_zero :  765

test_one :  764

choose_zero :  1325

choose_one :  204

F1score :  0.31611570247933884

AUC : 0.5697224788693837

Confusion Matrix
[[714  51]
 [611 153]]
True label 0
0.9333333333333333  
0.06666666666666667  
True label 1
0.7997382198952879  
0.20026178010471204  

Train_result {'loss': [6.54862227199865], 'acc': [0.5921425119352087]}
Saved model to disk



5

Epoch 1/1

   64/14483 [..............................] - ETA: 3s - loss: 6.5480 - acc: 0.5938
  320/14483 [..............................] - ETA: 3s - loss: 7.0013 - acc: 0.5656
  576/14483 [>.............................] - ETA: 2s - loss: 7.0156 - acc: 0.5642
  896/14483 [>.............................] - ETA: 2s - loss: 6.4348 - acc: 0.6004
 1152/14483 [=>............................] - ETA: 2s - loss: 5.9786 - acc: 0.6285
 1472/14483 [==>...........................] - ETA: 2s - loss: 5.8966 - acc: 0.6332
 1792/14483 [==>...........................] - ETA: 2s - loss: 5.6839 - acc: 0.6462
 2112/14483 [===>..........................] - ETA: 2s - loss: 5.6191 - acc: 0.6501
 2432/14483 [====>.........................] - ETA: 2s - loss: 5.7082 - acc: 0.6447
 2752/14483 [====>.........................] - ETA: 2s - loss: 5.7596 - acc: 0.6414
 3072/14483 [=====>........................] - ETA: 2s - loss: 5.7210 - acc: 0.6439
 3392/14483 [======>.......................] - ETA: 2s - loss: 5.6612 - acc: 0.6477
 3712/14483 [======>.......................] - ETA: 2s - loss: 5.6508 - acc: 0.6484
 4032/14483 [=======>......................] - ETA: 1s - loss: 5.6622 - acc: 0.6476
 4352/14483 [========>.....................] - ETA: 1s - loss: 5.7344 - acc: 0.6432
 4672/14483 [========>.....................] - ETA: 1s - loss: 5.8374 - acc: 0.6368
 4992/14483 [=========>....................] - ETA: 1s - loss: 5.8468 - acc: 0.6362
 5312/14483 [==========>...................] - ETA: 1s - loss: 5.8511 - acc: 0.6357
 5632/14483 [==========>...................] - ETA: 1s - loss: 5.8392 - acc: 0.6365
 5952/14483 [===========>..................] - ETA: 1s - loss: 5.8692 - acc: 0.6347
 6272/14483 [===========>..................] - ETA: 1s - loss: 5.8457 - acc: 0.6362
 6592/14483 [============>.................] - ETA: 1s - loss: 5.8251 - acc: 0.6374
 6912/14483 [=============>................] - ETA: 1s - loss: 5.8306 - acc: 0.6372
 7296/14483 [==============>...............] - ETA: 1s - loss: 5.8181 - acc: 0.6376
 7616/14483 [==============>...............] - ETA: 1s - loss: 5.8263 - acc: 0.6371
 7936/14483 [===============>..............] - ETA: 1s - loss: 5.8210 - acc: 0.6373
 8256/14483 [================>.............] - ETA: 1s - loss: 5.8296 - acc: 0.6369
 8576/14483 [================>.............] - ETA: 1s - loss: 5.8241 - acc: 0.6372
 8896/14483 [=================>............] - ETA: 0s - loss: 5.8157 - acc: 0.6378
 9216/14483 [==================>...........] - ETA: 0s - loss: 5.8324 - acc: 0.6368
 9536/14483 [==================>...........] - ETA: 0s - loss: 5.8344 - acc: 0.6367
 9856/14483 [===================>..........] - ETA: 0s - loss: 5.8173 - acc: 0.6378
10176/14483 [====================>.........] - ETA: 0s - loss: 5.8033 - acc: 0.6387
10496/14483 [====================>.........] - ETA: 0s - loss: 5.8196 - acc: 0.6377
10816/14483 [=====================>........] - ETA: 0s - loss: 5.8084 - acc: 0.6383
11136/14483 [======================>.......] - ETA: 0s - loss: 5.8123 - acc: 0.6381
11456/14483 [======================>.......] - ETA: 0s - loss: 5.8047 - acc: 0.6386
11776/14483 [=======================>......] - ETA: 0s - loss: 5.7984 - acc: 0.6389
12096/14483 [========================>.....] - ETA: 0s - loss: 5.7988 - acc: 0.6389
12416/14483 [========================>.....] - ETA: 0s - loss: 5.7986 - acc: 0.6389
12736/14483 [=========================>....] - ETA: 0s - loss: 5.7871 - acc: 0.6397
13056/14483 [==========================>...] - ETA: 0s - loss: 5.8020 - acc: 0.6388
13376/14483 [==========================>...] - ETA: 0s - loss: 5.8336 - acc: 0.6368
13696/14483 [===========================>..] - ETA: 0s - loss: 5.8450 - acc: 0.6361
14016/14483 [============================>.] - ETA: 0s - loss: 5.8335 - acc: 0.6368
14336/14483 [============================>.] - ETA: 0s - loss: 5.8289 - acc: 0.6371
14483/14483 [==============================] - 3s 177us/step - loss: 5.8276 - acc: 0.6372

Test accuracy: 65.27141922825376

data size :  16012

zero :  8007

one :  8005

train_zero :  7242

train_one :  7241

test_zero :  765

test_one :  764

choose_zero :  382

choose_one :  1147

F1score :  0.7221350078492936

AUC : 0.6550910241932724

Confusion Matrix
[[308 457]
 [ 74 690]]
True label 0
0.40261437908496733  
0.5973856209150327  
True label 1
0.0968586387434555  
0.9031413612565445  

Train_result {'loss': [5.827589055447011], 'acc': [0.6371608092493011]}
Saved model to disk



6

Epoch 1/1

   64/14483 [..............................] - ETA: 3s - loss: 5.7924 - acc: 0.6406
  320/14483 [..............................] - ETA: 3s - loss: 5.8932 - acc: 0.6344
  576/14483 [>.............................] - ETA: 2s - loss: 5.6708 - acc: 0.6476
  896/14483 [>.............................] - ETA: 2s - loss: 5.4987 - acc: 0.6585
 1216/14483 [=>............................] - ETA: 2s - loss: 5.4416 - acc: 0.6620
 1536/14483 [==>...........................] - ETA: 2s - loss: 5.3413 - acc: 0.6680
 1856/14483 [==>...........................] - ETA: 2s - loss: 5.5163 - acc: 0.6568
 2176/14483 [===>..........................] - ETA: 2s - loss: 5.5053 - acc: 0.6572
 2496/14483 [====>.........................] - ETA: 2s - loss: 5.4582 - acc: 0.6603
 2816/14483 [====>.........................] - ETA: 2s - loss: 5.5791 - acc: 0.6527
 3136/14483 [=====>........................] - ETA: 2s - loss: 5.5641 - acc: 0.6537
 3456/14483 [======>.......................] - ETA: 2s - loss: 5.5200 - acc: 0.6565
 3776/14483 [======>.......................] - ETA: 2s - loss: 5.5158 - acc: 0.6568
 4096/14483 [=======>......................] - ETA: 1s - loss: 5.4745 - acc: 0.6594
 4416/14483 [========>.....................] - ETA: 1s - loss: 5.4761 - acc: 0.6592
 4736/14483 [========>.....................] - ETA: 1s - loss: 5.4805 - acc: 0.6590
 5056/14483 [=========>....................] - ETA: 1s - loss: 5.4684 - acc: 0.6598
 5376/14483 [==========>...................] - ETA: 1s - loss: 5.4785 - acc: 0.6592
 5696/14483 [==========>...................] - ETA: 1s - loss: 5.4916 - acc: 0.6584
 6016/14483 [===========>..................] - ETA: 1s - loss: 5.5204 - acc: 0.6566
 6336/14483 [============>.................] - ETA: 1s - loss: 5.5596 - acc: 0.6542
 6656/14483 [============>.................] - ETA: 1s - loss: 5.5451 - acc: 0.6550
 6976/14483 [=============>................] - ETA: 1s - loss: 5.5385 - acc: 0.6554
 7296/14483 [==============>...............] - ETA: 1s - loss: 5.5442 - acc: 0.6550
 7616/14483 [==============>...............] - ETA: 1s - loss: 5.5729 - acc: 0.6532
 7936/14483 [===============>..............] - ETA: 1s - loss: 5.5554 - acc: 0.6544
 8256/14483 [================>.............] - ETA: 1s - loss: 5.5396 - acc: 0.6552
 8576/14483 [================>.............] - ETA: 1s - loss: 5.5396 - acc: 0.6552
 8896/14483 [=================>............] - ETA: 1s - loss: 5.5324 - acc: 0.6557
 9216/14483 [==================>...........] - ETA: 0s - loss: 5.5170 - acc: 0.6567
 9536/14483 [==================>...........] - ETA: 0s - loss: 5.5384 - acc: 0.6553
 9856/14483 [===================>..........] - ETA: 0s - loss: 5.5431 - acc: 0.6550
10176/14483 [====================>.........] - ETA: 0s - loss: 5.5334 - acc: 0.6556
10496/14483 [====================>.........] - ETA: 0s - loss: 5.5106 - acc: 0.6570
10816/14483 [=====================>........] - ETA: 0s - loss: 5.5025 - acc: 0.6575
11136/14483 [======================>.......] - ETA: 0s - loss: 5.4816 - acc: 0.6588
11456/14483 [======================>.......] - ETA: 0s - loss: 5.4948 - acc: 0.6579
11776/14483 [=======================>......] - ETA: 0s - loss: 5.4865 - acc: 0.6585
12096/14483 [========================>.....] - ETA: 0s - loss: 5.4626 - acc: 0.6600
12416/14483 [========================>.....] - ETA: 0s - loss: 5.4698 - acc: 0.6596
12736/14483 [=========================>....] - ETA: 0s - loss: 5.4653 - acc: 0.6599
13056/14483 [==========================>...] - ETA: 0s - loss: 5.4510 - acc: 0.6607
13376/14483 [==========================>...] - ETA: 0s - loss: 5.4483 - acc: 0.6609
13696/14483 [===========================>..] - ETA: 0s - loss: 5.4517 - acc: 0.6607
14016/14483 [============================>.] - ETA: 0s - loss: 5.4588 - acc: 0.6602
14336/14483 [============================>.] - ETA: 0s - loss: 5.4730 - acc: 0.6594
14483/14483 [==============================] - 3s 177us/step - loss: 5.4787 - acc: 0.6590

Test accuracy: 66.05624591236102

data size :  16012

zero :  8007

one :  8005

train_zero :  7242

train_one :  7241

test_zero :  765

test_one :  764

choose_zero :  458

choose_one :  1071

F1score :  0.71716621253406

AUC : 0.6616928446771378

Confusion Matrix
[[352 413]
 [106 658]]
True label 0
0.46013071895424834  
0.5398692810457516  
True label 1
0.1387434554973822  
0.8612565445026178  

Train_result {'loss': [5.478655429980475], 'acc': [0.6590485396918889]}
Saved model to disk



7

Epoch 1/1

   64/14483 [..............................] - ETA: 3s - loss: 6.5480 - acc: 0.5938
  320/14483 [..............................] - ETA: 3s - loss: 6.2961 - acc: 0.6094
  576/14483 [>.............................] - ETA: 2s - loss: 5.7645 - acc: 0.6424
  896/14483 [>.............................] - ETA: 2s - loss: 5.8080 - acc: 0.6395
 1216/14483 [=>............................] - ETA: 2s - loss: 5.8877 - acc: 0.6340
 1536/14483 [==>...........................] - ETA: 2s - loss: 5.7944 - acc: 0.6400
 1856/14483 [==>...........................] - ETA: 2s - loss: 5.6778 - acc: 0.6471
 2112/14483 [===>..........................] - ETA: 2s - loss: 5.6133 - acc: 0.6510
 2432/14483 [====>.........................] - ETA: 2s - loss: 5.5706 - acc: 0.6538
 2752/14483 [====>.........................] - ETA: 2s - loss: 5.6232 - acc: 0.6504
 3072/14483 [=====>........................] - ETA: 2s - loss: 5.6741 - acc: 0.6471
 3392/14483 [======>.......................] - ETA: 2s - loss: 5.6853 - acc: 0.6465
 3712/14483 [======>.......................] - ETA: 2s - loss: 5.6809 - acc: 0.6466
 4032/14483 [=======>......................] - ETA: 1s - loss: 5.7663 - acc: 0.6411
 4352/14483 [========>.....................] - ETA: 1s - loss: 5.7571 - acc: 0.6418
 4672/14483 [========>.....................] - ETA: 1s - loss: 5.7182 - acc: 0.6443
 4992/14483 [=========>....................] - ETA: 1s - loss: 5.7188 - acc: 0.6442
 5312/14483 [==========>...................] - ETA: 1s - loss: 5.6762 - acc: 0.6468
 5632/14483 [==========>...................] - ETA: 1s - loss: 5.6513 - acc: 0.6484
 5952/14483 [===========>..................] - ETA: 1s - loss: 5.6742 - acc: 0.6470
 6272/14483 [===========>..................] - ETA: 1s - loss: 5.6468 - acc: 0.6488
 6592/14483 [============>.................] - ETA: 1s - loss: 5.6281 - acc: 0.6499
 6912/14483 [=============>................] - ETA: 1s - loss: 5.5656 - acc: 0.6536
 7232/14483 [=============>................] - ETA: 1s - loss: 5.5795 - acc: 0.6528
 7552/14483 [==============>...............] - ETA: 1s - loss: 5.5480 - acc: 0.6548
 7872/14483 [===============>..............] - ETA: 1s - loss: 5.5454 - acc: 0.6550
 8192/14483 [===============>..............] - ETA: 1s - loss: 5.5459 - acc: 0.6548
 8512/14483 [================>.............] - ETA: 1s - loss: 5.5931 - acc: 0.6519
 8832/14483 [=================>............] - ETA: 1s - loss: 5.6094 - acc: 0.6509
 9152/14483 [=================>............] - ETA: 0s - loss: 5.6278 - acc: 0.6498
 9472/14483 [==================>...........] - ETA: 0s - loss: 5.6555 - acc: 0.6481
 9792/14483 [===================>..........] - ETA: 0s - loss: 5.6830 - acc: 0.6463
10112/14483 [===================>..........] - ETA: 0s - loss: 5.7076 - acc: 0.6448
10496/14483 [====================>.........] - ETA: 0s - loss: 5.7015 - acc: 0.6452
10816/14483 [=====================>........] - ETA: 0s - loss: 5.7066 - acc: 0.6449
11136/14483 [======================>.......] - ETA: 0s - loss: 5.7192 - acc: 0.6440
11456/14483 [======================>.......] - ETA: 0s - loss: 5.7367 - acc: 0.6430
11776/14483 [=======================>......] - ETA: 0s - loss: 5.7454 - acc: 0.6424
12096/14483 [========================>.....] - ETA: 0s - loss: 5.7411 - acc: 0.6426
12416/14483 [========================>.....] - ETA: 0s - loss: 5.7204 - acc: 0.6439
12736/14483 [=========================>....] - ETA: 0s - loss: 5.7357 - acc: 0.6430
13056/14483 [==========================>...] - ETA: 0s - loss: 5.7519 - acc: 0.6420
13376/14483 [==========================>...] - ETA: 0s - loss: 5.7599 - acc: 0.6414
13696/14483 [===========================>..] - ETA: 0s - loss: 5.7559 - acc: 0.6417
14016/14483 [============================>.] - ETA: 0s - loss: 5.7487 - acc: 0.6422
14336/14483 [============================>.] - ETA: 0s - loss: 5.7430 - acc: 0.6425
14483/14483 [==============================] - 3s 176us/step - loss: 5.7314 - acc: 0.6432

Test accuracy: 64.74820143884892

data size :  16012

zero :  8007

one :  8005

train_zero :  7242

train_one :  7241

test_zero :  765

test_one :  764

choose_zero :  922

choose_one :  607

F1score :  0.6068563092633116

AUC : 0.6480383601957362

Confusion Matrix
[[574 191]
 [348 416]]
True label 0
0.7503267973856209  
0.2496732026143791  
True label 1
0.45549738219895286  
0.5445026178010471  

Train_result {'loss': [5.731440526909207], 'acc': [0.6432368984285297]}
Saved model to disk



8

Epoch 1/1

   64/14483 [..............................] - ETA: 3s - loss: 5.5406 - acc: 0.6562
  320/14483 [..............................] - ETA: 3s - loss: 5.9939 - acc: 0.6281
  576/14483 [>.............................] - ETA: 2s - loss: 5.7040 - acc: 0.6458
  832/14483 [>.............................] - ETA: 2s - loss: 5.4794 - acc: 0.6599
 1152/14483 [=>............................] - ETA: 2s - loss: 5.5385 - acc: 0.6562
 1472/14483 [==>...........................] - ETA: 2s - loss: 5.4185 - acc: 0.6637
 1728/14483 [==>...........................] - ETA: 2s - loss: 5.3525 - acc: 0.6678
 2048/14483 [===>..........................] - ETA: 2s - loss: 5.2403 - acc: 0.6748
 2368/14483 [===>..........................] - ETA: 2s - loss: 5.1719 - acc: 0.6791
 2688/14483 [====>.........................] - ETA: 2s - loss: 5.1200 - acc: 0.6823
 3008/14483 [=====>........................] - ETA: 2s - loss: 5.1808 - acc: 0.6785
 3264/14483 [=====>........................] - ETA: 2s - loss: 5.1991 - acc: 0.6774
 3584/14483 [======>.......................] - ETA: 2s - loss: 5.1813 - acc: 0.6783
 3840/14483 [======>.......................] - ETA: 2s - loss: 5.2649 - acc: 0.6729
 4160/14483 [=======>......................] - ETA: 1s - loss: 5.4450 - acc: 0.6618
 4480/14483 [========>.....................] - ETA: 1s - loss: 5.6171 - acc: 0.6511
 4800/14483 [========>.....................] - ETA: 1s - loss: 5.6556 - acc: 0.6488
 5120/14483 [=========>....................] - ETA: 1s - loss: 5.7114 - acc: 0.6453
 5440/14483 [==========>...................] - ETA: 1s - loss: 5.6925 - acc: 0.6465
 5760/14483 [==========>...................] - ETA: 1s - loss: 5.6720 - acc: 0.6477
 6080/14483 [===========>..................] - ETA: 1s - loss: 5.6465 - acc: 0.6493
 6400/14483 [============>.................] - ETA: 1s - loss: 5.7394 - acc: 0.6436
 6720/14483 [============>.................] - ETA: 1s - loss: 5.7995 - acc: 0.6399
 7040/14483 [=============>................] - ETA: 1s - loss: 5.8367 - acc: 0.6375
 7360/14483 [==============>...............] - ETA: 1s - loss: 5.8654 - acc: 0.6357
 7680/14483 [==============>...............] - ETA: 1s - loss: 5.8500 - acc: 0.6366
 8000/14483 [===============>..............] - ETA: 1s - loss: 5.8319 - acc: 0.6376
 8320/14483 [================>.............] - ETA: 1s - loss: 5.8207 - acc: 0.6383
 8640/14483 [================>.............] - ETA: 1s - loss: 5.8541 - acc: 0.6362
 8960/14483 [=================>............] - ETA: 0s - loss: 5.8879 - acc: 0.6342
 9280/14483 [==================>...........] - ETA: 0s - loss: 5.9617 - acc: 0.6295
 9600/14483 [==================>...........] - ETA: 0s - loss: 6.0249 - acc: 0.6256
 9920/14483 [===================>..........] - ETA: 0s - loss: 6.0669 - acc: 0.6230
10240/14483 [====================>.........] - ETA: 0s - loss: 6.1023 - acc: 0.6208
10560/14483 [====================>.........] - ETA: 0s - loss: 6.1018 - acc: 0.6207
10880/14483 [=====================>........] - ETA: 0s - loss: 6.1001 - acc: 0.6209
11200/14483 [======================>.......] - ETA: 0s - loss: 6.1071 - acc: 0.6204
11520/14483 [======================>.......] - ETA: 0s - loss: 6.1222 - acc: 0.6194
11840/14483 [=======================>......] - ETA: 0s - loss: 6.1534 - acc: 0.6175
12160/14483 [========================>.....] - ETA: 0s - loss: 6.1784 - acc: 0.6160
12480/14483 [========================>.....] - ETA: 0s - loss: 6.2020 - acc: 0.6145
12800/14483 [=========================>....] - ETA: 0s - loss: 6.2082 - acc: 0.6141
13120/14483 [==========================>...] - ETA: 0s - loss: 6.1840 - acc: 0.6155
13440/14483 [==========================>...] - ETA: 0s - loss: 6.1663 - acc: 0.6167
13760/14483 [===========================>..] - ETA: 0s - loss: 6.1519 - acc: 0.6175
14080/14483 [============================>.] - ETA: 0s - loss: 6.1506 - acc: 0.6176
14400/14483 [============================>.] - ETA: 0s - loss: 6.1303 - acc: 0.6189
14483/14483 [==============================] - 3s 178us/step - loss: 6.1197 - acc: 0.6196

Test accuracy: 66.64486592544147

data size :  16012

zero :  8007

one :  8005

train_zero :  7242

train_one :  7241

test_zero :  765

test_one :  764

choose_zero :  801

choose_one :  728

F1score :  0.6581769436997319

AUC : 0.6669250248092257

Confusion Matrix
[[528 237]
 [273 491]]
True label 0
0.6901960784313725  
0.30980392156862746  
True label 1
0.35732984293193715  
0.6426701570680629  

Train_result {'loss': [6.119670227352101], 'acc': [0.619553959802609]}
Saved model to disk



9

Epoch 1/1

   64/14483 [..............................] - ETA: 3s - loss: 5.2888 - acc: 0.6719
  320/14483 [..............................] - ETA: 3s - loss: 5.2384 - acc: 0.6750
  576/14483 [>.............................] - ETA: 2s - loss: 5.5126 - acc: 0.6580
  896/14483 [>.............................] - ETA: 2s - loss: 5.5586 - acc: 0.6551
 1216/14483 [=>............................] - ETA: 2s - loss: 5.5953 - acc: 0.6521
 1536/14483 [==>...........................] - ETA: 2s - loss: 5.4370 - acc: 0.6621
 1856/14483 [==>...........................] - ETA: 2s - loss: 5.2899 - acc: 0.6713
 2176/14483 [===>..........................] - ETA: 2s - loss: 5.3578 - acc: 0.6668
 2496/14483 [====>.........................] - ETA: 2s - loss: 5.3941 - acc: 0.6647
 2816/14483 [====>.........................] - ETA: 2s - loss: 5.3822 - acc: 0.6655
 3136/14483 [=====>........................] - ETA: 2s - loss: 5.3469 - acc: 0.6677
 3456/14483 [======>.......................] - ETA: 2s - loss: 5.3065 - acc: 0.6701
 3776/14483 [======>.......................] - ETA: 1s - loss: 5.3183 - acc: 0.6692
 4096/14483 [=======>......................] - ETA: 1s - loss: 5.3081 - acc: 0.6699
 4416/14483 [========>.....................] - ETA: 1s - loss: 5.2831 - acc: 0.6714
 4736/14483 [========>.....................] - ETA: 1s - loss: 5.3128 - acc: 0.6696
 5056/14483 [=========>....................] - ETA: 1s - loss: 5.3559 - acc: 0.6669
 5376/14483 [==========>...................] - ETA: 1s - loss: 5.3464 - acc: 0.6674
 5696/14483 [==========>...................] - ETA: 1s - loss: 5.3309 - acc: 0.6684
 6016/14483 [===========>..................] - ETA: 1s - loss: 5.3340 - acc: 0.6682
 6336/14483 [============>.................] - ETA: 1s - loss: 5.3358 - acc: 0.6679
 6656/14483 [============>.................] - ETA: 1s - loss: 5.3021 - acc: 0.6701
 6976/14483 [=============>................] - ETA: 1s - loss: 5.3506 - acc: 0.6669
 7296/14483 [==============>...............] - ETA: 1s - loss: 5.3943 - acc: 0.6642
 7616/14483 [==============>...............] - ETA: 1s - loss: 5.4152 - acc: 0.6628
 7936/14483 [===============>..............] - ETA: 1s - loss: 5.4368 - acc: 0.6614
 8256/14483 [================>.............] - ETA: 1s - loss: 5.4369 - acc: 0.6615
 8576/14483 [================>.............] - ETA: 1s - loss: 5.4445 - acc: 0.6610
 8896/14483 [=================>............] - ETA: 1s - loss: 5.4326 - acc: 0.6616
 9216/14483 [==================>...........] - ETA: 0s - loss: 5.4469 - acc: 0.6608
 9536/14483 [==================>...........] - ETA: 0s - loss: 5.4636 - acc: 0.6598
 9856/14483 [===================>..........] - ETA: 0s - loss: 5.4914 - acc: 0.6581
10176/14483 [====================>.........] - ETA: 0s - loss: 5.5215 - acc: 0.6562
10496/14483 [====================>.........] - ETA: 0s - loss: 5.5740 - acc: 0.6530
10816/14483 [=====================>........] - ETA: 0s - loss: 5.6028 - acc: 0.6513
11136/14483 [======================>.......] - ETA: 0s - loss: 5.6517 - acc: 0.6483
11456/14483 [======================>.......] - ETA: 0s - loss: 5.7032 - acc: 0.6451
11776/14483 [=======================>......] - ETA: 0s - loss: 5.7879 - acc: 0.6398
12096/14483 [========================>.....] - ETA: 0s - loss: 5.8413 - acc: 0.6365
12416/14483 [========================>.....] - ETA: 0s - loss: 5.8868 - acc: 0.6337
12736/14483 [=========================>....] - ETA: 0s - loss: 5.9452 - acc: 0.6301
13056/14483 [==========================>...] - ETA: 0s - loss: 6.0056 - acc: 0.6264
13376/14483 [==========================>...] - ETA: 0s - loss: 6.0379 - acc: 0.6244
13696/14483 [===========================>..] - ETA: 0s - loss: 6.0639 - acc: 0.6228
14016/14483 [============================>.] - ETA: 0s - loss: 6.0980 - acc: 0.6207
14336/14483 [============================>.] - ETA: 0s - loss: 6.1384 - acc: 0.6182
14483/14483 [==============================] - 3s 178us/step - loss: 6.1540 - acc: 0.6173

Test accuracy: 51.53695225637671

data size :  16012

zero :  8007

one :  8005

train_zero :  7242

train_one :  7241

test_zero :  765

test_one :  764

choose_zero :  1496

choose_one :  33

F1score :  0.07026348808030113

AUC : 0.5163569790918112

Confusion Matrix
[[760   5]
 [736  28]]
True label 0
0.9934640522875817  
0.006535947712418301  
True label 1
0.9633507853403142  
0.03664921465968586  

Train_result {'loss': [6.153970130329624], 'acc': [0.6172754263578261]}
Saved model to disk



10

Epoch 1/1

   64/14483 [..............................] - ETA: 3s - loss: 6.7998 - acc: 0.5781
  320/14483 [..............................] - ETA: 3s - loss: 7.6057 - acc: 0.5281
  576/14483 [>.............................] - ETA: 2s - loss: 7.4434 - acc: 0.5382
  896/14483 [>.............................] - ETA: 2s - loss: 7.4936 - acc: 0.5346
 1216/14483 [=>............................] - ETA: 2s - loss: 7.3591 - acc: 0.5428
 1536/14483 [==>...........................] - ETA: 2s - loss: 6.8753 - acc: 0.5729
 1856/14483 [==>...........................] - ETA: 2s - loss: 6.5757 - acc: 0.5916
 2176/14483 [===>..........................] - ETA: 2s - loss: 6.4531 - acc: 0.5993
 2496/14483 [====>.........................] - ETA: 2s - loss: 6.3911 - acc: 0.6026
 2816/14483 [====>.........................] - ETA: 2s - loss: 6.5343 - acc: 0.5938
 3136/14483 [=====>........................] - ETA: 2s - loss: 6.6077 - acc: 0.5893
 3456/14483 [======>.......................] - ETA: 2s - loss: 6.6115 - acc: 0.5891
 3776/14483 [======>.......................] - ETA: 2s - loss: 6.7512 - acc: 0.5805
 4096/14483 [=======>......................] - ETA: 1s - loss: 6.8377 - acc: 0.5752
 4416/14483 [========>.....................] - ETA: 1s - loss: 6.9043 - acc: 0.5711
 4736/14483 [========>.....................] - ETA: 1s - loss: 6.9944 - acc: 0.5655
 5056/14483 [=========>....................] - ETA: 1s - loss: 7.0586 - acc: 0.5615
 5376/14483 [==========>...................] - ETA: 1s - loss: 7.1211 - acc: 0.5577
 5696/14483 [==========>...................] - ETA: 1s - loss: 7.1540 - acc: 0.5557
 6016/14483 [===========>..................] - ETA: 1s - loss: 7.2343 - acc: 0.5507
 6336/14483 [============>.................] - ETA: 1s - loss: 7.2785 - acc: 0.5480
 6656/14483 [============>.................] - ETA: 1s - loss: 7.2692 - acc: 0.5484
 6976/14483 [=============>................] - ETA: 1s - loss: 7.3216 - acc: 0.5452
 7296/14483 [==============>...............] - ETA: 1s - loss: 7.3783 - acc: 0.5417
 7616/14483 [==============>...............] - ETA: 1s - loss: 7.4407 - acc: 0.5378
 7936/14483 [===============>..............] - ETA: 1s - loss: 7.4413 - acc: 0.5378
 8192/14483 [===============>..............] - ETA: 1s - loss: 7.4350 - acc: 0.5382
 8512/14483 [================>.............] - ETA: 1s - loss: 7.4396 - acc: 0.5379
 8832/14483 [=================>............] - ETA: 1s - loss: 7.4492 - acc: 0.5374
 9152/14483 [=================>............] - ETA: 0s - loss: 7.4670 - acc: 0.5363
 9472/14483 [==================>...........] - ETA: 0s - loss: 7.5057 - acc: 0.5339
 9792/14483 [===================>..........] - ETA: 0s - loss: 7.5172 - acc: 0.5332
10112/14483 [===================>..........] - ETA: 0s - loss: 7.5344 - acc: 0.5321
10432/14483 [====================>.........] - ETA: 0s - loss: 7.5489 - acc: 0.5312
10752/14483 [=====================>........] - ETA: 0s - loss: 7.5731 - acc: 0.5298
11072/14483 [=====================>........] - ETA: 0s - loss: 7.5784 - acc: 0.5294
11392/14483 [======================>.......] - ETA: 0s - loss: 7.6047 - acc: 0.5278
11712/14483 [=======================>......] - ETA: 0s - loss: 7.6157 - acc: 0.5272
12032/14483 [=======================>......] - ETA: 0s - loss: 7.6101 - acc: 0.5275
12352/14483 [========================>.....] - ETA: 0s - loss: 7.6295 - acc: 0.5263
12672/14483 [=========================>....] - ETA: 0s - loss: 7.6480 - acc: 0.5252
12992/14483 [=========================>....] - ETA: 0s - loss: 7.6482 - acc: 0.5252
13312/14483 [==========================>...] - ETA: 0s - loss: 7.6557 - acc: 0.5247
13632/14483 [===========================>..] - ETA: 0s - loss: 7.6491 - acc: 0.5251
13952/14483 [===========================>..] - ETA: 0s - loss: 7.6608 - acc: 0.5244
14272/14483 [============================>.] - ETA: 0s - loss: 7.6777 - acc: 0.5233
14483/14483 [==============================] - 3s 177us/step - loss: 7.6838 - acc: 0.5230

Test accuracy: 50.35971223021583

data size :  16012

zero :  8007

one :  8005

train_zero :  7242

train_one :  7241

test_zero :  765

test_one :  764

choose_zero :  1518

choose_one :  11

F1score :  0.02064516129032258

AUC : 0.5026331998768093

Confusion Matrix
[[762   3]
 [756   8]]
True label 0
0.996078431372549  
0.00392156862745098  
True label 1
0.9895287958115183  
0.010471204188481676  

Train_result {'loss': [7.683788640191441], 'acc': [0.5229579506843597]}
Saved model to disk



11

Epoch 1/1

   64/14483 [..............................] - ETA: 3s - loss: 8.3109 - acc: 0.4844
  320/14483 [..............................] - ETA: 3s - loss: 8.1598 - acc: 0.4938
  576/14483 [>.............................] - ETA: 2s - loss: 7.7247 - acc: 0.5191
  896/14483 [>.............................] - ETA: 2s - loss: 7.5516 - acc: 0.5301
 1216/14483 [=>............................] - ETA: 2s - loss: 7.0356 - acc: 0.5625
 1536/14483 [==>...........................] - ETA: 2s - loss: 6.9130 - acc: 0.5703
 1856/14483 [==>...........................] - ETA: 2s - loss: 6.8762 - acc: 0.5727
 2176/14483 [===>..........................] - ETA: 2s - loss: 6.7607 - acc: 0.5800
 2496/14483 [====>.........................] - ETA: 2s - loss: 6.8045 - acc: 0.5773
 2816/14483 [====>.........................] - ETA: 2s - loss: 6.8154 - acc: 0.5767
 3136/14483 [=====>........................] - ETA: 2s - loss: 6.8344 - acc: 0.5756
 3456/14483 [======>.......................] - ETA: 2s - loss: 6.8498 - acc: 0.5747
 3776/14483 [======>.......................] - ETA: 2s - loss: 6.9096 - acc: 0.5710
 4096/14483 [=======>......................] - ETA: 1s - loss: 6.9443 - acc: 0.5688
 4416/14483 [========>.....................] - ETA: 1s - loss: 7.0142 - acc: 0.5645
 4736/14483 [========>.....................] - ETA: 1s - loss: 7.0642 - acc: 0.5614
 5056/14483 [=========>....................] - ETA: 1s - loss: 7.0921 - acc: 0.5597
 5376/14483 [==========>...................] - ETA: 1s - loss: 7.1437 - acc: 0.5565
 5696/14483 [==========>...................] - ETA: 1s - loss: 7.2126 - acc: 0.5521
 6016/14483 [===========>..................] - ETA: 1s - loss: 7.2683 - acc: 0.5487
 6336/14483 [============>.................] - ETA: 1s - loss: 7.3414 - acc: 0.5442
 6656/14483 [============>.................] - ETA: 1s - loss: 7.3444 - acc: 0.5440
 6976/14483 [=============>................] - ETA: 1s - loss: 7.3864 - acc: 0.5414
 7296/14483 [==============>...............] - ETA: 1s - loss: 7.4424 - acc: 0.5380
 7616/14483 [==============>...............] - ETA: 1s - loss: 7.4514 - acc: 0.5374
 7936/14483 [===============>..............] - ETA: 1s - loss: 7.4637 - acc: 0.5367
 8256/14483 [================>.............] - ETA: 1s - loss: 7.5414 - acc: 0.5319
 8576/14483 [================>.............] - ETA: 1s - loss: 7.5777 - acc: 0.5296
 8896/14483 [=================>............] - ETA: 1s - loss: 7.5914 - acc: 0.5288
 9216/14483 [==================>...........] - ETA: 0s - loss: 7.6233 - acc: 0.5268
 9536/14483 [==================>...........] - ETA: 0s - loss: 7.6363 - acc: 0.5260
 9856/14483 [===================>..........] - ETA: 0s - loss: 7.6549 - acc: 0.5249
10176/14483 [====================>.........] - ETA: 0s - loss: 7.6819 - acc: 0.5232
10496/14483 [====================>.........] - ETA: 0s - loss: 7.6872 - acc: 0.5229
10816/14483 [=====================>........] - ETA: 0s - loss: 7.6744 - acc: 0.5237
11136/14483 [======================>.......] - ETA: 0s - loss: 7.6710 - acc: 0.5239
11456/14483 [======================>.......] - ETA: 0s - loss: 7.6748 - acc: 0.5237
11776/14483 [=======================>......] - ETA: 0s - loss: 7.6880 - acc: 0.5228
12096/14483 [========================>.....] - ETA: 0s - loss: 7.6951 - acc: 0.5224
12416/14483 [========================>.....] - ETA: 0s - loss: 7.6889 - acc: 0.5228
12736/14483 [=========================>....] - ETA: 0s - loss: 7.7020 - acc: 0.5220
13056/14483 [==========================>...] - ETA: 0s - loss: 7.7219 - acc: 0.5208
13376/14483 [==========================>...] - ETA: 0s - loss: 7.7384 - acc: 0.5197
13696/14483 [===========================>..] - ETA: 0s - loss: 7.7388 - acc: 0.5197
14016/14483 [============================>.] - ETA: 0s - loss: 7.7415 - acc: 0.5195
14336/14483 [============================>.] - ETA: 0s - loss: 7.7565 - acc: 0.5186
14483/14483 [==============================] - 3s 177us/step - loss: 7.7523 - acc: 0.5189

Test accuracy: 50.16350555918901

data size :  16012

zero :  8007

one :  8005

train_zero :  7242

train_one :  7241

test_zero :  765

test_one :  764

choose_zero :  1527

choose_one :  2

F1score :  0.005221932114882507

AUC : 0.5013089005235603

Confusion Matrix
[[765   0]
 [762   2]]
True label 0
1.0  
0.0  
True label 1
0.9973821989528796  
0.002617801047120419  

Train_result {'loss': [7.75230602084508], 'acc': [0.5188842090665327]}
Saved model to disk



12

Epoch 1/1

   64/14483 [..............................] - ETA: 3s - loss: 7.3035 - acc: 0.5469
  320/14483 [..............................] - ETA: 3s - loss: 7.9583 - acc: 0.5062
  576/14483 [>.............................] - ETA: 2s - loss: 8.1366 - acc: 0.4948
  896/14483 [>.............................] - ETA: 2s - loss: 7.9341 - acc: 0.5067
 1216/14483 [=>............................] - ETA: 2s - loss: 8.0465 - acc: 0.5000
 1536/14483 [==>...........................] - ETA: 2s - loss: 7.9116 - acc: 0.5085
 1856/14483 [==>...........................] - ETA: 2s - loss: 8.0322 - acc: 0.5011
 2176/14483 [===>..........................] - ETA: 2s - loss: 7.9176 - acc: 0.5083
 2496/14483 [====>.........................] - ETA: 2s - loss: 7.8273 - acc: 0.5136
 2816/14483 [====>.........................] - ETA: 2s - loss: 7.7163 - acc: 0.5206
 3136/14483 [=====>........................] - ETA: 2s - loss: 7.5816 - acc: 0.5290
 3456/14483 [======>.......................] - ETA: 2s - loss: 7.4393 - acc: 0.5379
 3776/14483 [======>.......................] - ETA: 2s - loss: 7.3851 - acc: 0.5413
 4096/14483 [=======>......................] - ETA: 1s - loss: 7.2961 - acc: 0.5469
 4416/14483 [========>.....................] - ETA: 1s - loss: 7.2820 - acc: 0.5478
 4736/14483 [========>.....................] - ETA: 1s - loss: 7.1959 - acc: 0.5530
 5056/14483 [=========>....................] - ETA: 1s - loss: 7.0880 - acc: 0.5597
 5376/14483 [==========>...................] - ETA: 1s - loss: 6.9449 - acc: 0.5686
 5696/14483 [==========>...................] - ETA: 1s - loss: 6.8804 - acc: 0.5725
 6016/14483 [===========>..................] - ETA: 1s - loss: 6.7849 - acc: 0.5785
 6336/14483 [============>.................] - ETA: 1s - loss: 6.6635 - acc: 0.5860
 6656/14483 [============>.................] - ETA: 1s - loss: 6.6030 - acc: 0.5897
 6976/14483 [=============>................] - ETA: 1s - loss: 6.5418 - acc: 0.5935
 7296/14483 [==============>...............] - ETA: 1s - loss: 6.5023 - acc: 0.5959
 7616/14483 [==============>...............] - ETA: 1s - loss: 6.4475 - acc: 0.5993
 7936/14483 [===============>..............] - ETA: 1s - loss: 6.4287 - acc: 0.6004
 8256/14483 [================>.............] - ETA: 1s - loss: 6.3963 - acc: 0.6025
 8576/14483 [================>.............] - ETA: 1s - loss: 6.3643 - acc: 0.6045
 8896/14483 [=================>............] - ETA: 0s - loss: 6.3201 - acc: 0.6072
 9216/14483 [==================>...........] - ETA: 0s - loss: 6.3106 - acc: 0.6079
 9536/14483 [==================>...........] - ETA: 0s - loss: 6.2966 - acc: 0.6087
 9856/14483 [===================>..........] - ETA: 0s - loss: 6.2916 - acc: 0.6091
10176/14483 [====================>.........] - ETA: 0s - loss: 6.2594 - acc: 0.6110
10496/14483 [====================>.........] - ETA: 0s - loss: 6.2145 - acc: 0.6139
10816/14483 [=====================>........] - ETA: 0s - loss: 6.1692 - acc: 0.6167
11136/14483 [======================>.......] - ETA: 0s - loss: 6.1555 - acc: 0.6175
11456/14483 [======================>.......] - ETA: 0s - loss: 6.1383 - acc: 0.6186
11776/14483 [=======================>......] - ETA: 0s - loss: 6.1148 - acc: 0.6201
12096/14483 [========================>.....] - ETA: 0s - loss: 6.0940 - acc: 0.6214
12416/14483 [========================>.....] - ETA: 0s - loss: 6.0862 - acc: 0.6219
12736/14483 [=========================>....] - ETA: 0s - loss: 6.0624 - acc: 0.6234
13056/14483 [==========================>...] - ETA: 0s - loss: 6.0533 - acc: 0.6239
13376/14483 [==========================>...] - ETA: 0s - loss: 6.0410 - acc: 0.6247
13696/14483 [===========================>..] - ETA: 0s - loss: 6.0250 - acc: 0.6257
14016/14483 [============================>.] - ETA: 0s - loss: 6.0151 - acc: 0.6263
14336/14483 [============================>.] - ETA: 0s - loss: 6.0011 - acc: 0.6272
14483/14483 [==============================] - 3s 176us/step - loss: 6.0081 - acc: 0.6267

Test accuracy: 67.75670372792675

data size :  16012

zero :  8007

one :  8005

train_zero :  7242

train_one :  7241

test_zero :  765

test_one :  764

choose_zero :  606

choose_one :  923

F1score :  0.7077652637818612

AUC : 0.6773004140574206

Confusion Matrix
[[439 326]
 [167 597]]
True label 0
0.5738562091503268  
0.4261437908496732  
True label 1
0.21858638743455497  
0.7814136125654451  

Train_result {'loss': [6.008124883074643], 'acc': [0.6267347925524023]}
Saved model to disk



13

Epoch 1/1

   64/14483 [..............................] - ETA: 3s - loss: 4.7851 - acc: 0.7031
  320/14483 [..............................] - ETA: 3s - loss: 5.1996 - acc: 0.6750
  576/14483 [>.............................] - ETA: 2s - loss: 5.0371 - acc: 0.6858
  896/14483 [>.............................] - ETA: 2s - loss: 5.3215 - acc: 0.6685
 1216/14483 [=>............................] - ETA: 2s - loss: 5.5648 - acc: 0.6538
 1536/14483 [==>...........................] - ETA: 2s - loss: 5.5387 - acc: 0.6556
 1856/14483 [==>...........................] - ETA: 2s - loss: 5.5391 - acc: 0.6557
 2112/14483 [===>..........................] - ETA: 2s - loss: 5.5087 - acc: 0.6577
 2432/14483 [====>.........................] - ETA: 2s - loss: 5.4665 - acc: 0.6604
 2752/14483 [====>.........................] - ETA: 2s - loss: 5.4458 - acc: 0.6617
 3072/14483 [=====>........................] - ETA: 2s - loss: 5.4505 - acc: 0.6615
 3392/14483 [======>.......................] - ETA: 2s - loss: 5.4352 - acc: 0.6624
 3712/14483 [======>.......................] - ETA: 2s - loss: 5.5125 - acc: 0.6573
 4032/14483 [=======>......................] - ETA: 1s - loss: 5.5107 - acc: 0.6575
 4352/14483 [========>.....................] - ETA: 1s - loss: 5.5013 - acc: 0.6581
 4672/14483 [========>.....................] - ETA: 1s - loss: 5.5323 - acc: 0.6560
 4992/14483 [=========>....................] - ETA: 1s - loss: 5.5393 - acc: 0.6556
 5312/14483 [==========>...................] - ETA: 1s - loss: 5.5121 - acc: 0.6574
 5632/14483 [==========>...................] - ETA: 1s - loss: 5.4793 - acc: 0.6594
 5952/14483 [===========>..................] - ETA: 1s - loss: 5.4908 - acc: 0.6588
 6272/14483 [===========>..................] - ETA: 1s - loss: 5.4997 - acc: 0.6582
 6592/14483 [============>.................] - ETA: 1s - loss: 5.4699 - acc: 0.6600
 6912/14483 [=============>................] - ETA: 1s - loss: 5.5343 - acc: 0.6560
 7232/14483 [=============>................] - ETA: 1s - loss: 5.5435 - acc: 0.6554
 7552/14483 [==============>...............] - ETA: 1s - loss: 5.5669 - acc: 0.6540
 7872/14483 [===============>..............] - ETA: 1s - loss: 5.6293 - acc: 0.6502
 8192/14483 [===============>..............] - ETA: 1s - loss: 5.6672 - acc: 0.6478
 8512/14483 [================>.............] - ETA: 1s - loss: 5.6889 - acc: 0.6465
 8832/14483 [=================>............] - ETA: 1s - loss: 5.7365 - acc: 0.6436
 9152/14483 [=================>............] - ETA: 0s - loss: 5.7419 - acc: 0.6432
 9472/14483 [==================>...........] - ETA: 0s - loss: 5.8258 - acc: 0.6380
 9792/14483 [===================>..........] - ETA: 0s - loss: 5.8790 - acc: 0.6347
10112/14483 [===================>..........] - ETA: 0s - loss: 5.9336 - acc: 0.6313
10432/14483 [====================>.........] - ETA: 0s - loss: 5.9787 - acc: 0.6285
10752/14483 [=====================>........] - ETA: 0s - loss: 6.0257 - acc: 0.6257
11072/14483 [=====================>........] - ETA: 0s - loss: 6.0742 - acc: 0.6227
11392/14483 [======================>.......] - ETA: 0s - loss: 6.1059 - acc: 0.6207
11712/14483 [=======================>......] - ETA: 0s - loss: 6.1373 - acc: 0.6188
12032/14483 [=======================>......] - ETA: 0s - loss: 6.1817 - acc: 0.6160
12352/14483 [========================>.....] - ETA: 0s - loss: 6.2160 - acc: 0.6139
12672/14483 [=========================>....] - ETA: 0s - loss: 6.2663 - acc: 0.6108
12992/14483 [=========================>....] - ETA: 0s - loss: 6.2931 - acc: 0.6091
13312/14483 [==========================>...] - ETA: 0s - loss: 6.3151 - acc: 0.6077
13632/14483 [===========================>..] - ETA: 0s - loss: 6.3264 - acc: 0.6070
13952/14483 [===========================>..] - ETA: 0s - loss: 6.3454 - acc: 0.6059
14272/14483 [============================>.] - ETA: 0s - loss: 6.3454 - acc: 0.6058
14483/14483 [==============================] - 3s 179us/step - loss: 6.3509 - acc: 0.6055

Test accuracy: 60.62786134728581

data size :  16012

zero :  8007

one :  8005

train_zero :  7242

train_one :  7241

test_zero :  765

test_one :  764

choose_zero :  1111

choose_one :  418

F1score :  0.49069373942470385

AUC : 0.605189405605174

Confusion Matrix
[[637 128]
 [474 290]]
True label 0
0.8326797385620915  
0.16732026143790849  
True label 1
0.6204188481675392  
0.3795811518324607  

Train_result {'loss': [6.350901271759752], 'acc': [0.6054684803119262]}
Saved model to disk



14

Epoch 1/1

   64/14483 [..............................] - ETA: 3s - loss: 5.2888 - acc: 0.6719
  320/14483 [..............................] - ETA: 3s - loss: 6.9006 - acc: 0.5719
  576/14483 [>.............................] - ETA: 2s - loss: 6.6261 - acc: 0.5885
  896/14483 [>.............................] - ETA: 2s - loss: 6.0046 - acc: 0.6272
 1216/14483 [=>............................] - ETA: 2s - loss: 5.8302 - acc: 0.6382
 1536/14483 [==>...........................] - ETA: 2s - loss: 5.6439 - acc: 0.6497
 1856/14483 [==>...........................] - ETA: 2s - loss: 5.4719 - acc: 0.6600
 2176/14483 [===>..........................] - ETA: 2s - loss: 5.4376 - acc: 0.6622
 2496/14483 [====>.........................] - ETA: 2s - loss: 5.4960 - acc: 0.6587
 2816/14483 [====>.........................] - ETA: 2s - loss: 5.5125 - acc: 0.6577
 3136/14483 [=====>........................] - ETA: 2s - loss: 5.5331 - acc: 0.6562
 3456/14483 [======>.......................] - ETA: 2s - loss: 5.5804 - acc: 0.6534
 3712/14483 [======>.......................] - ETA: 2s - loss: 5.6515 - acc: 0.6490
 4032/14483 [=======>......................] - ETA: 1s - loss: 5.6753 - acc: 0.6473
 4352/14483 [========>.....................] - ETA: 1s - loss: 5.7025 - acc: 0.6457
 4672/14483 [========>.....................] - ETA: 1s - loss: 5.6741 - acc: 0.6475
 4992/14483 [=========>....................] - ETA: 1s - loss: 5.7004 - acc: 0.6458
 5312/14483 [==========>...................] - ETA: 1s - loss: 5.6797 - acc: 0.6470
 5632/14483 [==========>...................] - ETA: 1s - loss: 5.6661 - acc: 0.6479
 5952/14483 [===========>..................] - ETA: 1s - loss: 5.6729 - acc: 0.6475
 6272/14483 [===========>..................] - ETA: 1s - loss: 5.6815 - acc: 0.6470
 6592/14483 [============>.................] - ETA: 1s - loss: 5.6600 - acc: 0.6484
 6912/14483 [=============>................] - ETA: 1s - loss: 5.6638 - acc: 0.6481
 7232/14483 [=============>................] - ETA: 1s - loss: 5.6851 - acc: 0.6468
 7552/14483 [==============>...............] - ETA: 1s - loss: 5.6939 - acc: 0.6463
 7872/14483 [===============>..............] - ETA: 1s - loss: 5.7020 - acc: 0.6458
 8192/14483 [===============>..............] - ETA: 1s - loss: 5.7154 - acc: 0.6450
 8512/14483 [================>.............] - ETA: 1s - loss: 5.7429 - acc: 0.6433
 8832/14483 [=================>............] - ETA: 1s - loss: 5.7283 - acc: 0.6442
 9152/14483 [=================>............] - ETA: 0s - loss: 5.7288 - acc: 0.6442
 9472/14483 [==================>...........] - ETA: 0s - loss: 5.7462 - acc: 0.6432
 9792/14483 [===================>..........] - ETA: 0s - loss: 5.7757 - acc: 0.6413
10112/14483 [===================>..........] - ETA: 0s - loss: 5.7922 - acc: 0.6403
10432/14483 [====================>.........] - ETA: 0s - loss: 5.8061 - acc: 0.6395
10752/14483 [=====================>........] - ETA: 0s - loss: 5.8027 - acc: 0.6397
11072/14483 [=====================>........] - ETA: 0s - loss: 5.7995 - acc: 0.6399
11392/14483 [======================>.......] - ETA: 0s - loss: 5.8104 - acc: 0.6392
11712/14483 [=======================>......] - ETA: 0s - loss: 5.8209 - acc: 0.6386
12032/14483 [=======================>......] - ETA: 0s - loss: 5.8041 - acc: 0.6396
12352/14483 [========================>.....] - ETA: 0s - loss: 5.7999 - acc: 0.6399
12672/14483 [=========================>....] - ETA: 0s - loss: 5.8048 - acc: 0.6396
12992/14483 [=========================>....] - ETA: 0s - loss: 5.8032 - acc: 0.6397
13312/14483 [==========================>...] - ETA: 0s - loss: 5.7993 - acc: 0.6399
13632/14483 [===========================>..] - ETA: 0s - loss: 5.7873 - acc: 0.6407
13952/14483 [===========================>..] - ETA: 0s - loss: 5.7771 - acc: 0.6413
14272/14483 [============================>.] - ETA: 0s - loss: 5.7769 - acc: 0.6413
14483/14483 [==============================] - 3s 178us/step - loss: 5.7606 - acc: 0.6423

Test accuracy: 65.59843034663179

data size :  16012

zero :  8007

one :  8005

train_zero :  7242

train_one :  7241

test_zero :  765

test_one :  764

choose_zero :  805

choose_one :  724

F1score :  0.6465053763440861

AUC : 0.6554434862950416

Confusion Matrix
[[522 243]
 [283 481]]
True label 0
0.6823529411764706  
0.3176470588235294  
True label 1
0.3704188481675393  
0.6295811518324608  

Train_result {'loss': [5.760602192803657], 'acc': [0.6423392943245168]}
Saved model to disk



15

Epoch 1/1

   64/14483 [..............................] - ETA: 3s - loss: 6.2961 - acc: 0.6094
  320/14483 [..............................] - ETA: 3s - loss: 5.7421 - acc: 0.6438
  576/14483 [>.............................] - ETA: 2s - loss: 5.4846 - acc: 0.6597
  832/14483 [>.............................] - ETA: 2s - loss: 5.3856 - acc: 0.6659
 1152/14483 [=>............................] - ETA: 2s - loss: 5.5645 - acc: 0.6545
 1472/14483 [==>...........................] - ETA: 2s - loss: 5.5788 - acc: 0.6535
 1792/14483 [==>...........................] - ETA: 2s - loss: 5.6170 - acc: 0.6512
 2112/14483 [===>..........................] - ETA: 2s - loss: 5.5673 - acc: 0.6544
 2432/14483 [====>.........................] - ETA: 2s - loss: 5.6816 - acc: 0.6468
 2752/14483 [====>.........................] - ETA: 2s - loss: 5.8495 - acc: 0.6363
 3072/14483 [=====>........................] - ETA: 2s - loss: 5.8383 - acc: 0.6370
 3392/14483 [======>.......................] - ETA: 2s - loss: 5.9053 - acc: 0.6330
 3712/14483 [======>.......................] - ETA: 2s - loss: 5.9476 - acc: 0.6304
 4032/14483 [=======>......................] - ETA: 1s - loss: 6.0952 - acc: 0.6213
 4352/14483 [========>.....................] - ETA: 1s - loss: 6.1248 - acc: 0.6195
 4672/14483 [========>.....................] - ETA: 1s - loss: 6.2400 - acc: 0.6124
 4992/14483 [=========>....................] - ETA: 1s - loss: 6.2733 - acc: 0.6102
 5312/14483 [==========>...................] - ETA: 1s - loss: 6.2231 - acc: 0.6133
 5632/14483 [==========>...................] - ETA: 1s - loss: 6.2276 - acc: 0.6129
 5952/14483 [===========>..................] - ETA: 1s - loss: 6.2339 - acc: 0.6126
 6272/14483 [===========>..................] - ETA: 1s - loss: 6.2782 - acc: 0.6099
 6592/14483 [============>.................] - ETA: 1s - loss: 6.3060 - acc: 0.6082
 6912/14483 [=============>................] - ETA: 1s - loss: 6.3303 - acc: 0.6066
 7232/14483 [=============>................] - ETA: 1s - loss: 6.3048 - acc: 0.6081
 7552/14483 [==============>...............] - ETA: 1s - loss: 6.2511 - acc: 0.6115
 7872/14483 [===============>..............] - ETA: 1s - loss: 6.2265 - acc: 0.6129
 8192/14483 [===============>..............] - ETA: 1s - loss: 6.2154 - acc: 0.6136
 8512/14483 [================>.............] - ETA: 1s - loss: 6.1816 - acc: 0.6157
 8832/14483 [=================>............] - ETA: 1s - loss: 6.1292 - acc: 0.6190
 9152/14483 [=================>............] - ETA: 0s - loss: 6.1068 - acc: 0.6204
 9472/14483 [==================>...........] - ETA: 0s - loss: 6.1081 - acc: 0.6204
 9792/14483 [===================>..........] - ETA: 0s - loss: 6.0827 - acc: 0.6219
10112/14483 [===================>..........] - ETA: 0s - loss: 6.0703 - acc: 0.6227
10432/14483 [====================>.........] - ETA: 0s - loss: 6.0525 - acc: 0.6238
10752/14483 [=====================>........] - ETA: 0s - loss: 6.0223 - acc: 0.6257
11072/14483 [=====================>........] - ETA: 0s - loss: 6.0173 - acc: 0.6260
11392/14483 [======================>.......] - ETA: 0s - loss: 6.0351 - acc: 0.6249
11712/14483 [=======================>......] - ETA: 0s - loss: 6.0284 - acc: 0.6253
12032/14483 [=======================>......] - ETA: 0s - loss: 6.0212 - acc: 0.6257
12352/14483 [========================>.....] - ETA: 0s - loss: 6.0128 - acc: 0.6262
12672/14483 [=========================>....] - ETA: 0s - loss: 6.0060 - acc: 0.6267
12992/14483 [=========================>....] - ETA: 0s - loss: 5.9995 - acc: 0.6271
13312/14483 [==========================>...] - ETA: 0s - loss: 6.0126 - acc: 0.6263
13632/14483 [===========================>..] - ETA: 0s - loss: 6.0110 - acc: 0.6264
13952/14483 [===========================>..] - ETA: 0s - loss: 6.0049 - acc: 0.6268
14272/14483 [============================>.] - ETA: 0s - loss: 6.0086 - acc: 0.6265
14483/14483 [==============================] - 3s 177us/step - loss: 5.9956 - acc: 0.6274

Test accuracy: 65.14061478090255

data size :  16012

zero :  8007

one :  8005

train_zero :  7242

train_one :  7241

test_zero :  765

test_one :  764

choose_zero :  384

choose_one :  1145

F1score :  0.7207962283918282

AUC : 0.6517674434520754

Confusion Matrix
[[308 457]
 [ 76 688]]
True label 0
0.40261437908496733  
0.5973856209150327  
True label 1
0.09947643979057591  
0.900523560209424  

Train_result {'loss': [5.995626682949718], 'acc': [0.6273562106968973]}
Saved model to disk



[[65.27141922825376, 1], [65.729234793983, 2], [58.142576847612816, 3], [56.703727926749515, 4], [65.27141922825376, 5], [66.05624591236102, 6], [64.74820143884892, 7], [66.64486592544147, 8], [51.53695225637671, 9], [50.35971223021583, 10], [50.16350555918901, 11], [67.75670372792675, 12], [60.62786134728581, 13], [65.59843034663179, 14], [65.14061478090255, 15]]
max accuracy :  [67.75670372792675, 12]
