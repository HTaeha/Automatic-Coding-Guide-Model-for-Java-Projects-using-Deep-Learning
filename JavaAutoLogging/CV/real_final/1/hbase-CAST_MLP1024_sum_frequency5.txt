Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
sum_MLP.py:400: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=inputs, output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-08-21 04:26:03.733115: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-21 04:26:03.740193: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100085000 Hz
2019-08-21 04:26:03.742401: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x548ef30 executing computations on platform Host. Devices:
2019-08-21 04:26:03.742458: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
zero : 
39451

one : 
9019
hbase-CAST
all data

Sentence length Average : 88

Under 10 : 7234
Over 10, Under 200 : 35282
Over 200, Under 400 : 3981
Over 400 : 1973

hbase-CAST
updated_train_data

Sentence length Average : 90

Under 10 : 0
Over 10, Under 200 : 31581
Over 200, Under 400 : 5169
Over 400 : 0


Test_zero:  3235
Train_zero:  29064
zero:  32299
Test_one:  811
Train_one:  7686
one:  8497

Count model parameter.
Get a short summary of each layer dimensions and parameters.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 200)               0         
_________________________________________________________________
masking_1 (Masking)          (None, 200)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              205824    
_________________________________________________________________
dropout_1 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
dropout_2 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 2050      
=================================================================
Total params: 1,257,474
Trainable params: 1,257,474
Non-trainable params: 0
_________________________________________________________________
1

Epoch 1/1

   64/15373 [..............................] - ETA: 1:27 - loss: 5.5627 - acc: 0.5156
  320/15373 [..............................] - ETA: 19s - loss: 5.8135 - acc: 0.6031 
  640/15373 [>.............................] - ETA: 10s - loss: 7.0125 - acc: 0.5469
  960/15373 [>.............................] - ETA: 8s - loss: 7.3110 - acc: 0.5344 
 1280/15373 [=>............................] - ETA: 6s - loss: 7.5106 - acc: 0.5250
 1600/15373 [==>...........................] - ETA: 5s - loss: 7.5296 - acc: 0.5256
 1920/15373 [==>...........................] - ETA: 4s - loss: 7.6347 - acc: 0.5203
 2240/15373 [===>..........................] - ETA: 4s - loss: 7.6809 - acc: 0.5183
 2560/15373 [===>..........................] - ETA: 4s - loss: 7.7030 - acc: 0.5176
 2880/15373 [====>.........................] - ETA: 3s - loss: 7.7985 - acc: 0.5122
 3200/15373 [=====>........................] - ETA: 3s - loss: 7.8447 - acc: 0.5097
 3520/15373 [=====>........................] - ETA: 3s - loss: 7.8092 - acc: 0.5122
 3840/15373 [======>.......................] - ETA: 3s - loss: 7.8469 - acc: 0.5102
 4160/15373 [=======>......................] - ETA: 2s - loss: 7.8438 - acc: 0.5106
 4480/15373 [=======>......................] - ETA: 2s - loss: 7.8592 - acc: 0.5098
 4864/15373 [========>.....................] - ETA: 2s - loss: 7.8584 - acc: 0.5101
 5184/15373 [=========>....................] - ETA: 2s - loss: 7.8272 - acc: 0.5122
 5568/15373 [=========>....................] - ETA: 2s - loss: 7.8577 - acc: 0.5104
 5888/15373 [==========>...................] - ETA: 2s - loss: 7.8467 - acc: 0.5112
 6272/15373 [===========>..................] - ETA: 2s - loss: 7.8238 - acc: 0.5128
 6656/15373 [===========>..................] - ETA: 1s - loss: 7.8470 - acc: 0.5114
 7040/15373 [============>.................] - ETA: 1s - loss: 7.8471 - acc: 0.5115
 7424/15373 [=============>................] - ETA: 1s - loss: 7.9059 - acc: 0.5079
 7808/15373 [==============>...............] - ETA: 1s - loss: 7.9031 - acc: 0.5082
 8192/15373 [==============>...............] - ETA: 1s - loss: 7.9084 - acc: 0.5079
 8512/15373 [===============>..............] - ETA: 1s - loss: 7.9444 - acc: 0.5058
 8832/15373 [================>.............] - ETA: 1s - loss: 7.9540 - acc: 0.5052
 9216/15373 [================>.............] - ETA: 1s - loss: 7.9671 - acc: 0.5044
 9600/15373 [=================>............] - ETA: 1s - loss: 7.9758 - acc: 0.5040
 9984/15373 [==================>...........] - ETA: 1s - loss: 7.9468 - acc: 0.5058
10368/15373 [===================>..........] - ETA: 0s - loss: 7.9540 - acc: 0.5054
10752/15373 [===================>..........] - ETA: 0s - loss: 7.9368 - acc: 0.5065
11072/15373 [====================>.........] - ETA: 0s - loss: 7.9607 - acc: 0.5051
11456/15373 [=====================>........] - ETA: 0s - loss: 7.9640 - acc: 0.5049
11840/15373 [======================>.......] - ETA: 0s - loss: 7.9671 - acc: 0.5047
12224/15373 [======================>.......] - ETA: 0s - loss: 7.9752 - acc: 0.5043
12608/15373 [=======================>......] - ETA: 0s - loss: 7.9714 - acc: 0.5045
12928/15373 [========================>.....] - ETA: 0s - loss: 7.9698 - acc: 0.5046
13248/15373 [========================>.....] - ETA: 0s - loss: 7.9732 - acc: 0.5045
13568/15373 [=========================>....] - ETA: 0s - loss: 7.9812 - acc: 0.5040
13952/15373 [==========================>...] - ETA: 0s - loss: 7.9972 - acc: 0.5030
14336/15373 [==========================>...] - ETA: 0s - loss: 8.0067 - acc: 0.5024
14720/15373 [===========================>..] - ETA: 0s - loss: 8.0103 - acc: 0.5022
15104/15373 [============================>.] - ETA: 0s - loss: 8.0136 - acc: 0.5021
15373/15373 [==============================] - 3s 183us/step - loss: 8.0003 - acc: 0.5029

Test accuracy: 50.03080714725816

data size :  16996

zero :  8499

one :  8497

train_zero :  7687

train_one :  7686

test_zero :  812

test_one :  811

choose_zero :  1623

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[812   0]
 [811   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5028946854933589], 'loss': [8.000276792292123]}
Saved model to disk



2

Epoch 1/1

   64/15373 [..............................] - ETA: 5s - loss: 7.8072 - acc: 0.5156
  384/15373 [..............................] - ETA: 3s - loss: 8.1430 - acc: 0.4948
  704/15373 [>.............................] - ETA: 2s - loss: 8.3109 - acc: 0.4844
 1024/15373 [>.............................] - ETA: 2s - loss: 8.2637 - acc: 0.4873
 1344/15373 [=>............................] - ETA: 2s - loss: 8.2509 - acc: 0.4881
 1664/15373 [==>...........................] - ETA: 2s - loss: 8.1075 - acc: 0.4970
 1984/15373 [==>...........................] - ETA: 2s - loss: 8.1078 - acc: 0.4970
 2304/15373 [===>..........................] - ETA: 2s - loss: 7.9471 - acc: 0.5069
 2624/15373 [====>.........................] - ETA: 2s - loss: 8.0468 - acc: 0.5008
 2944/15373 [====>.........................] - ETA: 2s - loss: 7.9879 - acc: 0.5044
 3264/15373 [=====>........................] - ETA: 2s - loss: 8.0097 - acc: 0.5031
 3584/15373 [=====>........................] - ETA: 2s - loss: 8.0096 - acc: 0.5031
 3904/15373 [======>.......................] - ETA: 1s - loss: 7.9682 - acc: 0.5056
 4224/15373 [=======>......................] - ETA: 1s - loss: 7.9942 - acc: 0.5040
 4544/15373 [=======>......................] - ETA: 1s - loss: 7.9384 - acc: 0.5075
 4864/15373 [========>.....................] - ETA: 1s - loss: 7.9663 - acc: 0.5058
 5248/15373 [=========>....................] - ETA: 1s - loss: 7.9884 - acc: 0.5044
 5568/15373 [=========>....................] - ETA: 1s - loss: 8.0417 - acc: 0.5011
 5952/15373 [==========>...................] - ETA: 1s - loss: 8.0482 - acc: 0.5007
 6336/15373 [===========>..................] - ETA: 1s - loss: 8.0489 - acc: 0.5006
 6720/15373 [============>.................] - ETA: 1s - loss: 8.0351 - acc: 0.5015
 7104/15373 [============>.................] - ETA: 1s - loss: 7.9728 - acc: 0.5053
 7488/15373 [=============>................] - ETA: 1s - loss: 7.9385 - acc: 0.5075
 7872/15373 [==============>...............] - ETA: 1s - loss: 7.9608 - acc: 0.5061
 8256/15373 [===============>..............] - ETA: 1s - loss: 7.9927 - acc: 0.5041
 8640/15373 [===============>..............] - ETA: 1s - loss: 7.9919 - acc: 0.5042
 9024/15373 [================>.............] - ETA: 1s - loss: 7.9947 - acc: 0.5040
 9408/15373 [=================>............] - ETA: 0s - loss: 8.0094 - acc: 0.5031
 9792/15373 [==================>...........] - ETA: 0s - loss: 8.0294 - acc: 0.5018
10176/15373 [==================>...........] - ETA: 0s - loss: 8.0321 - acc: 0.5017
10560/15373 [===================>..........] - ETA: 0s - loss: 8.0468 - acc: 0.5008
10880/15373 [====================>.........] - ETA: 0s - loss: 8.0398 - acc: 0.5012
11264/15373 [====================>.........] - ETA: 0s - loss: 8.0390 - acc: 0.5012
11648/15373 [=====================>........] - ETA: 0s - loss: 8.0092 - acc: 0.5031
12032/15373 [======================>.......] - ETA: 0s - loss: 8.0175 - acc: 0.5026
12352/15373 [=======================>......] - ETA: 0s - loss: 8.0290 - acc: 0.5019
12736/15373 [=======================>......] - ETA: 0s - loss: 8.0312 - acc: 0.5017
13120/15373 [========================>.....] - ETA: 0s - loss: 8.0345 - acc: 0.5015
13504/15373 [=========================>....] - ETA: 0s - loss: 8.0495 - acc: 0.5006
13888/15373 [==========================>...] - ETA: 0s - loss: 8.0416 - acc: 0.5011
14272/15373 [==========================>...] - ETA: 0s - loss: 8.0602 - acc: 0.4999
14656/15373 [===========================>..] - ETA: 0s - loss: 8.0546 - acc: 0.5003
15040/15373 [============================>.] - ETA: 0s - loss: 8.0483 - acc: 0.5007
15373/15373 [==============================] - 2s 157us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03080714725816

data size :  16996

zero :  8499

one :  8497

train_zero :  7687

train_one :  7686

test_zero :  812

test_one :  811

choose_zero :  1623

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[812   0]
 [811   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000325245618557], 'loss': [8.058523515760724]}
Saved model to disk



3

Epoch 1/1

   64/15373 [..............................] - ETA: 2s - loss: 8.8146 - acc: 0.4531
  384/15373 [..............................] - ETA: 2s - loss: 7.7652 - acc: 0.5182
  704/15373 [>.............................] - ETA: 2s - loss: 7.7843 - acc: 0.5170
 1024/15373 [>.............................] - ETA: 2s - loss: 7.8387 - acc: 0.5137
 1344/15373 [=>............................] - ETA: 2s - loss: 7.8792 - acc: 0.5112
 1664/15373 [==>...........................] - ETA: 2s - loss: 7.9719 - acc: 0.5054
 1984/15373 [==>...........................] - ETA: 2s - loss: 8.0184 - acc: 0.5025
 2304/15373 [===>..........................] - ETA: 2s - loss: 7.9751 - acc: 0.5052
 2624/15373 [====>.........................] - ETA: 2s - loss: 8.0038 - acc: 0.5034
 2944/15373 [====>.........................] - ETA: 2s - loss: 8.0536 - acc: 0.5003
 3264/15373 [=====>........................] - ETA: 2s - loss: 8.0541 - acc: 0.5003
 3584/15373 [=====>........................] - ETA: 1s - loss: 8.0141 - acc: 0.5028
 3904/15373 [======>.......................] - ETA: 1s - loss: 7.9765 - acc: 0.5051
 4224/15373 [=======>......................] - ETA: 1s - loss: 8.0056 - acc: 0.5033
 4544/15373 [=======>......................] - ETA: 1s - loss: 8.0484 - acc: 0.5007
 4864/15373 [========>.....................] - ETA: 1s - loss: 8.0425 - acc: 0.5010
 5184/15373 [=========>....................] - ETA: 1s - loss: 8.0186 - acc: 0.5025
 5568/15373 [=========>....................] - ETA: 1s - loss: 8.0735 - acc: 0.4991
 5952/15373 [==========>...................] - ETA: 1s - loss: 8.0861 - acc: 0.4983
 6336/15373 [===========>..................] - ETA: 1s - loss: 8.0947 - acc: 0.4978
 6720/15373 [============>.................] - ETA: 1s - loss: 8.0926 - acc: 0.4979
 7104/15373 [============>.................] - ETA: 1s - loss: 8.0727 - acc: 0.4992
 7488/15373 [=============>................] - ETA: 1s - loss: 8.0849 - acc: 0.4984
 7808/15373 [==============>...............] - ETA: 1s - loss: 8.0735 - acc: 0.4991
 8128/15373 [==============>...............] - ETA: 1s - loss: 8.0848 - acc: 0.4984
 8512/15373 [===============>..............] - ETA: 1s - loss: 8.0799 - acc: 0.4987
 8896/15373 [================>.............] - ETA: 1s - loss: 8.0735 - acc: 0.4991
 9216/15373 [================>.............] - ETA: 0s - loss: 8.0923 - acc: 0.4979
 9600/15373 [=================>............] - ETA: 0s - loss: 8.0809 - acc: 0.4986
 9984/15373 [==================>...........] - ETA: 0s - loss: 8.0703 - acc: 0.4993
10368/15373 [===================>..........] - ETA: 0s - loss: 8.0964 - acc: 0.4977
10752/15373 [===================>..........] - ETA: 0s - loss: 8.0965 - acc: 0.4977
11136/15373 [====================>.........] - ETA: 0s - loss: 8.0967 - acc: 0.4977
11520/15373 [=====================>........] - ETA: 0s - loss: 8.0884 - acc: 0.4982
11904/15373 [======================>.......] - ETA: 0s - loss: 8.0861 - acc: 0.4983
12288/15373 [======================>.......] - ETA: 0s - loss: 8.0892 - acc: 0.4981
12672/15373 [=======================>......] - ETA: 0s - loss: 8.0730 - acc: 0.4991
13056/15373 [========================>.....] - ETA: 0s - loss: 8.0652 - acc: 0.4996
13440/15373 [=========================>....] - ETA: 0s - loss: 8.0543 - acc: 0.5003
13824/15373 [=========================>....] - ETA: 0s - loss: 8.0486 - acc: 0.5007
14208/15373 [==========================>...] - ETA: 0s - loss: 8.0625 - acc: 0.4998
14592/15373 [===========================>..] - ETA: 0s - loss: 8.0624 - acc: 0.4998
14976/15373 [============================>.] - ETA: 0s - loss: 8.0634 - acc: 0.4997
15360/15373 [============================>.] - ETA: 0s - loss: 8.0569 - acc: 0.5001
15373/15373 [==============================] - 2s 157us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03080714725816

data size :  16996

zero :  8499

one :  8497

train_zero :  7687

train_one :  7686

test_zero :  812

test_one :  811

choose_zero :  1623

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[812   0]
 [811   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000325245618557], 'loss': [8.058523529656714]}
Saved model to disk



4

Epoch 1/1

   64/15373 [..............................] - ETA: 3s - loss: 7.0517 - acc: 0.5625
  384/15373 [..............................] - ETA: 2s - loss: 7.8912 - acc: 0.5104
  704/15373 [>.............................] - ETA: 2s - loss: 7.9446 - acc: 0.5071
 1024/15373 [>.............................] - ETA: 2s - loss: 8.0590 - acc: 0.5000
 1344/15373 [=>............................] - ETA: 2s - loss: 8.0830 - acc: 0.4985
 1664/15373 [==>...........................] - ETA: 2s - loss: 8.0009 - acc: 0.5036
 1984/15373 [==>...........................] - ETA: 2s - loss: 8.0834 - acc: 0.4985
 2304/15373 [===>..........................] - ETA: 2s - loss: 8.0451 - acc: 0.5009
 2624/15373 [====>.........................] - ETA: 2s - loss: 8.0099 - acc: 0.5030
 2944/15373 [====>.........................] - ETA: 2s - loss: 7.9277 - acc: 0.5082
 3264/15373 [=====>........................] - ETA: 2s - loss: 7.9800 - acc: 0.5049
 3584/15373 [=====>........................] - ETA: 1s - loss: 7.9691 - acc: 0.5056
 3904/15373 [======>.......................] - ETA: 1s - loss: 7.9682 - acc: 0.5056
 4224/15373 [=======>......................] - ETA: 1s - loss: 7.9560 - acc: 0.5064
 4544/15373 [=======>......................] - ETA: 1s - loss: 7.9491 - acc: 0.5068
 4864/15373 [========>.....................] - ETA: 1s - loss: 7.9398 - acc: 0.5074
 5184/15373 [=========>....................] - ETA: 1s - loss: 7.9160 - acc: 0.5089
 5568/15373 [=========>....................] - ETA: 1s - loss: 7.9896 - acc: 0.5043
 5952/15373 [==========>...................] - ETA: 1s - loss: 7.9886 - acc: 0.5044
 6336/15373 [===========>..................] - ETA: 1s - loss: 7.9904 - acc: 0.5043
 6720/15373 [============>.................] - ETA: 1s - loss: 8.0327 - acc: 0.5016
 7104/15373 [============>.................] - ETA: 1s - loss: 8.0341 - acc: 0.5015
 7488/15373 [=============>................] - ETA: 1s - loss: 8.0418 - acc: 0.5011
 7872/15373 [==============>...............] - ETA: 1s - loss: 7.9997 - acc: 0.5037
 8192/15373 [==============>...............] - ETA: 1s - loss: 8.0138 - acc: 0.5028
 8576/15373 [===============>..............] - ETA: 1s - loss: 8.0083 - acc: 0.5031
 8960/15373 [================>.............] - ETA: 1s - loss: 8.0339 - acc: 0.5016
 9344/15373 [=================>............] - ETA: 0s - loss: 8.0452 - acc: 0.5009
 9728/15373 [=================>............] - ETA: 0s - loss: 8.0690 - acc: 0.4994
10048/15373 [==================>...........] - ETA: 0s - loss: 8.0655 - acc: 0.4996
10432/15373 [===================>..........] - ETA: 0s - loss: 8.0544 - acc: 0.5003
10816/15373 [====================>.........] - ETA: 0s - loss: 8.0605 - acc: 0.4999
11200/15373 [====================>.........] - ETA: 0s - loss: 8.0749 - acc: 0.4990
11584/15373 [=====================>........] - ETA: 0s - loss: 8.0827 - acc: 0.4985
11968/15373 [======================>.......] - ETA: 0s - loss: 8.0739 - acc: 0.4991
12352/15373 [=======================>......] - ETA: 0s - loss: 8.0838 - acc: 0.4985
12736/15373 [=======================>......] - ETA: 0s - loss: 8.0755 - acc: 0.4990
13056/15373 [========================>.....] - ETA: 0s - loss: 8.0763 - acc: 0.4989
13440/15373 [=========================>....] - ETA: 0s - loss: 8.0830 - acc: 0.4985
13824/15373 [=========================>....] - ETA: 0s - loss: 8.0730 - acc: 0.4991
14208/15373 [==========================>...] - ETA: 0s - loss: 8.0693 - acc: 0.4994
14592/15373 [===========================>..] - ETA: 0s - loss: 8.0624 - acc: 0.4998
14976/15373 [============================>.] - ETA: 0s - loss: 8.0677 - acc: 0.4995
15360/15373 [============================>.] - ETA: 0s - loss: 8.0611 - acc: 0.4999
15373/15373 [==============================] - 2s 157us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03080714725816

data size :  16996

zero :  8499

one :  8497

train_zero :  7687

train_one :  7686

test_zero :  812

test_one :  811

choose_zero :  1623

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[812   0]
 [811   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000325245715487], 'loss': [8.058523519699989]}
Saved model to disk



5

Epoch 1/1

   64/15373 [..............................] - ETA: 3s - loss: 8.3109 - acc: 0.4844
  384/15373 [..............................] - ETA: 2s - loss: 7.9751 - acc: 0.5052
  704/15373 [>.............................] - ETA: 2s - loss: 8.4025 - acc: 0.4787
 1024/15373 [>.............................] - ETA: 2s - loss: 8.2479 - acc: 0.4883
 1344/15373 [=>............................] - ETA: 2s - loss: 8.2269 - acc: 0.4896
 1664/15373 [==>...........................] - ETA: 2s - loss: 8.1850 - acc: 0.4922
 1984/15373 [==>...........................] - ETA: 2s - loss: 8.1809 - acc: 0.4924
 2368/15373 [===>..........................] - ETA: 2s - loss: 8.1271 - acc: 0.4958
 2688/15373 [====>.........................] - ETA: 2s - loss: 8.1070 - acc: 0.4970
 3008/15373 [====>.........................] - ETA: 2s - loss: 8.0590 - acc: 0.5000
 3328/15373 [=====>........................] - ETA: 2s - loss: 8.0542 - acc: 0.5003
 3648/15373 [======>.......................] - ETA: 1s - loss: 8.1076 - acc: 0.4970
 3968/15373 [======>.......................] - ETA: 1s - loss: 8.0753 - acc: 0.4990
 4288/15373 [=======>......................] - ETA: 1s - loss: 8.0854 - acc: 0.4984
 4672/15373 [========>.....................] - ETA: 1s - loss: 8.1073 - acc: 0.4970
 4992/15373 [========>.....................] - ETA: 1s - loss: 8.1495 - acc: 0.4944
 5312/15373 [=========>....................] - ETA: 1s - loss: 8.1713 - acc: 0.4930
 5696/15373 [==========>...................] - ETA: 1s - loss: 8.1468 - acc: 0.4946
 6080/15373 [==========>...................] - ETA: 1s - loss: 8.1333 - acc: 0.4954
 6464/15373 [===========>..................] - ETA: 1s - loss: 8.1563 - acc: 0.4940
 6848/15373 [============>.................] - ETA: 1s - loss: 8.1438 - acc: 0.4947
 7232/15373 [=============>................] - ETA: 1s - loss: 8.1504 - acc: 0.4943
 7616/15373 [=============>................] - ETA: 1s - loss: 8.1479 - acc: 0.4945
 7936/15373 [==============>...............] - ETA: 1s - loss: 8.1728 - acc: 0.4929
 8320/15373 [===============>..............] - ETA: 1s - loss: 8.1540 - acc: 0.4941
 8704/15373 [===============>..............] - ETA: 1s - loss: 8.1442 - acc: 0.4947
 9088/15373 [================>.............] - ETA: 1s - loss: 8.1300 - acc: 0.4956
 9472/15373 [=================>............] - ETA: 0s - loss: 8.1288 - acc: 0.4957
 9856/15373 [==================>...........] - ETA: 0s - loss: 8.1097 - acc: 0.4969
10176/15373 [==================>...........] - ETA: 0s - loss: 8.1240 - acc: 0.4960
10560/15373 [===================>..........] - ETA: 0s - loss: 8.1048 - acc: 0.4972
10880/15373 [====================>.........] - ETA: 0s - loss: 8.0665 - acc: 0.4995
11264/15373 [====================>.........] - ETA: 0s - loss: 8.0490 - acc: 0.5006
11648/15373 [=====================>........] - ETA: 0s - loss: 8.0341 - acc: 0.5015
12032/15373 [======================>.......] - ETA: 0s - loss: 8.0242 - acc: 0.5022
12416/15373 [=======================>......] - ETA: 0s - loss: 8.0253 - acc: 0.5021
12800/15373 [=======================>......] - ETA: 0s - loss: 8.0250 - acc: 0.5021
13184/15373 [========================>.....] - ETA: 0s - loss: 8.0297 - acc: 0.5018
13568/15373 [=========================>....] - ETA: 0s - loss: 8.0282 - acc: 0.5019
13952/15373 [==========================>...] - ETA: 0s - loss: 8.0371 - acc: 0.5014
14336/15373 [==========================>...] - ETA: 0s - loss: 8.0321 - acc: 0.5017
14720/15373 [===========================>..] - ETA: 0s - loss: 8.0371 - acc: 0.5014
15104/15373 [============================>.] - ETA: 0s - loss: 8.0430 - acc: 0.5010
15373/15373 [==============================] - 2s 157us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03080714725816

data size :  16996

zero :  8499

one :  8497

train_zero :  7687

train_one :  7686

test_zero :  812

test_one :  811

choose_zero :  1623

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[812   0]
 [811   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000325245715487], 'loss': [8.058523513744564]}
Saved model to disk



6

Epoch 1/1

   64/15373 [..............................] - ETA: 3s - loss: 7.5554 - acc: 0.5312
  384/15373 [..............................] - ETA: 2s - loss: 8.3529 - acc: 0.4818
  704/15373 [>.............................] - ETA: 2s - loss: 8.2193 - acc: 0.4901
 1024/15373 [>.............................] - ETA: 2s - loss: 8.0590 - acc: 0.5000
 1344/15373 [=>............................] - ETA: 2s - loss: 8.2269 - acc: 0.4896
 1664/15373 [==>...........................] - ETA: 2s - loss: 8.2334 - acc: 0.4892
 1984/15373 [==>...........................] - ETA: 2s - loss: 8.0266 - acc: 0.5020
 2304/15373 [===>..........................] - ETA: 2s - loss: 7.9821 - acc: 0.5048
 2624/15373 [====>.........................] - ETA: 2s - loss: 8.0713 - acc: 0.4992
 2944/15373 [====>.........................] - ETA: 2s - loss: 8.0317 - acc: 0.5017
 3264/15373 [=====>........................] - ETA: 2s - loss: 8.0739 - acc: 0.4991
 3584/15373 [=====>........................] - ETA: 2s - loss: 8.0366 - acc: 0.5014
 3904/15373 [======>.......................] - ETA: 1s - loss: 8.0425 - acc: 0.5010
 4224/15373 [=======>......................] - ETA: 1s - loss: 8.0362 - acc: 0.5014
 4544/15373 [=======>......................] - ETA: 1s - loss: 8.0271 - acc: 0.5020
 4864/15373 [========>.....................] - ETA: 1s - loss: 8.0657 - acc: 0.4996
 5184/15373 [=========>....................] - ETA: 1s - loss: 8.0715 - acc: 0.4992
 5504/15373 [=========>....................] - ETA: 1s - loss: 8.0854 - acc: 0.4984
 5824/15373 [==========>...................] - ETA: 1s - loss: 8.0978 - acc: 0.4976
 6144/15373 [==========>...................] - ETA: 1s - loss: 8.1194 - acc: 0.4963
 6528/15373 [===========>..................] - ETA: 1s - loss: 8.1677 - acc: 0.4933
 6912/15373 [============>.................] - ETA: 1s - loss: 8.1383 - acc: 0.4951
 7296/15373 [=============>................] - ETA: 1s - loss: 8.1474 - acc: 0.4945
 7680/15373 [=============>................] - ETA: 1s - loss: 8.1514 - acc: 0.4943
 8064/15373 [==============>...............] - ETA: 1s - loss: 8.1310 - acc: 0.4955
 8448/15373 [===============>..............] - ETA: 1s - loss: 8.1144 - acc: 0.4966
 8832/15373 [================>.............] - ETA: 1s - loss: 8.1320 - acc: 0.4955
 9216/15373 [================>.............] - ETA: 0s - loss: 8.1238 - acc: 0.4960
 9600/15373 [=================>............] - ETA: 0s - loss: 8.1296 - acc: 0.4956
 9984/15373 [==================>...........] - ETA: 0s - loss: 8.1269 - acc: 0.4958
10304/15373 [===================>..........] - ETA: 0s - loss: 8.1357 - acc: 0.4952
10688/15373 [===================>..........] - ETA: 0s - loss: 8.1299 - acc: 0.4956
11008/15373 [====================>.........] - ETA: 0s - loss: 8.0927 - acc: 0.4979
11392/15373 [=====================>........] - ETA: 0s - loss: 8.0732 - acc: 0.4991
11776/15373 [=====================>........] - ETA: 0s - loss: 8.0727 - acc: 0.4992
12160/15373 [======================>.......] - ETA: 0s - loss: 8.0856 - acc: 0.4984
12544/15373 [=======================>......] - ETA: 0s - loss: 8.0745 - acc: 0.4990
12928/15373 [========================>.....] - ETA: 0s - loss: 8.0840 - acc: 0.4985
13312/15373 [========================>.....] - ETA: 0s - loss: 8.0687 - acc: 0.4994
13696/15373 [=========================>....] - ETA: 0s - loss: 8.0696 - acc: 0.4993
14080/15373 [==========================>...] - ETA: 0s - loss: 8.0831 - acc: 0.4985
14464/15373 [===========================>..] - ETA: 0s - loss: 8.0813 - acc: 0.4986
14848/15373 [===========================>..] - ETA: 0s - loss: 8.0742 - acc: 0.4991
15232/15373 [============================>.] - ETA: 0s - loss: 8.0675 - acc: 0.4995
15373/15373 [==============================] - 2s 159us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03080714725816

data size :  16996

zero :  8499

one :  8497

train_zero :  7687

train_one :  7686

test_zero :  812

test_one :  811

choose_zero :  1623

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[812   0]
 [811   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000325245579784], 'loss': [8.058523523887397]}
Saved model to disk



7

Epoch 1/1

   64/15373 [..............................] - ETA: 3s - loss: 7.3035 - acc: 0.5469
  384/15373 [..............................] - ETA: 2s - loss: 8.1430 - acc: 0.4948
  704/15373 [>.............................] - ETA: 2s - loss: 8.1048 - acc: 0.4972
 1024/15373 [>.............................] - ETA: 2s - loss: 8.0748 - acc: 0.4990
 1344/15373 [=>............................] - ETA: 2s - loss: 8.1070 - acc: 0.4970
 1664/15373 [==>...........................] - ETA: 2s - loss: 8.1947 - acc: 0.4916
 1984/15373 [==>...........................] - ETA: 2s - loss: 8.1240 - acc: 0.4960
 2304/15373 [===>..........................] - ETA: 2s - loss: 8.1850 - acc: 0.4922
 2624/15373 [====>.........................] - ETA: 2s - loss: 8.2372 - acc: 0.4889
 2944/15373 [====>.........................] - ETA: 2s - loss: 8.2507 - acc: 0.4881
 3264/15373 [=====>........................] - ETA: 2s - loss: 8.2615 - acc: 0.4874
 3584/15373 [=====>........................] - ETA: 2s - loss: 8.3109 - acc: 0.4844
 3904/15373 [======>.......................] - ETA: 1s - loss: 8.2490 - acc: 0.4882
 4224/15373 [=======>......................] - ETA: 1s - loss: 8.2498 - acc: 0.4882
 4544/15373 [=======>......................] - ETA: 1s - loss: 8.2009 - acc: 0.4912
 4864/15373 [========>.....................] - ETA: 1s - loss: 8.2049 - acc: 0.4910
 5248/15373 [=========>....................] - ETA: 1s - loss: 8.1696 - acc: 0.4931
 5568/15373 [=========>....................] - ETA: 1s - loss: 8.1662 - acc: 0.4934
 5888/15373 [==========>...................] - ETA: 1s - loss: 8.1603 - acc: 0.4937
 6208/15373 [===========>..................] - ETA: 1s - loss: 8.1551 - acc: 0.4940
 6528/15373 [===========>..................] - ETA: 1s - loss: 8.1726 - acc: 0.4930
 6848/15373 [============>.................] - ETA: 1s - loss: 8.1108 - acc: 0.4968
 7168/15373 [============>.................] - ETA: 1s - loss: 8.1108 - acc: 0.4968
 7552/15373 [=============>................] - ETA: 1s - loss: 8.0868 - acc: 0.4983
 7872/15373 [==============>...............] - ETA: 1s - loss: 8.1041 - acc: 0.4972
 8192/15373 [==============>...............] - ETA: 1s - loss: 8.1043 - acc: 0.4972
 8512/15373 [===============>..............] - ETA: 1s - loss: 8.1348 - acc: 0.4953
 8896/15373 [================>.............] - ETA: 1s - loss: 8.1243 - acc: 0.4960
 9280/15373 [=================>............] - ETA: 1s - loss: 8.1042 - acc: 0.4972
 9664/15373 [=================>............] - ETA: 0s - loss: 8.1258 - acc: 0.4959
10048/15373 [==================>...........] - ETA: 0s - loss: 8.1216 - acc: 0.4961
10368/15373 [===================>..........] - ETA: 0s - loss: 8.1150 - acc: 0.4965
10688/15373 [===================>..........] - ETA: 0s - loss: 8.0877 - acc: 0.4982
11008/15373 [====================>.........] - ETA: 0s - loss: 8.0752 - acc: 0.4990
11328/15373 [=====================>........] - ETA: 0s - loss: 8.1046 - acc: 0.4972
11712/15373 [=====================>........] - ETA: 0s - loss: 8.1003 - acc: 0.4974
12096/15373 [======================>.......] - ETA: 0s - loss: 8.0844 - acc: 0.4984
12480/15373 [=======================>......] - ETA: 0s - loss: 8.0629 - acc: 0.4998
12864/15373 [========================>.....] - ETA: 0s - loss: 8.0891 - acc: 0.4981
13248/15373 [========================>.....] - ETA: 0s - loss: 8.0980 - acc: 0.4976
13568/15373 [=========================>....] - ETA: 0s - loss: 8.0864 - acc: 0.4983
13952/15373 [==========================>...] - ETA: 0s - loss: 8.0833 - acc: 0.4985
14336/15373 [==========================>...] - ETA: 0s - loss: 8.0793 - acc: 0.4987
14720/15373 [===========================>..] - ETA: 0s - loss: 8.0974 - acc: 0.4976
15040/15373 [============================>.] - ETA: 0s - loss: 8.0751 - acc: 0.4990
15373/15373 [==============================] - 2s 161us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03080714725816

data size :  16996

zero :  8499

one :  8497

train_zero :  7687

train_one :  7686

test_zero :  812

test_one :  811

choose_zero :  1623

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[812   0]
 [811   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000325245579784], 'loss': [8.05852351197655]}
Saved model to disk



8

Epoch 1/1

   64/15373 [..............................] - ETA: 3s - loss: 7.0517 - acc: 0.5625
  384/15373 [..............................] - ETA: 2s - loss: 8.4788 - acc: 0.4740
  704/15373 [>.............................] - ETA: 2s - loss: 8.2651 - acc: 0.4872
 1024/15373 [>.............................] - ETA: 2s - loss: 7.9331 - acc: 0.5078
 1344/15373 [=>............................] - ETA: 2s - loss: 7.8072 - acc: 0.5156
 1664/15373 [==>...........................] - ETA: 2s - loss: 7.7781 - acc: 0.5174
 1984/15373 [==>...........................] - ETA: 2s - loss: 7.8884 - acc: 0.5106
 2304/15373 [===>..........................] - ETA: 2s - loss: 7.9191 - acc: 0.5087
 2624/15373 [====>.........................] - ETA: 2s - loss: 7.8748 - acc: 0.5114
 2944/15373 [====>.........................] - ETA: 2s - loss: 7.8893 - acc: 0.5105
 3264/15373 [=====>........................] - ETA: 2s - loss: 7.8961 - acc: 0.5101
 3584/15373 [=====>........................] - ETA: 2s - loss: 7.8882 - acc: 0.5106
 3904/15373 [======>.......................] - ETA: 1s - loss: 7.8691 - acc: 0.5118
 4224/15373 [=======>......................] - ETA: 1s - loss: 7.8225 - acc: 0.5147
 4544/15373 [=======>......................] - ETA: 1s - loss: 7.9136 - acc: 0.5090
 4864/15373 [========>.....................] - ETA: 1s - loss: 7.9464 - acc: 0.5070
 5184/15373 [=========>....................] - ETA: 1s - loss: 7.9720 - acc: 0.5054
 5568/15373 [=========>....................] - ETA: 1s - loss: 7.9954 - acc: 0.5040
 5888/15373 [==========>...................] - ETA: 1s - loss: 7.9742 - acc: 0.5053
 6208/15373 [===========>..................] - ETA: 1s - loss: 7.9604 - acc: 0.5061
 6528/15373 [===========>..................] - ETA: 1s - loss: 7.9874 - acc: 0.5044
 6912/15373 [============>.................] - ETA: 1s - loss: 8.0077 - acc: 0.5032
 7296/15373 [=============>................] - ETA: 1s - loss: 8.0347 - acc: 0.5015
 7680/15373 [=============>................] - ETA: 1s - loss: 8.0171 - acc: 0.5026
 8064/15373 [==============>...............] - ETA: 1s - loss: 8.0491 - acc: 0.5006
 8448/15373 [===============>..............] - ETA: 1s - loss: 8.0533 - acc: 0.5004
 8832/15373 [================>.............] - ETA: 1s - loss: 8.0317 - acc: 0.5017
 9216/15373 [================>.............] - ETA: 0s - loss: 8.0258 - acc: 0.5021
 9600/15373 [=================>............] - ETA: 0s - loss: 8.0221 - acc: 0.5023
 9984/15373 [==================>...........] - ETA: 0s - loss: 8.0542 - acc: 0.5003
10368/15373 [===================>..........] - ETA: 0s - loss: 8.0466 - acc: 0.5008
10688/15373 [===================>..........] - ETA: 0s - loss: 8.0575 - acc: 0.5001
11008/15373 [====================>.........] - ETA: 0s - loss: 8.0693 - acc: 0.4994
11392/15373 [=====================>........] - ETA: 0s - loss: 8.0789 - acc: 0.4988
11776/15373 [=====================>........] - ETA: 0s - loss: 8.1015 - acc: 0.4974
12160/15373 [======================>.......] - ETA: 0s - loss: 8.0935 - acc: 0.4979
12544/15373 [=======================>......] - ETA: 0s - loss: 8.1027 - acc: 0.4973
12864/15373 [========================>.....] - ETA: 0s - loss: 8.1179 - acc: 0.4963
13184/15373 [========================>.....] - ETA: 0s - loss: 8.1177 - acc: 0.4964
13568/15373 [=========================>....] - ETA: 0s - loss: 8.1030 - acc: 0.4973
13952/15373 [==========================>...] - ETA: 0s - loss: 8.0960 - acc: 0.4977
14336/15373 [==========================>...] - ETA: 0s - loss: 8.0995 - acc: 0.4975
14720/15373 [===========================>..] - ETA: 0s - loss: 8.1028 - acc: 0.4973
15104/15373 [============================>.] - ETA: 0s - loss: 8.0740 - acc: 0.4991
15373/15373 [==============================] - 2s 159us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03080714725816

data size :  16996

zero :  8499

one :  8497

train_zero :  7687

train_one :  7686

test_zero :  812

test_one :  811

choose_zero :  1623

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[812   0]
 [811   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000325245618557], 'loss': [8.058523521716149]}
Saved model to disk



9

Epoch 1/1

   64/15373 [..............................] - ETA: 3s - loss: 9.3183 - acc: 0.4219
  384/15373 [..............................] - ETA: 2s - loss: 8.1850 - acc: 0.4922
  704/15373 [>.............................] - ETA: 2s - loss: 7.8072 - acc: 0.5156
 1024/15373 [>.............................] - ETA: 2s - loss: 8.0433 - acc: 0.5010
 1344/15373 [=>............................] - ETA: 2s - loss: 8.2389 - acc: 0.4888
 1664/15373 [==>...........................] - ETA: 2s - loss: 8.0978 - acc: 0.4976
 1984/15373 [==>...........................] - ETA: 2s - loss: 8.1403 - acc: 0.4950
 2304/15373 [===>..........................] - ETA: 2s - loss: 8.1360 - acc: 0.4952
 2624/15373 [====>.........................] - ETA: 2s - loss: 8.1696 - acc: 0.4931
 2944/15373 [====>.........................] - ETA: 2s - loss: 8.1740 - acc: 0.4929
 3264/15373 [=====>........................] - ETA: 2s - loss: 8.1183 - acc: 0.4963
 3584/15373 [=====>........................] - ETA: 1s - loss: 8.1760 - acc: 0.4927
 3904/15373 [======>.......................] - ETA: 1s - loss: 8.1788 - acc: 0.4926
 4224/15373 [=======>......................] - ETA: 1s - loss: 8.2155 - acc: 0.4903
 4544/15373 [=======>......................] - ETA: 1s - loss: 8.1867 - acc: 0.4921
 4864/15373 [========>.....................] - ETA: 1s - loss: 8.1551 - acc: 0.4940
 5184/15373 [=========>....................] - ETA: 1s - loss: 8.0901 - acc: 0.4981
 5504/15373 [=========>....................] - ETA: 1s - loss: 8.0298 - acc: 0.5018
 5824/15373 [==========>...................] - ETA: 1s - loss: 8.0507 - acc: 0.5005
 6208/15373 [===========>..................] - ETA: 1s - loss: 8.0590 - acc: 0.5000
 6592/15373 [===========>..................] - ETA: 1s - loss: 8.0517 - acc: 0.5005
 6976/15373 [============>.................] - ETA: 1s - loss: 8.0706 - acc: 0.4993
 7360/15373 [=============>................] - ETA: 1s - loss: 8.1050 - acc: 0.4971
 7744/15373 [==============>...............] - ETA: 1s - loss: 8.1194 - acc: 0.4963
 8128/15373 [==============>...............] - ETA: 1s - loss: 8.1622 - acc: 0.4936
 8512/15373 [===============>..............] - ETA: 1s - loss: 8.1613 - acc: 0.4937
 8832/15373 [================>.............] - ETA: 1s - loss: 8.1339 - acc: 0.4954
 9152/15373 [================>.............] - ETA: 1s - loss: 8.1348 - acc: 0.4953
 9536/15373 [=================>............] - ETA: 0s - loss: 8.1300 - acc: 0.4956
 9856/15373 [==================>...........] - ETA: 0s - loss: 8.1228 - acc: 0.4960
10240/15373 [==================>...........] - ETA: 0s - loss: 8.1126 - acc: 0.4967
10624/15373 [===================>..........] - ETA: 0s - loss: 8.0742 - acc: 0.4991
11008/15373 [====================>.........] - ETA: 0s - loss: 8.0752 - acc: 0.4990
11328/15373 [=====================>........] - ETA: 0s - loss: 8.0960 - acc: 0.4977
11712/15373 [=====================>........] - ETA: 0s - loss: 8.0577 - acc: 0.5001
12096/15373 [======================>.......] - ETA: 0s - loss: 8.0511 - acc: 0.5005
12480/15373 [=======================>......] - ETA: 0s - loss: 8.0500 - acc: 0.5006
12864/15373 [========================>.....] - ETA: 0s - loss: 8.0503 - acc: 0.5005
13248/15373 [========================>.....] - ETA: 0s - loss: 8.0615 - acc: 0.4998
13632/15373 [=========================>....] - ETA: 0s - loss: 8.0472 - acc: 0.5007
14016/15373 [==========================>...] - ETA: 0s - loss: 8.0533 - acc: 0.5004
14400/15373 [===========================>..] - ETA: 0s - loss: 8.0590 - acc: 0.5000
14784/15373 [===========================>..] - ETA: 0s - loss: 8.0580 - acc: 0.5001
15168/15373 [============================>.] - ETA: 0s - loss: 8.0580 - acc: 0.5001
15373/15373 [==============================] - 2s 158us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03080714725816

data size :  16996

zero :  8499

one :  8497

train_zero :  7687

train_one :  7686

test_zero :  812

test_one :  811

choose_zero :  1623

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[812   0]
 [811   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000325245715487], 'loss': [8.05852354947711]}
Saved model to disk



10

Epoch 1/1

   64/15373 [..............................] - ETA: 3s - loss: 8.5627 - acc: 0.4688
  384/15373 [..............................] - ETA: 2s - loss: 8.5208 - acc: 0.4714
  704/15373 [>.............................] - ETA: 2s - loss: 8.1048 - acc: 0.4972
 1024/15373 [>.............................] - ETA: 2s - loss: 8.1063 - acc: 0.4971
 1344/15373 [=>............................] - ETA: 2s - loss: 8.1910 - acc: 0.4918
 1728/15373 [==>...........................] - ETA: 2s - loss: 8.1243 - acc: 0.4959
 2048/15373 [==>...........................] - ETA: 2s - loss: 8.0827 - acc: 0.4985
 2368/15373 [===>..........................] - ETA: 2s - loss: 8.0318 - acc: 0.5017
 2688/15373 [====>.........................] - ETA: 2s - loss: 7.9751 - acc: 0.5052
 3008/15373 [====>.........................] - ETA: 2s - loss: 7.9251 - acc: 0.5083
 3328/15373 [=====>........................] - ETA: 2s - loss: 7.8605 - acc: 0.5123
 3648/15373 [======>.......................] - ETA: 1s - loss: 7.8249 - acc: 0.5145
 3968/15373 [======>.......................] - ETA: 1s - loss: 7.8559 - acc: 0.5126
 4288/15373 [=======>......................] - ETA: 1s - loss: 7.9125 - acc: 0.5091
 4608/15373 [=======>......................] - ETA: 1s - loss: 7.9541 - acc: 0.5065
 4928/15373 [========>.....................] - ETA: 1s - loss: 7.9511 - acc: 0.5067
 5248/15373 [=========>....................] - ETA: 1s - loss: 7.9731 - acc: 0.5053
 5568/15373 [=========>....................] - ETA: 1s - loss: 7.9722 - acc: 0.5054
 5888/15373 [==========>...................] - ETA: 1s - loss: 7.9742 - acc: 0.5053
 6272/15373 [===========>..................] - ETA: 1s - loss: 7.9999 - acc: 0.5037
 6656/15373 [===========>..................] - ETA: 1s - loss: 8.0009 - acc: 0.5036
 7040/15373 [============>.................] - ETA: 1s - loss: 8.0087 - acc: 0.5031
 7424/15373 [=============>................] - ETA: 1s - loss: 8.0091 - acc: 0.5031
 7808/15373 [==============>...............] - ETA: 1s - loss: 8.0446 - acc: 0.5009
 8192/15373 [==============>...............] - ETA: 1s - loss: 8.0748 - acc: 0.4990
 8576/15373 [===============>..............] - ETA: 1s - loss: 8.0403 - acc: 0.5012
 8960/15373 [================>.............] - ETA: 1s - loss: 8.0357 - acc: 0.5015
 9344/15373 [=================>............] - ETA: 0s - loss: 8.0452 - acc: 0.5009
 9728/15373 [=================>............] - ETA: 0s - loss: 8.0624 - acc: 0.4998
10112/15373 [==================>...........] - ETA: 0s - loss: 8.0686 - acc: 0.4994
10496/15373 [===================>..........] - ETA: 0s - loss: 8.0652 - acc: 0.4996
10880/15373 [====================>.........] - ETA: 0s - loss: 8.0753 - acc: 0.4990
11264/15373 [====================>.........] - ETA: 0s - loss: 8.0719 - acc: 0.4992
11648/15373 [=====================>........] - ETA: 0s - loss: 8.0715 - acc: 0.4992
11968/15373 [======================>.......] - ETA: 0s - loss: 8.0671 - acc: 0.4995
12288/15373 [======================>.......] - ETA: 0s - loss: 8.0735 - acc: 0.4991
12672/15373 [=======================>......] - ETA: 0s - loss: 8.0730 - acc: 0.4991
13056/15373 [========================>.....] - ETA: 0s - loss: 8.0665 - acc: 0.4995
13440/15373 [=========================>....] - ETA: 0s - loss: 8.0806 - acc: 0.4987
13824/15373 [=========================>....] - ETA: 0s - loss: 8.0730 - acc: 0.4991
14208/15373 [==========================>...] - ETA: 0s - loss: 8.0761 - acc: 0.4989
14528/15373 [===========================>..] - ETA: 0s - loss: 8.0779 - acc: 0.4988
14912/15373 [============================>.] - ETA: 0s - loss: 8.0645 - acc: 0.4997
15296/15373 [============================>.] - ETA: 0s - loss: 8.0569 - acc: 0.5001
15373/15373 [==============================] - 2s 157us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03080714725816

data size :  16996

zero :  8499

one :  8497

train_zero :  7687

train_one :  7686

test_zero :  812

test_one :  811

choose_zero :  1623

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[812   0]
 [811   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000325245579784], 'loss': [8.058523537783387]}
Saved model to disk



11

Epoch 1/1

   64/15373 [..............................] - ETA: 3s - loss: 8.3109 - acc: 0.4844
  384/15373 [..............................] - ETA: 2s - loss: 8.3109 - acc: 0.4844
  704/15373 [>.............................] - ETA: 2s - loss: 8.1506 - acc: 0.4943
 1024/15373 [>.............................] - ETA: 2s - loss: 8.4368 - acc: 0.4766
 1344/15373 [=>............................] - ETA: 2s - loss: 8.2749 - acc: 0.4866
 1664/15373 [==>...........................] - ETA: 2s - loss: 8.1656 - acc: 0.4934
 1984/15373 [==>...........................] - ETA: 2s - loss: 8.1890 - acc: 0.4919
 2304/15373 [===>..........................] - ETA: 2s - loss: 8.1500 - acc: 0.4944
 2624/15373 [====>.........................] - ETA: 2s - loss: 8.1450 - acc: 0.4947
 2944/15373 [====>.........................] - ETA: 2s - loss: 8.1904 - acc: 0.4918
 3264/15373 [=====>........................] - ETA: 2s - loss: 8.1924 - acc: 0.4917
 3584/15373 [=====>........................] - ETA: 1s - loss: 8.2075 - acc: 0.4908
 3904/15373 [======>.......................] - ETA: 1s - loss: 8.2737 - acc: 0.4867
 4224/15373 [=======>......................] - ETA: 1s - loss: 8.2269 - acc: 0.4896
 4544/15373 [=======>......................] - ETA: 1s - loss: 8.2400 - acc: 0.4888
 4928/15373 [========>.....................] - ETA: 1s - loss: 8.2291 - acc: 0.4894
 5312/15373 [=========>....................] - ETA: 1s - loss: 8.1986 - acc: 0.4913
 5696/15373 [==========>...................] - ETA: 1s - loss: 8.1496 - acc: 0.4944
 6080/15373 [==========>...................] - ETA: 1s - loss: 8.1386 - acc: 0.4951
 6464/15373 [===========>..................] - ETA: 1s - loss: 8.1488 - acc: 0.4944
 6848/15373 [============>.................] - ETA: 1s - loss: 8.1344 - acc: 0.4953
 7232/15373 [=============>................] - ETA: 1s - loss: 8.1281 - acc: 0.4957
 7616/15373 [=============>................] - ETA: 1s - loss: 8.1331 - acc: 0.4954
 8000/15373 [==============>...............] - ETA: 1s - loss: 8.1296 - acc: 0.4956
 8384/15373 [===============>..............] - ETA: 1s - loss: 8.1417 - acc: 0.4949
 8768/15373 [================>.............] - ETA: 1s - loss: 8.1418 - acc: 0.4949
 9152/15373 [================>.............] - ETA: 0s - loss: 8.1401 - acc: 0.4950
 9472/15373 [=================>............] - ETA: 0s - loss: 8.1475 - acc: 0.4945
 9856/15373 [==================>...........] - ETA: 0s - loss: 8.1163 - acc: 0.4964
10240/15373 [==================>...........] - ETA: 0s - loss: 8.1157 - acc: 0.4965
10624/15373 [===================>..........] - ETA: 0s - loss: 8.0894 - acc: 0.4981
11008/15373 [====================>.........] - ETA: 0s - loss: 8.0869 - acc: 0.4983
11392/15373 [=====================>........] - ETA: 0s - loss: 8.0675 - acc: 0.4995
11776/15373 [=====================>........] - ETA: 0s - loss: 8.0549 - acc: 0.5003
12160/15373 [======================>.......] - ETA: 0s - loss: 8.0537 - acc: 0.5003
12544/15373 [=======================>......] - ETA: 0s - loss: 8.0539 - acc: 0.5003
12928/15373 [========================>.....] - ETA: 0s - loss: 8.0354 - acc: 0.5015
13312/15373 [========================>.....] - ETA: 0s - loss: 8.0336 - acc: 0.5016
13696/15373 [=========================>....] - ETA: 0s - loss: 8.0296 - acc: 0.5018
14080/15373 [==========================>...] - ETA: 0s - loss: 8.0430 - acc: 0.5010
14464/15373 [===========================>..] - ETA: 0s - loss: 8.0579 - acc: 0.5001
14848/15373 [===========================>..] - ETA: 0s - loss: 8.0634 - acc: 0.4997
15232/15373 [============================>.] - ETA: 0s - loss: 8.0707 - acc: 0.4993
15373/15373 [==============================] - 2s 156us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03080714725816

data size :  16996

zero :  8499

one :  8497

train_zero :  7687

train_one :  7686

test_zero :  812

test_one :  811

choose_zero :  1623

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[812   0]
 [811   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000325245754259], 'loss': [8.058523525066073]}
Saved model to disk



12

Epoch 1/1

   64/15373 [..............................] - ETA: 3s - loss: 7.5554 - acc: 0.5312
  320/15373 [..............................] - ETA: 3s - loss: 8.2102 - acc: 0.4906
  640/15373 [>.............................] - ETA: 2s - loss: 8.1346 - acc: 0.4953
  960/15373 [>.............................] - ETA: 2s - loss: 8.1430 - acc: 0.4948
 1280/15373 [=>............................] - ETA: 2s - loss: 8.1094 - acc: 0.4969
 1600/15373 [==>...........................] - ETA: 2s - loss: 8.2202 - acc: 0.4900
 1920/15373 [==>...........................] - ETA: 2s - loss: 8.2521 - acc: 0.4880
 2240/15373 [===>..........................] - ETA: 2s - loss: 8.2821 - acc: 0.4862
 2560/15373 [===>..........................] - ETA: 2s - loss: 8.2794 - acc: 0.4863
 2880/15373 [====>.........................] - ETA: 2s - loss: 8.3333 - acc: 0.4830
 3200/15373 [=====>........................] - ETA: 2s - loss: 8.3361 - acc: 0.4828
 3520/15373 [=====>........................] - ETA: 1s - loss: 8.3017 - acc: 0.4849
 3840/15373 [======>.......................] - ETA: 1s - loss: 8.3151 - acc: 0.4841
 4160/15373 [=======>......................] - ETA: 1s - loss: 8.2489 - acc: 0.4882
 4480/15373 [=======>......................] - ETA: 1s - loss: 8.2138 - acc: 0.4904
 4800/15373 [========>.....................] - ETA: 1s - loss: 8.2068 - acc: 0.4908
 5120/15373 [========>.....................] - ETA: 1s - loss: 8.1535 - acc: 0.4941
 5504/15373 [=========>....................] - ETA: 1s - loss: 8.1528 - acc: 0.4942
 5888/15373 [==========>...................] - ETA: 1s - loss: 8.1138 - acc: 0.4966
 6272/15373 [===========>..................] - ETA: 1s - loss: 8.0796 - acc: 0.4987
 6656/15373 [===========>..................] - ETA: 1s - loss: 8.0808 - acc: 0.4986
 7040/15373 [============>.................] - ETA: 1s - loss: 8.0819 - acc: 0.4986
 7424/15373 [=============>................] - ETA: 1s - loss: 8.0721 - acc: 0.4992
 7808/15373 [==============>...............] - ETA: 1s - loss: 8.0859 - acc: 0.4983
 8192/15373 [==============>...............] - ETA: 1s - loss: 8.0709 - acc: 0.4993
 8576/15373 [===============>..............] - ETA: 1s - loss: 8.0609 - acc: 0.4999
 8960/15373 [================>.............] - ETA: 1s - loss: 8.0537 - acc: 0.5003
 9344/15373 [=================>............] - ETA: 0s - loss: 8.0383 - acc: 0.5013
 9728/15373 [=================>............] - ETA: 0s - loss: 8.0077 - acc: 0.5032
10112/15373 [==================>...........] - ETA: 0s - loss: 8.0224 - acc: 0.5023
10432/15373 [===================>..........] - ETA: 0s - loss: 8.0220 - acc: 0.5023
10816/15373 [====================>.........] - ETA: 0s - loss: 8.0248 - acc: 0.5021
11200/15373 [====================>.........] - ETA: 0s - loss: 8.0231 - acc: 0.5022
11584/15373 [=====================>........] - ETA: 0s - loss: 8.0257 - acc: 0.5021
11968/15373 [======================>.......] - ETA: 0s - loss: 8.0267 - acc: 0.5020
12352/15373 [=======================>......] - ETA: 0s - loss: 8.0303 - acc: 0.5018
12736/15373 [=======================>......] - ETA: 0s - loss: 8.0375 - acc: 0.5013
13120/15373 [========================>.....] - ETA: 0s - loss: 8.0369 - acc: 0.5014
13504/15373 [=========================>....] - ETA: 0s - loss: 8.0435 - acc: 0.5010
13888/15373 [==========================>...] - ETA: 0s - loss: 8.0312 - acc: 0.5017
14208/15373 [==========================>...] - ETA: 0s - loss: 8.0386 - acc: 0.5013
14592/15373 [===========================>..] - ETA: 0s - loss: 8.0502 - acc: 0.5005
14976/15373 [============================>.] - ETA: 0s - loss: 8.0504 - acc: 0.5005
15360/15373 [============================>.] - ETA: 0s - loss: 8.0580 - acc: 0.5001
15373/15373 [==============================] - 2s 157us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03080714725816

data size :  16996

zero :  8499

one :  8497

train_zero :  7687

train_one :  7686

test_zero :  812

test_one :  811

choose_zero :  1623

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[812   0]
 [811   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000325245579784], 'loss': [8.058523569545647]}
Saved model to disk



13

Epoch 1/1

   64/15373 [..............................] - ETA: 3s - loss: 7.8072 - acc: 0.5156
  320/15373 [..............................] - ETA: 2s - loss: 8.0590 - acc: 0.5000
  640/15373 [>.............................] - ETA: 2s - loss: 8.2102 - acc: 0.4906
  960/15373 [>.............................] - ETA: 2s - loss: 7.8912 - acc: 0.5104
 1280/15373 [=>............................] - ETA: 2s - loss: 8.0213 - acc: 0.5023
 1600/15373 [==>...........................] - ETA: 2s - loss: 7.9684 - acc: 0.5056
 1920/15373 [==>...........................] - ETA: 2s - loss: 7.8828 - acc: 0.5109
 2240/15373 [===>..........................] - ETA: 2s - loss: 7.9007 - acc: 0.5098
 2560/15373 [===>..........................] - ETA: 2s - loss: 7.9016 - acc: 0.5098
 2880/15373 [====>.........................] - ETA: 2s - loss: 7.9695 - acc: 0.5056
 3200/15373 [=====>........................] - ETA: 2s - loss: 7.9785 - acc: 0.5050
 3520/15373 [=====>........................] - ETA: 2s - loss: 8.0133 - acc: 0.5028
 3840/15373 [======>.......................] - ETA: 1s - loss: 7.9919 - acc: 0.5042
 4160/15373 [=======>......................] - ETA: 1s - loss: 8.0087 - acc: 0.5031
 4480/15373 [=======>......................] - ETA: 1s - loss: 7.9907 - acc: 0.5042
 4800/15373 [========>.....................] - ETA: 1s - loss: 7.9684 - acc: 0.5056
 5120/15373 [========>.....................] - ETA: 1s - loss: 7.9992 - acc: 0.5037
 5440/15373 [=========>....................] - ETA: 1s - loss: 8.0353 - acc: 0.5015
 5760/15373 [==========>...................] - ETA: 1s - loss: 8.0618 - acc: 0.4998
 6080/15373 [==========>...................] - ETA: 1s - loss: 8.0458 - acc: 0.5008
 6464/15373 [===========>..................] - ETA: 1s - loss: 8.0516 - acc: 0.5005
 6848/15373 [============>.................] - ETA: 1s - loss: 8.0732 - acc: 0.4991
 7232/15373 [=============>................] - ETA: 1s - loss: 8.0524 - acc: 0.5004
 7552/15373 [=============>................] - ETA: 1s - loss: 8.0719 - acc: 0.4992
 7936/15373 [==============>...............] - ETA: 1s - loss: 8.0651 - acc: 0.4996
 8320/15373 [===============>..............] - ETA: 1s - loss: 8.0455 - acc: 0.5008
 8704/15373 [===============>..............] - ETA: 1s - loss: 8.0442 - acc: 0.5009
 9088/15373 [================>.............] - ETA: 1s - loss: 8.0041 - acc: 0.5034
 9472/15373 [=================>............] - ETA: 0s - loss: 8.0250 - acc: 0.5021
 9856/15373 [==================>...........] - ETA: 0s - loss: 8.0067 - acc: 0.5032
10240/15373 [==================>...........] - ETA: 0s - loss: 8.0165 - acc: 0.5026
10624/15373 [===================>..........] - ETA: 0s - loss: 8.0135 - acc: 0.5028
11008/15373 [====================>.........] - ETA: 0s - loss: 8.0166 - acc: 0.5026
11328/15373 [=====================>........] - ETA: 0s - loss: 8.0349 - acc: 0.5015
11712/15373 [=====================>........] - ETA: 0s - loss: 8.0178 - acc: 0.5026
12096/15373 [======================>.......] - ETA: 0s - loss: 8.0137 - acc: 0.5028
12480/15373 [=======================>......] - ETA: 0s - loss: 8.0138 - acc: 0.5028
12864/15373 [========================>.....] - ETA: 0s - loss: 8.0327 - acc: 0.5016
13248/15373 [========================>.....] - ETA: 0s - loss: 8.0517 - acc: 0.5005
13632/15373 [=========================>....] - ETA: 0s - loss: 8.0650 - acc: 0.4996
14016/15373 [==========================>...] - ETA: 0s - loss: 8.0659 - acc: 0.4996
14400/15373 [===========================>..] - ETA: 0s - loss: 8.0602 - acc: 0.4999
14784/15373 [===========================>..] - ETA: 0s - loss: 8.0612 - acc: 0.4999
15168/15373 [============================>.] - ETA: 0s - loss: 8.0569 - acc: 0.5001
15373/15373 [==============================] - 2s 158us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03080714725816

data size :  16996

zero :  8499

one :  8497

train_zero :  7687

train_one :  7686

test_zero :  812

test_one :  811

choose_zero :  1623

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[812   0]
 [811   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000325245579784], 'loss': [8.058523525872538]}
Saved model to disk



14

Epoch 1/1

   64/15373 [..............................] - ETA: 3s - loss: 6.7998 - acc: 0.5781
  384/15373 [..............................] - ETA: 2s - loss: 8.1010 - acc: 0.4974
  704/15373 [>.............................] - ETA: 2s - loss: 7.9904 - acc: 0.5043
 1024/15373 [>.............................] - ETA: 2s - loss: 8.0748 - acc: 0.4990
 1344/15373 [=>............................] - ETA: 2s - loss: 8.1550 - acc: 0.4940
 1664/15373 [==>...........................] - ETA: 2s - loss: 8.2043 - acc: 0.4910
 1984/15373 [==>...........................] - ETA: 2s - loss: 8.2215 - acc: 0.4899
 2304/15373 [===>..........................] - ETA: 2s - loss: 8.2409 - acc: 0.4887
 2624/15373 [====>.........................] - ETA: 2s - loss: 8.2556 - acc: 0.4878
 2944/15373 [====>.........................] - ETA: 2s - loss: 8.2507 - acc: 0.4881
 3264/15373 [=====>........................] - ETA: 2s - loss: 8.2467 - acc: 0.4884
 3584/15373 [=====>........................] - ETA: 1s - loss: 8.2209 - acc: 0.4900
 3904/15373 [======>.......................] - ETA: 1s - loss: 8.1912 - acc: 0.4918
 4224/15373 [=======>......................] - ETA: 1s - loss: 8.1201 - acc: 0.4962
 4544/15373 [=======>......................] - ETA: 1s - loss: 8.1123 - acc: 0.4967
 4864/15373 [========>.....................] - ETA: 1s - loss: 8.1088 - acc: 0.4969
 5184/15373 [=========>....................] - ETA: 1s - loss: 8.1368 - acc: 0.4952
 5504/15373 [=========>....................] - ETA: 1s - loss: 8.1410 - acc: 0.4949
 5888/15373 [==========>...................] - ETA: 1s - loss: 8.1494 - acc: 0.4944
 6208/15373 [===========>..................] - ETA: 1s - loss: 8.1707 - acc: 0.4931
 6592/15373 [===========>..................] - ETA: 1s - loss: 8.1495 - acc: 0.4944
 6976/15373 [============>.................] - ETA: 1s - loss: 8.1515 - acc: 0.4943
 7360/15373 [=============>................] - ETA: 1s - loss: 8.1401 - acc: 0.4950
 7744/15373 [==============>...............] - ETA: 1s - loss: 8.1111 - acc: 0.4968
 8128/15373 [==============>...............] - ETA: 1s - loss: 8.1066 - acc: 0.4970
 8512/15373 [===============>..............] - ETA: 1s - loss: 8.1405 - acc: 0.4949
 8896/15373 [================>.............] - ETA: 1s - loss: 8.1569 - acc: 0.4939
 9280/15373 [=================>............] - ETA: 0s - loss: 8.1355 - acc: 0.4953
 9664/15373 [=================>............] - ETA: 0s - loss: 8.1324 - acc: 0.4954
10048/15373 [==================>...........] - ETA: 0s - loss: 8.1120 - acc: 0.4967
10432/15373 [===================>..........] - ETA: 0s - loss: 8.0760 - acc: 0.4989
10816/15373 [====================>.........] - ETA: 0s - loss: 8.0874 - acc: 0.4982
11200/15373 [====================>.........] - ETA: 0s - loss: 8.0936 - acc: 0.4979
11584/15373 [=====================>........] - ETA: 0s - loss: 8.0911 - acc: 0.4980
11968/15373 [======================>.......] - ETA: 0s - loss: 8.0846 - acc: 0.4984
12352/15373 [=======================>......] - ETA: 0s - loss: 8.0865 - acc: 0.4983
12736/15373 [=======================>......] - ETA: 0s - loss: 8.0793 - acc: 0.4987
13120/15373 [========================>.....] - ETA: 0s - loss: 8.0812 - acc: 0.4986
13504/15373 [=========================>....] - ETA: 0s - loss: 8.0555 - acc: 0.5002
13888/15373 [==========================>...] - ETA: 0s - loss: 8.0614 - acc: 0.4999
14272/15373 [==========================>...] - ETA: 0s - loss: 8.0489 - acc: 0.5006
14656/15373 [===========================>..] - ETA: 0s - loss: 8.0437 - acc: 0.5010
15040/15373 [============================>.] - ETA: 0s - loss: 8.0440 - acc: 0.5009
15373/15373 [==============================] - 2s 156us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03080714725816

data size :  16996

zero :  8499

one :  8497

train_zero :  7687

train_one :  7686

test_zero :  812

test_one :  811

choose_zero :  1623

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[812   0]
 [811   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000325245618557], 'loss': [8.058523551493268]}
Saved model to disk



15

Epoch 1/1

   64/15373 [..............................] - ETA: 3s - loss: 8.0590 - acc: 0.5000
  384/15373 [..............................] - ETA: 2s - loss: 8.2689 - acc: 0.4870
  704/15373 [>.............................] - ETA: 2s - loss: 8.4254 - acc: 0.4773
 1024/15373 [>.............................] - ETA: 2s - loss: 8.2952 - acc: 0.4854
 1344/15373 [=>............................] - ETA: 2s - loss: 8.2749 - acc: 0.4866
 1664/15373 [==>...........................] - ETA: 2s - loss: 8.1269 - acc: 0.4958
 1984/15373 [==>...........................] - ETA: 2s - loss: 8.0590 - acc: 0.5000
 2304/15373 [===>..........................] - ETA: 2s - loss: 8.0870 - acc: 0.4983
 2624/15373 [====>.........................] - ETA: 2s - loss: 8.1143 - acc: 0.4966
 2944/15373 [====>.........................] - ETA: 2s - loss: 8.0207 - acc: 0.5024
 3264/15373 [=====>........................] - ETA: 2s - loss: 8.0097 - acc: 0.5031
 3584/15373 [=====>........................] - ETA: 1s - loss: 8.0366 - acc: 0.5014
 3904/15373 [======>.......................] - ETA: 1s - loss: 8.0054 - acc: 0.5033
 4224/15373 [=======>......................] - ETA: 1s - loss: 8.0667 - acc: 0.4995
 4544/15373 [=======>......................] - ETA: 1s - loss: 8.1052 - acc: 0.4971
 4864/15373 [========>.....................] - ETA: 1s - loss: 8.1121 - acc: 0.4967
 5248/15373 [=========>....................] - ETA: 1s - loss: 8.0836 - acc: 0.4985
 5632/15373 [=========>....................] - ETA: 1s - loss: 8.0562 - acc: 0.5002
 6016/15373 [==========>...................] - ETA: 1s - loss: 8.0296 - acc: 0.5018
 6400/15373 [===========>..................] - ETA: 1s - loss: 8.0641 - acc: 0.4997
 6784/15373 [============>.................] - ETA: 1s - loss: 8.0543 - acc: 0.5003
 7168/15373 [============>.................] - ETA: 1s - loss: 8.0635 - acc: 0.4997
 7552/15373 [=============>................] - ETA: 1s - loss: 8.0911 - acc: 0.4980
 7936/15373 [==============>...............] - ETA: 1s - loss: 8.0875 - acc: 0.4982
 8320/15373 [===============>..............] - ETA: 1s - loss: 8.1133 - acc: 0.4966
 8704/15373 [===============>..............] - ETA: 1s - loss: 8.1109 - acc: 0.4968
 9088/15373 [================>.............] - ETA: 0s - loss: 8.0981 - acc: 0.4976
 9472/15373 [=================>............] - ETA: 0s - loss: 8.0710 - acc: 0.4993
 9856/15373 [==================>...........] - ETA: 0s - loss: 8.0770 - acc: 0.4989
10240/15373 [==================>...........] - ETA: 0s - loss: 8.0842 - acc: 0.4984
10560/15373 [===================>..........] - ETA: 0s - loss: 8.0789 - acc: 0.4988
10944/15373 [====================>.........] - ETA: 0s - loss: 8.0679 - acc: 0.4995
11328/15373 [=====================>........] - ETA: 0s - loss: 8.0548 - acc: 0.5003
11712/15373 [=====================>........] - ETA: 0s - loss: 8.0467 - acc: 0.5008
12096/15373 [======================>.......] - ETA: 0s - loss: 8.0617 - acc: 0.4998
12416/15373 [=======================>......] - ETA: 0s - loss: 8.0707 - acc: 0.4993
12800/15373 [=======================>......] - ETA: 0s - loss: 8.0616 - acc: 0.4998
13184/15373 [========================>.....] - ETA: 0s - loss: 8.0493 - acc: 0.5006
13568/15373 [=========================>....] - ETA: 0s - loss: 8.0472 - acc: 0.5007
13952/15373 [==========================>...] - ETA: 0s - loss: 8.0579 - acc: 0.5001
14336/15373 [==========================>...] - ETA: 0s - loss: 8.0590 - acc: 0.5000
14720/15373 [===========================>..] - ETA: 0s - loss: 8.0897 - acc: 0.4981
15104/15373 [============================>.] - ETA: 0s - loss: 8.0687 - acc: 0.4994
15373/15373 [==============================] - 2s 156us/step - loss: 8.0585 - acc: 0.5000
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)

Test accuracy: 50.03080714725816

data size :  16996

zero :  8499

one :  8497

train_zero :  7687

train_one :  7686

test_zero :  812

test_one :  811

choose_zero :  1623

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[812   0]
 [811   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000325245657329], 'loss': [8.058523533440889]}
Saved model to disk



[[50.03080714725816, 1], [50.03080714725816, 2], [50.03080714725816, 3], [50.03080714725816, 4], [50.03080714725816, 5], [50.03080714725816, 6], [50.03080714725816, 7], [50.03080714725816, 8], [50.03080714725816, 9], [50.03080714725816, 10], [50.03080714725816, 11], [50.03080714725816, 12], [50.03080714725816, 13], [50.03080714725816, 14], [50.03080714725816, 15]]
max accuracy :  [50.03080714725816, 15]
