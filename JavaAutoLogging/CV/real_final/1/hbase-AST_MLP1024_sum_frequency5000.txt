Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
sum_MLP.py:400: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor("de..., inputs=Tensor("in...)`
  model = Model(input=inputs, output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-08-21 14:34:53.502314: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-21 14:34:53.509703: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099840000 Hz
2019-08-21 14:34:53.511540: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x580ad10 executing computations on platform Host. Devices:
2019-08-21 14:34:53.511564: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
zero : 
39451

one : 
9019
hbase-AST
all data

Sentence length Average : 35

Under 10 : 21694
Over 10, Under 200 : 25475
Over 200, Under 400 : 1121
Over 400 : 180

hbase-AST
updated_train_data

Sentence length Average : 58

Under 10 : 0
Over 10, Under 200 : 22839
Over 200, Under 400 : 1085
Over 400 : 0


Test_zero:  1851
Train_zero:  16713
zero:  18564
Test_one:  763
Train_one:  7211
one:  7974

Count model parameter.
Get a short summary of each layer dimensions and parameters.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 200)               0         
_________________________________________________________________
masking_1 (Masking)          (None, 200)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              205824    
_________________________________________________________________
dropout_1 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
dropout_2 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 2050      
=================================================================
Total params: 1,257,474
Trainable params: 1,257,474
Non-trainable params: 0
_________________________________________________________________
1

Epoch 1/1

   64/14423 [..............................] - ETA: 1:02 - loss: 2.8446 - acc: 0.4375
  384/14423 [..............................] - ETA: 12s - loss: 7.8616 - acc: 0.4479 
  576/14423 [>.............................] - ETA: 9s - loss: 7.7595 - acc: 0.4757 
  832/14423 [>.............................] - ETA: 7s - loss: 7.9485 - acc: 0.4772
 1088/14423 [=>............................] - ETA: 6s - loss: 8.0634 - acc: 0.4770
 1216/14423 [=>............................] - ETA: 6s - loss: 7.9702 - acc: 0.4852
 1344/14423 [=>............................] - ETA: 6s - loss: 8.0506 - acc: 0.4821
 1472/14423 [==>...........................] - ETA: 6s - loss: 8.0842 - acc: 0.4817
 1664/14423 [==>...........................] - ETA: 5s - loss: 7.9747 - acc: 0.4904
 1792/14423 [==>...........................] - ETA: 5s - loss: 8.0347 - acc: 0.4877
 1984/14423 [===>..........................] - ETA: 5s - loss: 8.1264 - acc: 0.4834
 2176/14423 [===>..........................] - ETA: 5s - loss: 8.1501 - acc: 0.4830
 2368/14423 [===>..........................] - ETA: 5s - loss: 8.0883 - acc: 0.4878
 2624/14423 [====>.........................] - ETA: 4s - loss: 8.1223 - acc: 0.4867
 2816/14423 [====>.........................] - ETA: 4s - loss: 8.0894 - acc: 0.4893
 3072/14423 [=====>........................] - ETA: 4s - loss: 8.0658 - acc: 0.4915
 3264/14423 [=====>........................] - ETA: 4s - loss: 8.0506 - acc: 0.4930
 3584/14423 [======>.......................] - ETA: 3s - loss: 8.0019 - acc: 0.4967
 3904/14423 [=======>......................] - ETA: 3s - loss: 7.9736 - acc: 0.4990
 4160/14423 [=======>......................] - ETA: 3s - loss: 7.9478 - acc: 0.5010
 4416/14423 [========>.....................] - ETA: 3s - loss: 7.9616 - acc: 0.5005
 4736/14423 [========>.....................] - ETA: 3s - loss: 7.9545 - acc: 0.5013
 5056/14423 [=========>....................] - ETA: 2s - loss: 7.9739 - acc: 0.5004
 5312/14423 [==========>...................] - ETA: 2s - loss: 7.9689 - acc: 0.5009
 5696/14423 [==========>...................] - ETA: 2s - loss: 7.9608 - acc: 0.5018
 6016/14423 [===========>..................] - ETA: 2s - loss: 8.0009 - acc: 0.4995
 6272/14423 [============>.................] - ETA: 2s - loss: 7.9827 - acc: 0.5008
 6528/14423 [============>.................] - ETA: 2s - loss: 7.9931 - acc: 0.5003
 6784/14423 [=============>................] - ETA: 2s - loss: 8.0122 - acc: 0.4993
 7040/14423 [=============>................] - ETA: 2s - loss: 8.0048 - acc: 0.4999
 7296/14423 [==============>...............] - ETA: 2s - loss: 8.0266 - acc: 0.4986
 7616/14423 [==============>...............] - ETA: 1s - loss: 7.9983 - acc: 0.5005
 7744/14423 [===============>..............] - ETA: 1s - loss: 8.0014 - acc: 0.5004
 7872/14423 [===============>..............] - ETA: 1s - loss: 8.0146 - acc: 0.4996
 8000/14423 [===============>..............] - ETA: 1s - loss: 8.0314 - acc: 0.4986
 8192/14423 [================>.............] - ETA: 1s - loss: 8.0301 - acc: 0.4988
 8384/14423 [================>.............] - ETA: 1s - loss: 8.0327 - acc: 0.4987
 8576/14423 [================>.............] - ETA: 1s - loss: 8.0277 - acc: 0.4991
 8832/14423 [=================>............] - ETA: 1s - loss: 8.0377 - acc: 0.4985
 9088/14423 [=================>............] - ETA: 1s - loss: 8.0347 - acc: 0.4988
 9344/14423 [==================>...........] - ETA: 1s - loss: 8.0354 - acc: 0.4988
 9600/14423 [==================>...........] - ETA: 1s - loss: 8.0159 - acc: 0.5001
 9856/14423 [===================>..........] - ETA: 1s - loss: 8.0236 - acc: 0.4997
10112/14423 [====================>.........] - ETA: 1s - loss: 8.0037 - acc: 0.5010
10368/14423 [====================>.........] - ETA: 1s - loss: 8.0191 - acc: 0.5001
10688/14423 [=====================>........] - ETA: 1s - loss: 8.0233 - acc: 0.4999
10944/14423 [=====================>........] - ETA: 0s - loss: 8.0197 - acc: 0.5002
11264/14423 [======================>.......] - ETA: 0s - loss: 8.0051 - acc: 0.5012
11584/14423 [=======================>......] - ETA: 0s - loss: 7.9955 - acc: 0.5018
11904/14423 [=======================>......] - ETA: 0s - loss: 8.0039 - acc: 0.5013
12224/14423 [========================>.....] - ETA: 0s - loss: 7.9882 - acc: 0.5024
12544/14423 [=========================>....] - ETA: 0s - loss: 8.0029 - acc: 0.5015
12800/14423 [=========================>....] - ETA: 0s - loss: 8.0242 - acc: 0.5002
13120/14423 [==========================>...] - ETA: 0s - loss: 8.0201 - acc: 0.5005
13440/14423 [==========================>...] - ETA: 0s - loss: 8.0174 - acc: 0.5007
13760/14423 [===========================>..] - ETA: 0s - loss: 8.0161 - acc: 0.5009
14080/14423 [============================>.] - ETA: 0s - loss: 8.0273 - acc: 0.5002
14400/14423 [============================>.] - ETA: 0s - loss: 8.0314 - acc: 0.5000
14423/14423 [==============================] - 4s 253us/step - loss: 8.0354 - acc: 0.4998

Test accuracy: 50.03274394237066

data size :  15950

zero :  7976

one :  7974

train_zero :  7212

train_one :  7211

test_zero :  764

test_one :  763

choose_zero :  1527

choose_one :  0

F1score :  0.0

AUC : 0.3877656399031105

Confusion Matrix
[[764   0]
 [763   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.035350469877391], 'acc': [0.49975733204943573]}
Saved model to disk



2

Epoch 1/1

   64/14423 [..............................] - ETA: 2s - loss: 9.3183 - acc: 0.4219
  320/14423 [..............................] - ETA: 2s - loss: 8.0590 - acc: 0.5000
  576/14423 [>.............................] - ETA: 3s - loss: 8.1710 - acc: 0.4931
  832/14423 [>.............................] - ETA: 3s - loss: 8.1753 - acc: 0.4928
 1088/14423 [=>............................] - ETA: 2s - loss: 8.1627 - acc: 0.4936
 1408/14423 [=>............................] - ETA: 2s - loss: 8.2193 - acc: 0.4901
 1664/14423 [==>...........................] - ETA: 2s - loss: 8.0978 - acc: 0.4976
 1920/14423 [==>...........................] - ETA: 2s - loss: 8.2857 - acc: 0.4859
 2112/14423 [===>..........................] - ETA: 2s - loss: 8.3719 - acc: 0.4806
 2240/14423 [===>..........................] - ETA: 2s - loss: 8.3900 - acc: 0.4795
 2368/14423 [===>..........................] - ETA: 3s - loss: 8.3790 - acc: 0.4802
 2560/14423 [====>.........................] - ETA: 3s - loss: 8.3487 - acc: 0.4820
 2688/14423 [====>.........................] - ETA: 3s - loss: 8.3109 - acc: 0.4844
 2880/14423 [====>.........................] - ETA: 3s - loss: 8.2325 - acc: 0.4892
 3008/14423 [=====>........................] - ETA: 3s - loss: 8.1984 - acc: 0.4914
 3200/14423 [=====>........................] - ETA: 3s - loss: 8.1900 - acc: 0.4919
 3392/14423 [======>.......................] - ETA: 3s - loss: 8.2444 - acc: 0.4885
 3584/14423 [======>.......................] - ETA: 3s - loss: 8.1760 - acc: 0.4927
 3712/14423 [======>.......................] - ETA: 3s - loss: 8.1502 - acc: 0.4943
 3840/14423 [======>.......................] - ETA: 3s - loss: 8.1220 - acc: 0.4961
 4032/14423 [=======>......................] - ETA: 3s - loss: 8.1470 - acc: 0.4945
 4224/14423 [=======>......................] - ETA: 3s - loss: 8.2079 - acc: 0.4908
 4416/14423 [========>.....................] - ETA: 3s - loss: 8.2233 - acc: 0.4898
 4608/14423 [========>.....................] - ETA: 2s - loss: 8.1570 - acc: 0.4939
 4864/14423 [=========>....................] - ETA: 2s - loss: 8.1021 - acc: 0.4973
 5120/14423 [=========>....................] - ETA: 2s - loss: 8.0402 - acc: 0.5012
 5376/14423 [==========>...................] - ETA: 2s - loss: 8.0321 - acc: 0.5017
 5632/14423 [==========>...................] - ETA: 2s - loss: 8.0133 - acc: 0.5028
 5888/14423 [===========>..................] - ETA: 2s - loss: 8.0098 - acc: 0.5031
 6208/14423 [===========>..................] - ETA: 2s - loss: 8.0227 - acc: 0.5023
 6528/14423 [============>.................] - ETA: 2s - loss: 8.0368 - acc: 0.5014
 6848/14423 [=============>................] - ETA: 2s - loss: 8.0379 - acc: 0.5013
 7104/14423 [=============>................] - ETA: 1s - loss: 8.0500 - acc: 0.5006
 7424/14423 [==============>...............] - ETA: 1s - loss: 8.0634 - acc: 0.4997
 7552/14423 [==============>...............] - ETA: 1s - loss: 8.0825 - acc: 0.4985
 7680/14423 [==============>...............] - ETA: 1s - loss: 8.0863 - acc: 0.4983
 7808/14423 [===============>..............] - ETA: 1s - loss: 8.0673 - acc: 0.4995
 8064/14423 [===============>..............] - ETA: 1s - loss: 8.0730 - acc: 0.4991
 8384/14423 [================>.............] - ETA: 1s - loss: 8.1013 - acc: 0.4974
 8704/14423 [=================>............] - ETA: 1s - loss: 8.1016 - acc: 0.4974
 9024/14423 [=================>............] - ETA: 1s - loss: 8.1126 - acc: 0.4967
 9280/14423 [==================>...........] - ETA: 1s - loss: 8.1285 - acc: 0.4957
 9536/14423 [==================>...........] - ETA: 1s - loss: 8.1047 - acc: 0.4972
 9792/14423 [===================>..........] - ETA: 1s - loss: 8.1282 - acc: 0.4957
10048/14423 [===================>..........] - ETA: 1s - loss: 8.1344 - acc: 0.4953
10304/14423 [====================>.........] - ETA: 1s - loss: 8.1232 - acc: 0.4960
10560/14423 [====================>.........] - ETA: 0s - loss: 8.1094 - acc: 0.4969
10880/14423 [=====================>........] - ETA: 0s - loss: 8.1227 - acc: 0.4960
11200/14423 [======================>.......] - ETA: 0s - loss: 8.1152 - acc: 0.4965
11520/14423 [======================>.......] - ETA: 0s - loss: 8.1052 - acc: 0.4971
11840/14423 [=======================>......] - ETA: 0s - loss: 8.1135 - acc: 0.4966
12160/14423 [========================>.....] - ETA: 0s - loss: 8.1174 - acc: 0.4964
12480/14423 [========================>.....] - ETA: 0s - loss: 8.0991 - acc: 0.4975
12800/14423 [=========================>....] - ETA: 0s - loss: 8.1056 - acc: 0.4971
13120/14423 [==========================>...] - ETA: 0s - loss: 8.1020 - acc: 0.4973
13440/14423 [==========================>...] - ETA: 0s - loss: 8.0926 - acc: 0.4979
13760/14423 [===========================>..] - ETA: 0s - loss: 8.0989 - acc: 0.4975
14080/14423 [============================>.] - ETA: 0s - loss: 8.0774 - acc: 0.4989
14400/14423 [============================>.] - ETA: 0s - loss: 8.0557 - acc: 0.5002
14423/14423 [==============================] - 3s 238us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03274394237066

data size :  15950

zero :  7976

one :  7974

train_zero :  7212

train_one :  7211

test_zero :  764

test_one :  763

choose_zero :  1527

choose_one :  0

F1score :  0.0

AUC : 0.3877656399031105

Confusion Matrix
[[764   0]
 [763   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058489006567223], 'acc': [0.5000346668453576]}
Saved model to disk



3

Epoch 1/1

   64/14423 [..............................] - ETA: 3s - loss: 7.0517 - acc: 0.5625
  320/14423 [..............................] - ETA: 3s - loss: 8.7138 - acc: 0.4594
  576/14423 [>.............................] - ETA: 2s - loss: 8.1430 - acc: 0.4948
  896/14423 [>.............................] - ETA: 2s - loss: 8.0411 - acc: 0.5011
 1216/14423 [=>............................] - ETA: 2s - loss: 7.9265 - acc: 0.5082
 1472/14423 [==>...........................] - ETA: 2s - loss: 8.0262 - acc: 0.5020
 1664/14423 [==>...........................] - ETA: 2s - loss: 8.0687 - acc: 0.4994
 1984/14423 [===>..........................] - ETA: 2s - loss: 8.0347 - acc: 0.5015
 2304/14423 [===>..........................] - ETA: 2s - loss: 7.9751 - acc: 0.5052
 2432/14423 [====>.........................] - ETA: 2s - loss: 7.9398 - acc: 0.5074
 2624/14423 [====>.........................] - ETA: 2s - loss: 7.8748 - acc: 0.5114
 2816/14423 [====>.........................] - ETA: 2s - loss: 7.8759 - acc: 0.5114
 3008/14423 [=====>........................] - ETA: 2s - loss: 7.9304 - acc: 0.5080
 3264/14423 [=====>........................] - ETA: 2s - loss: 7.9455 - acc: 0.5070
 3456/14423 [======>.......................] - ETA: 2s - loss: 7.9331 - acc: 0.5078
 3712/14423 [======>.......................] - ETA: 2s - loss: 7.8984 - acc: 0.5100
 4032/14423 [=======>......................] - ETA: 2s - loss: 7.8951 - acc: 0.5102
 4352/14423 [========>.....................] - ETA: 2s - loss: 7.8739 - acc: 0.5115
 4608/14423 [========>.....................] - ETA: 2s - loss: 7.8177 - acc: 0.5150
 4864/14423 [=========>....................] - ETA: 2s - loss: 7.8569 - acc: 0.5125
 5056/14423 [=========>....................] - ETA: 2s - loss: 7.8678 - acc: 0.5119
 5248/14423 [=========>....................] - ETA: 2s - loss: 7.8932 - acc: 0.5103
 5440/14423 [==========>...................] - ETA: 2s - loss: 7.9050 - acc: 0.5096
 5568/14423 [==========>...................] - ETA: 2s - loss: 7.9085 - acc: 0.5093
 5696/14423 [==========>...................] - ETA: 2s - loss: 7.9147 - acc: 0.5090
 5888/14423 [===========>..................] - ETA: 2s - loss: 7.9140 - acc: 0.5090
 6144/14423 [===========>..................] - ETA: 2s - loss: 7.9331 - acc: 0.5078
 6336/14423 [============>.................] - ETA: 2s - loss: 7.9446 - acc: 0.5071
 6592/14423 [============>.................] - ETA: 1s - loss: 7.9466 - acc: 0.5070
 6848/14423 [=============>................] - ETA: 1s - loss: 7.9649 - acc: 0.5058
 7104/14423 [=============>................] - ETA: 1s - loss: 7.9229 - acc: 0.5084
 7360/14423 [==============>...............] - ETA: 1s - loss: 7.9342 - acc: 0.5077
 7680/14423 [==============>...............] - ETA: 1s - loss: 7.9394 - acc: 0.5074
 8000/14423 [===============>..............] - ETA: 1s - loss: 7.9281 - acc: 0.5081
 8256/14423 [================>.............] - ETA: 1s - loss: 7.9400 - acc: 0.5074
 8576/14423 [================>.............] - ETA: 1s - loss: 7.9275 - acc: 0.5082
 8832/14423 [=================>............] - ETA: 1s - loss: 7.9532 - acc: 0.5066
 9024/14423 [=================>............] - ETA: 1s - loss: 7.9608 - acc: 0.5061
 9152/14423 [==================>...........] - ETA: 1s - loss: 7.9692 - acc: 0.5056
 9344/14423 [==================>...........] - ETA: 1s - loss: 7.9935 - acc: 0.5041
 9600/14423 [==================>...........] - ETA: 1s - loss: 8.0036 - acc: 0.5034
 9984/14423 [===================>..........] - ETA: 1s - loss: 8.0058 - acc: 0.5033
10304/14423 [====================>.........] - ETA: 0s - loss: 8.0106 - acc: 0.5030
10496/14423 [====================>.........] - ETA: 0s - loss: 8.0145 - acc: 0.5028
10752/14423 [=====================>........] - ETA: 0s - loss: 8.0246 - acc: 0.5021
11072/14423 [======================>.......] - ETA: 0s - loss: 8.0328 - acc: 0.5016
11392/14423 [======================>.......] - ETA: 0s - loss: 8.0350 - acc: 0.5015
11712/14423 [=======================>......] - ETA: 0s - loss: 8.0522 - acc: 0.5004
12032/14423 [========================>.....] - ETA: 0s - loss: 8.0470 - acc: 0.5007
12352/14423 [========================>.....] - ETA: 0s - loss: 8.0421 - acc: 0.5011
12672/14423 [=========================>....] - ETA: 0s - loss: 8.0476 - acc: 0.5007
12928/14423 [=========================>....] - ETA: 0s - loss: 8.0516 - acc: 0.5005
13248/14423 [==========================>...] - ETA: 0s - loss: 8.0505 - acc: 0.5005
13568/14423 [===========================>..] - ETA: 0s - loss: 8.0519 - acc: 0.5004
13888/14423 [===========================>..] - ETA: 0s - loss: 8.0579 - acc: 0.5001
14208/14423 [============================>.] - ETA: 0s - loss: 8.0659 - acc: 0.4996
14423/14423 [==============================] - 3s 227us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03274394237066

data size :  15950

zero :  7976

one :  7974

train_zero :  7212

train_one :  7211

test_zero :  764

test_one :  763

choose_zero :  1527

choose_one :  0

F1score :  0.0

AUC : 0.3877656399031105

Confusion Matrix
[[764   0]
 [763   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058488998202819], 'acc': [0.5000346668432913]}
Saved model to disk



4

Epoch 1/1

   64/14423 [..............................] - ETA: 3s - loss: 7.3035 - acc: 0.5469
  320/14423 [..............................] - ETA: 2s - loss: 7.7568 - acc: 0.5188
  640/14423 [>.............................] - ETA: 2s - loss: 7.9583 - acc: 0.5062
  960/14423 [>.............................] - ETA: 2s - loss: 7.8576 - acc: 0.5125
 1280/14423 [=>............................] - ETA: 2s - loss: 7.9079 - acc: 0.5094
 1600/14423 [==>...........................] - ETA: 2s - loss: 7.8979 - acc: 0.5100
 1920/14423 [==>...........................] - ETA: 2s - loss: 7.9919 - acc: 0.5042
 2240/14423 [===>..........................] - ETA: 2s - loss: 7.9655 - acc: 0.5058
 2560/14423 [====>.........................] - ETA: 2s - loss: 7.9457 - acc: 0.5070
 2816/14423 [====>.........................] - ETA: 2s - loss: 7.9102 - acc: 0.5092
 3072/14423 [=====>........................] - ETA: 2s - loss: 7.9541 - acc: 0.5065
 3328/14423 [=====>........................] - ETA: 2s - loss: 7.9283 - acc: 0.5081
 3520/14423 [======>.......................] - ETA: 2s - loss: 7.9400 - acc: 0.5074
 3648/14423 [======>.......................] - ETA: 2s - loss: 7.9618 - acc: 0.5060
 3840/14423 [======>.......................] - ETA: 2s - loss: 7.9373 - acc: 0.5076
 4096/14423 [=======>......................] - ETA: 2s - loss: 7.9528 - acc: 0.5066
 4224/14423 [=======>......................] - ETA: 2s - loss: 7.9637 - acc: 0.5059
 4416/14423 [========>.....................] - ETA: 2s - loss: 7.9824 - acc: 0.5048
 4608/14423 [========>.....................] - ETA: 2s - loss: 7.9961 - acc: 0.5039
 4864/14423 [=========>....................] - ETA: 2s - loss: 7.9961 - acc: 0.5039
 5056/14423 [=========>....................] - ETA: 2s - loss: 7.9857 - acc: 0.5045
 5376/14423 [==========>...................] - ETA: 2s - loss: 7.9421 - acc: 0.5073
 5568/14423 [==========>...................] - ETA: 2s - loss: 7.9317 - acc: 0.5079
 5760/14423 [==========>...................] - ETA: 2s - loss: 7.9751 - acc: 0.5052
 6080/14423 [===========>..................] - ETA: 1s - loss: 8.0007 - acc: 0.5036
 6272/14423 [============>.................] - ETA: 1s - loss: 7.9974 - acc: 0.5038
 6464/14423 [============>.................] - ETA: 1s - loss: 8.0092 - acc: 0.5031
 6656/14423 [============>.................] - ETA: 1s - loss: 8.0639 - acc: 0.4997
 6848/14423 [=============>................] - ETA: 1s - loss: 8.0567 - acc: 0.5001
 7104/14423 [=============>................] - ETA: 1s - loss: 8.0522 - acc: 0.5004
 7424/14423 [==============>...............] - ETA: 1s - loss: 8.0352 - acc: 0.5015
 7744/14423 [===============>..............] - ETA: 1s - loss: 8.0320 - acc: 0.5017
 8064/14423 [===============>..............] - ETA: 1s - loss: 8.0251 - acc: 0.5021
 8384/14423 [================>.............] - ETA: 1s - loss: 8.0091 - acc: 0.5031
 8640/14423 [================>.............] - ETA: 1s - loss: 8.0199 - acc: 0.5024
 8960/14423 [=================>............] - ETA: 1s - loss: 8.0123 - acc: 0.5029
 9280/14423 [==================>...........] - ETA: 1s - loss: 8.0208 - acc: 0.5024
 9536/14423 [==================>...........] - ETA: 1s - loss: 8.0134 - acc: 0.5028
 9792/14423 [===================>..........] - ETA: 1s - loss: 8.0130 - acc: 0.5029
10048/14423 [===================>..........] - ETA: 1s - loss: 8.0173 - acc: 0.5026
10176/14423 [====================>.........] - ETA: 0s - loss: 8.0385 - acc: 0.5013
10368/14423 [====================>.........] - ETA: 0s - loss: 8.0419 - acc: 0.5011
10560/14423 [====================>.........] - ETA: 0s - loss: 8.0468 - acc: 0.5008
10816/14423 [=====================>........] - ETA: 0s - loss: 8.0590 - acc: 0.5000
11072/14423 [======================>.......] - ETA: 0s - loss: 8.0547 - acc: 0.5003
11328/14423 [======================>.......] - ETA: 0s - loss: 8.0676 - acc: 0.4995
11584/14423 [=======================>......] - ETA: 0s - loss: 8.0604 - acc: 0.4999
11840/14423 [=======================>......] - ETA: 0s - loss: 8.0618 - acc: 0.4998
12160/14423 [========================>.....] - ETA: 0s - loss: 8.0537 - acc: 0.5003
12480/14423 [========================>.....] - ETA: 0s - loss: 8.0448 - acc: 0.5009
12800/14423 [=========================>....] - ETA: 0s - loss: 8.0578 - acc: 0.5001
13120/14423 [==========================>...] - ETA: 0s - loss: 8.0750 - acc: 0.4990
13376/14423 [==========================>...] - ETA: 0s - loss: 8.0807 - acc: 0.4987
13696/14423 [===========================>..] - ETA: 0s - loss: 8.0838 - acc: 0.4985
14016/14423 [============================>.] - ETA: 0s - loss: 8.0602 - acc: 0.4999
14336/14423 [============================>.] - ETA: 0s - loss: 8.0602 - acc: 0.4999
14423/14423 [==============================] - 3s 224us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03274394237066

data size :  15950

zero :  7976

one :  7974

train_zero :  7212

train_one :  7211

test_zero :  764

test_one :  763

choose_zero :  1527

choose_one :  0

F1score :  0.0

AUC : 0.3877656399031105

Confusion Matrix
[[764   0]
 [763   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058488968811691], 'acc': [0.5000346668102305]}
Saved model to disk



5

Epoch 1/1

   64/14423 [..............................] - ETA: 3s - loss: 9.8220 - acc: 0.3906
  320/14423 [..............................] - ETA: 2s - loss: 8.5627 - acc: 0.4688
  576/14423 [>.............................] - ETA: 2s - loss: 8.5627 - acc: 0.4688
  832/14423 [>.............................] - ETA: 2s - loss: 8.2915 - acc: 0.4856
 1152/14423 [=>............................] - ETA: 2s - loss: 8.2829 - acc: 0.4861
 1472/14423 [==>...........................] - ETA: 2s - loss: 8.2123 - acc: 0.4905
 1792/14423 [==>...........................] - ETA: 2s - loss: 8.2659 - acc: 0.4872
 2112/14423 [===>..........................] - ETA: 2s - loss: 8.2193 - acc: 0.4901
 2432/14423 [====>.........................] - ETA: 2s - loss: 8.1916 - acc: 0.4918
 2752/14423 [====>.........................] - ETA: 2s - loss: 8.2523 - acc: 0.4880
 3072/14423 [=====>........................] - ETA: 2s - loss: 8.2112 - acc: 0.4906
 3392/14423 [======>.......................] - ETA: 2s - loss: 8.2159 - acc: 0.4903
 3712/14423 [======>.......................] - ETA: 1s - loss: 8.1633 - acc: 0.4935
 4032/14423 [=======>......................] - ETA: 1s - loss: 8.1790 - acc: 0.4926
 4352/14423 [========>.....................] - ETA: 1s - loss: 8.1516 - acc: 0.4943
 4544/14423 [========>.....................] - ETA: 1s - loss: 8.0874 - acc: 0.4982
 4864/14423 [=========>....................] - ETA: 1s - loss: 8.0988 - acc: 0.4975
 5184/14423 [=========>....................] - ETA: 1s - loss: 8.0839 - acc: 0.4985
 5504/14423 [==========>...................] - ETA: 1s - loss: 8.0971 - acc: 0.4976
 5760/14423 [==========>...................] - ETA: 1s - loss: 8.0758 - acc: 0.4990
 6016/14423 [===========>..................] - ETA: 1s - loss: 8.0778 - acc: 0.4988
 6272/14423 [============>.................] - ETA: 1s - loss: 8.0822 - acc: 0.4986
 6464/14423 [============>.................] - ETA: 1s - loss: 8.0865 - acc: 0.4983
 6720/14423 [============>.................] - ETA: 1s - loss: 8.0614 - acc: 0.4999
 6912/14423 [=============>................] - ETA: 1s - loss: 8.0404 - acc: 0.5012
 7104/14423 [=============>................] - ETA: 1s - loss: 8.0613 - acc: 0.4999
 7296/14423 [==============>...............] - ETA: 1s - loss: 8.0502 - acc: 0.5005
 7488/14423 [==============>...............] - ETA: 1s - loss: 8.0289 - acc: 0.5019
 7680/14423 [==============>...............] - ETA: 1s - loss: 8.0360 - acc: 0.5014
 7872/14423 [===============>..............] - ETA: 1s - loss: 8.0590 - acc: 0.5000
 8000/14423 [===============>..............] - ETA: 1s - loss: 8.0631 - acc: 0.4998
 8256/14423 [================>.............] - ETA: 1s - loss: 8.0493 - acc: 0.5006
 8448/14423 [================>.............] - ETA: 1s - loss: 8.0495 - acc: 0.5006
 8704/14423 [=================>............] - ETA: 1s - loss: 8.0498 - acc: 0.5006
 8960/14423 [=================>............] - ETA: 1s - loss: 8.0339 - acc: 0.5016
 9216/14423 [==================>...........] - ETA: 1s - loss: 8.0328 - acc: 0.5016
 9536/14423 [==================>...........] - ETA: 1s - loss: 8.0455 - acc: 0.5008
 9792/14423 [===================>..........] - ETA: 1s - loss: 8.0722 - acc: 0.4992
10048/14423 [===================>..........] - ETA: 0s - loss: 8.0542 - acc: 0.5003
10304/14423 [====================>.........] - ETA: 0s - loss: 8.0544 - acc: 0.5003
10560/14423 [====================>.........] - ETA: 0s - loss: 8.0728 - acc: 0.4991
10816/14423 [=====================>........] - ETA: 0s - loss: 8.0620 - acc: 0.4998
11072/14423 [======================>.......] - ETA: 0s - loss: 8.0590 - acc: 0.5000
11328/14423 [======================>.......] - ETA: 0s - loss: 8.0477 - acc: 0.5007
11648/14423 [=======================>......] - ETA: 0s - loss: 8.0521 - acc: 0.5004
11776/14423 [=======================>......] - ETA: 0s - loss: 8.0632 - acc: 0.4997
12032/14423 [========================>.....] - ETA: 0s - loss: 8.0698 - acc: 0.4993
12352/14423 [========================>.....] - ETA: 0s - loss: 8.0721 - acc: 0.4992
12608/14423 [=========================>....] - ETA: 0s - loss: 8.0782 - acc: 0.4988
12928/14423 [=========================>....] - ETA: 0s - loss: 8.0753 - acc: 0.4990
13312/14423 [==========================>...] - ETA: 0s - loss: 8.0796 - acc: 0.4987
13632/14423 [===========================>..] - ETA: 0s - loss: 8.0685 - acc: 0.4994
13952/14423 [============================>.] - ETA: 0s - loss: 8.0625 - acc: 0.4998
14272/14423 [============================>.] - ETA: 0s - loss: 8.0534 - acc: 0.5004
14423/14423 [==============================] - 3s 222us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03274394237066

data size :  15950

zero :  7976

one :  7974

train_zero :  7212

train_one :  7211

test_zero :  764

test_one :  763

choose_zero :  1527

choose_one :  0

F1score :  0.0

AUC : 0.3877656399031105

Confusion Matrix
[[764   0]
 [763   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058489015923454], 'acc': [0.5000346668267609]}
Saved model to disk



6

Epoch 1/1

   64/14423 [..............................] - ETA: 3s - loss: 9.3183 - acc: 0.4219
  320/14423 [..............................] - ETA: 2s - loss: 8.2605 - acc: 0.4875
  640/14423 [>.............................] - ETA: 2s - loss: 7.9583 - acc: 0.5062
  960/14423 [>.............................] - ETA: 2s - loss: 7.9751 - acc: 0.5052
 1280/14423 [=>............................] - ETA: 2s - loss: 8.1220 - acc: 0.4961
 1600/14423 [==>...........................] - ETA: 2s - loss: 8.1396 - acc: 0.4950
 1920/14423 [==>...........................] - ETA: 2s - loss: 8.0339 - acc: 0.5016
 2240/14423 [===>..........................] - ETA: 2s - loss: 8.0447 - acc: 0.5009
 2560/14423 [====>.........................] - ETA: 2s - loss: 8.0213 - acc: 0.5023
 2880/14423 [====>.........................] - ETA: 2s - loss: 7.9863 - acc: 0.5045
 3200/14423 [=====>........................] - ETA: 2s - loss: 8.0238 - acc: 0.5022
 3520/14423 [======>.......................] - ETA: 1s - loss: 8.0590 - acc: 0.5000
 3840/14423 [======>.......................] - ETA: 1s - loss: 8.0423 - acc: 0.5010
 4160/14423 [=======>......................] - ETA: 1s - loss: 8.0242 - acc: 0.5022
 4480/14423 [========>.....................] - ETA: 1s - loss: 8.0447 - acc: 0.5009
 4800/14423 [========>.....................] - ETA: 1s - loss: 8.0423 - acc: 0.5010
 5120/14423 [=========>....................] - ETA: 1s - loss: 7.9866 - acc: 0.5045
 5440/14423 [==========>...................] - ETA: 1s - loss: 7.9465 - acc: 0.5070
 5760/14423 [==========>...................] - ETA: 1s - loss: 7.9695 - acc: 0.5056
 6080/14423 [===========>..................] - ETA: 1s - loss: 7.9795 - acc: 0.5049
 6208/14423 [===========>..................] - ETA: 1s - loss: 8.0149 - acc: 0.5027
 6592/14423 [============>.................] - ETA: 1s - loss: 8.0444 - acc: 0.5009
 6848/14423 [=============>................] - ETA: 1s - loss: 8.0261 - acc: 0.5020
 7168/14423 [=============>................] - ETA: 1s - loss: 8.0366 - acc: 0.5014
 7360/14423 [==============>...............] - ETA: 1s - loss: 8.0087 - acc: 0.5031
 7616/14423 [==============>...............] - ETA: 1s - loss: 8.0019 - acc: 0.5035
 7744/14423 [===============>..............] - ETA: 1s - loss: 8.0029 - acc: 0.5035
 8000/14423 [===============>..............] - ETA: 1s - loss: 8.0006 - acc: 0.5036
 8320/14423 [================>.............] - ETA: 1s - loss: 7.9990 - acc: 0.5037
 8448/14423 [================>.............] - ETA: 1s - loss: 8.0228 - acc: 0.5022
 8640/14423 [================>.............] - ETA: 1s - loss: 8.0273 - acc: 0.5020
 8832/14423 [=================>............] - ETA: 1s - loss: 8.0554 - acc: 0.5002
 9152/14423 [==================>...........] - ETA: 1s - loss: 8.0450 - acc: 0.5009
 9408/14423 [==================>...........] - ETA: 1s - loss: 8.0368 - acc: 0.5014
 9600/14423 [==================>...........] - ETA: 0s - loss: 8.0339 - acc: 0.5016
 9792/14423 [===================>..........] - ETA: 0s - loss: 8.0360 - acc: 0.5014
 9984/14423 [===================>..........] - ETA: 0s - loss: 8.0526 - acc: 0.5004
10176/14423 [====================>.........] - ETA: 0s - loss: 8.0511 - acc: 0.5005
10432/14423 [====================>.........] - ETA: 0s - loss: 8.0498 - acc: 0.5006
10624/14423 [=====================>........] - ETA: 0s - loss: 8.0575 - acc: 0.5001
10816/14423 [=====================>........] - ETA: 0s - loss: 8.0471 - acc: 0.5007
11008/14423 [=====================>........] - ETA: 0s - loss: 8.0532 - acc: 0.5004
11264/14423 [======================>.......] - ETA: 0s - loss: 8.0576 - acc: 0.5001
11520/14423 [======================>.......] - ETA: 0s - loss: 8.0562 - acc: 0.5002
11712/14423 [=======================>......] - ETA: 0s - loss: 8.0646 - acc: 0.4997
11968/14423 [=======================>......] - ETA: 0s - loss: 8.0752 - acc: 0.4990
12224/14423 [========================>.....] - ETA: 0s - loss: 8.0894 - acc: 0.4981
12544/14423 [=========================>....] - ETA: 0s - loss: 8.0809 - acc: 0.4986
12800/14423 [=========================>....] - ETA: 0s - loss: 8.0868 - acc: 0.4983
13056/14423 [==========================>...] - ETA: 0s - loss: 8.0788 - acc: 0.4988
13312/14423 [==========================>...] - ETA: 0s - loss: 8.0651 - acc: 0.4996
13568/14423 [===========================>..] - ETA: 0s - loss: 8.0590 - acc: 0.5000
13696/14423 [===========================>..] - ETA: 0s - loss: 8.0685 - acc: 0.4994
13888/14423 [===========================>..] - ETA: 0s - loss: 8.0672 - acc: 0.4995
14144/14423 [============================>.] - ETA: 0s - loss: 8.0727 - acc: 0.4992
14400/14423 [============================>.] - ETA: 0s - loss: 8.0590 - acc: 0.5000
14423/14423 [==============================] - 3s 221us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03274394237066

data size :  15950

zero :  7976

one :  7974

train_zero :  7212

train_one :  7211

test_zero :  764

test_one :  763

choose_zero :  1527

choose_one :  0

F1score :  0.0

AUC : 0.3877656399031105

Confusion Matrix
[[764   0]
 [763   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.0584890108982], 'acc': [0.5000346668432913]}
Saved model to disk



7

Epoch 1/1

   64/14423 [..............................] - ETA: 3s - loss: 8.0590 - acc: 0.5000
  384/14423 [..............................] - ETA: 2s - loss: 7.6393 - acc: 0.5260
  704/14423 [>.............................] - ETA: 2s - loss: 7.8301 - acc: 0.5142
 1024/14423 [=>............................] - ETA: 2s - loss: 7.8544 - acc: 0.5127
 1280/14423 [=>............................] - ETA: 2s - loss: 7.8702 - acc: 0.5117
 1536/14423 [==>...........................] - ETA: 2s - loss: 7.9646 - acc: 0.5059
 1792/14423 [==>...........................] - ETA: 2s - loss: 8.1220 - acc: 0.4961
 2112/14423 [===>..........................] - ETA: 2s - loss: 8.0896 - acc: 0.4981
 2432/14423 [====>.........................] - ETA: 2s - loss: 8.1320 - acc: 0.4955
 2752/14423 [====>.........................] - ETA: 2s - loss: 8.1176 - acc: 0.4964
 3008/14423 [=====>........................] - ETA: 2s - loss: 8.1180 - acc: 0.4963
 3328/14423 [=====>........................] - ETA: 2s - loss: 8.1365 - acc: 0.4952
 3648/14423 [======>.......................] - ETA: 2s - loss: 8.0856 - acc: 0.4984
 3968/14423 [=======>......................] - ETA: 1s - loss: 8.0022 - acc: 0.5035
 4288/14423 [=======>......................] - ETA: 1s - loss: 7.9839 - acc: 0.5047
 4608/14423 [========>.....................] - ETA: 1s - loss: 8.0660 - acc: 0.4996
 4928/14423 [=========>....................] - ETA: 1s - loss: 8.0819 - acc: 0.4986
 5248/14423 [=========>....................] - ETA: 1s - loss: 8.1328 - acc: 0.4954
 5568/14423 [==========>...................] - ETA: 1s - loss: 8.1083 - acc: 0.4969
 5888/14423 [===========>..................] - ETA: 1s - loss: 8.0974 - acc: 0.4976
 6208/14423 [===========>..................] - ETA: 1s - loss: 8.0876 - acc: 0.4982
 6528/14423 [============>.................] - ETA: 1s - loss: 8.1010 - acc: 0.4974
 6848/14423 [=============>................] - ETA: 1s - loss: 8.0991 - acc: 0.4975
 7168/14423 [=============>................] - ETA: 1s - loss: 8.1153 - acc: 0.4965
 7488/14423 [==============>...............] - ETA: 1s - loss: 8.1086 - acc: 0.4969
 7808/14423 [===============>..............] - ETA: 1s - loss: 8.0838 - acc: 0.4985
 8128/14423 [===============>..............] - ETA: 1s - loss: 8.0789 - acc: 0.4988
 8448/14423 [================>.............] - ETA: 1s - loss: 8.0571 - acc: 0.5001
 8768/14423 [=================>............] - ETA: 1s - loss: 8.0499 - acc: 0.5006
 8960/14423 [=================>............] - ETA: 0s - loss: 8.0519 - acc: 0.5004
 9280/14423 [==================>...........] - ETA: 0s - loss: 8.0469 - acc: 0.5008
 9472/14423 [==================>...........] - ETA: 0s - loss: 8.0539 - acc: 0.5003
 9600/14423 [==================>...........] - ETA: 0s - loss: 8.0658 - acc: 0.4996
 9728/14423 [===================>..........] - ETA: 0s - loss: 8.0706 - acc: 0.4993
 9856/14423 [===================>..........] - ETA: 0s - loss: 8.0803 - acc: 0.4987
 9984/14423 [===================>..........] - ETA: 0s - loss: 8.0784 - acc: 0.4988
10176/14423 [====================>.........] - ETA: 0s - loss: 8.0464 - acc: 0.5008
10368/14423 [====================>.........] - ETA: 0s - loss: 8.0373 - acc: 0.5014
10496/14423 [====================>.........] - ETA: 0s - loss: 8.0468 - acc: 0.5008
10752/14423 [=====================>........] - ETA: 0s - loss: 8.0471 - acc: 0.5007
11008/14423 [=====================>........] - ETA: 0s - loss: 8.0488 - acc: 0.5006
11264/14423 [======================>.......] - ETA: 0s - loss: 8.0505 - acc: 0.5005
11456/14423 [======================>.......] - ETA: 0s - loss: 8.0506 - acc: 0.5005
11712/14423 [=======================>......] - ETA: 0s - loss: 8.0453 - acc: 0.5009
12032/14423 [========================>.....] - ETA: 0s - loss: 8.0323 - acc: 0.5017
12224/14423 [========================>.....] - ETA: 0s - loss: 8.0287 - acc: 0.5019
12416/14423 [========================>.....] - ETA: 0s - loss: 8.0370 - acc: 0.5014
12608/14423 [=========================>....] - ETA: 0s - loss: 8.0309 - acc: 0.5017
12800/14423 [=========================>....] - ETA: 0s - loss: 8.0339 - acc: 0.5016
13056/14423 [==========================>...] - ETA: 0s - loss: 8.0405 - acc: 0.5011
13376/14423 [==========================>...] - ETA: 0s - loss: 8.0422 - acc: 0.5010
13696/14423 [===========================>..] - ETA: 0s - loss: 8.0355 - acc: 0.5015
14016/14423 [============================>.] - ETA: 0s - loss: 8.0418 - acc: 0.5011
14272/14423 [============================>.] - ETA: 0s - loss: 8.0545 - acc: 0.5003
14423/14423 [==============================] - 3s 208us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03274394237066

data size :  15950

zero :  7976

one :  7974

train_zero :  7212

train_one :  7211

test_zero :  764

test_one :  763

choose_zero :  1527

choose_one :  0

F1score :  0.0

AUC : 0.3877656399031105

Confusion Matrix
[[764   0]
 [763   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.05848898408582], 'acc': [0.5000346668288271]}
Saved model to disk



8

Epoch 1/1

   64/14423 [..............................] - ETA: 3s - loss: 8.0590 - acc: 0.5000
  320/14423 [..............................] - ETA: 3s - loss: 8.4116 - acc: 0.4781
  576/14423 [>.............................] - ETA: 3s - loss: 8.2829 - acc: 0.4861
  896/14423 [>.............................] - ETA: 2s - loss: 8.1130 - acc: 0.4967
 1216/14423 [=>............................] - ETA: 2s - loss: 8.2181 - acc: 0.4901
 1472/14423 [==>...........................] - ETA: 2s - loss: 8.2780 - acc: 0.4864
 1792/14423 [==>...........................] - ETA: 2s - loss: 8.2839 - acc: 0.4860
 2112/14423 [===>..........................] - ETA: 2s - loss: 8.2346 - acc: 0.4891
 2432/14423 [====>.........................] - ETA: 2s - loss: 8.2181 - acc: 0.4901
 2752/14423 [====>.........................] - ETA: 2s - loss: 8.1879 - acc: 0.4920
 3072/14423 [=====>........................] - ETA: 2s - loss: 8.1377 - acc: 0.4951
 3392/14423 [======>.......................] - ETA: 2s - loss: 8.2064 - acc: 0.4909
 3712/14423 [======>.......................] - ETA: 1s - loss: 8.2240 - acc: 0.4898
 4032/14423 [=======>......................] - ETA: 1s - loss: 8.1350 - acc: 0.4953
 4416/14423 [========>.....................] - ETA: 1s - loss: 8.1247 - acc: 0.4959
 4736/14423 [========>.....................] - ETA: 1s - loss: 8.1748 - acc: 0.4928
 5056/14423 [=========>....................] - ETA: 1s - loss: 8.1642 - acc: 0.4935
 5376/14423 [==========>...................] - ETA: 1s - loss: 8.1820 - acc: 0.4924
 5696/14423 [==========>...................] - ETA: 1s - loss: 8.1496 - acc: 0.4944
 6016/14423 [===========>..................] - ETA: 1s - loss: 8.1662 - acc: 0.4934
 6336/14423 [============>.................] - ETA: 1s - loss: 8.1328 - acc: 0.4954
 6656/14423 [============>.................] - ETA: 1s - loss: 8.1511 - acc: 0.4943
 6976/14423 [=============>................] - ETA: 1s - loss: 8.1422 - acc: 0.4948
 7296/14423 [==============>...............] - ETA: 1s - loss: 8.1209 - acc: 0.4962
 7616/14423 [==============>...............] - ETA: 1s - loss: 8.1183 - acc: 0.4963
 7936/14423 [===============>..............] - ETA: 1s - loss: 8.1322 - acc: 0.4955
 8256/14423 [================>.............] - ETA: 1s - loss: 8.1371 - acc: 0.4952
 8576/14423 [================>.............] - ETA: 1s - loss: 8.1267 - acc: 0.4958
 8896/14423 [=================>............] - ETA: 0s - loss: 8.1170 - acc: 0.4964
 9216/14423 [==================>...........] - ETA: 0s - loss: 8.1290 - acc: 0.4957
 9536/14423 [==================>...........] - ETA: 0s - loss: 8.1250 - acc: 0.4959
 9856/14423 [===================>..........] - ETA: 0s - loss: 8.1294 - acc: 0.4956
10176/14423 [====================>.........] - ETA: 0s - loss: 8.1240 - acc: 0.4960
10496/14423 [====================>.........] - ETA: 0s - loss: 8.1128 - acc: 0.4967
10816/14423 [=====================>........] - ETA: 0s - loss: 8.1127 - acc: 0.4967
11136/14423 [======================>.......] - ETA: 0s - loss: 8.0996 - acc: 0.4975
11456/14423 [======================>.......] - ETA: 0s - loss: 8.0900 - acc: 0.4981
11776/14423 [=======================>......] - ETA: 0s - loss: 8.0960 - acc: 0.4977
12096/14423 [========================>.....] - ETA: 0s - loss: 8.0924 - acc: 0.4979
12416/14423 [========================>.....] - ETA: 0s - loss: 8.0993 - acc: 0.4975
12736/14423 [=========================>....] - ETA: 0s - loss: 8.0970 - acc: 0.4976
13056/14423 [==========================>...] - ETA: 0s - loss: 8.0739 - acc: 0.4991
13376/14423 [==========================>...] - ETA: 0s - loss: 8.0530 - acc: 0.5004
13696/14423 [===========================>..] - ETA: 0s - loss: 8.0355 - acc: 0.5015
13824/14423 [===========================>..] - ETA: 0s - loss: 8.0404 - acc: 0.5012
14080/14423 [============================>.] - ETA: 0s - loss: 8.0533 - acc: 0.5004
14336/14423 [============================>.] - ETA: 0s - loss: 8.0501 - acc: 0.5006
14423/14423 [==============================] - 3s 180us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03274394237066

data size :  15950

zero :  7976

one :  7974

train_zero :  7212

train_one :  7211

test_zero :  764

test_one :  763

choose_zero :  1527

choose_one :  0

F1score :  0.0

AUC : 0.3877656399031105

Confusion Matrix
[[764   0]
 [763   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058489013377766], 'acc': [0.5000346668401918]}
Saved model to disk



9

Epoch 1/1

   64/14423 [..............................] - ETA: 4s - loss: 9.5701 - acc: 0.4062
  320/14423 [..............................] - ETA: 3s - loss: 8.3109 - acc: 0.4844
  576/14423 [>.............................] - ETA: 3s - loss: 7.8912 - acc: 0.5104
  832/14423 [>.............................] - ETA: 2s - loss: 7.8072 - acc: 0.5156
 1088/14423 [=>............................] - ETA: 2s - loss: 7.7628 - acc: 0.5184
 1408/14423 [=>............................] - ETA: 2s - loss: 7.8530 - acc: 0.5128
 1728/14423 [==>...........................] - ETA: 2s - loss: 7.8912 - acc: 0.5104
 1920/14423 [==>...........................] - ETA: 2s - loss: 7.8995 - acc: 0.5099
 2112/14423 [===>..........................] - ETA: 2s - loss: 7.8912 - acc: 0.5104
 2240/14423 [===>..........................] - ETA: 2s - loss: 7.8288 - acc: 0.5143
 2368/14423 [===>..........................] - ETA: 3s - loss: 7.8276 - acc: 0.5144
 2560/14423 [====>.........................] - ETA: 3s - loss: 7.7946 - acc: 0.5164
 2752/14423 [====>.........................] - ETA: 3s - loss: 7.8599 - acc: 0.5124
 2944/14423 [=====>........................] - ETA: 2s - loss: 7.8893 - acc: 0.5105
 3200/14423 [=====>........................] - ETA: 2s - loss: 7.8425 - acc: 0.5134
 3456/14423 [======>.......................] - ETA: 2s - loss: 7.8492 - acc: 0.5130
 3776/14423 [======>.......................] - ETA: 2s - loss: 7.8542 - acc: 0.5127
 4096/14423 [=======>......................] - ETA: 2s - loss: 7.9134 - acc: 0.5090
 4416/14423 [========>.....................] - ETA: 2s - loss: 7.9167 - acc: 0.5088
 4736/14423 [========>.....................] - ETA: 2s - loss: 7.8923 - acc: 0.5103
 5056/14423 [=========>....................] - ETA: 2s - loss: 7.9220 - acc: 0.5085
 5376/14423 [==========>...................] - ETA: 2s - loss: 7.9391 - acc: 0.5074
 5696/14423 [==========>...................] - ETA: 1s - loss: 8.0053 - acc: 0.5033
 6016/14423 [===========>..................] - ETA: 1s - loss: 8.0162 - acc: 0.5027
 6400/14423 [============>.................] - ETA: 1s - loss: 8.0213 - acc: 0.5023
 6720/14423 [============>.................] - ETA: 1s - loss: 8.0255 - acc: 0.5021
 7104/14423 [=============>................] - ETA: 1s - loss: 8.0296 - acc: 0.5018
 7424/14423 [==============>...............] - ETA: 1s - loss: 8.0460 - acc: 0.5008
 7744/14423 [===============>..............] - ETA: 1s - loss: 8.0778 - acc: 0.4988
 8064/14423 [===============>..............] - ETA: 1s - loss: 8.0491 - acc: 0.5006
 8448/14423 [================>.............] - ETA: 1s - loss: 8.0762 - acc: 0.4989
 8768/14423 [=================>............] - ETA: 1s - loss: 8.0903 - acc: 0.4981
 9152/14423 [==================>...........] - ETA: 1s - loss: 8.1066 - acc: 0.4970
 9472/14423 [==================>...........] - ETA: 0s - loss: 8.1101 - acc: 0.4968
 9792/14423 [===================>..........] - ETA: 0s - loss: 8.0788 - acc: 0.4988
10112/14423 [====================>.........] - ETA: 0s - loss: 8.0686 - acc: 0.4994
10432/14423 [====================>.........] - ETA: 0s - loss: 8.0699 - acc: 0.4993
10752/14423 [=====================>........] - ETA: 0s - loss: 8.0845 - acc: 0.4984
11072/14423 [======================>.......] - ETA: 0s - loss: 8.0853 - acc: 0.4984
11392/14423 [======================>.......] - ETA: 0s - loss: 8.0732 - acc: 0.4991
11712/14423 [=======================>......] - ETA: 0s - loss: 8.0893 - acc: 0.4981
12032/14423 [========================>.....] - ETA: 0s - loss: 8.0832 - acc: 0.4985
12352/14423 [========================>.....] - ETA: 0s - loss: 8.0773 - acc: 0.4989
12672/14423 [=========================>....] - ETA: 0s - loss: 8.0641 - acc: 0.4997
12992/14423 [==========================>...] - ETA: 0s - loss: 8.0541 - acc: 0.5003
13312/14423 [==========================>...] - ETA: 0s - loss: 8.0397 - acc: 0.5012
13632/14423 [===========================>..] - ETA: 0s - loss: 8.0366 - acc: 0.5014
13952/14423 [============================>.] - ETA: 0s - loss: 8.0440 - acc: 0.5009
14272/14423 [============================>.] - ETA: 0s - loss: 8.0557 - acc: 0.5002
14423/14423 [==============================] - 3s 188us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03274394237066

data size :  15950

zero :  7976

one :  7974

train_zero :  7212

train_one :  7211

test_zero :  764

test_one :  763

choose_zero :  1527

choose_one :  0

F1score :  0.0

AUC : 0.3877656399031105

Confusion Matrix
[[764   0]
 [763   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058489004517448], 'acc': [0.5000346668598218]}
Saved model to disk



10

Epoch 1/1

   64/14423 [..............................] - ETA: 3s - loss: 7.8072 - acc: 0.5156
  320/14423 [..............................] - ETA: 3s - loss: 8.7138 - acc: 0.4594
  512/14423 [>.............................] - ETA: 3s - loss: 8.6257 - acc: 0.4648
  768/14423 [>.............................] - ETA: 3s - loss: 8.4998 - acc: 0.4727
  960/14423 [>.............................] - ETA: 3s - loss: 8.4788 - acc: 0.4740
 1216/14423 [=>............................] - ETA: 3s - loss: 8.3639 - acc: 0.4811
 1408/14423 [=>............................] - ETA: 3s - loss: 8.3796 - acc: 0.4801
 1600/14423 [==>...........................] - ETA: 3s - loss: 8.3814 - acc: 0.4800
 1856/14423 [==>...........................] - ETA: 3s - loss: 8.4151 - acc: 0.4779
 1984/14423 [===>..........................] - ETA: 3s - loss: 8.3921 - acc: 0.4793
 2112/14423 [===>..........................] - ETA: 3s - loss: 8.4483 - acc: 0.4759
 2304/14423 [===>..........................] - ETA: 3s - loss: 8.4578 - acc: 0.4753
 2560/14423 [====>.........................] - ETA: 3s - loss: 8.5061 - acc: 0.4723
 2816/14423 [====>.........................] - ETA: 3s - loss: 8.4712 - acc: 0.4744
 3072/14423 [=====>........................] - ETA: 3s - loss: 8.4158 - acc: 0.4779
 3328/14423 [=====>........................] - ETA: 3s - loss: 8.3884 - acc: 0.4796
 3520/14423 [======>.......................] - ETA: 2s - loss: 8.3567 - acc: 0.4815
 3776/14423 [======>.......................] - ETA: 2s - loss: 8.3152 - acc: 0.4841
 4032/14423 [=======>......................] - ETA: 2s - loss: 8.2989 - acc: 0.4851
 4352/14423 [========>.....................] - ETA: 2s - loss: 8.2924 - acc: 0.4855
 4672/14423 [========>.....................] - ETA: 2s - loss: 8.2281 - acc: 0.4895
 4992/14423 [=========>....................] - ETA: 2s - loss: 8.2011 - acc: 0.4912
 5312/14423 [==========>...................] - ETA: 2s - loss: 8.1804 - acc: 0.4925
 5632/14423 [==========>...................] - ETA: 2s - loss: 8.1936 - acc: 0.4917
 5952/14423 [===========>..................] - ETA: 2s - loss: 8.2080 - acc: 0.4908
 6272/14423 [============>.................] - ETA: 1s - loss: 8.1696 - acc: 0.4931
 6592/14423 [============>.................] - ETA: 1s - loss: 8.1740 - acc: 0.4929
 6848/14423 [=============>................] - ETA: 1s - loss: 8.1720 - acc: 0.4930
 6976/14423 [=============>................] - ETA: 1s - loss: 8.1838 - acc: 0.4923
 7104/14423 [=============>................] - ETA: 1s - loss: 8.1929 - acc: 0.4917
 7360/14423 [==============>...............] - ETA: 1s - loss: 8.1861 - acc: 0.4921
 7680/14423 [==============>...............] - ETA: 1s - loss: 8.1808 - acc: 0.4924
 8000/14423 [===============>..............] - ETA: 1s - loss: 8.1779 - acc: 0.4926
 8384/14423 [================>.............] - ETA: 1s - loss: 8.1552 - acc: 0.4940
 8640/14423 [================>.............] - ETA: 1s - loss: 8.1262 - acc: 0.4958
 8896/14423 [=================>............] - ETA: 1s - loss: 8.1460 - acc: 0.4946
 9216/14423 [==================>...........] - ETA: 1s - loss: 8.1430 - acc: 0.4948
 9536/14423 [==================>...........] - ETA: 1s - loss: 8.1351 - acc: 0.4953
 9792/14423 [===================>..........] - ETA: 1s - loss: 8.1331 - acc: 0.4954
10048/14423 [===================>..........] - ETA: 0s - loss: 8.1344 - acc: 0.4953
10368/14423 [====================>.........] - ETA: 0s - loss: 8.1306 - acc: 0.4956
10688/14423 [=====================>........] - ETA: 0s - loss: 8.1133 - acc: 0.4966
11008/14423 [=====================>........] - ETA: 0s - loss: 8.1191 - acc: 0.4963
11328/14423 [======================>.......] - ETA: 0s - loss: 8.1060 - acc: 0.4971
11648/14423 [=======================>......] - ETA: 0s - loss: 8.0964 - acc: 0.4977
11968/14423 [=======================>......] - ETA: 0s - loss: 8.0792 - acc: 0.4987
12288/14423 [========================>.....] - ETA: 0s - loss: 8.0669 - acc: 0.4995
12608/14423 [=========================>....] - ETA: 0s - loss: 8.0565 - acc: 0.5002
12928/14423 [=========================>....] - ETA: 0s - loss: 8.0603 - acc: 0.4999
13248/14423 [==========================>...] - ETA: 0s - loss: 8.0493 - acc: 0.5006
13568/14423 [===========================>..] - ETA: 0s - loss: 8.0674 - acc: 0.4995
13888/14423 [===========================>..] - ETA: 0s - loss: 8.0660 - acc: 0.4996
14208/14423 [============================>.] - ETA: 0s - loss: 8.0556 - acc: 0.5002
14423/14423 [==============================] - 3s 209us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03274394237066

data size :  15950

zero :  7976

one :  7974

train_zero :  7212

train_one :  7211

test_zero :  764

test_one :  763

choose_zero :  1527

choose_one :  0

F1score :  0.0

AUC : 0.3877656399031105

Confusion Matrix
[[764   0]
 [763   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.05848896725783], 'acc': [0.5000346668267609]}
Saved model to disk



11

Epoch 1/1

   64/14423 [..............................] - ETA: 2s - loss: 7.8072 - acc: 0.5156
  384/14423 [..............................] - ETA: 2s - loss: 8.8985 - acc: 0.4479
  704/14423 [>.............................] - ETA: 2s - loss: 8.7459 - acc: 0.4574
 1024/14423 [=>............................] - ETA: 2s - loss: 8.4840 - acc: 0.4736
 1344/14423 [=>............................] - ETA: 2s - loss: 8.1670 - acc: 0.4933
 1664/14423 [==>...........................] - ETA: 2s - loss: 7.9719 - acc: 0.5054
 1856/14423 [==>...........................] - ETA: 2s - loss: 7.9288 - acc: 0.5081
 2176/14423 [===>..........................] - ETA: 2s - loss: 7.7479 - acc: 0.5193
 2304/14423 [===>..........................] - ETA: 2s - loss: 7.7372 - acc: 0.5200
 2496/14423 [====>.........................] - ETA: 2s - loss: 7.7749 - acc: 0.5176
 2624/14423 [====>.........................] - ETA: 2s - loss: 7.8133 - acc: 0.5152
 2880/14423 [====>.........................] - ETA: 2s - loss: 7.9135 - acc: 0.5090
 3008/14423 [=====>........................] - ETA: 2s - loss: 7.9197 - acc: 0.5086
 3200/14423 [=====>........................] - ETA: 2s - loss: 7.8878 - acc: 0.5106
 3392/14423 [======>.......................] - ETA: 2s - loss: 7.8880 - acc: 0.5106
 3648/14423 [======>.......................] - ETA: 2s - loss: 7.9000 - acc: 0.5099
 3840/14423 [======>.......................] - ETA: 2s - loss: 7.9121 - acc: 0.5091
 4032/14423 [=======>......................] - ETA: 2s - loss: 7.9631 - acc: 0.5060
 4160/14423 [=======>......................] - ETA: 2s - loss: 7.9273 - acc: 0.5082
 4352/14423 [========>.....................] - ETA: 2s - loss: 7.9479 - acc: 0.5069
 4608/14423 [========>.....................] - ETA: 2s - loss: 7.9926 - acc: 0.5041
 4864/14423 [=========>....................] - ETA: 2s - loss: 8.0226 - acc: 0.5023
 5120/14423 [=========>....................] - ETA: 2s - loss: 7.9929 - acc: 0.5041
 5376/14423 [==========>...................] - ETA: 2s - loss: 7.9781 - acc: 0.5050
 5632/14423 [==========>...................] - ETA: 2s - loss: 8.0047 - acc: 0.5034
 5824/14423 [===========>..................] - ETA: 2s - loss: 8.0175 - acc: 0.5026
 6080/14423 [===========>..................] - ETA: 2s - loss: 7.9875 - acc: 0.5044
 6336/14423 [============>.................] - ETA: 2s - loss: 7.9929 - acc: 0.5041
 6656/14423 [============>.................] - ETA: 1s - loss: 7.9694 - acc: 0.5056
 6976/14423 [=============>................] - ETA: 1s - loss: 7.9759 - acc: 0.5052
 7296/14423 [==============>...............] - ETA: 1s - loss: 7.9596 - acc: 0.5062
 7616/14423 [==============>...............] - ETA: 1s - loss: 7.9977 - acc: 0.5038
 7936/14423 [===============>..............] - ETA: 1s - loss: 8.0123 - acc: 0.5029
 8256/14423 [================>.............] - ETA: 1s - loss: 7.9946 - acc: 0.5040
 8512/14423 [================>.............] - ETA: 1s - loss: 8.0098 - acc: 0.5031
 8640/14423 [================>.............] - ETA: 1s - loss: 8.0124 - acc: 0.5029
 8768/14423 [=================>............] - ETA: 1s - loss: 8.0021 - acc: 0.5035
 8960/14423 [=================>............] - ETA: 1s - loss: 7.9979 - acc: 0.5038
 9216/14423 [==================>...........] - ETA: 1s - loss: 8.0083 - acc: 0.5031
 9472/14423 [==================>...........] - ETA: 1s - loss: 8.0097 - acc: 0.5031
 9728/14423 [===================>..........] - ETA: 1s - loss: 8.0243 - acc: 0.5022
 9984/14423 [===================>..........] - ETA: 1s - loss: 8.0445 - acc: 0.5009
10240/14423 [====================>.........] - ETA: 1s - loss: 8.0575 - acc: 0.5001
10560/14423 [====================>.........] - ETA: 0s - loss: 8.0453 - acc: 0.5009
10880/14423 [=====================>........] - ETA: 0s - loss: 8.0487 - acc: 0.5006
11200/14423 [======================>.......] - ETA: 0s - loss: 8.0677 - acc: 0.4995
11520/14423 [======================>.......] - ETA: 0s - loss: 8.0493 - acc: 0.5006
11776/14423 [=======================>......] - ETA: 0s - loss: 8.0686 - acc: 0.4994
12096/14423 [========================>.....] - ETA: 0s - loss: 8.0537 - acc: 0.5003
12416/14423 [========================>.....] - ETA: 0s - loss: 8.0603 - acc: 0.4999
12736/14423 [=========================>....] - ETA: 0s - loss: 8.0692 - acc: 0.4994
13056/14423 [==========================>...] - ETA: 0s - loss: 8.0467 - acc: 0.5008
13376/14423 [==========================>...] - ETA: 0s - loss: 8.0603 - acc: 0.4999
13696/14423 [===========================>..] - ETA: 0s - loss: 8.0579 - acc: 0.5001
14016/14423 [============================>.] - ETA: 0s - loss: 8.0579 - acc: 0.5001
14336/14423 [============================>.] - ETA: 0s - loss: 8.0613 - acc: 0.4999
14423/14423 [==============================] - 3s 224us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03274394237066

data size :  15950

zero :  7976

one :  7974

train_zero :  7212

train_one :  7211

test_zero :  764

test_one :  763

choose_zero :  1527

choose_one :  0

F1score :  0.0

AUC : 0.3877656399031105

Confusion Matrix
[[764   0]
 [763   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058488998434244], 'acc': [0.5000346668102305]}
Saved model to disk



12

Epoch 1/1

   64/14423 [..............................] - ETA: 3s - loss: 8.5627 - acc: 0.4688
  320/14423 [..............................] - ETA: 3s - loss: 7.9583 - acc: 0.5062
  640/14423 [>.............................] - ETA: 2s - loss: 7.7568 - acc: 0.5188
  960/14423 [>.............................] - ETA: 2s - loss: 7.7233 - acc: 0.5208
 1280/14423 [=>............................] - ETA: 2s - loss: 7.7946 - acc: 0.5164
 1600/14423 [==>...........................] - ETA: 2s - loss: 7.9281 - acc: 0.5081
 1920/14423 [==>...........................] - ETA: 2s - loss: 7.8744 - acc: 0.5115
 2240/14423 [===>..........................] - ETA: 2s - loss: 7.8864 - acc: 0.5107
 2560/14423 [====>.........................] - ETA: 2s - loss: 7.8828 - acc: 0.5109
 2880/14423 [====>.........................] - ETA: 2s - loss: 7.8016 - acc: 0.5160
 3200/14423 [=====>........................] - ETA: 2s - loss: 7.8676 - acc: 0.5119
 3456/14423 [======>.......................] - ETA: 2s - loss: 7.9704 - acc: 0.5055
 3776/14423 [======>.......................] - ETA: 1s - loss: 7.9865 - acc: 0.5045
 4096/14423 [=======>......................] - ETA: 1s - loss: 8.0079 - acc: 0.5032
 4416/14423 [========>.....................] - ETA: 1s - loss: 8.0262 - acc: 0.5020
 4544/14423 [========>.....................] - ETA: 1s - loss: 8.0342 - acc: 0.5015
 4800/14423 [========>.....................] - ETA: 1s - loss: 8.0288 - acc: 0.5019
 4928/14423 [=========>....................] - ETA: 1s - loss: 8.0427 - acc: 0.5010
 5056/14423 [=========>....................] - ETA: 1s - loss: 8.0272 - acc: 0.5020
 5248/14423 [=========>....................] - ETA: 1s - loss: 8.0130 - acc: 0.5029
 5440/14423 [==========>...................] - ETA: 1s - loss: 7.9879 - acc: 0.5044
 5632/14423 [==========>...................] - ETA: 1s - loss: 8.0133 - acc: 0.5028
 5824/14423 [===========>..................] - ETA: 1s - loss: 8.0563 - acc: 0.5002
 6016/14423 [===========>..................] - ETA: 1s - loss: 8.0751 - acc: 0.4990
 6208/14423 [===========>..................] - ETA: 1s - loss: 8.0539 - acc: 0.5003
 6464/14423 [============>.................] - ETA: 1s - loss: 8.0266 - acc: 0.5020
 6656/14423 [============>.................] - ETA: 1s - loss: 8.0276 - acc: 0.5020
 6784/14423 [=============>................] - ETA: 1s - loss: 8.0472 - acc: 0.5007
 6976/14423 [=============>................] - ETA: 1s - loss: 8.0475 - acc: 0.5007
 7168/14423 [=============>................] - ETA: 1s - loss: 8.0276 - acc: 0.5020
 7424/14423 [==============>...............] - ETA: 1s - loss: 8.0135 - acc: 0.5028
 7616/14423 [==============>...............] - ETA: 1s - loss: 8.0083 - acc: 0.5032
 7872/14423 [===============>..............] - ETA: 1s - loss: 7.9915 - acc: 0.5042
 8128/14423 [===============>..............] - ETA: 1s - loss: 8.0214 - acc: 0.5023
 8384/14423 [================>.............] - ETA: 1s - loss: 8.0437 - acc: 0.5010
 8640/14423 [================>.............] - ETA: 1s - loss: 8.0404 - acc: 0.5012
 8960/14423 [=================>............] - ETA: 1s - loss: 8.0519 - acc: 0.5004
 9280/14423 [==================>...........] - ETA: 1s - loss: 8.0643 - acc: 0.4997
 9600/14423 [==================>...........] - ETA: 1s - loss: 8.0590 - acc: 0.5000
 9920/14423 [===================>..........] - ETA: 1s - loss: 8.0639 - acc: 0.4997
10240/14423 [====================>.........] - ETA: 0s - loss: 8.0748 - acc: 0.4990
10560/14423 [====================>.........] - ETA: 0s - loss: 8.0682 - acc: 0.4994
10816/14423 [=====================>........] - ETA: 0s - loss: 8.0695 - acc: 0.4994
11008/14423 [=====================>........] - ETA: 0s - loss: 8.0839 - acc: 0.4985
11200/14423 [======================>.......] - ETA: 0s - loss: 8.0835 - acc: 0.4985
11456/14423 [======================>.......] - ETA: 0s - loss: 8.0703 - acc: 0.4993
11776/14423 [=======================>......] - ETA: 0s - loss: 8.0673 - acc: 0.4995
12096/14423 [========================>.....] - ETA: 0s - loss: 8.0577 - acc: 0.5001
12352/14423 [========================>.....] - ETA: 0s - loss: 8.0551 - acc: 0.5002
12672/14423 [=========================>....] - ETA: 0s - loss: 8.0743 - acc: 0.4991
12928/14423 [=========================>....] - ETA: 0s - loss: 8.0777 - acc: 0.4988
13184/14423 [==========================>...] - ETA: 0s - loss: 8.0664 - acc: 0.4995
13504/14423 [===========================>..] - ETA: 0s - loss: 8.0602 - acc: 0.4999
13824/14423 [===========================>..] - ETA: 0s - loss: 8.0590 - acc: 0.5000
14144/14423 [============================>.] - ETA: 0s - loss: 8.0568 - acc: 0.5001
14423/14423 [==============================] - 3s 226us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03274394237066

data size :  15950

zero :  7976

one :  7974

train_zero :  7212

train_one :  7211

test_zero :  764

test_one :  763

choose_zero :  1527

choose_one :  0

F1score :  0.0

AUC : 0.3877656399031105

Confusion Matrix
[[764   0]
 [763   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058489007459867], 'acc': [0.5000346668267609]}
Saved model to disk



13

Epoch 1/1

   64/14423 [..............................] - ETA: 3s - loss: 7.5554 - acc: 0.5312
  320/14423 [..............................] - ETA: 2s - loss: 8.2605 - acc: 0.4875
  640/14423 [>.............................] - ETA: 2s - loss: 8.1598 - acc: 0.4938
  960/14423 [>.............................] - ETA: 2s - loss: 7.9919 - acc: 0.5042
 1280/14423 [=>............................] - ETA: 2s - loss: 7.7694 - acc: 0.5180
 1600/14423 [==>...........................] - ETA: 2s - loss: 7.8072 - acc: 0.5156
 1920/14423 [==>...........................] - ETA: 2s - loss: 7.7736 - acc: 0.5177
 2240/14423 [===>..........................] - ETA: 2s - loss: 7.8144 - acc: 0.5152
 2560/14423 [====>.........................] - ETA: 2s - loss: 7.7883 - acc: 0.5168
 2880/14423 [====>.........................] - ETA: 2s - loss: 7.8128 - acc: 0.5153
 3200/14423 [=====>........................] - ETA: 1s - loss: 7.8274 - acc: 0.5144
 3520/14423 [======>.......................] - ETA: 1s - loss: 7.8164 - acc: 0.5151
 3840/14423 [======>.......................] - ETA: 1s - loss: 7.7610 - acc: 0.5185
 4160/14423 [=======>......................] - ETA: 1s - loss: 7.7995 - acc: 0.5161
 4480/14423 [========>.....................] - ETA: 1s - loss: 7.8504 - acc: 0.5129
 4800/14423 [========>.....................] - ETA: 1s - loss: 7.8912 - acc: 0.5104
 5120/14423 [=========>....................] - ETA: 1s - loss: 7.9142 - acc: 0.5090
 5440/14423 [==========>...................] - ETA: 1s - loss: 7.9316 - acc: 0.5079
 5760/14423 [==========>...................] - ETA: 1s - loss: 7.9471 - acc: 0.5069
 5952/14423 [===========>..................] - ETA: 1s - loss: 7.9751 - acc: 0.5052
 6208/14423 [===========>..................] - ETA: 1s - loss: 7.9760 - acc: 0.5052
 6464/14423 [============>.................] - ETA: 1s - loss: 7.9817 - acc: 0.5048
 6656/14423 [============>.................] - ETA: 1s - loss: 7.9622 - acc: 0.5060
 6848/14423 [=============>................] - ETA: 1s - loss: 7.9743 - acc: 0.5053
 7040/14423 [=============>................] - ETA: 1s - loss: 7.9652 - acc: 0.5058
 7232/14423 [==============>...............] - ETA: 1s - loss: 7.9610 - acc: 0.5061
 7424/14423 [==============>...............] - ETA: 1s - loss: 7.9700 - acc: 0.5055
 7744/14423 [===============>..............] - ETA: 1s - loss: 7.9487 - acc: 0.5068
 8064/14423 [===============>..............] - ETA: 1s - loss: 7.9351 - acc: 0.5077
 8384/14423 [================>.............] - ETA: 1s - loss: 7.9648 - acc: 0.5058
 8704/14423 [=================>............] - ETA: 1s - loss: 7.9905 - acc: 0.5043
 8960/14423 [=================>............] - ETA: 1s - loss: 7.9853 - acc: 0.5046
 9152/14423 [==================>...........] - ETA: 1s - loss: 7.9816 - acc: 0.5048
 9344/14423 [==================>...........] - ETA: 1s - loss: 7.9693 - acc: 0.5056
 9536/14423 [==================>...........] - ETA: 0s - loss: 7.9847 - acc: 0.5046
 9728/14423 [===================>..........] - ETA: 0s - loss: 7.9944 - acc: 0.5040
 9920/14423 [===================>..........] - ETA: 0s - loss: 7.9892 - acc: 0.5043
10112/14423 [====================>.........] - ETA: 0s - loss: 7.9937 - acc: 0.5041
10368/14423 [====================>.........] - ETA: 0s - loss: 7.9906 - acc: 0.5042
10560/14423 [====================>.........] - ETA: 0s - loss: 7.9965 - acc: 0.5039
10816/14423 [=====================>........] - ETA: 0s - loss: 7.9965 - acc: 0.5039
11072/14423 [======================>.......] - ETA: 0s - loss: 8.0125 - acc: 0.5029
11328/14423 [======================>.......] - ETA: 0s - loss: 8.0263 - acc: 0.5020
11584/14423 [=======================>......] - ETA: 0s - loss: 8.0479 - acc: 0.5007
11904/14423 [=======================>......] - ETA: 0s - loss: 8.0658 - acc: 0.4996
12224/14423 [========================>.....] - ETA: 0s - loss: 8.0722 - acc: 0.4992
12480/14423 [========================>.....] - ETA: 0s - loss: 8.0784 - acc: 0.4988
12800/14423 [=========================>....] - ETA: 0s - loss: 8.0767 - acc: 0.4989
12992/14423 [==========================>...] - ETA: 0s - loss: 8.0764 - acc: 0.4989
13120/14423 [==========================>...] - ETA: 0s - loss: 8.0787 - acc: 0.4988
13248/14423 [==========================>...] - ETA: 0s - loss: 8.0870 - acc: 0.4983
13376/14423 [==========================>...] - ETA: 0s - loss: 8.0759 - acc: 0.4990
13632/14423 [===========================>..] - ETA: 0s - loss: 8.0626 - acc: 0.4998
13888/14423 [===========================>..] - ETA: 0s - loss: 8.0567 - acc: 0.5001
14144/14423 [============================>.] - ETA: 0s - loss: 8.0636 - acc: 0.4997
14400/14423 [============================>.] - ETA: 0s - loss: 8.0557 - acc: 0.5002
14423/14423 [==============================] - 3s 218us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03274394237066

data size :  15950

zero :  7976

one :  7974

train_zero :  7212

train_one :  7211

test_zero :  764

test_one :  763

choose_zero :  1527

choose_one :  0

F1score :  0.0

AUC : 0.3877656399031105

Confusion Matrix
[[764   0]
 [763   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058489005046422], 'acc': [0.5000346668453576]}
Saved model to disk



14

Epoch 1/1

   64/14423 [..............................] - ETA: 3s - loss: 8.3109 - acc: 0.4844
  320/14423 [..............................] - ETA: 2s - loss: 8.1598 - acc: 0.4938
  640/14423 [>.............................] - ETA: 2s - loss: 8.1094 - acc: 0.4969
  960/14423 [>.............................] - ETA: 2s - loss: 8.4284 - acc: 0.4771
 1280/14423 [=>............................] - ETA: 2s - loss: 8.3864 - acc: 0.4797
 1600/14423 [==>...........................] - ETA: 2s - loss: 8.3512 - acc: 0.4819
 1920/14423 [==>...........................] - ETA: 2s - loss: 8.2773 - acc: 0.4865
 2240/14423 [===>..........................] - ETA: 2s - loss: 8.2821 - acc: 0.4862
 2560/14423 [====>.........................] - ETA: 2s - loss: 8.2857 - acc: 0.4859
 2880/14423 [====>.........................] - ETA: 2s - loss: 8.2773 - acc: 0.4865
 3200/14423 [=====>........................] - ETA: 1s - loss: 8.2202 - acc: 0.4900
 3520/14423 [======>.......................] - ETA: 1s - loss: 8.1140 - acc: 0.4966
 3840/14423 [======>.......................] - ETA: 1s - loss: 8.0968 - acc: 0.4977
 4160/14423 [=======>......................] - ETA: 1s - loss: 8.0707 - acc: 0.4993
 4480/14423 [========>.....................] - ETA: 1s - loss: 8.0914 - acc: 0.4980
 4800/14423 [========>.....................] - ETA: 1s - loss: 8.0523 - acc: 0.5004
 5120/14423 [=========>....................] - ETA: 1s - loss: 8.0496 - acc: 0.5006
 5440/14423 [==========>...................] - ETA: 1s - loss: 8.0798 - acc: 0.4987
 5760/14423 [==========>...................] - ETA: 1s - loss: 8.1038 - acc: 0.4972
 6080/14423 [===========>..................] - ETA: 1s - loss: 8.0564 - acc: 0.5002
 6400/14423 [============>.................] - ETA: 1s - loss: 8.0540 - acc: 0.5003
 6720/14423 [============>.................] - ETA: 1s - loss: 8.0830 - acc: 0.4985
 7040/14423 [=============>................] - ETA: 1s - loss: 8.0774 - acc: 0.4989
 7232/14423 [==============>...............] - ETA: 1s - loss: 8.0858 - acc: 0.4983
 7552/14423 [==============>...............] - ETA: 1s - loss: 8.0697 - acc: 0.4993
 7872/14423 [===============>..............] - ETA: 1s - loss: 8.0631 - acc: 0.4997
 8192/14423 [================>.............] - ETA: 1s - loss: 8.0846 - acc: 0.4984
 8384/14423 [================>.............] - ETA: 1s - loss: 8.0764 - acc: 0.4989
 8640/14423 [================>.............] - ETA: 1s - loss: 8.0870 - acc: 0.4983
 8896/14423 [=================>............] - ETA: 1s - loss: 8.0790 - acc: 0.4988
 9088/14423 [=================>............] - ETA: 0s - loss: 8.0644 - acc: 0.4997
 9280/14423 [==================>...........] - ETA: 0s - loss: 8.0799 - acc: 0.4987
 9472/14423 [==================>...........] - ETA: 0s - loss: 8.0880 - acc: 0.4982
 9600/14423 [==================>...........] - ETA: 0s - loss: 8.0876 - acc: 0.4982
 9856/14423 [===================>..........] - ETA: 0s - loss: 8.1032 - acc: 0.4973
10048/14423 [===================>..........] - ETA: 0s - loss: 8.1072 - acc: 0.4970
10368/14423 [====================>.........] - ETA: 0s - loss: 8.0855 - acc: 0.4984
10752/14423 [=====================>........] - ETA: 0s - loss: 8.0935 - acc: 0.4979
11008/14423 [=====================>........] - ETA: 0s - loss: 8.0883 - acc: 0.4982
11328/14423 [======================>.......] - ETA: 0s - loss: 8.0747 - acc: 0.4990
11712/14423 [=======================>......] - ETA: 0s - loss: 8.0742 - acc: 0.4991
12096/14423 [========================>.....] - ETA: 0s - loss: 8.0977 - acc: 0.4976
12416/14423 [========================>.....] - ETA: 0s - loss: 8.0915 - acc: 0.4980
12672/14423 [=========================>....] - ETA: 0s - loss: 8.0858 - acc: 0.4983
12864/14423 [=========================>....] - ETA: 0s - loss: 8.0891 - acc: 0.4981
13056/14423 [==========================>...] - ETA: 0s - loss: 8.0850 - acc: 0.4984
13312/14423 [==========================>...] - ETA: 0s - loss: 8.0627 - acc: 0.4998
13504/14423 [===========================>..] - ETA: 0s - loss: 8.0555 - acc: 0.5002
13760/14423 [===========================>..] - ETA: 0s - loss: 8.0544 - acc: 0.5003
14080/14423 [============================>.] - ETA: 0s - loss: 8.0465 - acc: 0.5008
14336/14423 [============================>.] - ETA: 0s - loss: 8.0568 - acc: 0.5001
14423/14423 [==============================] - 3s 199us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03274394237066

data size :  15950

zero :  7976

one :  7974

train_zero :  7212

train_one :  7211

test_zero :  764

test_one :  763

choose_zero :  1527

choose_one :  0

F1score :  0.0

AUC : 0.3877656399031105

Confusion Matrix
[[764   0]
 [763   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058489025709475], 'acc': [0.5000346668432913]}
Saved model to disk



15

Epoch 1/1

   64/14423 [..............................] - ETA: 5s - loss: 9.8220 - acc: 0.3906
  320/14423 [..............................] - ETA: 3s - loss: 8.5124 - acc: 0.4719
  640/14423 [>.............................] - ETA: 3s - loss: 8.5879 - acc: 0.4672
  960/14423 [>.............................] - ETA: 2s - loss: 8.1262 - acc: 0.4958
 1280/14423 [=>............................] - ETA: 2s - loss: 7.9079 - acc: 0.5094
 1600/14423 [==>...........................] - ETA: 2s - loss: 7.9684 - acc: 0.5056
 1920/14423 [==>...........................] - ETA: 2s - loss: 7.9835 - acc: 0.5047
 2240/14423 [===>..........................] - ETA: 2s - loss: 7.9079 - acc: 0.5094
 2560/14423 [====>.........................] - ETA: 2s - loss: 7.8765 - acc: 0.5113
 2880/14423 [====>.........................] - ETA: 2s - loss: 7.9751 - acc: 0.5052
 3200/14423 [=====>........................] - ETA: 2s - loss: 7.9432 - acc: 0.5072
 3520/14423 [======>.......................] - ETA: 1s - loss: 7.9629 - acc: 0.5060
 3840/14423 [======>.......................] - ETA: 1s - loss: 8.0003 - acc: 0.5036
 4224/14423 [=======>......................] - ETA: 1s - loss: 7.9713 - acc: 0.5054
 4544/14423 [========>.....................] - ETA: 1s - loss: 7.9704 - acc: 0.5055
 4864/14423 [=========>....................] - ETA: 1s - loss: 8.0027 - acc: 0.5035
 5184/14423 [=========>....................] - ETA: 1s - loss: 8.0155 - acc: 0.5027
 5504/14423 [==========>...................] - ETA: 1s - loss: 7.9888 - acc: 0.5044
 5824/14423 [===========>..................] - ETA: 1s - loss: 7.9733 - acc: 0.5053
 6208/14423 [===========>..................] - ETA: 1s - loss: 7.9370 - acc: 0.5076
 6528/14423 [============>.................] - ETA: 1s - loss: 7.9232 - acc: 0.5084
 6848/14423 [=============>................] - ETA: 1s - loss: 7.9461 - acc: 0.5070
 7168/14423 [=============>................] - ETA: 1s - loss: 7.9646 - acc: 0.5059
 7488/14423 [==============>...............] - ETA: 1s - loss: 7.9600 - acc: 0.5061
 7808/14423 [===============>..............] - ETA: 1s - loss: 7.9579 - acc: 0.5063
 8128/14423 [===============>..............] - ETA: 1s - loss: 7.9718 - acc: 0.5054
 8448/14423 [================>.............] - ETA: 1s - loss: 7.9961 - acc: 0.5039
 8768/14423 [=================>............] - ETA: 0s - loss: 8.0094 - acc: 0.5031
 9088/14423 [=================>............] - ETA: 0s - loss: 7.9987 - acc: 0.5037
 9408/14423 [==================>...........] - ETA: 0s - loss: 7.9957 - acc: 0.5039
 9728/14423 [===================>..........] - ETA: 0s - loss: 8.0077 - acc: 0.5032
10048/14423 [===================>..........] - ETA: 0s - loss: 8.0189 - acc: 0.5025
10368/14423 [====================>.........] - ETA: 0s - loss: 8.0171 - acc: 0.5026
10688/14423 [=====================>........] - ETA: 0s - loss: 8.0244 - acc: 0.5022
11008/14423 [=====================>........] - ETA: 0s - loss: 8.0019 - acc: 0.5035
11328/14423 [======================>.......] - ETA: 0s - loss: 8.0249 - acc: 0.5021
11648/14423 [=======================>......] - ETA: 0s - loss: 8.0203 - acc: 0.5024
11968/14423 [=======================>......] - ETA: 0s - loss: 8.0281 - acc: 0.5019
12288/14423 [========================>.....] - ETA: 0s - loss: 8.0381 - acc: 0.5013
12608/14423 [=========================>....] - ETA: 0s - loss: 8.0245 - acc: 0.5021
12928/14423 [=========================>....] - ETA: 0s - loss: 8.0279 - acc: 0.5019
13120/14423 [==========================>...] - ETA: 0s - loss: 8.0197 - acc: 0.5024
13248/14423 [==========================>...] - ETA: 0s - loss: 8.0347 - acc: 0.5015
13568/14423 [===========================>..] - ETA: 0s - loss: 8.0484 - acc: 0.5007
13888/14423 [===========================>..] - ETA: 0s - loss: 8.0556 - acc: 0.5002
14208/14423 [============================>.] - ETA: 0s - loss: 8.0636 - acc: 0.4997
14400/14423 [============================>.] - ETA: 0s - loss: 8.0613 - acc: 0.4999
14423/14423 [==============================] - 3s 176us/step - loss: 8.0585 - acc: 0.5000
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)

Test accuracy: 50.03274394237066

data size :  15950

zero :  7976

one :  7974

train_zero :  7212

train_one :  7211

test_zero :  764

test_one :  763

choose_zero :  1527

choose_one :  0

F1score :  0.0

AUC : 0.3877656399031105

Confusion Matrix
[[764   0]
 [763   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'loss': [8.058489000550141], 'acc': [0.5000346668102305]}
Saved model to disk



[[50.03274394237066, 1], [50.03274394237066, 2], [50.03274394237066, 3], [50.03274394237066, 4], [50.03274394237066, 5], [50.03274394237066, 6], [50.03274394237066, 7], [50.03274394237066, 8], [50.03274394237066, 9], [50.03274394237066, 10], [50.03274394237066, 11], [50.03274394237066, 12], [50.03274394237066, 13], [50.03274394237066, 14], [50.03274394237066, 15]]
max accuracy :  [50.03274394237066, 15]
