Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
sum_MLP.py:400: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor("de..., inputs=Tensor("in...)`
  model = Model(input=inputs, output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-08-21 14:29:20.857415: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-21 14:29:20.870121: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099840000 Hz
2019-08-21 14:29:20.872223: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x67e1f60 executing computations on platform Host. Devices:
2019-08-21 14:29:20.872260: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
zero : 
39451

one : 
9019
hbase-AST
all data

Sentence length Average : 35

Under 10 : 21694
Over 10, Under 200 : 25475
Over 200, Under 400 : 1121
Over 400 : 180

hbase-AST
updated_train_data

Sentence length Average : 59

Under 10 : 0
Over 10, Under 200 : 22932
Over 200, Under 400 : 1156
Over 400 : 0


Test_zero:  1866
Train_zero:  16848
zero:  18714
Test_one:  764
Train_one:  7240
one:  8004

Count model parameter.
Get a short summary of each layer dimensions and parameters.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 200)               0         
_________________________________________________________________
masking_1 (Masking)          (None, 200)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              205824    
_________________________________________________________________
dropout_1 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
dropout_2 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 2050      
=================================================================
Total params: 1,257,474
Trainable params: 1,257,474
Non-trainable params: 0
_________________________________________________________________
1

Epoch 1/1

   64/14481 [..............................] - ETA: 1:29 - loss: 2.7341 - acc: 0.5469
  256/14481 [..............................] - ETA: 25s - loss: 6.2241 - acc: 0.5430 
  448/14481 [..............................] - ETA: 16s - loss: 6.9745 - acc: 0.5268
  640/14481 [>.............................] - ETA: 13s - loss: 7.3754 - acc: 0.5141
  832/14481 [>.............................] - ETA: 11s - loss: 7.6107 - acc: 0.5060
 1024/14481 [=>............................] - ETA: 9s - loss: 7.8364 - acc: 0.4961 
 1152/14481 [=>............................] - ETA: 9s - loss: 7.8332 - acc: 0.4983
 1344/14481 [=>............................] - ETA: 8s - loss: 7.8534 - acc: 0.4993
 1536/14481 [==>...........................] - ETA: 7s - loss: 7.9106 - acc: 0.4974
 1728/14481 [==>...........................] - ETA: 7s - loss: 8.0577 - acc: 0.4896
 1920/14481 [==>...........................] - ETA: 6s - loss: 8.0746 - acc: 0.4896
 2176/14481 [===>..........................] - ETA: 6s - loss: 8.0728 - acc: 0.4908
 2368/14481 [===>..........................] - ETA: 5s - loss: 8.0581 - acc: 0.4924
 2624/14481 [====>.........................] - ETA: 5s - loss: 7.9783 - acc: 0.4981
 2880/14481 [====>.........................] - ETA: 5s - loss: 7.9911 - acc: 0.4979
 3136/14481 [=====>........................] - ETA: 4s - loss: 7.9761 - acc: 0.4994
 3456/14481 [======>.......................] - ETA: 4s - loss: 7.8532 - acc: 0.5075
 3712/14481 [======>.......................] - ETA: 4s - loss: 7.9325 - acc: 0.5030
 3968/14481 [=======>......................] - ETA: 3s - loss: 7.9366 - acc: 0.5030
 4224/14481 [=======>......................] - ETA: 3s - loss: 7.9211 - acc: 0.5043
 4416/14481 [========>.....................] - ETA: 3s - loss: 7.9454 - acc: 0.5029
 4544/14481 [========>.....................] - ETA: 3s - loss: 7.9592 - acc: 0.5022
 4672/14481 [========>.....................] - ETA: 3s - loss: 7.9551 - acc: 0.5026
 4864/14481 [=========>....................] - ETA: 3s - loss: 7.9923 - acc: 0.5004
 5120/14481 [=========>....................] - ETA: 3s - loss: 8.0114 - acc: 0.4994
 5312/14481 [==========>...................] - ETA: 3s - loss: 8.0192 - acc: 0.4991
 5568/14481 [==========>...................] - ETA: 3s - loss: 7.9921 - acc: 0.5009
 5824/14481 [===========>..................] - ETA: 3s - loss: 7.9922 - acc: 0.5010
 6144/14481 [===========>..................] - ETA: 2s - loss: 8.0062 - acc: 0.5003
 6400/14481 [============>.................] - ETA: 2s - loss: 8.0083 - acc: 0.5003
 6720/14481 [============>.................] - ETA: 2s - loss: 8.0107 - acc: 0.5003
 6976/14481 [=============>................] - ETA: 2s - loss: 8.0079 - acc: 0.5006
 7232/14481 [=============>................] - ETA: 2s - loss: 8.0208 - acc: 0.4999
 7552/14481 [==============>...............] - ETA: 2s - loss: 8.0310 - acc: 0.4993
 7872/14481 [===============>..............] - ETA: 2s - loss: 8.0301 - acc: 0.4995
 8192/14481 [===============>..............] - ETA: 1s - loss: 8.0174 - acc: 0.5004
 8512/14481 [================>.............] - ETA: 1s - loss: 8.0039 - acc: 0.5013
 8832/14481 [=================>............] - ETA: 1s - loss: 7.9894 - acc: 0.5023
 9152/14481 [=================>............] - ETA: 1s - loss: 7.9778 - acc: 0.5031
 9472/14481 [==================>...........] - ETA: 1s - loss: 7.9856 - acc: 0.5026
 9792/14481 [===================>..........] - ETA: 1s - loss: 7.9996 - acc: 0.5018
10112/14481 [===================>..........] - ETA: 1s - loss: 7.9727 - acc: 0.5036
10432/14481 [====================>.........] - ETA: 1s - loss: 7.9986 - acc: 0.5020
10752/14481 [=====================>........] - ETA: 1s - loss: 8.0169 - acc: 0.5009
11072/14481 [=====================>........] - ETA: 0s - loss: 8.0195 - acc: 0.5008
11328/14481 [======================>.......] - ETA: 0s - loss: 8.0361 - acc: 0.4998
11648/14481 [=======================>......] - ETA: 0s - loss: 8.0326 - acc: 0.5001
11968/14481 [=======================>......] - ETA: 0s - loss: 8.0225 - acc: 0.5008
12288/14481 [========================>.....] - ETA: 0s - loss: 8.0169 - acc: 0.5011
12608/14481 [=========================>....] - ETA: 0s - loss: 8.0295 - acc: 0.5004
12928/14481 [=========================>....] - ETA: 0s - loss: 8.0302 - acc: 0.5004
13248/14481 [==========================>...] - ETA: 0s - loss: 8.0345 - acc: 0.5002
13568/14481 [===========================>..] - ETA: 0s - loss: 8.0351 - acc: 0.5001
13888/14481 [===========================>..] - ETA: 0s - loss: 8.0252 - acc: 0.5008
14208/14481 [============================>.] - ETA: 0s - loss: 8.0317 - acc: 0.5004
14481/14481 [==============================] - 4s 255us/step - loss: 8.0294 - acc: 0.5006

Test accuracy: 50.03270111183781

data size :  16010

zero :  8006

one :  8004

train_zero :  7241

train_one :  7240

test_zero :  765

test_one :  764

choose_zero :  1529

choose_one :  0

F1score :  0.0

AUC : 0.41607381172364233

Confusion Matrix
[[765   0]
 [764   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5005869760437406], 'loss': [8.029391772278961]}
Saved model to disk



2

Epoch 1/1

   64/14481 [..............................] - ETA: 5s - loss: 8.8146 - acc: 0.4531
  320/14481 [..............................] - ETA: 3s - loss: 7.6057 - acc: 0.5281
  576/14481 [>.............................] - ETA: 3s - loss: 8.1710 - acc: 0.4931
  704/14481 [>.............................] - ETA: 3s - loss: 8.1506 - acc: 0.4943
  960/14481 [>.............................] - ETA: 3s - loss: 8.2773 - acc: 0.4865
 1152/14481 [=>............................] - ETA: 3s - loss: 8.2549 - acc: 0.4878
 1408/14481 [=>............................] - ETA: 3s - loss: 8.2079 - acc: 0.4908
 1664/14481 [==>...........................] - ETA: 3s - loss: 8.1850 - acc: 0.4922
 1920/14481 [==>...........................] - ETA: 3s - loss: 8.1010 - acc: 0.4974
 2112/14481 [===>..........................] - ETA: 3s - loss: 8.0667 - acc: 0.4995
 2304/14481 [===>..........................] - ETA: 3s - loss: 8.1290 - acc: 0.4957
 2496/14481 [====>.........................] - ETA: 3s - loss: 8.0913 - acc: 0.4980
 2688/14481 [====>.........................] - ETA: 3s - loss: 8.0710 - acc: 0.4993
 2880/14481 [====>.........................] - ETA: 3s - loss: 8.0590 - acc: 0.5000
 3136/14481 [=====>........................] - ETA: 3s - loss: 8.1104 - acc: 0.4968
 3392/14481 [======>.......................] - ETA: 3s - loss: 8.0543 - acc: 0.5003
 3648/14481 [======>.......................] - ETA: 3s - loss: 8.0635 - acc: 0.4997
 3968/14481 [=======>......................] - ETA: 2s - loss: 8.1037 - acc: 0.4972
 4288/14481 [=======>......................] - ETA: 2s - loss: 8.0778 - acc: 0.4988
 4608/14481 [========>.....................] - ETA: 2s - loss: 8.0206 - acc: 0.5024
 4864/14481 [=========>....................] - ETA: 2s - loss: 8.0093 - acc: 0.5031
 5184/14481 [=========>....................] - ETA: 2s - loss: 8.0528 - acc: 0.5004
 5504/14481 [==========>...................] - ETA: 2s - loss: 8.0737 - acc: 0.4991
 5696/14481 [==========>...................] - ETA: 2s - loss: 8.0534 - acc: 0.5004
 5824/14481 [===========>..................] - ETA: 2s - loss: 8.0452 - acc: 0.5009
 5952/14481 [===========>..................] - ETA: 2s - loss: 8.0455 - acc: 0.5008
 6208/14481 [===========>..................] - ETA: 2s - loss: 8.0435 - acc: 0.5010
 6464/14481 [============>.................] - ETA: 2s - loss: 8.0441 - acc: 0.5009
 6720/14481 [============>.................] - ETA: 2s - loss: 8.0543 - acc: 0.5003
 6976/14481 [=============>................] - ETA: 1s - loss: 8.0845 - acc: 0.4984
 7296/14481 [==============>...............] - ETA: 1s - loss: 8.0679 - acc: 0.4995
 7616/14481 [==============>...............] - ETA: 1s - loss: 8.0379 - acc: 0.5013
 7936/14481 [===============>..............] - ETA: 1s - loss: 8.0489 - acc: 0.5006
 8256/14481 [================>.............] - ETA: 1s - loss: 8.0298 - acc: 0.5018
 8512/14481 [================>.............] - ETA: 1s - loss: 8.0269 - acc: 0.5020
 8832/14481 [=================>............] - ETA: 1s - loss: 8.0353 - acc: 0.5015
 9152/14481 [=================>............] - ETA: 1s - loss: 8.0432 - acc: 0.5010
 9472/14481 [==================>...........] - ETA: 1s - loss: 8.0556 - acc: 0.5002
 9792/14481 [===================>..........] - ETA: 1s - loss: 8.0640 - acc: 0.4997
10112/14481 [===================>..........] - ETA: 1s - loss: 8.0575 - acc: 0.5001
10432/14481 [====================>.........] - ETA: 0s - loss: 8.0421 - acc: 0.5011
10752/14481 [=====================>........] - ETA: 0s - loss: 8.0246 - acc: 0.5021
11072/14481 [=====================>........] - ETA: 0s - loss: 8.0372 - acc: 0.5014
11392/14481 [======================>.......] - ETA: 0s - loss: 8.0506 - acc: 0.5005
11712/14481 [=======================>......] - ETA: 0s - loss: 8.0577 - acc: 0.5001
12032/14481 [=======================>......] - ETA: 0s - loss: 8.0738 - acc: 0.4991
12352/14481 [========================>.....] - ETA: 0s - loss: 8.0708 - acc: 0.4993
12672/14481 [=========================>....] - ETA: 0s - loss: 8.0769 - acc: 0.4989
12992/14481 [=========================>....] - ETA: 0s - loss: 8.0727 - acc: 0.4992
13312/14481 [==========================>...] - ETA: 0s - loss: 8.0724 - acc: 0.4992
13632/14481 [===========================>..] - ETA: 0s - loss: 8.0661 - acc: 0.4996
13952/14481 [===========================>..] - ETA: 0s - loss: 8.0752 - acc: 0.4990
14272/14481 [============================>.] - ETA: 0s - loss: 8.0511 - acc: 0.5005
14481/14481 [==============================] - 3s 219us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03270111183781

data size :  16010

zero :  8006

one :  8004

train_zero :  7241

train_one :  7240

test_zero :  765

test_one :  764

choose_zero :  1529

choose_one :  0

F1score :  0.0

AUC : 0.41607381172364233

Confusion Matrix
[[765   0]
 [764   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000345280269062], 'loss': [8.058491282136753]}
Saved model to disk



3

Epoch 1/1

   64/14481 [..............................] - ETA: 2s - loss: 8.5627 - acc: 0.4688
  320/14481 [..............................] - ETA: 3s - loss: 7.6057 - acc: 0.5281
  576/14481 [>.............................] - ETA: 3s - loss: 7.7792 - acc: 0.5174
  768/14481 [>.............................] - ETA: 3s - loss: 7.8912 - acc: 0.5104
  960/14481 [>.............................] - ETA: 3s - loss: 8.0423 - acc: 0.5010
 1152/14481 [=>............................] - ETA: 4s - loss: 8.0730 - acc: 0.4991
 1344/14481 [=>............................] - ETA: 4s - loss: 8.1670 - acc: 0.4933
 1536/14481 [==>...........................] - ETA: 4s - loss: 8.2060 - acc: 0.4909
 1792/14481 [==>...........................] - ETA: 3s - loss: 8.1760 - acc: 0.4927
 1920/14481 [==>...........................] - ETA: 4s - loss: 8.1850 - acc: 0.4922
 2176/14481 [===>..........................] - ETA: 3s - loss: 8.1998 - acc: 0.4913
 2368/14481 [===>..........................] - ETA: 3s - loss: 8.2564 - acc: 0.4878
 2560/14481 [====>.........................] - ETA: 3s - loss: 8.2542 - acc: 0.4879
 2752/14481 [====>.........................] - ETA: 3s - loss: 8.1820 - acc: 0.4924
 2944/14481 [=====>........................] - ETA: 3s - loss: 8.1795 - acc: 0.4925
 3200/14481 [=====>........................] - ETA: 3s - loss: 8.1699 - acc: 0.4931
 3456/14481 [======>.......................] - ETA: 3s - loss: 8.1850 - acc: 0.4922
 3712/14481 [======>.......................] - ETA: 3s - loss: 8.1719 - acc: 0.4930
 3968/14481 [=======>......................] - ETA: 3s - loss: 8.1484 - acc: 0.4945
 4224/14481 [=======>......................] - ETA: 3s - loss: 8.1735 - acc: 0.4929
 4480/14481 [========>.....................] - ETA: 2s - loss: 8.1670 - acc: 0.4933
 4736/14481 [========>.....................] - ETA: 2s - loss: 8.1441 - acc: 0.4947
 4992/14481 [=========>....................] - ETA: 2s - loss: 8.1204 - acc: 0.4962
 5248/14481 [=========>....................] - ETA: 2s - loss: 8.1143 - acc: 0.4966
 5568/14481 [==========>...................] - ETA: 2s - loss: 8.0938 - acc: 0.4978
 5824/14481 [===========>..................] - ETA: 2s - loss: 8.1006 - acc: 0.4974
 6080/14481 [===========>..................] - ETA: 2s - loss: 8.1147 - acc: 0.4965
 6208/14481 [===========>..................] - ETA: 2s - loss: 8.1110 - acc: 0.4968
 6400/14481 [============>.................] - ETA: 2s - loss: 8.1044 - acc: 0.4972
 6592/14481 [============>.................] - ETA: 2s - loss: 8.1251 - acc: 0.4959
 6848/14481 [=============>................] - ETA: 2s - loss: 8.1155 - acc: 0.4965
 7104/14481 [=============>................] - ETA: 2s - loss: 8.0795 - acc: 0.4987
 7424/14481 [==============>...............] - ETA: 1s - loss: 8.0634 - acc: 0.4997
 7808/14481 [===============>..............] - ETA: 1s - loss: 8.0611 - acc: 0.4999
 8064/14481 [===============>..............] - ETA: 1s - loss: 8.0610 - acc: 0.4999
 8384/14481 [================>.............] - ETA: 1s - loss: 8.0687 - acc: 0.4994
 8640/14481 [================>.............] - ETA: 1s - loss: 8.0572 - acc: 0.5001
 8896/14481 [=================>............] - ETA: 1s - loss: 8.0754 - acc: 0.4990
 9216/14481 [==================>...........] - ETA: 1s - loss: 8.0730 - acc: 0.4991
 9536/14481 [==================>...........] - ETA: 1s - loss: 8.0810 - acc: 0.4986
 9856/14481 [===================>..........] - ETA: 1s - loss: 8.0901 - acc: 0.4981
10176/14481 [====================>.........] - ETA: 1s - loss: 8.1050 - acc: 0.4972
10496/14481 [====================>.........] - ETA: 0s - loss: 8.0852 - acc: 0.4984
10816/14481 [=====================>........] - ETA: 0s - loss: 8.0710 - acc: 0.4993
11136/14481 [======================>.......] - ETA: 0s - loss: 8.0764 - acc: 0.4989
11456/14481 [======================>.......] - ETA: 0s - loss: 8.0661 - acc: 0.4996
11776/14481 [=======================>......] - ETA: 0s - loss: 8.0686 - acc: 0.4994
12096/14481 [========================>.....] - ETA: 0s - loss: 8.0750 - acc: 0.4990
12416/14481 [========================>.....] - ETA: 0s - loss: 8.0733 - acc: 0.4991
12736/14481 [=========================>....] - ETA: 0s - loss: 8.0666 - acc: 0.4995
13056/14481 [==========================>...] - ETA: 0s - loss: 8.0763 - acc: 0.4989
13376/14481 [==========================>...] - ETA: 0s - loss: 8.0844 - acc: 0.4984
13696/14481 [===========================>..] - ETA: 0s - loss: 8.0791 - acc: 0.4988
14016/14481 [============================>.] - ETA: 0s - loss: 8.0717 - acc: 0.4992
14336/14481 [============================>.] - ETA: 0s - loss: 8.0680 - acc: 0.4994
14481/14481 [==============================] - 3s 225us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03270111183781

data size :  16010

zero :  8006

one :  8004

train_zero :  7241

train_one :  7240

test_zero :  765

test_one :  764

choose_zero :  1529

choose_one :  0

F1score :  0.0

AUC : 0.41607381172364233

Confusion Matrix
[[765   0]
 [764   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000345280351383], 'loss': [8.058491259910037]}
Saved model to disk



4

Epoch 1/1

   64/14481 [..............................] - ETA: 3s - loss: 8.5627 - acc: 0.4688
  320/14481 [..............................] - ETA: 3s - loss: 8.5124 - acc: 0.4719
  576/14481 [>.............................] - ETA: 3s - loss: 7.8632 - acc: 0.5122
  832/14481 [>.............................] - ETA: 2s - loss: 7.7491 - acc: 0.5192
 1088/14481 [=>............................] - ETA: 2s - loss: 7.6739 - acc: 0.5239
 1216/14481 [=>............................] - ETA: 3s - loss: 7.6481 - acc: 0.5255
 1408/14481 [=>............................] - ETA: 3s - loss: 7.6355 - acc: 0.5263
 1536/14481 [==>...........................] - ETA: 3s - loss: 7.7128 - acc: 0.5215
 1664/14481 [==>...........................] - ETA: 3s - loss: 7.8169 - acc: 0.5150
 1856/14481 [==>...........................] - ETA: 3s - loss: 7.8593 - acc: 0.5124
 2048/14481 [===>..........................] - ETA: 3s - loss: 8.0276 - acc: 0.5020
 2176/14481 [===>..........................] - ETA: 3s - loss: 8.0739 - acc: 0.4991
 2304/14481 [===>..........................] - ETA: 3s - loss: 8.0870 - acc: 0.4983
 2432/14481 [====>.........................] - ETA: 3s - loss: 8.0988 - acc: 0.4975
 2624/14481 [====>.........................] - ETA: 3s - loss: 8.1205 - acc: 0.4962
 2816/14481 [====>.........................] - ETA: 3s - loss: 8.1850 - acc: 0.4922
 2944/14481 [=====>........................] - ETA: 3s - loss: 8.1521 - acc: 0.4942
 3136/14481 [=====>........................] - ETA: 3s - loss: 8.1207 - acc: 0.4962
 3328/14481 [=====>........................] - ETA: 3s - loss: 8.0736 - acc: 0.4991
 3520/14481 [======>.......................] - ETA: 3s - loss: 8.0728 - acc: 0.4991
 3712/14481 [======>.......................] - ETA: 3s - loss: 8.0938 - acc: 0.4978
 3968/14481 [=======>......................] - ETA: 3s - loss: 8.1525 - acc: 0.4942
 4160/14481 [=======>......................] - ETA: 3s - loss: 8.1133 - acc: 0.4966
 4416/14481 [========>.....................] - ETA: 3s - loss: 8.1028 - acc: 0.4973
 4672/14481 [========>.....................] - ETA: 2s - loss: 8.0832 - acc: 0.4985
 4992/14481 [=========>....................] - ETA: 2s - loss: 8.0558 - acc: 0.5002
 5312/14481 [==========>...................] - ETA: 2s - loss: 8.0469 - acc: 0.5008
 5632/14481 [==========>...................] - ETA: 2s - loss: 8.0304 - acc: 0.5018
 5888/14481 [===========>..................] - ETA: 2s - loss: 7.9933 - acc: 0.5041
 6208/14481 [===========>..................] - ETA: 2s - loss: 7.9760 - acc: 0.5052
 6528/14481 [============>.................] - ETA: 2s - loss: 7.9677 - acc: 0.5057
 6784/14481 [=============>................] - ETA: 2s - loss: 7.9830 - acc: 0.5047
 6976/14481 [=============>................] - ETA: 2s - loss: 7.9990 - acc: 0.5037
 7104/14481 [=============>................] - ETA: 2s - loss: 7.9933 - acc: 0.5041
 7232/14481 [=============>................] - ETA: 2s - loss: 8.0100 - acc: 0.5030
 7424/14481 [==============>...............] - ETA: 1s - loss: 7.9983 - acc: 0.5038
 7680/14481 [==============>...............] - ETA: 1s - loss: 7.9877 - acc: 0.5044
 7872/14481 [===============>..............] - ETA: 1s - loss: 7.9935 - acc: 0.5041
 8192/14481 [===============>..............] - ETA: 1s - loss: 8.0020 - acc: 0.5035
 8448/14481 [================>.............] - ETA: 1s - loss: 8.0152 - acc: 0.5027
 8704/14481 [=================>............] - ETA: 1s - loss: 8.0313 - acc: 0.5017
 8960/14481 [=================>............] - ETA: 1s - loss: 8.0375 - acc: 0.5013
 9280/14481 [==================>...........] - ETA: 1s - loss: 8.0417 - acc: 0.5011
 9536/14481 [==================>...........] - ETA: 1s - loss: 8.0438 - acc: 0.5009
 9792/14481 [===================>..........] - ETA: 1s - loss: 8.0558 - acc: 0.5002
10048/14481 [===================>..........] - ETA: 1s - loss: 8.0542 - acc: 0.5003
10368/14481 [====================>.........] - ETA: 1s - loss: 8.0590 - acc: 0.5000
10624/14481 [=====================>........] - ETA: 0s - loss: 8.0454 - acc: 0.5008
10944/14481 [=====================>........] - ETA: 0s - loss: 8.0163 - acc: 0.5026
11264/14481 [======================>.......] - ETA: 0s - loss: 8.0147 - acc: 0.5028
11584/14481 [======================>.......] - ETA: 0s - loss: 8.0368 - acc: 0.5014
11904/14481 [=======================>......] - ETA: 0s - loss: 8.0401 - acc: 0.5012
12224/14481 [========================>.....] - ETA: 0s - loss: 8.0366 - acc: 0.5014
12544/14481 [========================>.....] - ETA: 0s - loss: 8.0385 - acc: 0.5013
12864/14481 [=========================>....] - ETA: 0s - loss: 8.0390 - acc: 0.5012
13184/14481 [==========================>...] - ETA: 0s - loss: 8.0517 - acc: 0.5005
13504/14481 [==========================>...] - ETA: 0s - loss: 8.0734 - acc: 0.4991
13824/14481 [===========================>..] - ETA: 0s - loss: 8.0660 - acc: 0.4996
14144/14481 [============================>.] - ETA: 0s - loss: 8.0602 - acc: 0.4999
14464/14481 [============================>.] - ETA: 0s - loss: 8.0579 - acc: 0.5001
14481/14481 [==============================] - 3s 234us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03270111183781

data size :  16010

zero :  8006

one :  8004

train_zero :  7241

train_one :  7240

test_zero :  765

test_one :  764

choose_zero :  1529

choose_one :  0

F1score :  0.0

AUC : 0.41607381172364233

Confusion Matrix
[[765   0]
 [764   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000345280042678], 'loss': [8.058491244861726]}
Saved model to disk



5

Epoch 1/1

   64/14481 [..............................] - ETA: 3s - loss: 8.5627 - acc: 0.4688
  320/14481 [..............................] - ETA: 3s - loss: 8.0590 - acc: 0.5000
  640/14481 [>.............................] - ETA: 3s - loss: 8.2857 - acc: 0.4859
  896/14481 [>.............................] - ETA: 3s - loss: 8.0051 - acc: 0.5033
 1216/14481 [=>............................] - ETA: 2s - loss: 8.2579 - acc: 0.4877
 1536/14481 [==>...........................] - ETA: 2s - loss: 8.1745 - acc: 0.4928
 1792/14481 [==>...........................] - ETA: 2s - loss: 8.0680 - acc: 0.4994
 1984/14481 [===>..........................] - ETA: 2s - loss: 8.0103 - acc: 0.5030
 2176/14481 [===>..........................] - ETA: 2s - loss: 8.0294 - acc: 0.5018
 2368/14481 [===>..........................] - ETA: 3s - loss: 8.0795 - acc: 0.4987
 2496/14481 [====>.........................] - ETA: 3s - loss: 8.1236 - acc: 0.4960
 2752/14481 [====>.........................] - ETA: 2s - loss: 8.0298 - acc: 0.5018
 2944/14481 [=====>........................] - ETA: 2s - loss: 8.0700 - acc: 0.4993
 3136/14481 [=====>........................] - ETA: 2s - loss: 8.0796 - acc: 0.4987
 3328/14481 [=====>........................] - ETA: 2s - loss: 8.1365 - acc: 0.4952
 3520/14481 [======>.......................] - ETA: 2s - loss: 8.1232 - acc: 0.4960
 3648/14481 [======>.......................] - ETA: 2s - loss: 8.1076 - acc: 0.4970
 3904/14481 [=======>......................] - ETA: 2s - loss: 8.0921 - acc: 0.4980
 4160/14481 [=======>......................] - ETA: 2s - loss: 8.1017 - acc: 0.4974
 4288/14481 [=======>......................] - ETA: 2s - loss: 8.1305 - acc: 0.4956
 4480/14481 [========>.....................] - ETA: 2s - loss: 8.1382 - acc: 0.4951
 4672/14481 [========>.....................] - ETA: 2s - loss: 8.1487 - acc: 0.4944
 4864/14481 [=========>....................] - ETA: 2s - loss: 8.1783 - acc: 0.4926
 5120/14481 [=========>....................] - ETA: 2s - loss: 8.1755 - acc: 0.4928
 5376/14481 [==========>...................] - ETA: 2s - loss: 8.1460 - acc: 0.4946
 5632/14481 [==========>...................] - ETA: 2s - loss: 8.1106 - acc: 0.4968
 5888/14481 [===========>..................] - ETA: 2s - loss: 8.1412 - acc: 0.4949
 6208/14481 [===========>..................] - ETA: 2s - loss: 8.1291 - acc: 0.4957
 6528/14481 [============>.................] - ETA: 2s - loss: 8.1183 - acc: 0.4963
 6848/14481 [=============>................] - ETA: 1s - loss: 8.1155 - acc: 0.4965
 7168/14481 [=============>................] - ETA: 1s - loss: 8.1108 - acc: 0.4968
 7488/14481 [==============>...............] - ETA: 1s - loss: 8.0978 - acc: 0.4976
 7808/14481 [===============>..............] - ETA: 1s - loss: 8.0756 - acc: 0.4990
 8000/14481 [===============>..............] - ETA: 1s - loss: 8.0772 - acc: 0.4989
 8128/14481 [===============>..............] - ETA: 1s - loss: 8.0709 - acc: 0.4993
 8320/14481 [================>.............] - ETA: 1s - loss: 8.0571 - acc: 0.5001
 8512/14481 [================>.............] - ETA: 1s - loss: 8.0401 - acc: 0.5012
 8768/14481 [=================>............] - ETA: 1s - loss: 8.0499 - acc: 0.5006
 8960/14481 [=================>............] - ETA: 1s - loss: 8.0554 - acc: 0.5002
 9216/14481 [==================>...........] - ETA: 1s - loss: 8.0748 - acc: 0.4990
 9472/14481 [==================>...........] - ETA: 1s - loss: 8.0778 - acc: 0.4988
 9792/14481 [===================>..........] - ETA: 1s - loss: 8.0854 - acc: 0.4984
10112/14481 [===================>..........] - ETA: 1s - loss: 8.1037 - acc: 0.4972
10432/14481 [====================>.........] - ETA: 1s - loss: 8.1116 - acc: 0.4967
10688/14481 [=====================>........] - ETA: 0s - loss: 8.1103 - acc: 0.4968
11008/14481 [=====================>........] - ETA: 0s - loss: 8.1074 - acc: 0.4970
11328/14481 [======================>.......] - ETA: 0s - loss: 8.0875 - acc: 0.4982
11648/14481 [=======================>......] - ETA: 0s - loss: 8.0923 - acc: 0.4979
11904/14481 [=======================>......] - ETA: 0s - loss: 8.0780 - acc: 0.4988
12224/14481 [========================>.....] - ETA: 0s - loss: 8.0630 - acc: 0.4998
12544/14481 [========================>.....] - ETA: 0s - loss: 8.0668 - acc: 0.4995
12864/14481 [=========================>....] - ETA: 0s - loss: 8.0954 - acc: 0.4977
13184/14481 [==========================>...] - ETA: 0s - loss: 8.0945 - acc: 0.4978
13504/14481 [==========================>...] - ETA: 0s - loss: 8.0865 - acc: 0.4983
13824/14481 [===========================>..] - ETA: 0s - loss: 8.0800 - acc: 0.4987
14144/14481 [============================>.] - ETA: 0s - loss: 8.0659 - acc: 0.4996
14464/14481 [============================>.] - ETA: 0s - loss: 8.0613 - acc: 0.4999
14481/14481 [==============================] - 3s 233us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03270111183781

data size :  16010

zero :  8006

one :  8004

train_zero :  7241

train_one :  7240

test_zero :  765

test_one :  764

choose_zero :  1529

choose_one :  0

F1score :  0.0

AUC : 0.41607381172364233

Confusion Matrix
[[765   0]
 [764   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000345280269062], 'loss': [8.058491225236358]}
Saved model to disk



6

Epoch 1/1

   64/14481 [..............................] - ETA: 3s - loss: 8.5627 - acc: 0.4688
  320/14481 [..............................] - ETA: 2s - loss: 7.9583 - acc: 0.5062
  512/14481 [>.............................] - ETA: 3s - loss: 8.1535 - acc: 0.4941
  832/14481 [>.............................] - ETA: 3s - loss: 8.4465 - acc: 0.4760
 1152/14481 [=>............................] - ETA: 2s - loss: 8.3809 - acc: 0.4800
 1472/14481 [==>...........................] - ETA: 2s - loss: 8.2123 - acc: 0.4905
 1728/14481 [==>...........................] - ETA: 2s - loss: 8.1710 - acc: 0.4931
 1920/14481 [==>...........................] - ETA: 2s - loss: 8.1598 - acc: 0.4938
 2112/14481 [===>..........................] - ETA: 2s - loss: 8.1506 - acc: 0.4943
 2304/14481 [===>..........................] - ETA: 2s - loss: 8.1780 - acc: 0.4926
 2496/14481 [====>.........................] - ETA: 2s - loss: 8.1817 - acc: 0.4924
 2688/14481 [====>.........................] - ETA: 2s - loss: 8.2329 - acc: 0.4892
 2880/14481 [====>.........................] - ETA: 2s - loss: 8.2102 - acc: 0.4906
 3072/14481 [=====>........................] - ETA: 2s - loss: 8.2112 - acc: 0.4906
 3264/14481 [=====>........................] - ETA: 2s - loss: 8.2319 - acc: 0.4893
 3456/14481 [======>.......................] - ETA: 2s - loss: 8.2596 - acc: 0.4876
 3648/14481 [======>.......................] - ETA: 2s - loss: 8.2711 - acc: 0.4868
 3904/14481 [=======>......................] - ETA: 2s - loss: 8.2613 - acc: 0.4874
 4096/14481 [=======>......................] - ETA: 2s - loss: 8.2519 - acc: 0.4880
 4416/14481 [========>.....................] - ETA: 2s - loss: 8.1941 - acc: 0.4916
 4672/14481 [========>.....................] - ETA: 2s - loss: 8.2005 - acc: 0.4912
 4928/14481 [=========>....................] - ETA: 2s - loss: 8.1964 - acc: 0.4915
 5120/14481 [=========>....................] - ETA: 2s - loss: 8.1850 - acc: 0.4922
 5376/14481 [==========>...................] - ETA: 2s - loss: 8.1730 - acc: 0.4929
 5632/14481 [==========>...................] - ETA: 2s - loss: 8.1564 - acc: 0.4940
 5888/14481 [===========>..................] - ETA: 2s - loss: 8.1576 - acc: 0.4939
 6144/14481 [===========>..................] - ETA: 2s - loss: 8.1430 - acc: 0.4948
 6400/14481 [============>.................] - ETA: 1s - loss: 8.1774 - acc: 0.4927
 6720/14481 [============>.................] - ETA: 1s - loss: 8.1910 - acc: 0.4918
 6976/14481 [=============>................] - ETA: 1s - loss: 8.1884 - acc: 0.4920
 7296/14481 [==============>...............] - ETA: 1s - loss: 8.1540 - acc: 0.4941
 7616/14481 [==============>...............] - ETA: 1s - loss: 8.1564 - acc: 0.4940
 7936/14481 [===============>..............] - ETA: 1s - loss: 8.1484 - acc: 0.4945
 8192/14481 [===============>..............] - ETA: 1s - loss: 8.1594 - acc: 0.4938
 8320/14481 [================>.............] - ETA: 1s - loss: 8.1443 - acc: 0.4947
 8512/14481 [================>.............] - ETA: 1s - loss: 8.1291 - acc: 0.4957
 8768/14481 [=================>............] - ETA: 1s - loss: 8.1197 - acc: 0.4962
 9088/14481 [=================>............] - ETA: 1s - loss: 8.1300 - acc: 0.4956
 9408/14481 [==================>...........] - ETA: 1s - loss: 8.1190 - acc: 0.4963
 9792/14481 [===================>..........] - ETA: 1s - loss: 8.1150 - acc: 0.4965
10112/14481 [===================>..........] - ETA: 1s - loss: 8.1085 - acc: 0.4969
10368/14481 [====================>.........] - ETA: 0s - loss: 8.0948 - acc: 0.4978
10688/14481 [=====================>........] - ETA: 0s - loss: 8.0847 - acc: 0.4984
11008/14481 [=====================>........] - ETA: 0s - loss: 8.0854 - acc: 0.4984
11328/14481 [======================>.......] - ETA: 0s - loss: 8.0832 - acc: 0.4985
11648/14481 [=======================>......] - ETA: 0s - loss: 8.0812 - acc: 0.4986
11904/14481 [=======================>......] - ETA: 0s - loss: 8.1078 - acc: 0.4970
12224/14481 [========================>.....] - ETA: 0s - loss: 8.1263 - acc: 0.4958
12544/14481 [========================>.....] - ETA: 0s - loss: 8.1297 - acc: 0.4956
12864/14481 [=========================>....] - ETA: 0s - loss: 8.1192 - acc: 0.4963
13184/14481 [==========================>...] - ETA: 0s - loss: 8.0982 - acc: 0.4976
13504/14481 [==========================>...] - ETA: 0s - loss: 8.0925 - acc: 0.4979
13824/14481 [===========================>..] - ETA: 0s - loss: 8.0684 - acc: 0.4994
14144/14481 [============================>.] - ETA: 0s - loss: 8.0682 - acc: 0.4994
14464/14481 [============================>.] - ETA: 0s - loss: 8.0635 - acc: 0.4997
14481/14481 [==============================] - 3s 216us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03270111183781

data size :  16010

zero :  8006

one :  8004

train_zero :  7241

train_one :  7240

test_zero :  765

test_one :  764

choose_zero :  1529

choose_one :  0

F1score :  0.0

AUC : 0.41607381172364233

Confusion Matrix
[[765   0]
 [764   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.500034528018674], 'loss': [8.058491207142165]}
Saved model to disk



7

Epoch 1/1

   64/14481 [..............................] - ETA: 3s - loss: 8.3109 - acc: 0.4844
  320/14481 [..............................] - ETA: 3s - loss: 7.5554 - acc: 0.5312
  640/14481 [>.............................] - ETA: 2s - loss: 8.2605 - acc: 0.4875
  960/14481 [>.............................] - ETA: 2s - loss: 7.8576 - acc: 0.5125
 1280/14481 [=>............................] - ETA: 2s - loss: 8.0087 - acc: 0.5031
 1600/14481 [==>...........................] - ETA: 2s - loss: 8.0389 - acc: 0.5012
 1920/14481 [==>...........................] - ETA: 2s - loss: 8.0674 - acc: 0.4995
 2240/14481 [===>..........................] - ETA: 2s - loss: 7.9799 - acc: 0.5049
 2560/14481 [====>.........................] - ETA: 2s - loss: 7.9835 - acc: 0.5047
 2752/14481 [====>.........................] - ETA: 2s - loss: 8.0415 - acc: 0.5011
 3072/14481 [=====>........................] - ETA: 2s - loss: 8.0276 - acc: 0.5020
 3456/14481 [======>.......................] - ETA: 2s - loss: 8.0171 - acc: 0.5026
 3840/14481 [======>.......................] - ETA: 2s - loss: 7.9793 - acc: 0.5049
 4096/14481 [=======>......................] - ETA: 2s - loss: 7.9882 - acc: 0.5044
 4416/14481 [========>.....................] - ETA: 1s - loss: 7.9933 - acc: 0.5041
 4672/14481 [========>.....................] - ETA: 1s - loss: 7.9935 - acc: 0.5041
 4800/14481 [========>.....................] - ETA: 1s - loss: 8.0053 - acc: 0.5033
 5056/14481 [=========>....................] - ETA: 1s - loss: 8.0304 - acc: 0.5018
 5312/14481 [==========>...................] - ETA: 1s - loss: 8.0166 - acc: 0.5026
 5504/14481 [==========>...................] - ETA: 1s - loss: 8.0620 - acc: 0.4998
 5696/14481 [==========>...................] - ETA: 1s - loss: 8.0619 - acc: 0.4998
 5888/14481 [===========>..................] - ETA: 1s - loss: 8.0974 - acc: 0.4976
 6208/14481 [===========>..................] - ETA: 1s - loss: 8.0616 - acc: 0.4998
 6528/14481 [============>.................] - ETA: 1s - loss: 8.0566 - acc: 0.5002
 6784/14481 [=============>................] - ETA: 1s - loss: 8.0662 - acc: 0.4996
 7168/14481 [=============>................] - ETA: 1s - loss: 8.0635 - acc: 0.4997
 7488/14481 [==============>...............] - ETA: 1s - loss: 8.0354 - acc: 0.5015
 7808/14481 [===============>..............] - ETA: 1s - loss: 8.0322 - acc: 0.5017
 8064/14481 [===============>..............] - ETA: 1s - loss: 8.0211 - acc: 0.5024
 8320/14481 [================>.............] - ETA: 1s - loss: 8.0242 - acc: 0.5022
 8512/14481 [================>.............] - ETA: 1s - loss: 8.0060 - acc: 0.5033
 8768/14481 [=================>............] - ETA: 1s - loss: 8.0241 - acc: 0.5022
 9024/14481 [=================>............] - ETA: 1s - loss: 8.0198 - acc: 0.5024
 9280/14481 [==================>...........] - ETA: 1s - loss: 8.0035 - acc: 0.5034
 9536/14481 [==================>...........] - ETA: 1s - loss: 7.9931 - acc: 0.5041
 9792/14481 [===================>..........] - ETA: 1s - loss: 7.9932 - acc: 0.5041
10112/14481 [===================>..........] - ETA: 0s - loss: 8.0001 - acc: 0.5037
10368/14481 [====================>.........] - ETA: 0s - loss: 7.9891 - acc: 0.5043
10688/14481 [=====================>........] - ETA: 0s - loss: 7.9957 - acc: 0.5039
11008/14481 [=====================>........] - ETA: 0s - loss: 8.0078 - acc: 0.5032
11328/14481 [======================>.......] - ETA: 0s - loss: 7.9993 - acc: 0.5037
11456/14481 [======================>.......] - ETA: 0s - loss: 8.0084 - acc: 0.5031
11584/14481 [======================>.......] - ETA: 0s - loss: 8.0117 - acc: 0.5029
11776/14481 [=======================>......] - ETA: 0s - loss: 8.0303 - acc: 0.5018
11904/14481 [=======================>......] - ETA: 0s - loss: 8.0442 - acc: 0.5009
12160/14481 [========================>.....] - ETA: 0s - loss: 8.0471 - acc: 0.5007
12416/14481 [========================>.....] - ETA: 0s - loss: 8.0461 - acc: 0.5008
12672/14481 [=========================>....] - ETA: 0s - loss: 8.0540 - acc: 0.5003
12928/14481 [=========================>....] - ETA: 0s - loss: 8.0678 - acc: 0.4995
13248/14481 [==========================>...] - ETA: 0s - loss: 8.0870 - acc: 0.4983
13568/14481 [===========================>..] - ETA: 0s - loss: 8.0816 - acc: 0.4986
13888/14481 [===========================>..] - ETA: 0s - loss: 8.0590 - acc: 0.5000
14208/14481 [============================>.] - ETA: 0s - loss: 8.0590 - acc: 0.5000
14481/14481 [==============================] - 3s 218us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03270111183781

data size :  16010

zero :  8006

one :  8004

train_zero :  7241

train_one :  7240

test_zero :  765

test_one :  764

choose_zero :  1529

choose_one :  0

F1score :  0.0

AUC : 0.41607381172364233

Confusion Matrix
[[765   0]
 [764   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.500034528016616], 'loss': [8.058491226553498]}
Saved model to disk



8

Epoch 1/1

   64/14481 [..............................] - ETA: 3s - loss: 9.3183 - acc: 0.4219
  320/14481 [..............................] - ETA: 2s - loss: 7.6057 - acc: 0.5281
  640/14481 [>.............................] - ETA: 2s - loss: 8.0842 - acc: 0.4984
  960/14481 [>.............................] - ETA: 2s - loss: 7.9079 - acc: 0.5094
 1280/14481 [=>............................] - ETA: 2s - loss: 8.0590 - acc: 0.5000
 1600/14481 [==>...........................] - ETA: 2s - loss: 8.1195 - acc: 0.4963
 1920/14481 [==>...........................] - ETA: 2s - loss: 8.1430 - acc: 0.4948
 2240/14481 [===>..........................] - ETA: 2s - loss: 8.1310 - acc: 0.4955
 2560/14481 [====>.........................] - ETA: 2s - loss: 8.0842 - acc: 0.4984
 2880/14481 [====>.........................] - ETA: 2s - loss: 8.0814 - acc: 0.4986
 3200/14481 [=====>........................] - ETA: 1s - loss: 8.0993 - acc: 0.4975
 3520/14481 [======>.......................] - ETA: 1s - loss: 8.1094 - acc: 0.4969
 3840/14481 [======>.......................] - ETA: 1s - loss: 8.0590 - acc: 0.5000
 4160/14481 [=======>......................] - ETA: 1s - loss: 8.1017 - acc: 0.4974
 4480/14481 [========>.....................] - ETA: 1s - loss: 8.0411 - acc: 0.5011
 4800/14481 [========>.....................] - ETA: 1s - loss: 8.0792 - acc: 0.4988
 5120/14481 [=========>....................] - ETA: 1s - loss: 8.1157 - acc: 0.4965
 5440/14481 [==========>...................] - ETA: 1s - loss: 8.1450 - acc: 0.4947
 5760/14481 [==========>...................] - ETA: 1s - loss: 8.1262 - acc: 0.4958
 6080/14481 [===========>..................] - ETA: 1s - loss: 8.0909 - acc: 0.4980
 6400/14481 [============>.................] - ETA: 1s - loss: 8.0868 - acc: 0.4983
 6592/14481 [============>.................] - ETA: 1s - loss: 8.0908 - acc: 0.4980
 6848/14481 [=============>................] - ETA: 1s - loss: 8.0991 - acc: 0.4975
 7168/14481 [=============>................] - ETA: 1s - loss: 8.1085 - acc: 0.4969
 7488/14481 [==============>...............] - ETA: 1s - loss: 8.0870 - acc: 0.4983
 7680/14481 [==============>...............] - ETA: 1s - loss: 8.1115 - acc: 0.4967
 7872/14481 [===============>..............] - ETA: 1s - loss: 8.0836 - acc: 0.4985
 8000/14481 [===============>..............] - ETA: 1s - loss: 8.0973 - acc: 0.4976
 8128/14481 [===============>..............] - ETA: 1s - loss: 8.1126 - acc: 0.4967
 8320/14481 [================>.............] - ETA: 1s - loss: 8.1036 - acc: 0.4972
 8512/14481 [================>.............] - ETA: 1s - loss: 8.1045 - acc: 0.4972
 8704/14481 [=================>............] - ETA: 1s - loss: 8.0961 - acc: 0.4977
 8768/14481 [=================>............] - ETA: 1s - loss: 8.0977 - acc: 0.4976
 8960/14481 [=================>............] - ETA: 1s - loss: 8.1022 - acc: 0.4973
 9152/14481 [=================>............] - ETA: 1s - loss: 8.1048 - acc: 0.4972
 9408/14481 [==================>...........] - ETA: 1s - loss: 8.1276 - acc: 0.4957
 9536/14481 [==================>...........] - ETA: 1s - loss: 8.1182 - acc: 0.4963
 9728/14481 [===================>..........] - ETA: 1s - loss: 8.1088 - acc: 0.4969
 9920/14481 [===================>..........] - ETA: 1s - loss: 8.0948 - acc: 0.4978
10112/14481 [===================>..........] - ETA: 0s - loss: 8.1005 - acc: 0.4974
10304/14481 [====================>.........] - ETA: 0s - loss: 8.0888 - acc: 0.4982
10560/14481 [====================>.........] - ETA: 0s - loss: 8.0957 - acc: 0.4977
10816/14481 [=====================>........] - ETA: 0s - loss: 8.0963 - acc: 0.4977
11072/14481 [=====================>........] - ETA: 0s - loss: 8.0823 - acc: 0.4986
11392/14481 [======================>.......] - ETA: 0s - loss: 8.0647 - acc: 0.4996
11712/14481 [=======================>......] - ETA: 0s - loss: 8.0577 - acc: 0.5001
12032/14481 [=======================>......] - ETA: 0s - loss: 8.0671 - acc: 0.4995
12352/14481 [========================>.....] - ETA: 0s - loss: 8.0525 - acc: 0.5004
12672/14481 [=========================>....] - ETA: 0s - loss: 8.0552 - acc: 0.5002
12928/14481 [=========================>....] - ETA: 0s - loss: 8.0478 - acc: 0.5007
13184/14481 [==========================>...] - ETA: 0s - loss: 8.0615 - acc: 0.4998
13312/14481 [==========================>...] - ETA: 0s - loss: 8.0554 - acc: 0.5002
13440/14481 [==========================>...] - ETA: 0s - loss: 8.0554 - acc: 0.5002
13632/14481 [===========================>..] - ETA: 0s - loss: 8.0602 - acc: 0.4999
13888/14481 [===========================>..] - ETA: 0s - loss: 8.0602 - acc: 0.4999
14080/14481 [============================>.] - ETA: 0s - loss: 8.0590 - acc: 0.5000
14336/14481 [============================>.] - ETA: 0s - loss: 8.0613 - acc: 0.4999
14481/14481 [==============================] - 3s 227us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03270111183781

data size :  16010

zero :  8006

one :  8004

train_zero :  7241

train_one :  7240

test_zero :  765

test_one :  764

choose_zero :  1529

choose_one :  0

F1score :  0.0

AUC : 0.41607381172364233

Confusion Matrix
[[765   0]
 [764   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000345280351383], 'loss': [8.058491224083863]}
Saved model to disk



9

Epoch 1/1

   64/14481 [..............................] - ETA: 3s - loss: 8.0590 - acc: 0.5000
  320/14481 [..............................] - ETA: 3s - loss: 7.9583 - acc: 0.5062
  640/14481 [>.............................] - ETA: 2s - loss: 8.2102 - acc: 0.4906
  960/14481 [>.............................] - ETA: 2s - loss: 8.2941 - acc: 0.4854
 1280/14481 [=>............................] - ETA: 2s - loss: 8.1724 - acc: 0.4930
 1600/14481 [==>...........................] - ETA: 2s - loss: 8.1699 - acc: 0.4931
 1920/14481 [==>...........................] - ETA: 2s - loss: 8.1346 - acc: 0.4953
 2240/14481 [===>..........................] - ETA: 2s - loss: 7.9943 - acc: 0.5040
 2560/14481 [====>.........................] - ETA: 2s - loss: 8.0402 - acc: 0.5012
 2880/14481 [====>.........................] - ETA: 2s - loss: 8.0199 - acc: 0.5024
 3200/14481 [=====>........................] - ETA: 2s - loss: 7.9936 - acc: 0.5041
 3520/14481 [======>.......................] - ETA: 1s - loss: 7.8988 - acc: 0.5099
 3840/14481 [======>.......................] - ETA: 1s - loss: 7.8953 - acc: 0.5102
 4160/14481 [=======>......................] - ETA: 1s - loss: 7.9312 - acc: 0.5079
 4480/14481 [========>.....................] - ETA: 1s - loss: 7.9187 - acc: 0.5087
 4800/14481 [========>.....................] - ETA: 1s - loss: 7.9046 - acc: 0.5096
 5120/14481 [=========>....................] - ETA: 1s - loss: 7.9457 - acc: 0.5070
 5440/14481 [==========>...................] - ETA: 1s - loss: 7.9287 - acc: 0.5081
 5760/14481 [==========>...................] - ETA: 1s - loss: 7.9639 - acc: 0.5059
 6080/14481 [===========>..................] - ETA: 1s - loss: 7.9928 - acc: 0.5041
 6400/14481 [============>.................] - ETA: 1s - loss: 7.9759 - acc: 0.5052
 6720/14481 [============>.................] - ETA: 1s - loss: 7.9679 - acc: 0.5057
 7040/14481 [=============>................] - ETA: 1s - loss: 7.9995 - acc: 0.5037
 7360/14481 [==============>...............] - ETA: 1s - loss: 7.9802 - acc: 0.5049
 7680/14481 [==============>...............] - ETA: 1s - loss: 7.9961 - acc: 0.5039
 7936/14481 [===============>..............] - ETA: 1s - loss: 7.9920 - acc: 0.5042
 8192/14481 [===============>..............] - ETA: 1s - loss: 7.9843 - acc: 0.5046
 8512/14481 [================>.............] - ETA: 1s - loss: 7.9909 - acc: 0.5042
 8832/14481 [=================>............] - ETA: 1s - loss: 7.9550 - acc: 0.5065
 9088/14481 [=================>............] - ETA: 0s - loss: 7.9828 - acc: 0.5047
 9280/14481 [==================>...........] - ETA: 0s - loss: 7.9878 - acc: 0.5044
 9472/14481 [==================>...........] - ETA: 0s - loss: 7.9791 - acc: 0.5050
 9664/14481 [===================>..........] - ETA: 0s - loss: 7.9890 - acc: 0.5043
 9856/14481 [===================>..........] - ETA: 0s - loss: 7.9806 - acc: 0.5049
10112/14481 [===================>..........] - ETA: 0s - loss: 7.9825 - acc: 0.5047
10432/14481 [====================>.........] - ETA: 0s - loss: 8.0034 - acc: 0.5035
10624/14481 [=====================>........] - ETA: 0s - loss: 8.0059 - acc: 0.5033
10816/14481 [=====================>........] - ETA: 0s - loss: 8.0173 - acc: 0.5026
11008/14481 [=====================>........] - ETA: 0s - loss: 8.0356 - acc: 0.5015
11200/14481 [======================>.......] - ETA: 0s - loss: 8.0360 - acc: 0.5014
11520/14481 [======================>.......] - ETA: 0s - loss: 8.0395 - acc: 0.5012
11840/14481 [=======================>......] - ETA: 0s - loss: 8.0441 - acc: 0.5009
12160/14481 [========================>.....] - ETA: 0s - loss: 8.0339 - acc: 0.5016
12544/14481 [========================>.....] - ETA: 0s - loss: 8.0411 - acc: 0.5011
12928/14481 [=========================>....] - ETA: 0s - loss: 8.0366 - acc: 0.5014
13312/14481 [==========================>...] - ETA: 0s - loss: 8.0457 - acc: 0.5008
13632/14481 [===========================>..] - ETA: 0s - loss: 8.0354 - acc: 0.5015
14016/14481 [============================>.] - ETA: 0s - loss: 8.0349 - acc: 0.5015
14336/14481 [============================>.] - ETA: 0s - loss: 8.0602 - acc: 0.4999
14481/14481 [==============================] - 3s 190us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03270111183781

data size :  16010

zero :  8006

one :  8004

train_zero :  7241

train_one :  7240

test_zero :  765

test_one :  764

choose_zero :  1529

choose_one :  0

F1score :  0.0

AUC : 0.41607381172364233

Confusion Matrix
[[765   0]
 [764   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000345280042678], 'loss': [8.058491232217193]}
Saved model to disk



10

Epoch 1/1

   64/14481 [..............................] - ETA: 6s - loss: 8.3109 - acc: 0.4844
  192/14481 [..............................] - ETA: 5s - loss: 7.3875 - acc: 0.5417
  448/14481 [..............................] - ETA: 4s - loss: 7.9511 - acc: 0.5067
  704/14481 [>.............................] - ETA: 3s - loss: 7.9217 - acc: 0.5085
  960/14481 [>.............................] - ETA: 3s - loss: 7.8744 - acc: 0.5115
 1216/14481 [=>............................] - ETA: 3s - loss: 7.9265 - acc: 0.5082
 1536/14481 [==>...........................] - ETA: 3s - loss: 7.8387 - acc: 0.5137
 1792/14481 [==>...........................] - ETA: 3s - loss: 7.9331 - acc: 0.5078
 2112/14481 [===>..........................] - ETA: 2s - loss: 8.0285 - acc: 0.5019
 2432/14481 [====>.........................] - ETA: 2s - loss: 8.0392 - acc: 0.5012
 2752/14481 [====>.........................] - ETA: 2s - loss: 8.0649 - acc: 0.4996
 3072/14481 [=====>........................] - ETA: 2s - loss: 8.1010 - acc: 0.4974
 3392/14481 [======>.......................] - ETA: 2s - loss: 8.1446 - acc: 0.4947
 3712/14481 [======>.......................] - ETA: 2s - loss: 8.1806 - acc: 0.4925
 4032/14481 [=======>......................] - ETA: 2s - loss: 8.2110 - acc: 0.4906
 4352/14481 [========>.....................] - ETA: 2s - loss: 8.1961 - acc: 0.4915
 4672/14481 [========>.....................] - ETA: 1s - loss: 8.2074 - acc: 0.4908
 4992/14481 [=========>....................] - ETA: 1s - loss: 8.1462 - acc: 0.4946
 5312/14481 [==========>...................] - ETA: 1s - loss: 8.1561 - acc: 0.4940
 5632/14481 [==========>...................] - ETA: 1s - loss: 8.1335 - acc: 0.4954
 5952/14481 [===========>..................] - ETA: 1s - loss: 8.0943 - acc: 0.4978
 6272/14481 [===========>..................] - ETA: 1s - loss: 8.1156 - acc: 0.4965
 6592/14481 [============>.................] - ETA: 1s - loss: 8.0957 - acc: 0.4977
 6912/14481 [=============>................] - ETA: 1s - loss: 8.0987 - acc: 0.4975
 7232/14481 [=============>................] - ETA: 1s - loss: 8.1170 - acc: 0.4964
 7552/14481 [==============>...............] - ETA: 1s - loss: 8.1081 - acc: 0.4970
 7872/14481 [===============>..............] - ETA: 1s - loss: 8.1000 - acc: 0.4975
 8192/14481 [===============>..............] - ETA: 1s - loss: 8.0650 - acc: 0.4996
 8512/14481 [================>.............] - ETA: 1s - loss: 8.0458 - acc: 0.5008
 8832/14481 [=================>............] - ETA: 1s - loss: 8.0408 - acc: 0.5011
 9152/14481 [=================>............] - ETA: 0s - loss: 8.0362 - acc: 0.5014
 9472/14481 [==================>...........] - ETA: 0s - loss: 8.0233 - acc: 0.5022
 9792/14481 [===================>..........] - ETA: 0s - loss: 8.0245 - acc: 0.5021
10112/14481 [===================>..........] - ETA: 0s - loss: 8.0080 - acc: 0.5032
10432/14481 [====================>.........] - ETA: 0s - loss: 8.0405 - acc: 0.5012
10752/14481 [=====================>........] - ETA: 0s - loss: 8.0321 - acc: 0.5017
11072/14481 [=====================>........] - ETA: 0s - loss: 8.0299 - acc: 0.5018
11392/14481 [======================>.......] - ETA: 0s - loss: 8.0237 - acc: 0.5022
11712/14481 [=======================>......] - ETA: 0s - loss: 8.0219 - acc: 0.5023
12032/14481 [=======================>......] - ETA: 0s - loss: 8.0135 - acc: 0.5028
12352/14481 [========================>.....] - ETA: 0s - loss: 8.0082 - acc: 0.5032
12672/14481 [=========================>....] - ETA: 0s - loss: 8.0183 - acc: 0.5025
12992/14481 [=========================>....] - ETA: 0s - loss: 8.0256 - acc: 0.5021
13312/14481 [==========================>...] - ETA: 0s - loss: 8.0324 - acc: 0.5017
13632/14481 [===========================>..] - ETA: 0s - loss: 8.0413 - acc: 0.5011
13952/14481 [===========================>..] - ETA: 0s - loss: 8.0325 - acc: 0.5016
14272/14481 [============================>.] - ETA: 0s - loss: 8.0421 - acc: 0.5011
14481/14481 [==============================] - 3s 178us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03270111183781

data size :  16010

zero :  8006

one :  8004

train_zero :  7241

train_one :  7240

test_zero :  765

test_one :  764

choose_zero :  1529

choose_one :  0

F1score :  0.0

AUC : 0.41607381172364233

Confusion Matrix
[[765   0]
 [764   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000345280073548], 'loss': [8.058491261786958]}
Saved model to disk



11

Epoch 1/1

   64/14481 [..............................] - ETA: 4s - loss: 9.5701 - acc: 0.4062
  320/14481 [..............................] - ETA: 3s - loss: 8.8650 - acc: 0.4500
  640/14481 [>.............................] - ETA: 3s - loss: 8.6635 - acc: 0.4625
  960/14481 [>.............................] - ETA: 2s - loss: 8.4788 - acc: 0.4740
 1280/14481 [=>............................] - ETA: 2s - loss: 8.5753 - acc: 0.4680
 1536/14481 [==>...........................] - ETA: 2s - loss: 8.5103 - acc: 0.4720
 1792/14481 [==>...........................] - ETA: 2s - loss: 8.5807 - acc: 0.4676
 1984/14481 [===>..........................] - ETA: 2s - loss: 8.5140 - acc: 0.4718
 2176/14481 [===>..........................] - ETA: 2s - loss: 8.4368 - acc: 0.4766
 2432/14481 [====>.........................] - ETA: 2s - loss: 8.3971 - acc: 0.4790
 2688/14481 [====>.........................] - ETA: 2s - loss: 8.3529 - acc: 0.4818
 2944/14481 [=====>........................] - ETA: 2s - loss: 8.4259 - acc: 0.4772
 3200/14481 [=====>........................] - ETA: 2s - loss: 8.3310 - acc: 0.4831
 3520/14481 [======>.......................] - ETA: 2s - loss: 8.3842 - acc: 0.4798
 3776/14481 [======>.......................] - ETA: 2s - loss: 8.3450 - acc: 0.4823
 4096/14481 [=======>......................] - ETA: 2s - loss: 8.3699 - acc: 0.4807
 4416/14481 [========>.....................] - ETA: 2s - loss: 8.3802 - acc: 0.4801
 4736/14481 [========>.....................] - ETA: 2s - loss: 8.2973 - acc: 0.4852
 5056/14481 [=========>....................] - ETA: 1s - loss: 8.2631 - acc: 0.4873
 5376/14481 [==========>...................] - ETA: 1s - loss: 8.2359 - acc: 0.4890
 5632/14481 [==========>...................] - ETA: 1s - loss: 8.2107 - acc: 0.4906
 5760/14481 [==========>...................] - ETA: 1s - loss: 8.1794 - acc: 0.4925
 5888/14481 [===========>..................] - ETA: 1s - loss: 8.1850 - acc: 0.4922
 6016/14481 [===========>..................] - ETA: 1s - loss: 8.1957 - acc: 0.4915
 6208/14481 [===========>..................] - ETA: 1s - loss: 8.2356 - acc: 0.4890
 6464/14481 [============>.................] - ETA: 1s - loss: 8.2186 - acc: 0.4901
 6720/14481 [============>.................] - ETA: 1s - loss: 8.2054 - acc: 0.4909
 6976/14481 [=============>................] - ETA: 1s - loss: 8.1884 - acc: 0.4920
 7232/14481 [=============>................] - ETA: 1s - loss: 8.1749 - acc: 0.4928
 7552/14481 [==============>...............] - ETA: 1s - loss: 8.1487 - acc: 0.4944
 7872/14481 [===============>..............] - ETA: 1s - loss: 8.1307 - acc: 0.4956
 8192/14481 [===============>..............] - ETA: 1s - loss: 8.1299 - acc: 0.4956
 8512/14481 [================>.............] - ETA: 1s - loss: 8.1424 - acc: 0.4948
 8832/14481 [=================>............] - ETA: 1s - loss: 8.1539 - acc: 0.4941
 9152/14481 [=================>............] - ETA: 1s - loss: 8.1084 - acc: 0.4969
 9472/14481 [==================>...........] - ETA: 1s - loss: 8.0710 - acc: 0.4993
 9792/14481 [===================>..........] - ETA: 1s - loss: 8.0673 - acc: 0.4995
10112/14481 [===================>..........] - ETA: 0s - loss: 8.0814 - acc: 0.4986
10432/14481 [====================>.........] - ETA: 0s - loss: 8.0807 - acc: 0.4987
10752/14481 [=====================>........] - ETA: 0s - loss: 8.0710 - acc: 0.4993
11072/14481 [=====================>........] - ETA: 0s - loss: 8.0721 - acc: 0.4992
11392/14481 [======================>.......] - ETA: 0s - loss: 8.0590 - acc: 0.5000
11712/14481 [=======================>......] - ETA: 0s - loss: 8.0522 - acc: 0.5004
12032/14481 [=======================>......] - ETA: 0s - loss: 8.0497 - acc: 0.5006
12352/14481 [========================>.....] - ETA: 0s - loss: 8.0408 - acc: 0.5011
12672/14481 [=========================>....] - ETA: 0s - loss: 8.0285 - acc: 0.5019
13056/14481 [==========================>...] - ETA: 0s - loss: 8.0393 - acc: 0.5012
13376/14481 [==========================>...] - ETA: 0s - loss: 8.0578 - acc: 0.5001
13760/14481 [===========================>..] - ETA: 0s - loss: 8.0661 - acc: 0.4996
14080/14481 [============================>.] - ETA: 0s - loss: 8.0739 - acc: 0.4991
14400/14481 [============================>.] - ETA: 0s - loss: 8.0568 - acc: 0.5001
14481/14481 [==============================] - 3s 199us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03270111183781

data size :  16010

zero :  8006

one :  8004

train_zero :  7241

train_one :  7240

test_zero :  765

test_one :  764

choose_zero :  1529

choose_one :  0

F1score :  0.0

AUC : 0.41607381172364233

Confusion Matrix
[[765   0]
 [764   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000345280124999], 'loss': [8.058491224182648]}
Saved model to disk



12

Epoch 1/1

   64/14481 [..............................] - ETA: 3s - loss: 7.5554 - acc: 0.5312
  256/14481 [..............................] - ETA: 4s - loss: 8.1220 - acc: 0.4961
  576/14481 [>.............................] - ETA: 3s - loss: 7.8632 - acc: 0.5122
  896/14481 [>.............................] - ETA: 3s - loss: 7.8072 - acc: 0.5156
 1216/14481 [=>............................] - ETA: 2s - loss: 7.8470 - acc: 0.5132
 1472/14481 [==>...........................] - ETA: 2s - loss: 7.9277 - acc: 0.5082
 1664/14481 [==>...........................] - ETA: 2s - loss: 7.9912 - acc: 0.5042
 1856/14481 [==>...........................] - ETA: 2s - loss: 8.1285 - acc: 0.4957
 1984/14481 [===>..........................] - ETA: 3s - loss: 8.0834 - acc: 0.4985
 2240/14481 [===>..........................] - ETA: 2s - loss: 8.0447 - acc: 0.5009
 2496/14481 [====>.........................] - ETA: 2s - loss: 8.0332 - acc: 0.5016
 2624/14481 [====>.........................] - ETA: 2s - loss: 8.0652 - acc: 0.4996
 2816/14481 [====>.........................] - ETA: 2s - loss: 8.0705 - acc: 0.4993
 3008/14481 [=====>........................] - ETA: 2s - loss: 8.1073 - acc: 0.4970
 3200/14481 [=====>........................] - ETA: 2s - loss: 8.1296 - acc: 0.4956
 3392/14481 [======>.......................] - ETA: 2s - loss: 8.1398 - acc: 0.4950
 3584/14481 [======>.......................] - ETA: 2s - loss: 8.1490 - acc: 0.4944
 3776/14481 [======>.......................] - ETA: 2s - loss: 8.1615 - acc: 0.4936
 3968/14481 [=======>......................] - ETA: 2s - loss: 8.2093 - acc: 0.4907
 4160/14481 [=======>......................] - ETA: 2s - loss: 8.1908 - acc: 0.4918
 4416/14481 [========>.....................] - ETA: 2s - loss: 8.1612 - acc: 0.4937
 4672/14481 [========>.....................] - ETA: 2s - loss: 8.1384 - acc: 0.4951
 4928/14481 [=========>....................] - ETA: 2s - loss: 8.1506 - acc: 0.4943
 5120/14481 [=========>....................] - ETA: 2s - loss: 8.1566 - acc: 0.4939
 5376/14481 [==========>...................] - ETA: 2s - loss: 8.1580 - acc: 0.4939
 5632/14481 [==========>...................] - ETA: 2s - loss: 8.1449 - acc: 0.4947
 5952/14481 [===========>..................] - ETA: 2s - loss: 8.1647 - acc: 0.4934
 6208/14481 [===========>..................] - ETA: 2s - loss: 8.2096 - acc: 0.4907
 6464/14481 [============>.................] - ETA: 2s - loss: 8.2311 - acc: 0.4893
 6784/14481 [=============>................] - ETA: 1s - loss: 8.2040 - acc: 0.4910
 7040/14481 [=============>................] - ETA: 1s - loss: 8.2147 - acc: 0.4903
 7360/14481 [==============>...............] - ETA: 1s - loss: 8.2233 - acc: 0.4898
 7680/14481 [==============>...............] - ETA: 1s - loss: 8.2018 - acc: 0.4911
 7936/14481 [===============>..............] - ETA: 1s - loss: 8.1647 - acc: 0.4934
 8000/14481 [===============>..............] - ETA: 1s - loss: 8.1578 - acc: 0.4939
 8128/14481 [===============>..............] - ETA: 1s - loss: 8.1423 - acc: 0.4948
 8384/14481 [================>.............] - ETA: 1s - loss: 8.1321 - acc: 0.4955
 8640/14481 [================>.............] - ETA: 1s - loss: 8.1299 - acc: 0.4956
 8896/14481 [=================>............] - ETA: 1s - loss: 8.1333 - acc: 0.4954
 9152/14481 [=================>............] - ETA: 1s - loss: 8.1172 - acc: 0.4964
 9472/14481 [==================>...........] - ETA: 1s - loss: 8.1288 - acc: 0.4957
 9792/14481 [===================>..........] - ETA: 1s - loss: 8.1364 - acc: 0.4952
10112/14481 [===================>..........] - ETA: 1s - loss: 8.1276 - acc: 0.4957
10432/14481 [====================>.........] - ETA: 0s - loss: 8.1193 - acc: 0.4963
10752/14481 [=====================>........] - ETA: 0s - loss: 8.1130 - acc: 0.4967
11072/14481 [=====================>........] - ETA: 0s - loss: 8.1013 - acc: 0.4974
11392/14481 [======================>.......] - ETA: 0s - loss: 8.1029 - acc: 0.4973
11712/14481 [=======================>......] - ETA: 0s - loss: 8.1182 - acc: 0.4963
12032/14481 [=======================>......] - ETA: 0s - loss: 8.1126 - acc: 0.4967
12352/14481 [========================>.....] - ETA: 0s - loss: 8.1230 - acc: 0.4960
12672/14481 [=========================>....] - ETA: 0s - loss: 8.1176 - acc: 0.4964
12992/14481 [=========================>....] - ETA: 0s - loss: 8.1099 - acc: 0.4968
13312/14481 [==========================>...] - ETA: 0s - loss: 8.1087 - acc: 0.4969
13632/14481 [===========================>..] - ETA: 0s - loss: 8.0910 - acc: 0.4980
13952/14481 [===========================>..] - ETA: 0s - loss: 8.0741 - acc: 0.4991
14272/14481 [============================>.] - ETA: 0s - loss: 8.0613 - acc: 0.4999
14481/14481 [==============================] - 3s 222us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03270111183781

data size :  16010

zero :  8006

one :  8004

train_zero :  7241

train_one :  7240

test_zero :  765

test_one :  764

choose_zero :  1529

choose_one :  0

F1score :  0.0

AUC : 0.41607381172364233

Confusion Matrix
[[765   0]
 [764   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000345280269062], 'loss': [8.058491242095734]}
Saved model to disk



13

Epoch 1/1

   64/14481 [..............................] - ETA: 3s - loss: 8.3109 - acc: 0.4844
  320/14481 [..............................] - ETA: 3s - loss: 7.7568 - acc: 0.5188
  640/14481 [>.............................] - ETA: 2s - loss: 7.6561 - acc: 0.5250
  960/14481 [>.............................] - ETA: 2s - loss: 7.8744 - acc: 0.5115
 1280/14481 [=>............................] - ETA: 2s - loss: 7.9079 - acc: 0.5094
 1600/14481 [==>...........................] - ETA: 2s - loss: 7.9684 - acc: 0.5056
 1856/14481 [==>...........................] - ETA: 2s - loss: 7.9462 - acc: 0.5070
 2176/14481 [===>..........................] - ETA: 2s - loss: 7.9257 - acc: 0.5083
 2496/14481 [====>.........................] - ETA: 2s - loss: 7.9493 - acc: 0.5068
 2816/14481 [====>.........................] - ETA: 2s - loss: 7.9274 - acc: 0.5082
 3072/14481 [=====>........................] - ETA: 2s - loss: 7.9803 - acc: 0.5049
 3328/14481 [=====>........................] - ETA: 2s - loss: 7.9961 - acc: 0.5039
 3520/14481 [======>.......................] - ETA: 2s - loss: 8.0728 - acc: 0.4991
 3648/14481 [======>.......................] - ETA: 2s - loss: 8.0325 - acc: 0.5016
 3904/14481 [=======>......................] - ETA: 2s - loss: 7.9971 - acc: 0.5038
 4160/14481 [=======>......................] - ETA: 2s - loss: 7.9971 - acc: 0.5038
 4352/14481 [========>.....................] - ETA: 2s - loss: 8.0146 - acc: 0.5028
 4608/14481 [========>.....................] - ETA: 2s - loss: 8.0555 - acc: 0.5002
 4800/14481 [========>.....................] - ETA: 2s - loss: 8.0557 - acc: 0.5002
 4928/14481 [=========>....................] - ETA: 2s - loss: 8.0329 - acc: 0.5016
 5120/14481 [=========>....................] - ETA: 2s - loss: 8.0590 - acc: 0.5000
 5312/14481 [==========>...................] - ETA: 2s - loss: 8.0469 - acc: 0.5008
 5504/14481 [==========>...................] - ETA: 2s - loss: 8.0415 - acc: 0.5011
 5696/14481 [==========>...................] - ETA: 2s - loss: 8.0534 - acc: 0.5004
 5888/14481 [===========>..................] - ETA: 2s - loss: 8.0645 - acc: 0.4997
 6144/14481 [===========>..................] - ETA: 1s - loss: 8.0748 - acc: 0.4990
 6336/14481 [============>.................] - ETA: 1s - loss: 8.0412 - acc: 0.5011
 6464/14481 [============>.................] - ETA: 1s - loss: 8.0516 - acc: 0.5005
 6656/14481 [============>.................] - ETA: 1s - loss: 8.0760 - acc: 0.4989
 6848/14481 [=============>................] - ETA: 1s - loss: 8.0496 - acc: 0.5006
 7104/14481 [=============>................] - ETA: 1s - loss: 8.0386 - acc: 0.5013
 7424/14481 [==============>...............] - ETA: 1s - loss: 8.0612 - acc: 0.4999
 7744/14481 [===============>..............] - ETA: 1s - loss: 8.0570 - acc: 0.5001
 8064/14481 [===============>..............] - ETA: 1s - loss: 8.0730 - acc: 0.4991
 8384/14481 [================>.............] - ETA: 1s - loss: 8.0802 - acc: 0.4987
 8704/14481 [=================>............] - ETA: 1s - loss: 8.0757 - acc: 0.4990
 9024/14481 [=================>............] - ETA: 1s - loss: 8.0590 - acc: 0.5000
 9344/14481 [==================>...........] - ETA: 1s - loss: 8.0590 - acc: 0.5000
 9536/14481 [==================>...........] - ETA: 1s - loss: 8.0590 - acc: 0.5000
 9664/14481 [===================>..........] - ETA: 1s - loss: 8.0624 - acc: 0.4998
 9792/14481 [===================>..........] - ETA: 1s - loss: 8.0508 - acc: 0.5005
 9984/14481 [===================>..........] - ETA: 1s - loss: 8.0494 - acc: 0.5006
10304/14481 [====================>.........] - ETA: 0s - loss: 8.0622 - acc: 0.4998
10560/14481 [====================>.........] - ETA: 0s - loss: 8.0652 - acc: 0.4996
10880/14481 [=====================>........] - ETA: 0s - loss: 8.0635 - acc: 0.4997
11200/14481 [======================>.......] - ETA: 0s - loss: 8.0533 - acc: 0.5004
11520/14481 [======================>.......] - ETA: 0s - loss: 8.0479 - acc: 0.5007
11840/14481 [=======================>......] - ETA: 0s - loss: 8.0386 - acc: 0.5013
12160/14481 [========================>.....] - ETA: 0s - loss: 8.0471 - acc: 0.5007
12480/14481 [========================>.....] - ETA: 0s - loss: 8.0578 - acc: 0.5001
12800/14481 [=========================>....] - ETA: 0s - loss: 8.0616 - acc: 0.4998
13120/14481 [==========================>...] - ETA: 0s - loss: 8.0615 - acc: 0.4998
13440/14481 [==========================>...] - ETA: 0s - loss: 8.0662 - acc: 0.4996
13760/14481 [===========================>..] - ETA: 0s - loss: 8.0544 - acc: 0.5003
14080/14481 [============================>.] - ETA: 0s - loss: 8.0590 - acc: 0.5000
14400/14481 [============================>.] - ETA: 0s - loss: 8.0579 - acc: 0.5001
14481/14481 [==============================] - 3s 218us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03270111183781

data size :  16010

zero :  8006

one :  8004

train_zero :  7241

train_one :  7240

test_zero :  765

test_one :  764

choose_zero :  1529

choose_one :  0

F1score :  0.0

AUC : 0.41607381172364233

Confusion Matrix
[[765   0]
 [764   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000345280083839], 'loss': [8.058491243017732]}
Saved model to disk



14

Epoch 1/1

   64/14481 [..............................] - ETA: 3s - loss: 6.5480 - acc: 0.5938
  320/14481 [..............................] - ETA: 2s - loss: 8.0087 - acc: 0.5031
  640/14481 [>.............................] - ETA: 2s - loss: 8.2605 - acc: 0.4875
  960/14481 [>.............................] - ETA: 2s - loss: 8.3445 - acc: 0.4823
 1280/14481 [=>............................] - ETA: 2s - loss: 8.2605 - acc: 0.4875
 1600/14481 [==>...........................] - ETA: 2s - loss: 8.2505 - acc: 0.4881
 1920/14481 [==>...........................] - ETA: 2s - loss: 8.2437 - acc: 0.4885
 2240/14481 [===>..........................] - ETA: 2s - loss: 8.3109 - acc: 0.4844
 2560/14481 [====>.........................] - ETA: 2s - loss: 8.3424 - acc: 0.4824
 2880/14481 [====>.........................] - ETA: 2s - loss: 8.1542 - acc: 0.4941
 3200/14481 [=====>........................] - ETA: 2s - loss: 8.1447 - acc: 0.4947
 3520/14481 [======>.......................] - ETA: 1s - loss: 8.1232 - acc: 0.4960
 3840/14481 [======>.......................] - ETA: 1s - loss: 8.0674 - acc: 0.4995
 4160/14481 [=======>......................] - ETA: 1s - loss: 8.0009 - acc: 0.5036
 4480/14481 [========>.....................] - ETA: 1s - loss: 8.0555 - acc: 0.5002
 4672/14481 [========>.....................] - ETA: 1s - loss: 8.0211 - acc: 0.5024
 4992/14481 [=========>....................] - ETA: 1s - loss: 8.0687 - acc: 0.4994
 5312/14481 [==========>...................] - ETA: 1s - loss: 8.0166 - acc: 0.5026
 5632/14481 [==========>...................] - ETA: 1s - loss: 8.0075 - acc: 0.5032
 5952/14481 [===========>..................] - ETA: 1s - loss: 8.0022 - acc: 0.5035
 6144/14481 [===========>..................] - ETA: 1s - loss: 7.9882 - acc: 0.5044
 6336/14481 [============>.................] - ETA: 1s - loss: 8.0362 - acc: 0.5014
 6592/14481 [============>.................] - ETA: 1s - loss: 8.0175 - acc: 0.5026
 6912/14481 [=============>................] - ETA: 1s - loss: 8.0008 - acc: 0.5036
 7232/14481 [=============>................] - ETA: 1s - loss: 8.0212 - acc: 0.5024
 7552/14481 [==============>...............] - ETA: 1s - loss: 8.0313 - acc: 0.5017
 7808/14481 [===============>..............] - ETA: 1s - loss: 8.0508 - acc: 0.5005
 8128/14481 [===============>..............] - ETA: 1s - loss: 8.0590 - acc: 0.5000
 8384/14481 [================>.............] - ETA: 1s - loss: 8.0744 - acc: 0.4990
 8576/14481 [================>.............] - ETA: 1s - loss: 8.0835 - acc: 0.4985
 8768/14481 [=================>............] - ETA: 1s - loss: 8.0885 - acc: 0.4982
 9088/14481 [=================>............] - ETA: 1s - loss: 8.0892 - acc: 0.4981
 9408/14481 [==================>...........] - ETA: 0s - loss: 8.0933 - acc: 0.4979
 9792/14481 [===================>..........] - ETA: 0s - loss: 8.0739 - acc: 0.4991
10048/14481 [===================>..........] - ETA: 0s - loss: 8.0799 - acc: 0.4987
10304/14481 [====================>.........] - ETA: 0s - loss: 8.0950 - acc: 0.4978
10496/14481 [====================>.........] - ETA: 0s - loss: 8.0759 - acc: 0.4990
10752/14481 [=====================>........] - ETA: 0s - loss: 8.0740 - acc: 0.4991
11008/14481 [=====================>........] - ETA: 0s - loss: 8.0810 - acc: 0.4986
11200/14481 [======================>.......] - ETA: 0s - loss: 8.0921 - acc: 0.4979
11456/14481 [======================>.......] - ETA: 0s - loss: 8.0886 - acc: 0.4982
11648/14481 [=======================>......] - ETA: 0s - loss: 8.0826 - acc: 0.4985
11904/14481 [=======================>......] - ETA: 0s - loss: 8.0780 - acc: 0.4988
12160/14481 [========================>.....] - ETA: 0s - loss: 8.0776 - acc: 0.4988
12416/14481 [========================>.....] - ETA: 0s - loss: 8.0746 - acc: 0.4990
12736/14481 [=========================>....] - ETA: 0s - loss: 8.0806 - acc: 0.4987
13056/14481 [==========================>...] - ETA: 0s - loss: 8.0837 - acc: 0.4985
13376/14481 [==========================>...] - ETA: 0s - loss: 8.0699 - acc: 0.4993
13696/14481 [===========================>..] - ETA: 0s - loss: 8.0732 - acc: 0.4991
14016/14481 [============================>.] - ETA: 0s - loss: 8.0648 - acc: 0.4996
14208/14481 [============================>.] - ETA: 0s - loss: 8.0670 - acc: 0.4995
14336/14481 [============================>.] - ETA: 0s - loss: 8.0647 - acc: 0.4997
14464/14481 [============================>.] - ETA: 0s - loss: 8.0557 - acc: 0.5002
14481/14481 [==============================] - 3s 210us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03270111183781

data size :  16010

zero :  8006

one :  8004

train_zero :  7241

train_one :  7240

test_zero :  765

test_one :  764

choose_zero :  1529

choose_one :  0

F1score :  0.0

AUC : 0.41607381172364233

Confusion Matrix
[[765   0]
 [764   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000345280124999], 'loss': [8.058491253686556]}
Saved model to disk



15

Epoch 1/1

   64/14481 [..............................] - ETA: 3s - loss: 6.0443 - acc: 0.6250
  320/14481 [..............................] - ETA: 2s - loss: 7.6561 - acc: 0.5250
  640/14481 [>.............................] - ETA: 2s - loss: 7.9079 - acc: 0.5094
  960/14481 [>.............................] - ETA: 2s - loss: 7.8744 - acc: 0.5115
 1280/14481 [=>............................] - ETA: 2s - loss: 7.7946 - acc: 0.5164
 1600/14481 [==>...........................] - ETA: 2s - loss: 7.9785 - acc: 0.5050
 1920/14481 [==>...........................] - ETA: 2s - loss: 7.9247 - acc: 0.5083
 2176/14481 [===>..........................] - ETA: 2s - loss: 7.9553 - acc: 0.5064
 2496/14481 [====>.........................] - ETA: 2s - loss: 8.0784 - acc: 0.4988
 2816/14481 [====>.........................] - ETA: 2s - loss: 7.9503 - acc: 0.5067
 3136/14481 [=====>........................] - ETA: 1s - loss: 7.9357 - acc: 0.5077
 3456/14481 [======>.......................] - ETA: 1s - loss: 7.9518 - acc: 0.5067
 3776/14481 [======>.......................] - ETA: 1s - loss: 7.9267 - acc: 0.5082
 4096/14481 [=======>......................] - ETA: 1s - loss: 7.9764 - acc: 0.5051
 4416/14481 [========>.....................] - ETA: 1s - loss: 7.9860 - acc: 0.5045
 4736/14481 [========>.....................] - ETA: 1s - loss: 7.9842 - acc: 0.5046
 5056/14481 [=========>....................] - ETA: 1s - loss: 8.0080 - acc: 0.5032
 5376/14481 [==========>...................] - ETA: 1s - loss: 8.0171 - acc: 0.5026
 5696/14481 [==========>...................] - ETA: 1s - loss: 8.0166 - acc: 0.5026
 6080/14481 [===========>..................] - ETA: 1s - loss: 8.0590 - acc: 0.5000
 6336/14481 [============>.................] - ETA: 1s - loss: 8.0565 - acc: 0.5002
 6656/14481 [============>.................] - ETA: 1s - loss: 8.0373 - acc: 0.5014
 6976/14481 [=============>................] - ETA: 1s - loss: 8.0267 - acc: 0.5020
 7296/14481 [==============>...............] - ETA: 1s - loss: 8.0303 - acc: 0.5018
 7680/14481 [==============>...............] - ETA: 1s - loss: 8.0402 - acc: 0.5012
 8000/14481 [===============>..............] - ETA: 1s - loss: 8.0631 - acc: 0.4998
 8320/14481 [================>.............] - ETA: 1s - loss: 8.0184 - acc: 0.5025
 8640/14481 [================>.............] - ETA: 0s - loss: 8.0367 - acc: 0.5014
 8960/14481 [=================>............] - ETA: 0s - loss: 8.0195 - acc: 0.5025
 9280/14481 [==================>...........] - ETA: 0s - loss: 8.0452 - acc: 0.5009
 9664/14481 [===================>..........] - ETA: 0s - loss: 8.0407 - acc: 0.5011
10048/14481 [===================>..........] - ETA: 0s - loss: 8.0526 - acc: 0.5004
10368/14481 [====================>.........] - ETA: 0s - loss: 8.0497 - acc: 0.5006
10752/14481 [=====================>........] - ETA: 0s - loss: 8.0620 - acc: 0.4998
10944/14481 [=====================>........] - ETA: 0s - loss: 8.0620 - acc: 0.4998
11264/14481 [======================>.......] - ETA: 0s - loss: 8.0562 - acc: 0.5002
11584/14481 [======================>.......] - ETA: 0s - loss: 8.0312 - acc: 0.5017
11904/14481 [=======================>......] - ETA: 0s - loss: 8.0401 - acc: 0.5012
12224/14481 [========================>.....] - ETA: 0s - loss: 8.0485 - acc: 0.5007
12416/14481 [========================>.....] - ETA: 0s - loss: 8.0616 - acc: 0.4998
12608/14481 [=========================>....] - ETA: 0s - loss: 8.0642 - acc: 0.4997
12736/14481 [=========================>....] - ETA: 0s - loss: 8.0641 - acc: 0.4997
12992/14481 [=========================>....] - ETA: 0s - loss: 8.0479 - acc: 0.5007
13184/14481 [==========================>...] - ETA: 0s - loss: 8.0456 - acc: 0.5008
13376/14481 [==========================>...] - ETA: 0s - loss: 8.0349 - acc: 0.5015
13568/14481 [===========================>..] - ETA: 0s - loss: 8.0448 - acc: 0.5009
13760/14481 [===========================>..] - ETA: 0s - loss: 8.0368 - acc: 0.5014
13952/14481 [===========================>..] - ETA: 0s - loss: 8.0394 - acc: 0.5012
14144/14481 [============================>.] - ETA: 0s - loss: 8.0522 - acc: 0.5004
14400/14481 [============================>.] - ETA: 0s - loss: 8.0579 - acc: 0.5001
14481/14481 [==============================] - 3s 191us/step - loss: 8.0585 - acc: 0.5000
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)

Test accuracy: 50.03270111183781

data size :  16010

zero :  8006

one :  8004

train_zero :  7241

train_one :  7240

test_zero :  765

test_one :  764

choose_zero :  1529

choose_one :  0

F1score :  0.0

AUC : 0.41607381172364233

Confusion Matrix
[[765   0]
 [764   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000345280042678], 'loss': [8.058491261721102]}
Saved model to disk



[[50.03270111183781, 1], [50.03270111183781, 2], [50.03270111183781, 3], [50.03270111183781, 4], [50.03270111183781, 5], [50.03270111183781, 6], [50.03270111183781, 7], [50.03270111183781, 8], [50.03270111183781, 9], [50.03270111183781, 10], [50.03270111183781, 11], [50.03270111183781, 12], [50.03270111183781, 13], [50.03270111183781, 14], [50.03270111183781, 15]]
max accuracy :  [50.03270111183781, 15]
