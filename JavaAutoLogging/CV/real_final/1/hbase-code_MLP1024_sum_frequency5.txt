Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
sum_MLP.py:400: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor("de..., inputs=Tensor("in...)`
  model = Model(input=inputs, output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-08-21 04:22:30.247814: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-21 04:22:30.258427: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100085000 Hz
2019-08-21 04:22:30.260935: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x85a64d0 executing computations on platform Host. Devices:
2019-08-21 04:22:30.260981: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
zero : 
39451

one : 
9019
hbase-code
all data

Sentence length Average : 55

Under 10 : 8165
Over 10, Under 200 : 37669
Over 200, Under 400 : 2147
Over 400 : 489

hbase-code
updated_train_data

Sentence length Average : 62

Under 10 : 0
Over 10, Under 200 : 32523
Over 200, Under 400 : 2158
Over 400 : 0


Test_zero:  3007
Train_zero:  26923
zero:  29930
Test_one:  821
Train_one:  7758
one:  8579

Count model parameter.
Get a short summary of each layer dimensions and parameters.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 200)               0         
_________________________________________________________________
masking_1 (Masking)          (None, 200)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              205824    
_________________________________________________________________
dropout_1 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
dropout_2 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 2050      
=================================================================
Total params: 1,257,474
Trainable params: 1,257,474
Non-trainable params: 0
_________________________________________________________________
1

Epoch 1/1

   64/15517 [..............................] - ETA: 1:36 - loss: 3.4764 - acc: 0.4688
  320/15517 [..............................] - ETA: 21s - loss: 6.5017 - acc: 0.5188 
  640/15517 [>.............................] - ETA: 11s - loss: 5.8161 - acc: 0.5922
  960/15517 [>.............................] - ETA: 8s - loss: 6.0354 - acc: 0.5885 
 1280/15517 [=>............................] - ETA: 6s - loss: 6.5791 - acc: 0.5641
 1600/15517 [==>...........................] - ETA: 5s - loss: 6.6534 - acc: 0.5650
 1920/15517 [==>...........................] - ETA: 5s - loss: 6.9549 - acc: 0.5500
 2240/15517 [===>..........................] - ETA: 4s - loss: 7.1558 - acc: 0.5402
 2560/15517 [===>..........................] - ETA: 4s - loss: 7.2246 - acc: 0.5379
 2880/15517 [====>.........................] - ETA: 3s - loss: 7.2949 - acc: 0.5351
 3200/15517 [=====>........................] - ETA: 3s - loss: 7.3965 - acc: 0.5300
 3520/15517 [=====>........................] - ETA: 3s - loss: 7.4659 - acc: 0.5267
 3904/15517 [======>.......................] - ETA: 3s - loss: 7.5367 - acc: 0.5233
 4224/15517 [=======>......................] - ETA: 2s - loss: 7.6449 - acc: 0.5173
 4544/15517 [=======>......................] - ETA: 2s - loss: 7.6492 - acc: 0.5176
 4864/15517 [========>.....................] - ETA: 2s - loss: 7.6464 - acc: 0.5183
 5184/15517 [=========>....................] - ETA: 2s - loss: 7.6936 - acc: 0.5158
 5568/15517 [=========>....................] - ETA: 2s - loss: 7.7304 - acc: 0.5140
 5952/15517 [==========>...................] - ETA: 2s - loss: 7.7325 - acc: 0.5139
 6336/15517 [===========>..................] - ETA: 2s - loss: 7.7040 - acc: 0.5161
 6720/15517 [===========>..................] - ETA: 1s - loss: 7.7459 - acc: 0.5138
 7104/15517 [============>.................] - ETA: 1s - loss: 7.7242 - acc: 0.5155
 7488/15517 [=============>................] - ETA: 1s - loss: 7.7758 - acc: 0.5126
 7808/15517 [==============>...............] - ETA: 1s - loss: 7.7730 - acc: 0.5129
 8192/15517 [==============>...............] - ETA: 1s - loss: 7.7785 - acc: 0.5128
 8576/15517 [===============>..............] - ETA: 1s - loss: 7.8118 - acc: 0.5110
 8960/15517 [================>.............] - ETA: 1s - loss: 7.8529 - acc: 0.5086
 9344/15517 [=================>............] - ETA: 1s - loss: 7.8838 - acc: 0.5068
 9728/15517 [=================>............] - ETA: 1s - loss: 7.8874 - acc: 0.5068
10112/15517 [==================>...........] - ETA: 1s - loss: 7.9035 - acc: 0.5059
10496/15517 [===================>..........] - ETA: 0s - loss: 7.8985 - acc: 0.5064
10880/15517 [====================>.........] - ETA: 0s - loss: 7.8878 - acc: 0.5072
11264/15517 [====================>.........] - ETA: 0s - loss: 7.9108 - acc: 0.5059
11648/15517 [=====================>........] - ETA: 0s - loss: 7.9213 - acc: 0.5053
12032/15517 [======================>.......] - ETA: 0s - loss: 7.9069 - acc: 0.5063
12416/15517 [=======================>......] - ETA: 0s - loss: 7.9064 - acc: 0.5064
12800/15517 [=======================>......] - ETA: 0s - loss: 7.9173 - acc: 0.5059
13184/15517 [========================>.....] - ETA: 0s - loss: 7.8970 - acc: 0.5072
13568/15517 [=========================>....] - ETA: 0s - loss: 7.9217 - acc: 0.5057
13952/15517 [=========================>....] - ETA: 0s - loss: 7.9278 - acc: 0.5054
14336/15517 [==========================>...] - ETA: 0s - loss: 7.9325 - acc: 0.5052
14720/15517 [===========================>..] - ETA: 0s - loss: 7.9259 - acc: 0.5057
15104/15517 [============================>.] - ETA: 0s - loss: 7.9272 - acc: 0.5057
15488/15517 [============================>.] - ETA: 0s - loss: 7.9232 - acc: 0.5060
15517/15517 [==============================] - 3s 182us/step - loss: 7.9229 - acc: 0.5060

Test accuracy: 50.03043213633597

data size :  17160

zero :  8581

one :  8579

train_zero :  7759

train_one :  7758

test_zero :  822

test_one :  821

choose_zero :  1643

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[822   0]
 [821   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5060256492494654], 'loss': [7.922893855592797]}
Saved model to disk



2

Epoch 1/1

   64/15517 [..............................] - ETA: 3s - loss: 9.0664 - acc: 0.4375
  384/15517 [..............................] - ETA: 2s - loss: 8.3109 - acc: 0.4844
  704/15517 [>.............................] - ETA: 2s - loss: 8.4254 - acc: 0.4773
 1024/15517 [>.............................] - ETA: 2s - loss: 8.3896 - acc: 0.4795
 1344/15517 [=>............................] - ETA: 2s - loss: 8.2150 - acc: 0.4903
 1664/15517 [==>...........................] - ETA: 2s - loss: 8.3109 - acc: 0.4844
 1984/15517 [==>...........................] - ETA: 2s - loss: 8.3028 - acc: 0.4849
 2304/15517 [===>..........................] - ETA: 2s - loss: 8.3599 - acc: 0.4813
 2624/15517 [====>.........................] - ETA: 2s - loss: 8.2986 - acc: 0.4851
 2944/15517 [====>.........................] - ETA: 2s - loss: 8.2288 - acc: 0.4895
 3264/15517 [=====>........................] - ETA: 2s - loss: 8.2418 - acc: 0.4887
 3584/15517 [=====>........................] - ETA: 1s - loss: 8.2434 - acc: 0.4886
 3904/15517 [======>.......................] - ETA: 1s - loss: 8.1581 - acc: 0.4939
 4224/15517 [=======>......................] - ETA: 1s - loss: 8.2079 - acc: 0.4908
 4544/15517 [=======>......................] - ETA: 1s - loss: 8.1903 - acc: 0.4919
 4864/15517 [========>.....................] - ETA: 1s - loss: 8.1618 - acc: 0.4936
 5184/15517 [=========>....................] - ETA: 1s - loss: 8.1399 - acc: 0.4950
 5504/15517 [=========>....................] - ETA: 1s - loss: 8.1440 - acc: 0.4947
 5824/15517 [==========>...................] - ETA: 1s - loss: 8.1061 - acc: 0.4971
 6208/15517 [===========>..................] - ETA: 1s - loss: 8.0824 - acc: 0.4986
 6528/15517 [===========>..................] - ETA: 1s - loss: 8.0541 - acc: 0.5003
 6912/15517 [============>.................] - ETA: 1s - loss: 8.0427 - acc: 0.5010
 7296/15517 [=============>................] - ETA: 1s - loss: 7.9950 - acc: 0.5040
 7680/15517 [=============>................] - ETA: 1s - loss: 7.9919 - acc: 0.5042
 8000/15517 [==============>...............] - ETA: 1s - loss: 8.0188 - acc: 0.5025
 8384/15517 [===============>..............] - ETA: 1s - loss: 8.0244 - acc: 0.5021
 8768/15517 [===============>..............] - ETA: 1s - loss: 8.0186 - acc: 0.5025
 9152/15517 [================>.............] - ETA: 1s - loss: 8.0256 - acc: 0.5021
 9536/15517 [=================>............] - ETA: 0s - loss: 8.0151 - acc: 0.5027
 9920/15517 [==================>...........] - ETA: 0s - loss: 8.0347 - acc: 0.5015
10304/15517 [==================>...........] - ETA: 0s - loss: 8.0465 - acc: 0.5008
10688/15517 [===================>..........] - ETA: 0s - loss: 8.0606 - acc: 0.4999
11072/15517 [====================>.........] - ETA: 0s - loss: 8.0576 - acc: 0.5001
11456/15517 [=====================>........] - ETA: 0s - loss: 8.0590 - acc: 0.5000
11840/15517 [=====================>........] - ETA: 0s - loss: 8.0414 - acc: 0.5011
12224/15517 [======================>.......] - ETA: 0s - loss: 8.0445 - acc: 0.5009
12608/15517 [=======================>......] - ETA: 0s - loss: 8.0693 - acc: 0.4994
12992/15517 [========================>.....] - ETA: 0s - loss: 8.0590 - acc: 0.5000
13376/15517 [========================>.....] - ETA: 0s - loss: 8.0651 - acc: 0.4996
13760/15517 [=========================>....] - ETA: 0s - loss: 8.0567 - acc: 0.5001
14144/15517 [==========================>...] - ETA: 0s - loss: 8.0613 - acc: 0.4999
14528/15517 [===========================>..] - ETA: 0s - loss: 8.0657 - acc: 0.4996
14912/15517 [===========================>..] - ETA: 0s - loss: 8.0569 - acc: 0.5001
15296/15517 [============================>.] - ETA: 0s - loss: 8.0443 - acc: 0.5009
15517/15517 [==============================] - 2s 157us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03043213633597

data size :  17160

zero :  8581

one :  8579

train_zero :  7759

train_one :  7758

test_zero :  822

test_one :  821

choose_zero :  1643

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[822   0]
 [821   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000322227138615], 'loss': [8.05852839556015]}
Saved model to disk



3

Epoch 1/1

   64/15517 [..............................] - ETA: 4s - loss: 7.5554 - acc: 0.5312
  320/15517 [..............................] - ETA: 3s - loss: 8.1598 - acc: 0.4938
  640/15517 [>.............................] - ETA: 3s - loss: 7.9079 - acc: 0.5094
  960/15517 [>.............................] - ETA: 2s - loss: 7.8744 - acc: 0.5115
 1280/15517 [=>............................] - ETA: 2s - loss: 8.0339 - acc: 0.5016
 1600/15517 [==>...........................] - ETA: 2s - loss: 7.9281 - acc: 0.5081
 1920/15517 [==>...........................] - ETA: 2s - loss: 7.9415 - acc: 0.5073
 2240/15517 [===>..........................] - ETA: 2s - loss: 7.9943 - acc: 0.5040
 2560/15517 [===>..........................] - ETA: 2s - loss: 8.0276 - acc: 0.5020
 2880/15517 [====>.........................] - ETA: 2s - loss: 7.9751 - acc: 0.5052
 3200/15517 [=====>........................] - ETA: 2s - loss: 8.0036 - acc: 0.5034
 3520/15517 [=====>........................] - ETA: 2s - loss: 7.8896 - acc: 0.5105
 3840/15517 [======>.......................] - ETA: 1s - loss: 7.9247 - acc: 0.5083
 4160/15517 [=======>......................] - ETA: 1s - loss: 7.8731 - acc: 0.5115
 4480/15517 [=======>......................] - ETA: 1s - loss: 7.9295 - acc: 0.5080
 4800/15517 [========>.....................] - ETA: 1s - loss: 8.0120 - acc: 0.5029
 5120/15517 [========>.....................] - ETA: 1s - loss: 7.9992 - acc: 0.5037
 5504/15517 [=========>....................] - ETA: 1s - loss: 8.0034 - acc: 0.5035
 5888/15517 [==========>...................] - ETA: 1s - loss: 8.0536 - acc: 0.5003
 6272/15517 [===========>..................] - ETA: 1s - loss: 8.0822 - acc: 0.4986
 6656/15517 [===========>..................] - ETA: 1s - loss: 8.0857 - acc: 0.4983
 7040/15517 [============>.................] - ETA: 1s - loss: 8.0888 - acc: 0.4982
 7424/15517 [=============>................] - ETA: 1s - loss: 8.0851 - acc: 0.4984
 7808/15517 [==============>...............] - ETA: 1s - loss: 8.1148 - acc: 0.4965
 8192/15517 [==============>...............] - ETA: 1s - loss: 8.0827 - acc: 0.4985
 8512/15517 [===============>..............] - ETA: 1s - loss: 8.0666 - acc: 0.4995
 8896/15517 [================>.............] - ETA: 1s - loss: 8.0862 - acc: 0.4983
 9280/15517 [================>.............] - ETA: 1s - loss: 8.0973 - acc: 0.4976
 9664/15517 [=================>............] - ETA: 0s - loss: 8.0941 - acc: 0.4978
10048/15517 [==================>...........] - ETA: 0s - loss: 8.0911 - acc: 0.4980
10368/15517 [===================>..........] - ETA: 0s - loss: 8.0995 - acc: 0.4975
10688/15517 [===================>..........] - ETA: 0s - loss: 8.1088 - acc: 0.4969
11072/15517 [====================>.........] - ETA: 0s - loss: 8.1289 - acc: 0.4957
11392/15517 [=====================>........] - ETA: 0s - loss: 8.1255 - acc: 0.4959
11776/15517 [=====================>........] - ETA: 0s - loss: 8.1028 - acc: 0.4973
12160/15517 [======================>.......] - ETA: 0s - loss: 8.0962 - acc: 0.4977
12544/15517 [=======================>......] - ETA: 0s - loss: 8.0732 - acc: 0.4991
12928/15517 [=======================>......] - ETA: 0s - loss: 8.0578 - acc: 0.5001
13312/15517 [========================>.....] - ETA: 0s - loss: 8.0518 - acc: 0.5005
13696/15517 [=========================>....] - ETA: 0s - loss: 8.0649 - acc: 0.4996
14016/15517 [==========================>...] - ETA: 0s - loss: 8.0682 - acc: 0.4994
14400/15517 [==========================>...] - ETA: 0s - loss: 8.0814 - acc: 0.4986
14784/15517 [===========================>..] - ETA: 0s - loss: 8.0798 - acc: 0.4987
15168/15517 [============================>.] - ETA: 0s - loss: 8.0590 - acc: 0.5000
15517/15517 [==============================] - 2s 158us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03043213633597

data size :  17160

zero :  8581

one :  8579

train_zero :  7759

train_one :  7758

test_zero :  822

test_one :  821

choose_zero :  1643

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[822   0]
 [821   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000322227541946], 'loss': [8.058528381977498]}
Saved model to disk



4

Epoch 1/1

   64/15517 [..............................] - ETA: 3s - loss: 6.5480 - acc: 0.5938
  384/15517 [..............................] - ETA: 2s - loss: 7.7233 - acc: 0.5208
  704/15517 [>.............................] - ETA: 2s - loss: 7.6011 - acc: 0.5284
 1024/15517 [>.............................] - ETA: 2s - loss: 7.6970 - acc: 0.5225
 1344/15517 [=>............................] - ETA: 2s - loss: 7.6033 - acc: 0.5283
 1664/15517 [==>...........................] - ETA: 2s - loss: 7.7297 - acc: 0.5204
 1984/15517 [==>...........................] - ETA: 2s - loss: 7.7341 - acc: 0.5202
 2304/15517 [===>..........................] - ETA: 2s - loss: 7.8212 - acc: 0.5148
 2624/15517 [====>.........................] - ETA: 2s - loss: 7.8318 - acc: 0.5141
 2944/15517 [====>.........................] - ETA: 2s - loss: 7.8291 - acc: 0.5143
 3264/15517 [=====>........................] - ETA: 2s - loss: 7.8516 - acc: 0.5129
 3584/15517 [=====>........................] - ETA: 2s - loss: 7.8702 - acc: 0.5117
 3904/15517 [======>.......................] - ETA: 1s - loss: 7.9104 - acc: 0.5092
 4224/15517 [=======>......................] - ETA: 1s - loss: 7.9102 - acc: 0.5092
 4544/15517 [=======>......................] - ETA: 1s - loss: 7.9243 - acc: 0.5084
 4928/15517 [========>.....................] - ETA: 1s - loss: 7.9413 - acc: 0.5073
 5312/15517 [=========>....................] - ETA: 1s - loss: 7.9134 - acc: 0.5090
 5696/15517 [==========>...................] - ETA: 1s - loss: 7.9345 - acc: 0.5077
 6080/15517 [==========>...................] - ETA: 1s - loss: 7.9875 - acc: 0.5044
 6464/15517 [===========>..................] - ETA: 1s - loss: 8.0167 - acc: 0.5026
 6848/15517 [============>.................] - ETA: 1s - loss: 8.0237 - acc: 0.5022
 7232/15517 [============>.................] - ETA: 1s - loss: 7.9922 - acc: 0.5041
 7616/15517 [=============>................] - ETA: 1s - loss: 8.0463 - acc: 0.5008
 8000/15517 [==============>...............] - ETA: 1s - loss: 8.0570 - acc: 0.5001
 8320/15517 [===============>..............] - ETA: 1s - loss: 8.0435 - acc: 0.5010
 8640/15517 [===============>..............] - ETA: 1s - loss: 8.0143 - acc: 0.5028
 8960/15517 [================>.............] - ETA: 1s - loss: 8.0267 - acc: 0.5020
 9344/15517 [=================>............] - ETA: 0s - loss: 8.0521 - acc: 0.5004
 9728/15517 [=================>............] - ETA: 0s - loss: 8.0657 - acc: 0.4996
10112/15517 [==================>...........] - ETA: 0s - loss: 8.0654 - acc: 0.4996
10496/15517 [===================>..........] - ETA: 0s - loss: 8.0882 - acc: 0.4982
10816/15517 [===================>..........] - ETA: 0s - loss: 8.0903 - acc: 0.4981
11136/15517 [====================>.........] - ETA: 0s - loss: 8.0967 - acc: 0.4977
11520/15517 [=====================>........] - ETA: 0s - loss: 8.0982 - acc: 0.4976
11904/15517 [======================>.......] - ETA: 0s - loss: 8.0848 - acc: 0.4984
12288/15517 [======================>.......] - ETA: 0s - loss: 8.0682 - acc: 0.4994
12672/15517 [=======================>......] - ETA: 0s - loss: 8.0730 - acc: 0.4991
13056/15517 [========================>.....] - ETA: 0s - loss: 8.0739 - acc: 0.4991
13440/15517 [========================>.....] - ETA: 0s - loss: 8.0698 - acc: 0.4993
13824/15517 [=========================>....] - ETA: 0s - loss: 8.0660 - acc: 0.4996
14208/15517 [==========================>...] - ETA: 0s - loss: 8.0625 - acc: 0.4998
14592/15517 [===========================>..] - ETA: 0s - loss: 8.0469 - acc: 0.5008
14976/15517 [===========================>..] - ETA: 0s - loss: 8.0580 - acc: 0.5001
15360/15517 [============================>.] - ETA: 0s - loss: 8.0601 - acc: 0.4999
15517/15517 [==============================] - 2s 157us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03043213633597

data size :  17160

zero :  8581

one :  8579

train_zero :  7759

train_one :  7758

test_zero :  822

test_one :  821

choose_zero :  1643

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[822   0]
 [821   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000322226850521], 'loss': [8.05852841547318]}
Saved model to disk



5

Epoch 1/1

   64/15517 [..............................] - ETA: 3s - loss: 8.0590 - acc: 0.5000
  384/15517 [..............................] - ETA: 2s - loss: 8.8985 - acc: 0.4479
  704/15517 [>.............................] - ETA: 2s - loss: 8.7001 - acc: 0.4602
 1024/15517 [>.............................] - ETA: 2s - loss: 8.5942 - acc: 0.4668
 1344/15517 [=>............................] - ETA: 2s - loss: 8.5388 - acc: 0.4702
 1664/15517 [==>...........................] - ETA: 2s - loss: 8.3884 - acc: 0.4796
 1984/15517 [==>...........................] - ETA: 2s - loss: 8.3678 - acc: 0.4808
 2304/15517 [===>..........................] - ETA: 2s - loss: 8.4438 - acc: 0.4761
 2624/15517 [====>.........................] - ETA: 2s - loss: 8.3539 - acc: 0.4817
 2944/15517 [====>.........................] - ETA: 2s - loss: 8.3328 - acc: 0.4830
 3264/15517 [=====>........................] - ETA: 2s - loss: 8.2664 - acc: 0.4871
 3584/15517 [=====>........................] - ETA: 2s - loss: 8.2839 - acc: 0.4860
 3904/15517 [======>.......................] - ETA: 1s - loss: 8.2242 - acc: 0.4898
 4224/15517 [=======>......................] - ETA: 1s - loss: 8.1659 - acc: 0.4934
 4544/15517 [=======>......................] - ETA: 1s - loss: 8.1619 - acc: 0.4936
 4864/15517 [========>.....................] - ETA: 1s - loss: 8.1750 - acc: 0.4928
 5184/15517 [=========>....................] - ETA: 1s - loss: 8.1834 - acc: 0.4923
 5568/15517 [=========>....................] - ETA: 1s - loss: 8.2038 - acc: 0.4910
 5952/15517 [==========>...................] - ETA: 1s - loss: 8.1809 - acc: 0.4924
 6336/15517 [===========>..................] - ETA: 1s - loss: 8.1633 - acc: 0.4935
 6720/15517 [===========>..................] - ETA: 1s - loss: 8.1526 - acc: 0.4942
 7040/15517 [============>.................] - ETA: 1s - loss: 8.1277 - acc: 0.4957
 7424/15517 [=============>................] - ETA: 1s - loss: 8.1003 - acc: 0.4974
 7744/15517 [=============>................] - ETA: 1s - loss: 8.0944 - acc: 0.4978
 8128/15517 [==============>...............] - ETA: 1s - loss: 8.0888 - acc: 0.4982
 8512/15517 [===============>..............] - ETA: 1s - loss: 8.1121 - acc: 0.4967
 8896/15517 [================>.............] - ETA: 1s - loss: 8.1116 - acc: 0.4967
 9280/15517 [================>.............] - ETA: 1s - loss: 8.0938 - acc: 0.4978
 9664/15517 [=================>............] - ETA: 0s - loss: 8.0941 - acc: 0.4978
10048/15517 [==================>...........] - ETA: 0s - loss: 8.1104 - acc: 0.4968
10432/15517 [===================>..........] - ETA: 0s - loss: 8.1008 - acc: 0.4974
10816/15517 [===================>..........] - ETA: 0s - loss: 8.0874 - acc: 0.4982
11200/15517 [====================>.........] - ETA: 0s - loss: 8.0634 - acc: 0.4997
11584/15517 [=====================>........] - ETA: 0s - loss: 8.0451 - acc: 0.5009
11968/15517 [======================>.......] - ETA: 0s - loss: 8.0335 - acc: 0.5016
12352/15517 [======================>.......] - ETA: 0s - loss: 8.0343 - acc: 0.5015
12736/15517 [=======================>......] - ETA: 0s - loss: 8.0363 - acc: 0.5014
13120/15517 [========================>.....] - ETA: 0s - loss: 8.0308 - acc: 0.5018
13504/15517 [=========================>....] - ETA: 0s - loss: 8.0268 - acc: 0.5020
13888/15517 [=========================>....] - ETA: 0s - loss: 8.0382 - acc: 0.5013
14272/15517 [==========================>...] - ETA: 0s - loss: 8.0331 - acc: 0.5016
14656/15517 [===========================>..] - ETA: 0s - loss: 8.0338 - acc: 0.5016
15040/15517 [============================>.] - ETA: 0s - loss: 8.0387 - acc: 0.5013
15424/15517 [============================>.] - ETA: 0s - loss: 8.0580 - acc: 0.5001
15517/15517 [==============================] - 2s 157us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03043213633597

data size :  17160

zero :  8581

one :  8579

train_zero :  7759

train_one :  7758

test_zero :  822

test_one :  821

choose_zero :  1643

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[822   0]
 [821   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000322226850521], 'loss': [8.058528404564036]}
Saved model to disk



6

Epoch 1/1

   64/15517 [..............................] - ETA: 3s - loss: 8.0590 - acc: 0.5000
  384/15517 [..............................] - ETA: 2s - loss: 8.3948 - acc: 0.4792
  704/15517 [>.............................] - ETA: 2s - loss: 8.1048 - acc: 0.4972
 1024/15517 [>.............................] - ETA: 2s - loss: 8.0433 - acc: 0.5010
 1344/15517 [=>............................] - ETA: 2s - loss: 8.0950 - acc: 0.4978
 1664/15517 [==>...........................] - ETA: 2s - loss: 8.1365 - acc: 0.4952
 1984/15517 [==>...........................] - ETA: 2s - loss: 8.0184 - acc: 0.5025
 2304/15517 [===>..........................] - ETA: 2s - loss: 8.0241 - acc: 0.5022
 2624/15517 [====>.........................] - ETA: 2s - loss: 7.9976 - acc: 0.5038
 2944/15517 [====>.........................] - ETA: 2s - loss: 8.0098 - acc: 0.5031
 3264/15517 [=====>........................] - ETA: 2s - loss: 7.9702 - acc: 0.5055
 3584/15517 [=====>........................] - ETA: 2s - loss: 7.9826 - acc: 0.5047
 3904/15517 [======>.......................] - ETA: 1s - loss: 8.0260 - acc: 0.5020
 4288/15517 [=======>......................] - ETA: 1s - loss: 7.9463 - acc: 0.5070
 4672/15517 [========>.....................] - ETA: 1s - loss: 7.9314 - acc: 0.5079
 4992/15517 [========>.....................] - ETA: 1s - loss: 7.9977 - acc: 0.5038
 5376/15517 [=========>....................] - ETA: 1s - loss: 7.9961 - acc: 0.5039
 5760/15517 [==========>...................] - ETA: 1s - loss: 7.9947 - acc: 0.5040
 6144/15517 [==========>...................] - ETA: 1s - loss: 7.9830 - acc: 0.5047
 6528/15517 [===========>..................] - ETA: 1s - loss: 7.9899 - acc: 0.5043
 6912/15517 [============>.................] - ETA: 1s - loss: 8.0241 - acc: 0.5022
 7232/15517 [============>.................] - ETA: 1s - loss: 8.0167 - acc: 0.5026
 7616/15517 [=============>................] - ETA: 1s - loss: 7.9934 - acc: 0.5041
 7936/15517 [==============>...............] - ETA: 1s - loss: 7.9778 - acc: 0.5050
 8256/15517 [==============>...............] - ETA: 1s - loss: 8.0122 - acc: 0.5029
 8640/15517 [===============>..............] - ETA: 1s - loss: 8.0348 - acc: 0.5015
 9024/15517 [================>.............] - ETA: 1s - loss: 8.0483 - acc: 0.5007
 9344/15517 [=================>............] - ETA: 0s - loss: 8.0349 - acc: 0.5015
 9664/15517 [=================>............] - ETA: 0s - loss: 8.0357 - acc: 0.5014
10048/15517 [==================>...........] - ETA: 0s - loss: 8.0510 - acc: 0.5005
10432/15517 [===================>..........] - ETA: 0s - loss: 8.0421 - acc: 0.5011
10816/15517 [===================>..........] - ETA: 0s - loss: 8.0635 - acc: 0.4997
11136/15517 [====================>.........] - ETA: 0s - loss: 8.0533 - acc: 0.5004
11456/15517 [=====================>........] - ETA: 0s - loss: 8.0478 - acc: 0.5007
11840/15517 [=====================>........] - ETA: 0s - loss: 8.0454 - acc: 0.5008
12224/15517 [======================>.......] - ETA: 0s - loss: 8.0590 - acc: 0.5000
12608/15517 [=======================>......] - ETA: 0s - loss: 8.0590 - acc: 0.5000
12992/15517 [========================>.....] - ETA: 0s - loss: 8.0429 - acc: 0.5010
13376/15517 [========================>.....] - ETA: 0s - loss: 8.0687 - acc: 0.4994
13760/15517 [=========================>....] - ETA: 0s - loss: 8.0602 - acc: 0.4999
14144/15517 [==========================>...] - ETA: 0s - loss: 8.0727 - acc: 0.4992
14528/15517 [===========================>..] - ETA: 0s - loss: 8.0679 - acc: 0.4994
14912/15517 [===========================>..] - ETA: 0s - loss: 8.0720 - acc: 0.4992
15232/15517 [============================>.] - ETA: 0s - loss: 8.0696 - acc: 0.4993
15517/15517 [==============================] - 2s 159us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03043213633597

data size :  17160

zero :  8581

one :  8579

train_zero :  7759

train_one :  7758

test_zero :  822

test_one :  821

choose_zero :  1643

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[822   0]
 [821   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000322227541946], 'loss': [8.058528423278597]}
Saved model to disk



7

Epoch 1/1

   64/15517 [..............................] - ETA: 3s - loss: 8.3109 - acc: 0.4844
  384/15517 [..............................] - ETA: 2s - loss: 8.3529 - acc: 0.4818
  704/15517 [>.............................] - ETA: 2s - loss: 8.2651 - acc: 0.4872
 1024/15517 [>.............................] - ETA: 2s - loss: 8.7359 - acc: 0.4580
 1344/15517 [=>............................] - ETA: 2s - loss: 8.3948 - acc: 0.4792
 1664/15517 [==>...........................] - ETA: 2s - loss: 8.3206 - acc: 0.4838
 1984/15517 [==>...........................] - ETA: 2s - loss: 8.3028 - acc: 0.4849
 2304/15517 [===>..........................] - ETA: 2s - loss: 8.2199 - acc: 0.4900
 2624/15517 [====>.........................] - ETA: 2s - loss: 8.2126 - acc: 0.4905
 2944/15517 [====>.........................] - ETA: 2s - loss: 8.2397 - acc: 0.4888
 3264/15517 [=====>........................] - ETA: 2s - loss: 8.2023 - acc: 0.4911
 3584/15517 [=====>........................] - ETA: 2s - loss: 8.0995 - acc: 0.4975
 3904/15517 [======>.......................] - ETA: 1s - loss: 8.1127 - acc: 0.4967
 4224/15517 [=======>......................] - ETA: 1s - loss: 8.1201 - acc: 0.4962
 4544/15517 [=======>......................] - ETA: 1s - loss: 8.1193 - acc: 0.4963
 4864/15517 [========>.....................] - ETA: 1s - loss: 8.1154 - acc: 0.4965
 5184/15517 [=========>....................] - ETA: 1s - loss: 8.1368 - acc: 0.4952
 5568/15517 [=========>....................] - ETA: 1s - loss: 8.1140 - acc: 0.4966
 5952/15517 [==========>...................] - ETA: 1s - loss: 8.1132 - acc: 0.4966
 6336/15517 [===========>..................] - ETA: 1s - loss: 8.1125 - acc: 0.4967
 6720/15517 [===========>..................] - ETA: 1s - loss: 8.1094 - acc: 0.4969
 7104/15517 [============>.................] - ETA: 1s - loss: 8.0999 - acc: 0.4975
 7488/15517 [=============>................] - ETA: 1s - loss: 8.0935 - acc: 0.4979
 7872/15517 [==============>...............] - ETA: 1s - loss: 8.0795 - acc: 0.4987
 8256/15517 [==============>...............] - ETA: 1s - loss: 8.0493 - acc: 0.5006
 8640/15517 [===============>..............] - ETA: 1s - loss: 8.0161 - acc: 0.5027
 9024/15517 [================>.............] - ETA: 1s - loss: 8.0269 - acc: 0.5020
 9408/15517 [=================>............] - ETA: 0s - loss: 8.0094 - acc: 0.5031
 9792/15517 [=================>............] - ETA: 0s - loss: 7.9949 - acc: 0.5040
10176/15517 [==================>...........] - ETA: 0s - loss: 7.9957 - acc: 0.5039
10560/15517 [===================>..........] - ETA: 0s - loss: 8.0331 - acc: 0.5016
10944/15517 [====================>.........] - ETA: 0s - loss: 8.0370 - acc: 0.5014
11328/15517 [====================>.........] - ETA: 0s - loss: 8.0292 - acc: 0.5019
11712/15517 [=====================>........] - ETA: 0s - loss: 8.0384 - acc: 0.5013
12096/15517 [======================>.......] - ETA: 0s - loss: 8.0337 - acc: 0.5016
12416/15517 [=======================>......] - ETA: 0s - loss: 8.0227 - acc: 0.5023
12800/15517 [=======================>......] - ETA: 0s - loss: 8.0339 - acc: 0.5016
13184/15517 [========================>.....] - ETA: 0s - loss: 8.0358 - acc: 0.5014
13504/15517 [=========================>....] - ETA: 0s - loss: 8.0400 - acc: 0.5012
13888/15517 [=========================>....] - ETA: 0s - loss: 8.0416 - acc: 0.5011
14272/15517 [==========================>...] - ETA: 0s - loss: 8.0489 - acc: 0.5006
14656/15517 [===========================>..] - ETA: 0s - loss: 8.0349 - acc: 0.5015
15040/15517 [============================>.] - ETA: 0s - loss: 8.0526 - acc: 0.5004
15424/15517 [============================>.] - ETA: 0s - loss: 8.0528 - acc: 0.5004
15517/15517 [==============================] - 2s 157us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03043213633597

data size :  17160

zero :  8581

one :  8579

train_zero :  7759

train_one :  7758

test_zero :  822

test_one :  821

choose_zero :  1643

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[822   0]
 [821   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000322227138615], 'loss': [8.058528427212034]}
Saved model to disk



8

Epoch 1/1

   64/15517 [..............................] - ETA: 3s - loss: 7.8072 - acc: 0.5156
  384/15517 [..............................] - ETA: 2s - loss: 8.3948 - acc: 0.4792
  704/15517 [>.............................] - ETA: 2s - loss: 8.6314 - acc: 0.4645
 1024/15517 [>.............................] - ETA: 2s - loss: 8.2165 - acc: 0.4902
 1344/15517 [=>............................] - ETA: 2s - loss: 8.3589 - acc: 0.4814
 1664/15517 [==>...........................] - ETA: 2s - loss: 8.2334 - acc: 0.4892
 1984/15517 [==>...........................] - ETA: 2s - loss: 8.1890 - acc: 0.4919
 2304/15517 [===>..........................] - ETA: 2s - loss: 8.0940 - acc: 0.4978
 2624/15517 [====>.........................] - ETA: 2s - loss: 8.1082 - acc: 0.4970
 2944/15517 [====>.........................] - ETA: 2s - loss: 8.1028 - acc: 0.4973
 3264/15517 [=====>........................] - ETA: 2s - loss: 8.1035 - acc: 0.4972
 3584/15517 [=====>........................] - ETA: 1s - loss: 8.0231 - acc: 0.5022
 3904/15517 [======>.......................] - ETA: 1s - loss: 8.0178 - acc: 0.5026
 4224/15517 [=======>......................] - ETA: 1s - loss: 8.0400 - acc: 0.5012
 4544/15517 [=======>......................] - ETA: 1s - loss: 8.0697 - acc: 0.4993
 4864/15517 [========>.....................] - ETA: 1s - loss: 8.0226 - acc: 0.5023
 5248/15517 [=========>....................] - ETA: 1s - loss: 8.0222 - acc: 0.5023
 5568/15517 [=========>....................] - ETA: 1s - loss: 8.0098 - acc: 0.5031
 5952/15517 [==========>...................] - ETA: 1s - loss: 8.0076 - acc: 0.5032
 6336/15517 [===========>..................] - ETA: 1s - loss: 8.0005 - acc: 0.5036
 6720/15517 [===========>..................] - ETA: 1s - loss: 7.9871 - acc: 0.5045
 7104/15517 [============>.................] - ETA: 1s - loss: 7.9683 - acc: 0.5056
 7488/15517 [=============>................] - ETA: 1s - loss: 8.0160 - acc: 0.5027
 7808/15517 [==============>...............] - ETA: 1s - loss: 8.0178 - acc: 0.5026
 8192/15517 [==============>...............] - ETA: 1s - loss: 8.0040 - acc: 0.5034
 8576/15517 [===============>..............] - ETA: 1s - loss: 8.0045 - acc: 0.5034
 8896/15517 [================>.............] - ETA: 1s - loss: 7.9993 - acc: 0.5037
 9280/15517 [================>.............] - ETA: 0s - loss: 7.9965 - acc: 0.5039
 9664/15517 [=================>............] - ETA: 0s - loss: 7.9873 - acc: 0.5044
 9984/15517 [==================>...........] - ETA: 0s - loss: 7.9945 - acc: 0.5040
10368/15517 [===================>..........] - ETA: 0s - loss: 8.0093 - acc: 0.5031
10752/15517 [===================>..........] - ETA: 0s - loss: 8.0096 - acc: 0.5031
11136/15517 [====================>.........] - ETA: 0s - loss: 8.0084 - acc: 0.5031
11456/15517 [=====================>........] - ETA: 0s - loss: 8.0253 - acc: 0.5021
11840/15517 [=====================>........] - ETA: 0s - loss: 8.0291 - acc: 0.5019
12224/15517 [======================>.......] - ETA: 0s - loss: 8.0340 - acc: 0.5016
12544/15517 [=======================>......] - ETA: 0s - loss: 8.0513 - acc: 0.5005
12928/15517 [=======================>......] - ETA: 0s - loss: 8.0466 - acc: 0.5008
13248/15517 [========================>.....] - ETA: 0s - loss: 8.0578 - acc: 0.5001
13632/15517 [=========================>....] - ETA: 0s - loss: 8.0709 - acc: 0.4993
14016/15517 [==========================>...] - ETA: 0s - loss: 8.0751 - acc: 0.4990
14400/15517 [==========================>...] - ETA: 0s - loss: 8.0814 - acc: 0.4986
14720/15517 [===========================>..] - ETA: 0s - loss: 8.0689 - acc: 0.4994
15104/15517 [============================>.] - ETA: 0s - loss: 8.0665 - acc: 0.4995
15488/15517 [============================>.] - ETA: 0s - loss: 8.0622 - acc: 0.4998
15517/15517 [==============================] - 2s 157us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03043213633597

data size :  17160

zero :  8581

one :  8579

train_zero :  7759

train_one :  7758

test_zero :  822

test_one :  821

choose_zero :  1643

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[822   0]
 [821   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000322226773696], 'loss': [8.058528382930128]}
Saved model to disk



9

Epoch 1/1

   64/15517 [..............................] - ETA: 3s - loss: 8.3109 - acc: 0.4844
  384/15517 [..............................] - ETA: 2s - loss: 8.1850 - acc: 0.4922
  704/15517 [>.............................] - ETA: 2s - loss: 8.2193 - acc: 0.4901
 1024/15517 [>.............................] - ETA: 2s - loss: 8.5155 - acc: 0.4717
 1344/15517 [=>............................] - ETA: 2s - loss: 8.4308 - acc: 0.4769
 1664/15517 [==>...........................] - ETA: 2s - loss: 8.2625 - acc: 0.4874
 1984/15517 [==>...........................] - ETA: 2s - loss: 8.2378 - acc: 0.4889
 2304/15517 [===>..........................] - ETA: 2s - loss: 8.1010 - acc: 0.4974
 2624/15517 [====>.........................] - ETA: 2s - loss: 8.1942 - acc: 0.4916
 2944/15517 [====>.........................] - ETA: 2s - loss: 8.2616 - acc: 0.4874
 3264/15517 [=====>........................] - ETA: 2s - loss: 8.1726 - acc: 0.4930
 3584/15517 [=====>........................] - ETA: 1s - loss: 8.2165 - acc: 0.4902
 3904/15517 [======>.......................] - ETA: 1s - loss: 8.2531 - acc: 0.4880
 4224/15517 [=======>......................] - ETA: 1s - loss: 8.2575 - acc: 0.4877
 4544/15517 [=======>......................] - ETA: 1s - loss: 8.2790 - acc: 0.4864
 4864/15517 [========>.....................] - ETA: 1s - loss: 8.1717 - acc: 0.4930
 5184/15517 [=========>....................] - ETA: 1s - loss: 8.1710 - acc: 0.4931
 5568/15517 [=========>....................] - ETA: 1s - loss: 8.1140 - acc: 0.4966
 5952/15517 [==========>...................] - ETA: 1s - loss: 8.0888 - acc: 0.4982
 6336/15517 [===========>..................] - ETA: 1s - loss: 8.0565 - acc: 0.5002
 6720/15517 [===========>..................] - ETA: 1s - loss: 8.0231 - acc: 0.5022
 7104/15517 [============>.................] - ETA: 1s - loss: 8.0590 - acc: 0.5000
 7488/15517 [=============>................] - ETA: 1s - loss: 8.0677 - acc: 0.4995
 7872/15517 [==============>...............] - ETA: 1s - loss: 8.0488 - acc: 0.5006
 8256/15517 [==============>...............] - ETA: 1s - loss: 8.0590 - acc: 0.5000
 8640/15517 [===============>..............] - ETA: 1s - loss: 8.0609 - acc: 0.4999
 9024/15517 [================>.............] - ETA: 1s - loss: 8.0769 - acc: 0.4989
 9344/15517 [=================>............] - ETA: 0s - loss: 8.0797 - acc: 0.4987
 9728/15517 [=================>............] - ETA: 0s - loss: 8.0624 - acc: 0.4998
10048/15517 [==================>...........] - ETA: 0s - loss: 8.0590 - acc: 0.5000
10368/15517 [===================>..........] - ETA: 0s - loss: 8.0839 - acc: 0.4985
10752/15517 [===================>..........] - ETA: 0s - loss: 8.0785 - acc: 0.4988
11136/15517 [====================>.........] - ETA: 0s - loss: 8.0663 - acc: 0.4996
11520/15517 [=====================>........] - ETA: 0s - loss: 8.0688 - acc: 0.4994
11904/15517 [======================>.......] - ETA: 0s - loss: 8.0590 - acc: 0.5000
12224/15517 [======================>.......] - ETA: 0s - loss: 8.0551 - acc: 0.5002
12544/15517 [=======================>......] - ETA: 0s - loss: 8.0244 - acc: 0.5022
12928/15517 [=======================>......] - ETA: 0s - loss: 8.0216 - acc: 0.5023
13312/15517 [========================>.....] - ETA: 0s - loss: 8.0227 - acc: 0.5023
13696/15517 [=========================>....] - ETA: 0s - loss: 8.0002 - acc: 0.5037
14016/15517 [==========================>...] - ETA: 0s - loss: 8.0165 - acc: 0.5026
14336/15517 [==========================>...] - ETA: 0s - loss: 8.0321 - acc: 0.5017
14720/15517 [===========================>..] - ETA: 0s - loss: 8.0295 - acc: 0.5018
15104/15517 [============================>.] - ETA: 0s - loss: 8.0430 - acc: 0.5010
15488/15517 [============================>.] - ETA: 0s - loss: 8.0580 - acc: 0.5001
15517/15517 [==============================] - 2s 158us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03043213633597

data size :  17160

zero :  8581

one :  8579

train_zero :  7759

train_one :  7758

test_zero :  822

test_one :  821

choose_zero :  1643

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[822   0]
 [821   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.500032222706179], 'loss': [8.058528389844374]}
Saved model to disk



10

Epoch 1/1

   64/15517 [..............................] - ETA: 3s - loss: 6.7998 - acc: 0.5781
  384/15517 [..............................] - ETA: 2s - loss: 8.6047 - acc: 0.4661
  704/15517 [>.............................] - ETA: 2s - loss: 8.3796 - acc: 0.4801
 1024/15517 [>.............................] - ETA: 2s - loss: 8.2794 - acc: 0.4863
 1344/15517 [=>............................] - ETA: 2s - loss: 8.0950 - acc: 0.4978
 1664/15517 [==>...........................] - ETA: 2s - loss: 8.0881 - acc: 0.4982
 1984/15517 [==>...........................] - ETA: 2s - loss: 8.0997 - acc: 0.4975
 2304/15517 [===>..........................] - ETA: 2s - loss: 8.1500 - acc: 0.4944
 2624/15517 [====>.........................] - ETA: 2s - loss: 8.1205 - acc: 0.4962
 2944/15517 [====>.........................] - ETA: 2s - loss: 8.1466 - acc: 0.4946
 3264/15517 [=====>........................] - ETA: 2s - loss: 8.0936 - acc: 0.4979
 3584/15517 [=====>........................] - ETA: 2s - loss: 8.1265 - acc: 0.4958
 3904/15517 [======>.......................] - ETA: 1s - loss: 8.0838 - acc: 0.4985
 4224/15517 [=======>......................] - ETA: 1s - loss: 8.0743 - acc: 0.4991
 4544/15517 [=======>......................] - ETA: 1s - loss: 8.0555 - acc: 0.5002
 4864/15517 [========>.....................] - ETA: 1s - loss: 8.0789 - acc: 0.4988
 5184/15517 [=========>....................] - ETA: 1s - loss: 8.0808 - acc: 0.4986
 5504/15517 [=========>....................] - ETA: 1s - loss: 8.0708 - acc: 0.4993
 5888/15517 [==========>...................] - ETA: 1s - loss: 8.0289 - acc: 0.5019
 6272/15517 [===========>..................] - ETA: 1s - loss: 8.0565 - acc: 0.5002
 6656/15517 [===========>..................] - ETA: 1s - loss: 8.0518 - acc: 0.5005
 7040/15517 [============>.................] - ETA: 1s - loss: 8.0728 - acc: 0.4991
 7360/15517 [=============>................] - ETA: 1s - loss: 8.0875 - acc: 0.4982
 7680/15517 [=============>................] - ETA: 1s - loss: 8.0737 - acc: 0.4991
 8064/15517 [==============>...............] - ETA: 1s - loss: 8.0730 - acc: 0.4991
 8448/15517 [===============>..............] - ETA: 1s - loss: 8.0972 - acc: 0.4976
 8832/15517 [================>.............] - ETA: 1s - loss: 8.1229 - acc: 0.4960
 9216/15517 [================>.............] - ETA: 1s - loss: 8.0975 - acc: 0.4976
 9600/15517 [=================>............] - ETA: 0s - loss: 8.0826 - acc: 0.4985
 9984/15517 [==================>...........] - ETA: 0s - loss: 8.0800 - acc: 0.4987
10368/15517 [===================>..........] - ETA: 0s - loss: 8.0808 - acc: 0.4986
10752/15517 [===================>..........] - ETA: 0s - loss: 8.0770 - acc: 0.4989
11136/15517 [====================>.........] - ETA: 0s - loss: 8.0735 - acc: 0.4991
11520/15517 [=====================>........] - ETA: 0s - loss: 8.0800 - acc: 0.4987
11904/15517 [======================>.......] - ETA: 0s - loss: 8.0970 - acc: 0.4976
12288/15517 [======================>.......] - ETA: 0s - loss: 8.1023 - acc: 0.4973
12672/15517 [=======================>......] - ETA: 0s - loss: 8.0896 - acc: 0.4981
13056/15517 [========================>.....] - ETA: 0s - loss: 8.0800 - acc: 0.4987
13440/15517 [========================>.....] - ETA: 0s - loss: 8.0626 - acc: 0.4998
13824/15517 [=========================>....] - ETA: 0s - loss: 8.0625 - acc: 0.4998
14208/15517 [==========================>...] - ETA: 0s - loss: 8.0625 - acc: 0.4998
14592/15517 [===========================>..] - ETA: 0s - loss: 8.0613 - acc: 0.4999
14976/15517 [===========================>..] - ETA: 0s - loss: 8.0558 - acc: 0.5002
15360/15517 [============================>.] - ETA: 0s - loss: 8.0590 - acc: 0.5000
15517/15517 [==============================] - 2s 158us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03043213633597

data size :  17160

zero :  8581

one :  8579

train_zero :  7759

train_one :  7758

test_zero :  822

test_one :  821

choose_zero :  1643

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[822   0]
 [821   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.500032222706179], 'loss': [8.05852837607734]}
Saved model to disk



11

Epoch 1/1

   64/15517 [..............................] - ETA: 3s - loss: 8.0590 - acc: 0.5000
  384/15517 [..............................] - ETA: 2s - loss: 7.7233 - acc: 0.5208
  704/15517 [>.............................] - ETA: 2s - loss: 7.4638 - acc: 0.5369
 1024/15517 [>.............................] - ETA: 2s - loss: 7.7285 - acc: 0.5205
 1344/15517 [=>............................] - ETA: 2s - loss: 7.8672 - acc: 0.5119
 1664/15517 [==>...........................] - ETA: 2s - loss: 7.9041 - acc: 0.5096
 1984/15517 [==>...........................] - ETA: 2s - loss: 7.8803 - acc: 0.5111
 2304/15517 [===>..........................] - ETA: 2s - loss: 7.9611 - acc: 0.5061
 2624/15517 [====>.........................] - ETA: 2s - loss: 7.9239 - acc: 0.5084
 2944/15517 [====>.........................] - ETA: 2s - loss: 7.9495 - acc: 0.5068
 3264/15517 [=====>........................] - ETA: 2s - loss: 7.9307 - acc: 0.5080
 3584/15517 [=====>........................] - ETA: 1s - loss: 7.9286 - acc: 0.5081
 3904/15517 [======>.......................] - ETA: 1s - loss: 7.9765 - acc: 0.5051
 4224/15517 [=======>......................] - ETA: 1s - loss: 8.0094 - acc: 0.5031
 4544/15517 [=======>......................] - ETA: 1s - loss: 8.0378 - acc: 0.5013
 4928/15517 [========>.....................] - ETA: 1s - loss: 8.0165 - acc: 0.5026
 5248/15517 [=========>....................] - ETA: 1s - loss: 8.0345 - acc: 0.5015
 5632/15517 [=========>....................] - ETA: 1s - loss: 8.0447 - acc: 0.5009
 5952/15517 [==========>...................] - ETA: 1s - loss: 8.0509 - acc: 0.5005
 6336/15517 [===========>..................] - ETA: 1s - loss: 8.0489 - acc: 0.5006
 6720/15517 [===========>..................] - ETA: 1s - loss: 8.0471 - acc: 0.5007
 7104/15517 [============>.................] - ETA: 1s - loss: 8.0477 - acc: 0.5007
 7488/15517 [=============>................] - ETA: 1s - loss: 8.0892 - acc: 0.4981
 7872/15517 [==============>...............] - ETA: 1s - loss: 8.1102 - acc: 0.4968
 8256/15517 [==============>...............] - ETA: 1s - loss: 8.1371 - acc: 0.4952
 8640/15517 [===============>..............] - ETA: 1s - loss: 8.1449 - acc: 0.4947
 9024/15517 [================>.............] - ETA: 1s - loss: 8.1519 - acc: 0.4942
 9344/15517 [=================>............] - ETA: 0s - loss: 8.1298 - acc: 0.4956
 9728/15517 [=================>............] - ETA: 0s - loss: 8.1253 - acc: 0.4959
10112/15517 [==================>...........] - ETA: 0s - loss: 8.1196 - acc: 0.4962
10496/15517 [===================>..........] - ETA: 0s - loss: 8.1374 - acc: 0.4951
10880/15517 [====================>.........] - ETA: 0s - loss: 8.1168 - acc: 0.4964
11264/15517 [====================>.........] - ETA: 0s - loss: 8.0877 - acc: 0.4982
11648/15517 [=====================>........] - ETA: 0s - loss: 8.1061 - acc: 0.4971
12032/15517 [======================>.......] - ETA: 0s - loss: 8.1019 - acc: 0.4973
12416/15517 [=======================>......] - ETA: 0s - loss: 8.0980 - acc: 0.4976
12800/15517 [=======================>......] - ETA: 0s - loss: 8.0880 - acc: 0.4982
13184/15517 [========================>.....] - ETA: 0s - loss: 8.0774 - acc: 0.4989
13568/15517 [=========================>....] - ETA: 0s - loss: 8.0721 - acc: 0.4992
13952/15517 [=========================>....] - ETA: 0s - loss: 8.0602 - acc: 0.4999
14336/15517 [==========================>...] - ETA: 0s - loss: 8.0534 - acc: 0.5003
14720/15517 [===========================>..] - ETA: 0s - loss: 8.0590 - acc: 0.5000
15040/15517 [============================>.] - ETA: 0s - loss: 8.0483 - acc: 0.5007
15424/15517 [============================>.] - ETA: 0s - loss: 8.0580 - acc: 0.5001
15517/15517 [==============================] - 2s 156us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03043213633597

data size :  17160

zero :  8581

one :  8579

train_zero :  7759

train_one :  7758

test_zero :  822

test_one :  821

choose_zero :  1643

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[822   0]
 [821   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.500032222706179], 'loss': [8.058528385726555]}
Saved model to disk



12

Epoch 1/1

   64/15517 [..............................] - ETA: 3s - loss: 8.0590 - acc: 0.5000
  384/15517 [..............................] - ETA: 2s - loss: 7.9751 - acc: 0.5052
  704/15517 [>.............................] - ETA: 2s - loss: 7.8988 - acc: 0.5099
 1024/15517 [>.............................] - ETA: 2s - loss: 8.0118 - acc: 0.5029
 1344/15517 [=>............................] - ETA: 2s - loss: 7.9511 - acc: 0.5067
 1664/15517 [==>...........................] - ETA: 2s - loss: 8.0203 - acc: 0.5024
 1984/15517 [==>...........................] - ETA: 2s - loss: 8.1240 - acc: 0.4960
 2304/15517 [===>..........................] - ETA: 2s - loss: 8.0171 - acc: 0.5026
 2624/15517 [====>.........................] - ETA: 2s - loss: 7.9608 - acc: 0.5061
 2944/15517 [====>.........................] - ETA: 2s - loss: 7.9441 - acc: 0.5071
 3264/15517 [=====>........................] - ETA: 2s - loss: 7.9603 - acc: 0.5061
 3584/15517 [=====>........................] - ETA: 1s - loss: 8.0680 - acc: 0.4994
 3904/15517 [======>.......................] - ETA: 1s - loss: 8.1003 - acc: 0.4974
 4224/15517 [=======>......................] - ETA: 1s - loss: 8.0705 - acc: 0.4993
 4544/15517 [=======>......................] - ETA: 1s - loss: 8.1371 - acc: 0.4952
 4864/15517 [========>.....................] - ETA: 1s - loss: 8.1651 - acc: 0.4934
 5184/15517 [=========>....................] - ETA: 1s - loss: 8.1585 - acc: 0.4938
 5568/15517 [=========>....................] - ETA: 1s - loss: 8.1314 - acc: 0.4955
 5888/15517 [==========>...................] - ETA: 1s - loss: 8.1603 - acc: 0.4937
 6208/15517 [===========>..................] - ETA: 1s - loss: 8.1499 - acc: 0.4944
 6528/15517 [===========>..................] - ETA: 1s - loss: 8.1356 - acc: 0.4953
 6848/15517 [============>.................] - ETA: 1s - loss: 8.1108 - acc: 0.4968
 7232/15517 [============>.................] - ETA: 1s - loss: 8.0992 - acc: 0.4975
 7552/15517 [=============>................] - ETA: 1s - loss: 8.1188 - acc: 0.4963
 7872/15517 [==============>...............] - ETA: 1s - loss: 8.1328 - acc: 0.4954
 8256/15517 [==============>...............] - ETA: 1s - loss: 8.1567 - acc: 0.4939
 8640/15517 [===============>..............] - ETA: 1s - loss: 8.1579 - acc: 0.4939
 9024/15517 [================>.............] - ETA: 1s - loss: 8.1609 - acc: 0.4937
 9408/15517 [=================>............] - ETA: 0s - loss: 8.1293 - acc: 0.4956
 9792/15517 [=================>............] - ETA: 0s - loss: 8.1051 - acc: 0.4971
10176/15517 [==================>...........] - ETA: 0s - loss: 8.1113 - acc: 0.4968
10560/15517 [===================>..........] - ETA: 0s - loss: 8.0865 - acc: 0.4983
10944/15517 [====================>.........] - ETA: 0s - loss: 8.0767 - acc: 0.4989
11328/15517 [====================>.........] - ETA: 0s - loss: 8.0647 - acc: 0.4996
11712/15517 [=====================>........] - ETA: 0s - loss: 8.0728 - acc: 0.4991
12096/15517 [======================>.......] - ETA: 0s - loss: 8.0577 - acc: 0.5001
12416/15517 [=======================>......] - ETA: 0s - loss: 8.0629 - acc: 0.4998
12800/15517 [=======================>......] - ETA: 0s - loss: 8.0603 - acc: 0.4999
13120/15517 [========================>.....] - ETA: 0s - loss: 8.0664 - acc: 0.4995
13504/15517 [=========================>....] - ETA: 0s - loss: 8.0543 - acc: 0.5003
13888/15517 [=========================>....] - ETA: 0s - loss: 8.0602 - acc: 0.4999
14208/15517 [==========================>...] - ETA: 0s - loss: 8.0693 - acc: 0.4994
14592/15517 [===========================>..] - ETA: 0s - loss: 8.0701 - acc: 0.4993
14976/15517 [===========================>..] - ETA: 0s - loss: 8.0472 - acc: 0.5007
15296/15517 [============================>.] - ETA: 0s - loss: 8.0506 - acc: 0.5005
15517/15517 [==============================] - 2s 158us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03043213633597

data size :  17160

zero :  8581

one :  8579

train_zero :  7759

train_one :  7758

test_zero :  822

test_one :  821

choose_zero :  1643

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[822   0]
 [821   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000322227196233], 'loss': [8.058528370115724]}
Saved model to disk



13

Epoch 1/1

   64/15517 [..............................] - ETA: 3s - loss: 7.0517 - acc: 0.5625
  384/15517 [..............................] - ETA: 2s - loss: 7.5134 - acc: 0.5339
  704/15517 [>.............................] - ETA: 2s - loss: 7.8301 - acc: 0.5142
 1024/15517 [>.............................] - ETA: 2s - loss: 7.9331 - acc: 0.5078
 1344/15517 [=>............................] - ETA: 2s - loss: 7.8912 - acc: 0.5104
 1664/15517 [==>...........................] - ETA: 2s - loss: 7.8847 - acc: 0.5108
 1984/15517 [==>...........................] - ETA: 2s - loss: 7.7991 - acc: 0.5161
 2304/15517 [===>..........................] - ETA: 2s - loss: 7.9191 - acc: 0.5087
 2624/15517 [====>.........................] - ETA: 2s - loss: 7.8809 - acc: 0.5111
 2944/15517 [====>.........................] - ETA: 2s - loss: 7.9714 - acc: 0.5054
 3264/15517 [=====>........................] - ETA: 2s - loss: 7.9652 - acc: 0.5058
 3584/15517 [=====>........................] - ETA: 1s - loss: 8.0051 - acc: 0.5033
 3904/15517 [======>.......................] - ETA: 1s - loss: 8.0467 - acc: 0.5008
 4224/15517 [=======>......................] - ETA: 1s - loss: 8.0476 - acc: 0.5007
 4544/15517 [=======>......................] - ETA: 1s - loss: 8.0378 - acc: 0.5013
 4928/15517 [========>.....................] - ETA: 1s - loss: 8.0558 - acc: 0.5002
 5312/15517 [=========>....................] - ETA: 1s - loss: 8.0257 - acc: 0.5021
 5696/15517 [==========>...................] - ETA: 1s - loss: 8.0308 - acc: 0.5018
 6080/15517 [==========>...................] - ETA: 1s - loss: 8.0697 - acc: 0.4993
 6400/15517 [===========>..................] - ETA: 1s - loss: 8.0641 - acc: 0.4997
 6784/15517 [============>.................] - ETA: 1s - loss: 8.0686 - acc: 0.4994
 7168/15517 [============>.................] - ETA: 1s - loss: 8.0501 - acc: 0.5006
 7552/15517 [=============>................] - ETA: 1s - loss: 8.0719 - acc: 0.4992
 7936/15517 [==============>...............] - ETA: 1s - loss: 8.0875 - acc: 0.4982
 8256/15517 [==============>...............] - ETA: 1s - loss: 8.0493 - acc: 0.5006
 8640/15517 [===============>..............] - ETA: 1s - loss: 8.0590 - acc: 0.5000
 9024/15517 [================>.............] - ETA: 1s - loss: 8.0751 - acc: 0.4990
 9408/15517 [=================>............] - ETA: 0s - loss: 8.0693 - acc: 0.4994
 9792/15517 [=================>............] - ETA: 0s - loss: 8.0590 - acc: 0.5000
10176/15517 [==================>...........] - ETA: 0s - loss: 8.0733 - acc: 0.4991
10560/15517 [===================>..........] - ETA: 0s - loss: 8.0484 - acc: 0.5007
10944/15517 [====================>.........] - ETA: 0s - loss: 8.0532 - acc: 0.5004
11328/15517 [====================>.........] - ETA: 0s - loss: 8.0619 - acc: 0.4998
11712/15517 [=====================>........] - ETA: 0s - loss: 8.0742 - acc: 0.4991
12096/15517 [======================>.......] - ETA: 0s - loss: 8.0710 - acc: 0.4993
12480/15517 [=======================>......] - ETA: 0s - loss: 8.0629 - acc: 0.4998
12864/15517 [=======================>......] - ETA: 0s - loss: 8.0540 - acc: 0.5003
13184/15517 [========================>.....] - ETA: 0s - loss: 8.0639 - acc: 0.4997
13568/15517 [=========================>....] - ETA: 0s - loss: 8.0424 - acc: 0.5010
13952/15517 [=========================>....] - ETA: 0s - loss: 8.0498 - acc: 0.5006
14336/15517 [==========================>...] - ETA: 0s - loss: 8.0478 - acc: 0.5007
14720/15517 [===========================>..] - ETA: 0s - loss: 8.0547 - acc: 0.5003
15104/15517 [============================>.] - ETA: 0s - loss: 8.0473 - acc: 0.5007
15488/15517 [============================>.] - ETA: 0s - loss: 8.0590 - acc: 0.5000
15517/15517 [==============================] - 2s 157us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03043213633597

data size :  17160

zero :  8581

one :  8579

train_zero :  7759

train_one :  7758

test_zero :  822

test_one :  821

choose_zero :  1643

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[822   0]
 [821   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000322226850521], 'loss': [8.058528408497475]}
Saved model to disk



14

Epoch 1/1

   64/15517 [..............................] - ETA: 3s - loss: 5.0369 - acc: 0.6875
  384/15517 [..............................] - ETA: 2s - loss: 7.4714 - acc: 0.5365
  704/15517 [>.............................] - ETA: 2s - loss: 7.8301 - acc: 0.5142
 1024/15517 [>.............................] - ETA: 2s - loss: 7.9961 - acc: 0.5039
 1344/15517 [=>............................] - ETA: 2s - loss: 7.9151 - acc: 0.5089
 1664/15517 [==>...........................] - ETA: 2s - loss: 7.9912 - acc: 0.5042
 1984/15517 [==>...........................] - ETA: 2s - loss: 7.8966 - acc: 0.5101
 2304/15517 [===>..........................] - ETA: 2s - loss: 7.9471 - acc: 0.5069
 2624/15517 [====>.........................] - ETA: 2s - loss: 7.9178 - acc: 0.5088
 2944/15517 [====>.........................] - ETA: 2s - loss: 7.9331 - acc: 0.5078
 3264/15517 [=====>........................] - ETA: 2s - loss: 7.9949 - acc: 0.5040
 3584/15517 [=====>........................] - ETA: 1s - loss: 7.9601 - acc: 0.5061
 3904/15517 [======>.......................] - ETA: 1s - loss: 7.9765 - acc: 0.5051
 4224/15517 [=======>......................] - ETA: 1s - loss: 8.0285 - acc: 0.5019
 4544/15517 [=======>......................] - ETA: 1s - loss: 8.0520 - acc: 0.5004
 4864/15517 [========>.....................] - ETA: 1s - loss: 8.0557 - acc: 0.5002
 5184/15517 [=========>....................] - ETA: 1s - loss: 8.0404 - acc: 0.5012
 5504/15517 [=========>....................] - ETA: 1s - loss: 8.0385 - acc: 0.5013
 5888/15517 [==========>...................] - ETA: 1s - loss: 8.0344 - acc: 0.5015
 6208/15517 [===========>..................] - ETA: 1s - loss: 8.0435 - acc: 0.5010
 6592/15517 [===========>..................] - ETA: 1s - loss: 8.0370 - acc: 0.5014
 6976/15517 [============>.................] - ETA: 1s - loss: 8.0544 - acc: 0.5003
 7296/15517 [=============>................] - ETA: 1s - loss: 8.0679 - acc: 0.4995
 7616/15517 [=============>................] - ETA: 1s - loss: 8.0844 - acc: 0.4984
 7936/15517 [==============>...............] - ETA: 1s - loss: 8.0570 - acc: 0.5001
 8320/15517 [===============>..............] - ETA: 1s - loss: 8.0281 - acc: 0.5019
 8704/15517 [===============>..............] - ETA: 1s - loss: 8.0479 - acc: 0.5007
 9024/15517 [================>.............] - ETA: 1s - loss: 8.0448 - acc: 0.5009
 9408/15517 [=================>............] - ETA: 0s - loss: 8.0693 - acc: 0.4994
 9792/15517 [=================>............] - ETA: 0s - loss: 8.0804 - acc: 0.4987
10176/15517 [==================>...........] - ETA: 0s - loss: 8.0812 - acc: 0.4986
10560/15517 [===================>..........] - ETA: 0s - loss: 8.0713 - acc: 0.4992
10944/15517 [====================>.........] - ETA: 0s - loss: 8.0561 - acc: 0.5002
11328/15517 [====================>.........] - ETA: 0s - loss: 8.0562 - acc: 0.5002
11712/15517 [=====================>........] - ETA: 0s - loss: 8.0632 - acc: 0.4997
12096/15517 [======================>.......] - ETA: 0s - loss: 8.0724 - acc: 0.4992
12480/15517 [=======================>......] - ETA: 0s - loss: 8.0694 - acc: 0.4994
12864/15517 [=======================>......] - ETA: 0s - loss: 8.0540 - acc: 0.5003
13248/15517 [========================>.....] - ETA: 0s - loss: 8.0542 - acc: 0.5003
13632/15517 [=========================>....] - ETA: 0s - loss: 8.0626 - acc: 0.4998
14016/15517 [==========================>...] - ETA: 0s - loss: 8.0763 - acc: 0.4989
14400/15517 [==========================>...] - ETA: 0s - loss: 8.0714 - acc: 0.4992
14784/15517 [===========================>..] - ETA: 0s - loss: 8.0765 - acc: 0.4989
15168/15517 [============================>.] - ETA: 0s - loss: 8.0644 - acc: 0.4997
15517/15517 [==============================] - 2s 158us/step - loss: 8.0585 - acc: 0.5000

Test accuracy: 50.03043213633597

data size :  17160

zero :  8581

one :  8579

train_zero :  7759

train_one :  7758

test_zero :  822

test_one :  821

choose_zero :  1643

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[822   0]
 [821   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000322226850521], 'loss': [8.058528378996689]}
Saved model to disk



15

Epoch 1/1

   64/15517 [..............................] - ETA: 3s - loss: 8.0590 - acc: 0.5000
  320/15517 [..............................] - ETA: 3s - loss: 8.1094 - acc: 0.4969
  640/15517 [>.............................] - ETA: 2s - loss: 8.1598 - acc: 0.4938
  960/15517 [>.............................] - ETA: 2s - loss: 7.8072 - acc: 0.5156
 1280/15517 [=>............................] - ETA: 2s - loss: 7.8953 - acc: 0.5102
 1600/15517 [==>...........................] - ETA: 2s - loss: 7.9079 - acc: 0.5094
 1920/15517 [==>...........................] - ETA: 2s - loss: 8.0255 - acc: 0.5021
 2240/15517 [===>..........................] - ETA: 2s - loss: 8.0087 - acc: 0.5031
 2560/15517 [===>..........................] - ETA: 2s - loss: 7.9772 - acc: 0.5051
 2880/15517 [====>.........................] - ETA: 2s - loss: 8.1094 - acc: 0.4969
 3200/15517 [=====>........................] - ETA: 2s - loss: 8.0490 - acc: 0.5006
 3520/15517 [=====>........................] - ETA: 2s - loss: 8.0407 - acc: 0.5011
 3840/15517 [======>.......................] - ETA: 1s - loss: 8.0507 - acc: 0.5005
 4160/15517 [=======>......................] - ETA: 1s - loss: 8.0435 - acc: 0.5010
 4480/15517 [=======>......................] - ETA: 1s - loss: 8.0231 - acc: 0.5022
 4800/15517 [========>.....................] - ETA: 1s - loss: 8.0288 - acc: 0.5019
 5120/15517 [========>.....................] - ETA: 1s - loss: 8.0433 - acc: 0.5010
 5504/15517 [=========>....................] - ETA: 1s - loss: 8.0093 - acc: 0.5031
 5824/15517 [==========>...................] - ETA: 1s - loss: 8.0646 - acc: 0.4997
 6144/15517 [==========>...................] - ETA: 1s - loss: 8.0564 - acc: 0.5002
 6528/15517 [===========>..................] - ETA: 1s - loss: 8.0393 - acc: 0.5012
 6848/15517 [============>.................] - ETA: 1s - loss: 8.0638 - acc: 0.4997
 7232/15517 [============>.................] - ETA: 1s - loss: 8.0568 - acc: 0.5001
 7552/15517 [=============>................] - ETA: 1s - loss: 8.0420 - acc: 0.5011
 7936/15517 [==============>...............] - ETA: 1s - loss: 8.0611 - acc: 0.4999
 8320/15517 [===============>..............] - ETA: 1s - loss: 8.0281 - acc: 0.5019
 8640/15517 [===============>..............] - ETA: 1s - loss: 8.0535 - acc: 0.5003
 9024/15517 [================>.............] - ETA: 1s - loss: 8.0733 - acc: 0.4991
 9408/15517 [=================>............] - ETA: 0s - loss: 8.0745 - acc: 0.4990
 9728/15517 [=================>............] - ETA: 0s - loss: 8.0822 - acc: 0.4986
10112/15517 [==================>...........] - ETA: 0s - loss: 8.0830 - acc: 0.4985
10432/15517 [===================>..........] - ETA: 0s - loss: 8.0482 - acc: 0.5007
10816/15517 [===================>..........] - ETA: 0s - loss: 8.0427 - acc: 0.5010
11200/15517 [====================>.........] - ETA: 0s - loss: 8.0418 - acc: 0.5011
11520/15517 [=====================>........] - ETA: 0s - loss: 8.0479 - acc: 0.5007
11904/15517 [======================>.......] - ETA: 0s - loss: 8.0590 - acc: 0.5000
12224/15517 [======================>.......] - ETA: 0s - loss: 8.0485 - acc: 0.5007
12544/15517 [=======================>......] - ETA: 0s - loss: 8.0423 - acc: 0.5010
12928/15517 [=======================>......] - ETA: 0s - loss: 8.0603 - acc: 0.4999
13248/15517 [========================>.....] - ETA: 0s - loss: 8.0469 - acc: 0.5008
13568/15517 [=========================>....] - ETA: 0s - loss: 8.0484 - acc: 0.5007
13888/15517 [=========================>....] - ETA: 0s - loss: 8.0649 - acc: 0.4996
14208/15517 [==========================>...] - ETA: 0s - loss: 8.0738 - acc: 0.4991
14592/15517 [===========================>..] - ETA: 0s - loss: 8.0690 - acc: 0.4994
14976/15517 [===========================>..] - ETA: 0s - loss: 8.0623 - acc: 0.4998
15360/15517 [============================>.] - ETA: 0s - loss: 8.0611 - acc: 0.4999
15517/15517 [==============================] - 2s 160us/step - loss: 8.0585 - acc: 0.5000
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)

Test accuracy: 50.03043213633597

data size :  17160

zero :  8581

one :  8579

train_zero :  7759

train_one :  7758

test_zero :  822

test_one :  821

choose_zero :  1643

choose_one :  0

F1score :  0.0

AUC : 0.5

Confusion Matrix
[[822   0]
 [821   0]]
True label 0
1.0  
0.0  
True label 1
1.0  
0.0  

Train_result {'acc': [0.5000322227196233], 'loss': [8.058528401583228]}
Saved model to disk



[[50.03043213633597, 1], [50.03043213633597, 2], [50.03043213633597, 3], [50.03043213633597, 4], [50.03043213633597, 5], [50.03043213633597, 6], [50.03043213633597, 7], [50.03043213633597, 8], [50.03043213633597, 9], [50.03043213633597, 10], [50.03043213633597, 11], [50.03043213633597, 12], [50.03043213633597, 13], [50.03043213633597, 14], [50.03043213633597, 15]]
max accuracy :  [50.03043213633597, 15]
