Compiled from "BulkLoadHFiles.java"
public interface org.apache.hadoop.hbase.tool.BulkLoadHFiles {
  public static final java.lang.String RETRY_ON_IO_EXCEPTION;

  public static final java.lang.String MAX_FILES_PER_REGION_PER_FAMILY;

  public static final java.lang.String ASSIGN_SEQ_IDS;

  public static final java.lang.String CREATE_TABLE_CONF_KEY;

  public static final java.lang.String IGNORE_UNMATCHED_CF_CONF_KEY;

  public static final java.lang.String ALWAYS_COPY_FILES;

  public abstract java.util.Map<org.apache.hadoop.hbase.tool.BulkLoadHFiles$LoadQueueItem, java.nio.ByteBuffer> bulkLoad(org.apache.hadoop.hbase.TableName, java.util.Map<byte[], java.util.List<org.apache.hadoop.fs.Path>>) throws org.apache.hadoop.hbase.TableNotFoundException, java.io.IOException;

  public abstract java.util.Map<org.apache.hadoop.hbase.tool.BulkLoadHFiles$LoadQueueItem, java.nio.ByteBuffer> bulkLoad(org.apache.hadoop.hbase.TableName, org.apache.hadoop.fs.Path) throws org.apache.hadoop.hbase.TableNotFoundException, java.io.IOException;

  public static org.apache.hadoop.hbase.tool.BulkLoadHFiles create(org.apache.hadoop.conf.Configuration);
    Code:
       0: new           #1                  // class org/apache/hadoop/hbase/tool/BulkLoadHFilesTool
       3: dup
       4: aload_0
       5: invokespecial #2                  // Method org/apache/hadoop/hbase/tool/BulkLoadHFilesTool."<init>":(Lorg/apache/hadoop/conf/Configuration;)V
       8: areturn
}
