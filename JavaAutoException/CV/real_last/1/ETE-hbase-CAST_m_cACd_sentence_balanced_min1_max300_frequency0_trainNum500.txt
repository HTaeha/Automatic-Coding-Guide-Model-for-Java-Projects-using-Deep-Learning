Using TensorFlow backend.
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
/home/2014313303/taeha/JavaAutoException/model.py:139: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor("ou...)`
  model = Model(input=[input1, input2, input3, input4], output=output)
WARNING:tensorflow:From /home/2014313303/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-10-11 16:34:51.273289: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-11 16:34:51.290393: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099865000 Hz
2019-10-11 16:34:51.292182: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0xd338fe0 executing computations on platform Host. Devices:
2019-10-11 16:34:51.292238: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
First data
zero :  10049
one :  10279

Second data
zero :  10049
one :  10279

Third data
zero :  10049
one :  10279

4th data
zero :  10049
one :  10279

hbase-code
After set document size of train data, the number of zero and one label data :  241 259
After set document size of test data, the number of zero and one label data :  9808 10020

Sentence length Average : 44

Under 10 : 3104
Over 10, Under 30 : 7785
Over 30, Under 100 : 7330
Over 100, Under 150 : 1113
Over 150, Under 200 : 509
Over 200, Under 400 : 487
Over 400 : 0

After balance out data.
hbase-code

Sentence length Average : 44

Under 10 : 3104
Over 10, Under 30 : 7785
Over 30, Under 100 : 7330
Over 100, Under 150 : 1113
Over 150, Under 200 : 509
Over 200, Under 400 : 487
Over 400 : 0

300
hbase-AST
After set document size of train data, the number of zero and one label data :  241 259
After set document size of test data, the number of zero and one label data :  9808 10020
After balance out data.
hbase-AST

Sentence length Average : 30

Under 10 : 7492
Over 10, Under 30 : 6294
Over 30, Under 100 : 5232
Over 100, Under 150 : 774
Over 150, Under 200 : 347
Over 200, Under 400 : 186
Over 400 : 3

621
hbase-CAST
After set document size of train data, the number of zero and one label data :  241 259
After set document size of test data, the number of zero and one label data :  9808 10020
After balance out data.
hbase-CAST

Sentence length Average : 66

Under 10 : 1960
Over 10, Under 30 : 6663
Over 30, Under 100 : 7615
Over 100, Under 150 : 1826
Over 150, Under 200 : 842
Over 200, Under 400 : 1236
Over 400 : 186

697
hbase-depth_num
After set document size of train data, the number of zero and one label data :  241 259
After set document size of test data, the number of zero and one label data :  9808 10020
After balance out data.
hbase-depth_num

Sentence length Average : 30

Under 10 : 7492
Over 10, Under 30 : 6294
Over 30, Under 100 : 5232
Over 100, Under 150 : 774
Over 150, Under 200 : 347
Over 200, Under 400 : 186
Over 400 : 3

621
Count model parameter.
Get a short summary of each layer dimensions and parameters.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 300, 200)     0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 621, 200)     0                                            
__________________________________________________________________________________________________
masking_1 (Masking)             (None, 300, 200)     0           input_1[0][0]                    
__________________________________________________________________________________________________
masking_2 (Masking)             (None, 621, 200)     0           input_2[0][0]                    
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 697, 200)     0                                            
__________________________________________________________________________________________________
forwards_1 (LSTM)               (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
backwords_1 (LSTM)              (None, 64)           67840       masking_1[0][0]                  
__________________________________________________________________________________________________
forwards_2 (LSTM)               (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
backwards_2 (LSTM)              (None, 64)           67840       masking_2[0][0]                  
__________________________________________________________________________________________________
masking_3 (Masking)             (None, 697, 200)     0           input_3[0][0]                    
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 621, 200)     0                                            
__________________________________________________________________________________________________
after_dp_forward_1 (Dropout)    (None, 64)           0           forwards_1[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_1 (Dropout)   (None, 64)           0           backwords_1[0][0]                
__________________________________________________________________________________________________
after_dp_forward_2 (Dropout)    (None, 64)           0           forwards_2[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_2 (Dropout)   (None, 64)           0           backwards_2[0][0]                
__________________________________________________________________________________________________
forwards_3 (LSTM)               (None, 64)           67840       masking_3[0][0]                  
__________________________________________________________________________________________________
backwards_3 (LSTM)              (None, 64)           67840       masking_3[0][0]                  
__________________________________________________________________________________________________
masking_4 (Masking)             (None, 621, 200)     0           input_4[0][0]                    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128)          0           after_dp_forward_1[0][0]         
                                                                 after_dp_backward_1[0][0]        
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 128)          0           after_dp_forward_2[0][0]         
                                                                 after_dp_backward_2[0][0]        
__________________________________________________________________________________________________
after_dp_forward_3 (Dropout)    (None, 64)           0           forwards_3[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_3 (Dropout)   (None, 64)           0           backwards_3[0][0]                
__________________________________________________________________________________________________
forwards_4 (LSTM)               (None, 64)           67840       masking_4[0][0]                  
__________________________________________________________________________________________________
backwards_4 (LSTM)              (None, 64)           67840       masking_4[0][0]                  
__________________________________________________________________________________________________
after_dp_1 (Dropout)            (None, 128)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
after_dp_2 (Dropout)            (None, 128)          0           concatenate_2[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 128)          0           after_dp_forward_3[0][0]         
                                                                 after_dp_backward_3[0][0]        
__________________________________________________________________________________________________
after_dp_forward_4 (Dropout)    (None, 64)           0           forwards_4[0][0]                 
__________________________________________________________________________________________________
after_dp_backward_4 (Dropout)   (None, 64)           0           backwards_4[0][0]                
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 256)          0           after_dp_1[0][0]                 
                                                                 after_dp_2[0][0]                 
__________________________________________________________________________________________________
after_dp_3 (Dropout)            (None, 128)          0           concatenate_3[0][0]              
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 128)          0           after_dp_forward_4[0][0]         
                                                                 after_dp_backward_4[0][0]        
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 384)          0           concatenate_5[0][0]              
                                                                 after_dp_3[0][0]                 
__________________________________________________________________________________________________
after_dp_4 (Dropout)            (None, 128)          0           concatenate_4[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 512)          0           concatenate_6[0][0]              
                                                                 after_dp_4[0][0]                 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 384)          196992      concatenate_7[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 512)          197120      dense_1[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 256)          131328      dense_2[0][0]                    
__________________________________________________________________________________________________
output (Dense)                  (None, 2)            514         dense_3[0][0]                    
==================================================================================================
Total params: 1,068,674
Trainable params: 1,068,674
Non-trainable params: 0
__________________________________________________________________________________________________
1

Epoch 1/1

 64/500 [==>...........................] - ETA: 1:16 - loss: 0.7073 - acc: 0.4844
128/500 [======>.......................] - ETA: 38s - loss: 0.8404 - acc: 0.4688 
192/500 [==========>...................] - ETA: 25s - loss: 0.7938 - acc: 0.5000
256/500 [==============>...............] - ETA: 17s - loss: 0.8436 - acc: 0.4727
320/500 [==================>...........] - ETA: 11s - loss: 0.8148 - acc: 0.4938
384/500 [======================>.......] - ETA: 6s - loss: 0.7963 - acc: 0.5000 
448/500 [=========================>....] - ETA: 2s - loss: 0.7797 - acc: 0.5067
500/500 [==============================] - 27s 55ms/step - loss: 0.7731 - acc: 0.5120

Test accuracy: 50.53964091184184

data size :  20328

zero :  10049

one :  10279

train_zero :  241

train_one :  259

test_zero :  9808

test_one :  10020

choose_zero :  1

choose_one :  19827

F1score :  0.6714242637451

AUC :  0.7547062990658162

Confusion Matrix
[[    1  9807]
 [    0 10020]]
True label 0
0.00010195758564437195  
0.9998980424143556  
True label 1
0.0  
1.0  

Train_result {'loss': [0.7730544562339783], 'acc': [0.5119999980926514]}
Saved model to disk


2

Epoch 1/1

 64/500 [==>...........................] - ETA: 19s - loss: 0.6166 - acc: 0.6250
128/500 [======>.......................] - ETA: 14s - loss: 0.6670 - acc: 0.5547
192/500 [==========>...................] - ETA: 12s - loss: 0.6639 - acc: 0.5781
256/500 [==============>...............] - ETA: 9s - loss: 0.6567 - acc: 0.6055 
320/500 [==================>...........] - ETA: 6s - loss: 0.6525 - acc: 0.6219
384/500 [======================>.......] - ETA: 4s - loss: 0.6588 - acc: 0.6094
448/500 [=========================>....] - ETA: 1s - loss: 0.6599 - acc: 0.6071
500/500 [==============================] - 19s 38ms/step - loss: 0.6582 - acc: 0.6100

Test accuracy: 69.6187210006052

data size :  20328

zero :  10049

one :  10279

train_zero :  241

train_one :  259

test_zero :  9808

test_one :  10020

choose_zero :  11626

choose_one :  8202

F1score :  0.6694106025683241

AUC :  0.7658705427643897

Confusion Matrix
[[7705 2103]
 [3921 6099]]
True label 0
0.7855831973898858  
0.2144168026101142  
True label 1
0.3913173652694611  
0.608682634730539  

Train_result {'loss': [0.6581595478057861], 'acc': [0.6099999976158142]}
Saved model to disk


3

Epoch 1/1

 64/500 [==>...........................] - ETA: 17s - loss: 0.5756 - acc: 0.7656
128/500 [======>.......................] - ETA: 14s - loss: 0.6118 - acc: 0.6953
192/500 [==========>...................] - ETA: 11s - loss: 0.6193 - acc: 0.6562
256/500 [==============>...............] - ETA: 9s - loss: 0.5990 - acc: 0.6719 
320/500 [==================>...........] - ETA: 6s - loss: 0.6005 - acc: 0.6719
384/500 [======================>.......] - ETA: 4s - loss: 0.6018 - acc: 0.6745
448/500 [=========================>....] - ETA: 1s - loss: 0.6012 - acc: 0.6741
500/500 [==============================] - 19s 37ms/step - loss: 0.5949 - acc: 0.6780

Test accuracy: 71.6007665926972

data size :  20328

zero :  10049

one :  10279

train_zero :  241

train_one :  259

test_zero :  9808

test_one :  10020

choose_zero :  10231

choose_one :  9597

F1score :  0.7129530509252179

AUC :  0.7805541598287926

Confusion Matrix
[[7204 2604]
 [3027 6993]]
True label 0
0.7345024469820555  
0.26549755301794453  
True label 1
0.3020958083832335  
0.6979041916167664  

Train_result {'loss': [0.5949419407844544], 'acc': [0.6779999971389771]}
Saved model to disk


4

Epoch 1/1

 64/500 [==>...........................] - ETA: 17s - loss: 0.4996 - acc: 0.7188
128/500 [======>.......................] - ETA: 15s - loss: 0.6001 - acc: 0.6719
192/500 [==========>...................] - ETA: 11s - loss: 0.5995 - acc: 0.6615
256/500 [==============>...............] - ETA: 9s - loss: 0.5857 - acc: 0.6797 
320/500 [==================>...........] - ETA: 6s - loss: 0.5769 - acc: 0.6875
384/500 [======================>.......] - ETA: 4s - loss: 0.5767 - acc: 0.6849
448/500 [=========================>....] - ETA: 1s - loss: 0.5764 - acc: 0.6964
500/500 [==============================] - 19s 37ms/step - loss: 0.5619 - acc: 0.7060

Test accuracy: 72.40770627395602

data size :  20328

zero :  10049

one :  10279

train_zero :  241

train_one :  259

test_zero :  9808

test_one :  10020

choose_zero :  11181

choose_one :  8647

F1score :  0.7069159479295012

AUC :  0.8019568530150141

Confusion Matrix
[[7759 2049]
 [3422 6598]]
True label 0
0.7910889070146819  
0.2089110929853181  
True label 1
0.34151696606786425  
0.6584830339321357  

Train_result {'loss': [0.5618982532024384], 'acc': [0.7060000028610229]}
Saved model to disk


5

Epoch 1/1

 64/500 [==>...........................] - ETA: 42s - loss: 0.5704 - acc: 0.6719
128/500 [======>.......................] - ETA: 34s - loss: 0.5306 - acc: 0.7188
192/500 [==========>...................] - ETA: 28s - loss: 0.5089 - acc: 0.7396
256/500 [==============>...............] - ETA: 21s - loss: 0.5007 - acc: 0.7500
320/500 [==================>...........] - ETA: 16s - loss: 0.5049 - acc: 0.7562
384/500 [======================>.......] - ETA: 11s - loss: 0.4968 - acc: 0.7630
448/500 [=========================>....] - ETA: 5s - loss: 0.4880 - acc: 0.7701 
500/500 [==============================] - 53s 106ms/step - loss: 0.5030 - acc: 0.7560

Test accuracy: 73.38612063748235

data size :  20328

zero :  10049

one :  10279

train_zero :  241

train_one :  259

test_zero :  9808

test_one :  10020

choose_zero :  9769

choose_one :  10059

F1score :  0.7371881069774391

AUC :  0.8071959262551569

Confusion Matrix
[[7150 2658]
 [2619 7401]]
True label 0
0.7289967373572593  
0.2710032626427406  
True label 1
0.26137724550898206  
0.738622754491018  

Train_result {'loss': [0.5029695043563843], 'acc': [0.7559999976158142]}
Saved model to disk


6

Epoch 1/1

 64/500 [==>...........................] - ETA: 18s - loss: 0.5750 - acc: 0.6875
128/500 [======>.......................] - ETA: 15s - loss: 0.5409 - acc: 0.7109
192/500 [==========>...................] - ETA: 14s - loss: 0.5132 - acc: 0.7448
256/500 [==============>...............] - ETA: 10s - loss: 0.5008 - acc: 0.7578
320/500 [==================>...........] - ETA: 7s - loss: 0.5013 - acc: 0.7531 
384/500 [======================>.......] - ETA: 4s - loss: 0.4883 - acc: 0.7656
448/500 [=========================>....] - ETA: 2s - loss: 0.5024 - acc: 0.7589
500/500 [==============================] - 20s 40ms/step - loss: 0.5049 - acc: 0.7560

Test accuracy: 72.19084123461771

data size :  20328

zero :  10049

one :  10279

train_zero :  241

train_one :  259

test_zero :  9808

test_one :  10020

choose_zero :  7924

choose_one :  11904

F1score :  0.7484948002189381

AUC :  0.8100722189389573

Confusion Matrix
[[6109 3699]
 [1815 8205]]
True label 0
0.6228588907014682  
0.3771411092985318  
True label 1
0.18113772455089822  
0.8188622754491018  

Train_result {'loss': [0.5048920798301697], 'acc': [0.7559999985694885]}
Saved model to disk


7

Epoch 1/1

 64/500 [==>...........................] - ETA: 16s - loss: 0.5655 - acc: 0.7188
128/500 [======>.......................] - ETA: 13s - loss: 0.4926 - acc: 0.7656
192/500 [==========>...................] - ETA: 11s - loss: 0.4806 - acc: 0.7656
256/500 [==============>...............] - ETA: 8s - loss: 0.4680 - acc: 0.7734 
320/500 [==================>...........] - ETA: 6s - loss: 0.4634 - acc: 0.7812
384/500 [======================>.......] - ETA: 3s - loss: 0.4811 - acc: 0.7604
448/500 [=========================>....] - ETA: 1s - loss: 0.4789 - acc: 0.7634
500/500 [==============================] - 16s 33ms/step - loss: 0.4693 - acc: 0.7680

Test accuracy: 72.15049425055477

data size :  20328

zero :  10049

one :  10279

train_zero :  241

train_one :  259

test_zero :  9808

test_one :  10020

choose_zero :  7054

choose_one :  12774

F1score :  0.7577432657716943

AUC :  0.8159912587142192

Confusion Matrix
[[5670 4138]
 [1384 8636]]
True label 0
0.5780995106035889  
0.4219004893964111  
True label 1
0.13812375249501  
0.86187624750499  

Train_result {'loss': [0.46934563517570493], 'acc': [0.7679999980926514]}
Saved model to disk


8

Epoch 1/1

 64/500 [==>...........................] - ETA: 17s - loss: 0.5826 - acc: 0.7188
128/500 [======>.......................] - ETA: 14s - loss: 0.5234 - acc: 0.7578
192/500 [==========>...................] - ETA: 11s - loss: 0.5034 - acc: 0.7604
256/500 [==============>...............] - ETA: 9s - loss: 0.4681 - acc: 0.7930 
320/500 [==================>...........] - ETA: 6s - loss: 0.4574 - acc: 0.7937
384/500 [======================>.......] - ETA: 4s - loss: 0.4763 - acc: 0.7812
448/500 [=========================>....] - ETA: 1s - loss: 0.4562 - acc: 0.7991
500/500 [==============================] - 17s 35ms/step - loss: 0.4585 - acc: 0.7980

Test accuracy: 74.56122654831552

data size :  20328

zero :  10049

one :  10279

train_zero :  241

train_one :  259

test_zero :  9808

test_one :  10020

choose_zero :  9952

choose_one :  9876

F1score :  0.7464817048652996

AUC :  0.8184160278545682

Confusion Matrix
[[7358 2450]
 [2594 7426]]
True label 0
0.7502039151712887  
0.24979608482871127  
True label 1
0.25888223552894213  
0.7411177644710579  

Train_result {'loss': [0.4584743115901947], 'acc': [0.7980000028610229]}
Saved model to disk


9

Epoch 1/1

 64/500 [==>...........................] - ETA: 16s - loss: 0.4457 - acc: 0.7656
128/500 [======>.......................] - ETA: 13s - loss: 0.4126 - acc: 0.7891
192/500 [==========>...................] - ETA: 11s - loss: 0.4544 - acc: 0.7656
256/500 [==============>...............] - ETA: 8s - loss: 0.4471 - acc: 0.7734 
320/500 [==================>...........] - ETA: 6s - loss: 0.4436 - acc: 0.7844
384/500 [======================>.......] - ETA: 4s - loss: 0.4153 - acc: 0.8073
448/500 [=========================>....] - ETA: 1s - loss: 0.4182 - acc: 0.8080
500/500 [==============================] - 17s 35ms/step - loss: 0.4194 - acc: 0.8080

Test accuracy: 74.43514222311882

data size :  20328

zero :  10049

one :  10279

train_zero :  241

train_one :  259

test_zero :  9808

test_one :  10020

choose_zero :  9653

choose_one :  10175

F1score :  0.7489972765536024

AUC :  0.822818529946632

Confusion Matrix
[[7196 2612]
 [2457 7563]]
True label 0
0.7336867862969005  
0.2663132137030995  
True label 1
0.24520958083832337  
0.7547904191616767  

Train_result {'loss': [0.419361878156662], 'acc': [0.8079999980926513]}
Saved model to disk


10

Epoch 1/1

 64/500 [==>...........................] - ETA: 17s - loss: 0.4439 - acc: 0.7656
128/500 [======>.......................] - ETA: 13s - loss: 0.3912 - acc: 0.8125
192/500 [==========>...................] - ETA: 11s - loss: 0.3922 - acc: 0.8021
256/500 [==============>...............] - ETA: 8s - loss: 0.3799 - acc: 0.8203 
320/500 [==================>...........] - ETA: 6s - loss: 0.3916 - acc: 0.8250
384/500 [======================>.......] - ETA: 4s - loss: 0.3899 - acc: 0.8255
448/500 [=========================>....] - ETA: 1s - loss: 0.3915 - acc: 0.8281
500/500 [==============================] - 18s 36ms/step - loss: 0.3936 - acc: 0.8240

Test accuracy: 73.87028444623765

data size :  20328

zero :  10049

one :  10279

train_zero :  241

train_one :  259

test_zero :  9808

test_one :  10020

choose_zero :  8749

choose_one :  11079

F1score :  0.7544433385468505

AUC :  0.821292788607125

Confusion Matrix
[[6688 3120]
 [2061 7959]]
True label 0
0.6818923327895595  
0.3181076672104405  
True label 1
0.205688622754491  
0.7943113772455089  

Train_result {'loss': [0.393623046875], 'acc': [0.8240000028610229]}
Saved model to disk


11

Epoch 1/1

 64/500 [==>...........................] - ETA: 16s - loss: 0.4804 - acc: 0.7969
128/500 [======>.......................] - ETA: 13s - loss: 0.3944 - acc: 0.8359
192/500 [==========>...................] - ETA: 11s - loss: 0.3702 - acc: 0.8385
256/500 [==============>...............] - ETA: 8s - loss: 0.3526 - acc: 0.8516 
320/500 [==================>...........] - ETA: 6s - loss: 0.3480 - acc: 0.8500
384/500 [======================>.......] - ETA: 3s - loss: 0.3400 - acc: 0.8516
448/500 [=========================>....] - ETA: 1s - loss: 0.3290 - acc: 0.8571
500/500 [==============================] - 17s 34ms/step - loss: 0.3283 - acc: 0.8580

Test accuracy: 73.95097841436352

data size :  20328

zero :  10049

one :  10279

train_zero :  241

train_one :  259

test_zero :  9808

test_one :  10020

choose_zero :  8319

choose_one :  11509

F1score :  0.7600910399925682

AUC :  0.8261441024964753

Confusion Matrix
[[6481 3327]
 [1838 8182]]
True label 0
0.6607871125611745  
0.33921288743882544  
True label 1
0.18343313373253492  
0.8165668662674651  

Train_result {'loss': [0.3282721025943756], 'acc': [0.8580000023841858]}
Saved model to disk


12

Epoch 1/1

 64/500 [==>...........................] - ETA: 16s - loss: 0.3310 - acc: 0.7969
128/500 [======>.......................] - ETA: 14s - loss: 0.3433 - acc: 0.8203
192/500 [==========>...................] - ETA: 11s - loss: 0.3211 - acc: 0.8281
256/500 [==============>...............] - ETA: 8s - loss: 0.3015 - acc: 0.8516 
320/500 [==================>...........] - ETA: 6s - loss: 0.2983 - acc: 0.8562
384/500 [======================>.......] - ETA: 4s - loss: 0.3173 - acc: 0.8464
448/500 [=========================>....] - ETA: 1s - loss: 0.3282 - acc: 0.8393
500/500 [==============================] - 17s 35ms/step - loss: 0.3171 - acc: 0.8480

Test accuracy: 74.67722412749647

data size :  20328

zero :  10049

one :  10279

train_zero :  241

train_one :  259

test_zero :  9808

test_one :  10020

choose_zero :  10539

choose_one :  9289

F1score :  0.7399658190481122

AUC :  0.8283016094645945

Confusion Matrix
[[7663 2145]
 [2876 7144]]
True label 0
0.7813009787928222  
0.21869902120717782  
True label 1
0.2870259481037924  
0.7129740518962076  

Train_result {'loss': [0.3170963884592056], 'acc': [0.8480000004768372]}
Saved model to disk


13

Epoch 1/1

 64/500 [==>...........................] - ETA: 16s - loss: 0.2404 - acc: 0.8906
128/500 [======>.......................] - ETA: 13s - loss: 0.2343 - acc: 0.8906
192/500 [==========>...................] - ETA: 10s - loss: 0.2278 - acc: 0.9062
256/500 [==============>...............] - ETA: 8s - loss: 0.2309 - acc: 0.8984 
320/500 [==================>...........] - ETA: 6s - loss: 0.2459 - acc: 0.8875
384/500 [======================>.......] - ETA: 3s - loss: 0.2662 - acc: 0.8828
448/500 [=========================>....] - ETA: 1s - loss: 0.2604 - acc: 0.8817
500/500 [==============================] - 17s 34ms/step - loss: 0.2703 - acc: 0.8780

Test accuracy: 74.37966512003229

data size :  20328

zero :  10049

one :  10279

train_zero :  241

train_one :  259

test_zero :  9808

test_one :  10020

choose_zero :  8748

choose_one :  11080

F1score :  0.7592417061611374

AUC :  0.826009308870025

Confusion Matrix
[[6738 3070]
 [2010 8010]]
True label 0
0.6869902120717781  
0.31300978792822187  
True label 1
0.20059880239520958  
0.7994011976047904  

Train_result {'loss': [0.2703126857280731], 'acc': [0.8780000009536744]}
Saved model to disk


14

Epoch 1/1

 64/500 [==>...........................] - ETA: 15s - loss: 0.3515 - acc: 0.8281
128/500 [======>.......................] - ETA: 12s - loss: 0.3069 - acc: 0.8672
192/500 [==========>...................] - ETA: 10s - loss: 0.2808 - acc: 0.8802
256/500 [==============>...............] - ETA: 8s - loss: 0.2595 - acc: 0.8906 
320/500 [==================>...........] - ETA: 5s - loss: 0.2575 - acc: 0.8875
384/500 [======================>.......] - ETA: 3s - loss: 0.2614 - acc: 0.8854
448/500 [=========================>....] - ETA: 1s - loss: 0.2567 - acc: 0.8862
500/500 [==============================] - 17s 34ms/step - loss: 0.2530 - acc: 0.8860

Test accuracy: 74.11236635061529

data size :  20328

zero :  10049

one :  10279

train_zero :  241

train_one :  259

test_zero :  9808

test_one :  10020

choose_zero :  9327

choose_one :  10501

F1score :  0.7498659909361143

AUC :  0.8198714011617874

Confusion Matrix
[[7001 2807]
 [2326 7694]]
True label 0
0.713805057096248  
0.286194942903752  
True label 1
0.23213572854291417  
0.7678642714570858  

Train_result {'loss': [0.25299829030036924], 'acc': [0.8859999976158142]}
Saved model to disk


15

Epoch 1/1

 64/500 [==>...........................] - ETA: 15s - loss: 0.2141 - acc: 0.9219
128/500 [======>.......................] - ETA: 14s - loss: 0.2442 - acc: 0.8906
192/500 [==========>...................] - ETA: 10s - loss: 0.2184 - acc: 0.9115
256/500 [==============>...............] - ETA: 8s - loss: 0.2215 - acc: 0.9062 
320/500 [==================>...........] - ETA: 6s - loss: 0.2242 - acc: 0.9031
384/500 [======================>.......] - ETA: 4s - loss: 0.2268 - acc: 0.9036
448/500 [=========================>....] - ETA: 1s - loss: 0.2398 - acc: 0.9040
500/500 [==============================] - 17s 35ms/step - loss: 0.2286 - acc: 0.9120

Test accuracy: 74.82348194472463

data size :  20328

zero :  10049

one :  10279

train_zero :  241

train_one :  259

test_zero :  9808

test_one :  10020

choose_zero :  9746

choose_one :  10082

F1score :  0.7516665008456869

AUC :  0.8245760416361405

Confusion Matrix
[[7281 2527]
 [2465 7555]]
True label 0
0.7423531810766721  
0.2576468189233279  
True label 1
0.24600798403193613  
0.7539920159680639  

Train_result {'loss': [0.22863024485111236], 'acc': [0.9119999985694885]}
Saved model to disk


[[50.53964091184184, 1], [69.6187210006052, 2], [71.6007665926972, 3], [72.40770627395602, 4], [73.38612063748235, 5], [72.19084123461771, 6], [72.15049425055477, 7], [74.56122654831552, 8], [74.43514222311882, 9], [73.87028444623765, 10], [73.95097841436352, 11], [74.67722412749647, 12], [74.37966512003229, 13], [74.11236635061529, 14], [74.82348194472463, 15]]
max accuracy :  [74.82348194472463, 15]
