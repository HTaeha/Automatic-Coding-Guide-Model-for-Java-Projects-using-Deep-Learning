(3516, 23) (4608, 23)
      0  1  2  3  4  5  6  7  8  9  D 11 12 13 14 15 16 17 18 19 20 21 22
0     p  x  s  n  t  p  f  c  n  k  e  e  s  s  w  w  p  w  o  p  k  s  u
1     e  x  s  y  t  a  f  c  b  k  e  c  s  s  w  w  p  w  o  p  n  n  g
2     e  b  s  w  t  l  f  c  b  n  e  c  s  s  w  w  p  w  o  p  n  n  m
3     p  x  y  w  t  p  f  c  n  n  e  e  s  s  w  w  p  w  o  p  k  s  u
4     e  x  y  y  t  a  f  c  b  n  e  c  s  s  w  w  p  w  o  p  k  n  g
5     e  b  s  w  t  a  f  c  b  g  e  c  s  s  w  w  p  w  o  p  k  n  m
6     e  b  y  w  t  l  f  c  b  n  e  c  s  s  w  w  p  w  o  p  n  s  m
7     p  x  y  w  t  p  f  c  n  p  e  e  s  s  w  w  p  w  o  p  k  v  g
8     e  b  s  y  t  a  f  c  b  g  e  c  s  s  w  w  p  w  o  p  k  s  m
9     e  x  y  y  t  l  f  c  b  g  e  c  s  s  w  w  p  w  o  p  n  n  g
10    e  x  y  y  t  a  f  c  b  n  e  c  s  s  w  w  p  w  o  p  k  s  m
11    e  b  s  y  t  a  f  c  b  w  e  c  s  s  w  w  p  w  o  p  n  s  g
12    p  x  y  w  t  p  f  c  n  k  e  e  s  s  w  w  p  w  o  p  n  v  u
13    e  s  f  g  f  n  f  c  n  k  e  e  s  s  w  w  p  w  o  p  n  y  u
14    p  x  s  n  t  p  f  c  n  n  e  e  s  s  w  w  p  w  o  p  k  s  g
15    p  x  y  w  t  p  f  c  n  n  e  e  s  s  w  w  p  w  o  p  n  s  u
16    p  x  s  n  t  p  f  c  n  k  e  e  s  s  w  w  p  w  o  p  n  s  u
17    e  b  s  y  t  a  f  c  b  k  e  c  s  s  w  w  p  w  o  p  n  s  m
18    p  x  y  n  t  p  f  c  n  n  e  e  s  s  w  w  p  w  o  p  n  v  g
19    e  b  y  y  t  l  f  c  b  k  e  c  s  s  w  w  p  w  o  p  n  s  m
20    e  b  y  w  t  a  f  c  b  w  e  c  s  s  w  w  p  w  o  p  n  n  m
21    e  b  s  w  t  l  f  c  b  g  e  c  s  s  w  w  p  w  o  p  k  s  m
22    p  f  s  w  t  p  f  c  n  n  e  e  s  s  w  w  p  w  o  p  n  v  g
23    e  x  y  y  t  a  f  c  b  n  e  c  s  s  w  w  p  w  o  p  n  n  m
24    e  x  y  w  t  l  f  c  b  w  e  c  s  s  w  w  p  w  o  p  n  n  m
25    e  f  f  n  f  n  f  c  n  k  e  e  s  s  w  w  p  w  o  p  k  y  u
26    e  b  s  y  t  l  f  c  b  g  e  c  s  s  w  w  p  w  o  p  n  n  m
27    p  x  y  w  t  p  f  c  n  k  e  e  s  s  w  w  p  w  o  p  n  s  u
28    e  x  y  y  t  l  f  c  b  n  e  c  s  s  w  w  p  w  o  p  n  n  m
29    e  x  y  n  t  l  f  c  b  p  e  r  s  y  w  w  p  w  o  p  n  y  p
...  .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. ..
3486  e  b  f  g  f  n  f  w  b  w  e  ?  k  k  w  w  p  w  t  p  w  n  g
3487  e  f  s  n  f  n  a  c  b  o  e  ?  s  s  o  o  p  o  o  p  o  c  l
3488  e  b  s  n  f  n  a  c  b  o  e  ?  s  s  o  o  p  n  o  p  y  c  l
3489  e  f  s  n  f  n  a  c  b  o  e  ?  s  s  o  o  p  n  o  p  o  v  l
3490  e  b  f  g  f  n  f  w  b  g  e  ?  s  s  w  w  p  w  t  p  w  s  g
3491  e  b  f  g  f  n  f  w  b  p  e  ?  k  k  w  w  p  w  t  p  w  s  g
3492  e  k  f  w  f  n  f  w  b  g  e  ?  s  k  w  w  p  w  t  p  w  s  g
3493  e  k  s  n  f  n  a  c  b  n  e  ?  s  s  o  o  p  n  o  p  o  v  l
3494  e  k  s  n  f  n  a  c  b  n  e  ?  s  s  o  o  p  o  o  p  n  v  l
3495  e  b  s  g  f  n  f  w  b  g  e  ?  k  s  w  w  p  w  t  p  w  n  g
3496  p  x  y  c  f  m  f  c  b  y  e  c  k  y  c  c  p  w  n  n  w  c  d
3497  e  k  f  w  f  n  f  w  b  w  e  ?  k  s  w  w  p  w  t  p  w  n  g
3498  e  k  f  w  f  n  f  w  b  w  e  ?  k  k  w  w  p  w  t  p  w  s  g
3499  e  f  s  n  f  n  a  c  b  o  e  ?  s  s  o  o  p  n  o  p  b  v  l
3500  e  x  s  n  f  n  a  c  b  y  e  ?  s  s  o  o  p  n  o  p  n  c  l
3501  e  k  s  n  f  n  a  c  b  y  e  ?  s  s  o  o  p  n  o  p  o  c  l
3502  e  k  s  n  f  n  a  c  b  y  e  ?  s  s  o  o  p  o  o  p  n  v  l
3503  e  k  s  n  f  n  a  c  b  y  e  ?  s  s  o  o  p  n  o  p  y  v  l
3504  e  k  s  n  f  n  a  c  b  o  e  ?  s  s  o  o  p  o  o  p  n  v  l
3505  e  x  s  n  f  n  a  c  b  y  e  ?  s  s  o  o  p  o  o  p  n  c  l
3506  e  b  s  w  f  n  f  w  b  w  e  ?  s  s  w  w  p  w  t  p  w  n  g
3507  e  x  s  n  f  n  a  c  b  o  e  ?  s  s  o  o  p  o  o  p  n  v  l
3508  e  k  s  w  f  n  f  w  b  p  e  ?  s  s  w  w  p  w  t  p  w  n  g
3509  e  k  s  n  f  n  a  c  b  o  e  ?  s  s  o  o  p  n  o  p  b  v  l
3510  p  f  y  c  f  m  a  c  b  y  e  c  k  y  c  c  p  w  n  n  w  c  d
3511  e  x  s  n  f  n  a  c  b  y  e  ?  s  s  o  o  p  o  o  p  o  v  l
3512  e  k  s  n  f  n  a  c  b  y  e  ?  s  s  o  o  p  o  o  p  b  c  l
3513  e  x  s  n  f  n  a  c  b  y  e  ?  s  s  o  o  p  n  o  p  b  v  l
3514  e  f  s  n  f  n  a  c  b  n  e  ?  s  s  o  o  p  o  o  p  b  c  l
3515  e  x  s  n  f  n  a  c  b  y  e  ?  s  s  o  o  p  o  o  p  o  c  l

[3516 rows x 23 columns]       0  1  2  3  4  5  6  7  8  9  D 11 12 13 14 15 16 17 18 19 20 21 22
0     e  x  s  g  f  n  f  w  b  k  t  e  s  s  w  w  p  w  o  e  n  a  g
1     e  x  f  n  f  n  f  w  b  n  t  e  s  f  w  w  p  w  o  e  k  a  g
2     e  f  f  w  f  n  f  w  b  k  t  e  s  s  w  w  p  w  o  e  n  a  g
3     e  x  s  y  t  a  f  w  n  n  t  b  s  s  w  w  p  w  o  p  n  v  d
4     e  x  f  y  t  l  f  w  n  w  t  b  s  s  w  w  p  w  o  p  n  v  d
5     e  x  f  y  t  a  f  w  n  p  t  b  s  s  w  w  p  w  o  p  n  v  d
6     e  f  f  g  f  n  f  w  b  n  t  e  s  s  w  w  p  w  o  e  n  a  g
7     e  f  s  n  f  n  f  w  b  k  t  e  s  s  w  w  p  w  o  e  k  a  g
8     e  f  f  y  t  l  f  w  n  p  t  b  s  s  w  w  p  w  o  p  n  v  d
9     e  f  f  y  t  l  f  w  n  w  t  b  s  s  w  w  p  w  o  p  n  v  d
10    e  f  s  y  t  l  f  w  n  p  t  b  s  s  w  w  p  w  o  p  n  v  d
11    e  x  s  w  t  l  f  w  n  n  t  b  s  s  w  w  p  w  o  p  u  v  d
12    e  x  s  n  f  n  f  w  b  k  t  e  f  s  w  w  p  w  o  e  n  s  g
13    e  x  f  g  f  n  f  w  b  n  t  e  s  s  w  w  p  w  o  e  n  s  g
14    e  x  s  n  f  n  f  w  b  k  t  e  s  s  w  w  p  w  o  e  k  s  g
15    e  x  s  n  f  n  f  w  b  n  t  e  s  s  w  w  p  w  o  e  n  a  g
16    e  x  f  n  f  n  f  w  b  p  t  e  f  s  w  w  p  w  o  e  k  s  g
17    e  x  f  w  t  a  f  w  n  w  t  b  s  s  w  w  p  w  o  p  u  v  d
18    e  x  s  y  t  l  f  w  n  p  t  b  s  s  w  w  p  w  o  p  u  v  d
19    e  f  s  g  f  n  f  w  b  k  t  e  s  s  w  w  p  w  o  e  n  a  g
20    e  x  s  w  f  n  f  w  b  n  t  e  s  f  w  w  p  w  o  e  k  s  g
21    e  f  f  g  f  n  f  w  b  h  t  e  s  s  w  w  p  w  o  e  n  a  g
22    e  f  s  w  t  l  f  w  n  w  t  b  s  s  w  w  p  w  o  p  u  v  d
23    e  f  s  w  t  a  f  w  n  p  t  b  s  s  w  w  p  w  o  p  n  v  d
24    e  f  f  w  t  l  f  w  n  w  t  b  s  s  w  w  p  w  o  p  n  v  d
25    e  x  f  g  f  n  f  w  b  k  t  e  f  f  w  w  p  w  o  e  k  s  g
26    e  f  f  w  f  n  f  w  b  k  t  e  s  f  w  w  p  w  o  e  n  a  g
27    e  x  s  n  f  n  f  w  b  p  t  e  f  s  w  w  p  w  o  e  n  a  g
28    e  x  s  w  t  a  f  w  n  w  t  b  s  s  w  w  p  w  o  p  u  v  d
29    e  x  f  y  t  l  f  w  n  n  t  b  s  s  w  w  p  w  o  p  u  v  d
...  .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. ..
4578  p  k  y  n  f  f  f  c  n  b  t  ?  k  k  w  p  p  w  o  e  w  v  d
4579  p  k  s  e  f  s  f  c  n  b  t  ?  s  k  w  p  p  w  o  e  w  v  l
4580  p  k  s  n  f  f  f  c  n  b  t  ?  s  s  w  p  p  w  o  e  w  v  p
4581  p  k  s  n  f  s  f  c  n  b  t  ?  k  s  p  p  p  w  o  e  w  v  d
4582  p  k  s  n  f  s  f  c  n  b  t  ?  k  k  p  p  p  w  o  e  w  v  p
4583  p  k  y  n  f  y  f  c  n  b  t  ?  s  k  p  w  p  w  o  e  w  v  l
4584  p  k  y  e  f  f  f  c  n  b  t  ?  s  s  p  p  p  w  o  e  w  v  l
4585  p  k  s  e  f  f  f  c  n  b  t  ?  k  k  w  w  p  w  o  e  w  v  p
4586  p  k  y  e  f  s  f  c  n  b  t  ?  k  k  w  w  p  w  o  e  w  v  l
4587  p  k  y  e  f  f  f  c  n  b  t  ?  k  k  w  w  p  w  o  e  w  v  p
4588  p  k  y  e  f  f  f  c  n  b  t  ?  s  s  w  w  p  w  o  e  w  v  l
4589  p  k  s  n  f  s  f  c  n  b  t  ?  s  k  p  w  p  w  o  e  w  v  d
4590  p  k  y  n  f  f  f  c  n  b  t  ?  k  s  w  w  p  w  o  e  w  v  p
4591  p  k  s  e  f  s  f  c  n  b  t  ?  k  k  p  p  p  w  o  e  w  v  p
4592  p  k  y  n  f  y  f  c  n  b  t  ?  s  s  w  w  p  w  o  e  w  v  l
4593  p  x  s  e  f  f  f  c  n  b  t  ?  k  s  w  p  p  w  o  e  w  v  p
4594  p  k  y  e  f  f  f  c  n  b  t  ?  k  k  w  p  p  w  o  e  w  v  d
4595  p  k  s  n  f  f  f  c  n  b  t  ?  k  s  p  p  p  w  o  e  w  v  d
4596  p  k  y  e  f  f  f  c  n  b  t  ?  s  k  w  w  p  w  o  e  w  v  p
4597  p  k  y  e  f  y  f  c  n  b  t  ?  s  s  p  p  p  w  o  e  w  v  p
4598  p  x  s  n  f  y  f  c  n  b  t  ?  k  k  w  w  p  w  o  e  w  v  d
4599  p  k  y  n  f  s  f  c  n  b  t  ?  k  k  p  p  p  w  o  e  w  v  l
4600  p  k  s  e  f  y  f  c  n  b  t  ?  k  k  w  p  p  w  o  e  w  v  d
4601  p  k  s  e  f  s  f  c  n  b  t  ?  s  s  p  w  p  w  o  e  w  v  p
4602  p  k  y  e  f  y  f  c  n  b  t  ?  k  s  p  w  p  w  o  e  w  v  l
4603  p  k  y  e  f  y  f  c  n  b  t  ?  k  k  p  p  p  w  o  e  w  v  d
4604  p  k  y  n  f  s  f  c  n  b  t  ?  s  k  p  w  p  w  o  e  w  v  l
4605  p  k  s  e  f  y  f  c  n  b  t  ?  k  s  p  w  p  w  o  e  w  v  d
4606  p  k  y  n  f  f  f  c  n  b  t  ?  k  s  p  w  p  w  o  e  w  v  d
4607  p  k  y  n  f  y  f  c  n  b  t  ?  s  k  w  w  p  w  o  e  w  v  l

[4608 rows x 23 columns]/home/2014313303/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)

data loaded.
data split end. (4608, 22) (3516, 22) (4608,) (3516,)
data preprocessed. (4608, 22) (3516, 22) (4608,) (3516,)
data form. (460, 22) (4148, 22) (460,) (4148,)
4148
params initial finished.
(3976, 22) (3976,)
result: [0. 0. 0. ... 0. 0. 1.] 3516 460 0 (8124, 30)
Error rate: 0.04782608695652173
[[0.05022831 0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [0. 0. 0. ... 0. 0. 1.] 3516 460 1 (8124, 30)
Error rate: 0.02168949771689497
[[0.05022831 0.02217036 0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [1. 1. 0. ... 1. 1. 1.] 3516 460 2 (8124, 30)
Error rate: 0.07234539089848306
[[0.05022831 0.02217036 0.07798742 0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [0. 0. 0. ... 0. 0. 1.] 3516 460 3 (8124, 30)
Error rate: 0.04382504288164667
[[0.05022831 0.02217036 0.07798742 0.04583371 0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [0. 1. 0. ... 0. 0. 1.] 3516 460 4 (8124, 30)
Error rate: 0.0242244997191157
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [1. 1. 1. ... 0. 1. 1.] 3516 460 5 (8124, 30)
Error rate: 0.11006553282171505
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [1. 0. 0. ... 0. 0. 1.] 3516 460 6 (8124, 30)
Error rate: 0.0668815352159294
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.07167529 0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [1. 1. 1. ... 0. 0. 1.] 3516 460 7 (8124, 30)
Error rate: 0.04070052906046455
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.07167529 0.04242734 0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [1. 1. 0. ... 0. 0. 1.] 3516 460 8 (8124, 30)
Error rate: 0.059113208793530825
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.07167529 0.04242734 0.06282712 0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [0. 0. 0. ... 0. 0. 1.] 3516 460 9 (8124, 30)
Error rate: 0.04200022780605128
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.07167529 0.04242734 0.06282712 0.04384158 0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [1. 0. 0. ... 0. 0. 1.] 3516 460 10 (8124, 30)
Error rate: 0.1365372495644509
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.07167529 0.04242734 0.06282712 0.04384158 0.15812755 0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [1. 1. 1. ... 1. 0. 1.] 3516 460 11 (8124, 30)
Error rate: 0.12753988769982116
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.07167529 0.04242734 0.06282712 0.04384158 0.15812755 0.1461842
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [0. 0. 0. ... 0. 0. 1.] 3516 460 12 (8124, 30)
Error rate: 0.04664059856447966
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.07167529 0.04242734 0.06282712 0.04384158 0.15812755 0.1461842
  0.04892237 0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [1. 0. 0. ... 0. 0. 1.] 3516 460 13 (8124, 30)
Error rate: 0.10019663204465551
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.07167529 0.04242734 0.06282712 0.04384158 0.15812755 0.1461842
  0.04892237 0.11135392 0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [1. 1. 1. ... 1. 1. 1.] 3516 460 14 (8124, 30)
Error rate: 0.29608620275126385
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.07167529 0.04242734 0.06282712 0.04384158 0.15812755 0.1461842
  0.04892237 0.11135392 0.4206285  0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [0. 0. 0. ... 0. 0. 1.] 3516 460 15 (8124, 30)
Error rate: 0.04967015821630618
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.07167529 0.04242734 0.06282712 0.04384158 0.15812755 0.1461842
  0.04892237 0.11135392 0.4206285  0.05226623 0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [1. 1. 0. ... 0. 0. 1.] 3516 460 16 (8124, 30)
Error rate: 0.13722752810310557
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.07167529 0.04242734 0.06282712 0.04384158 0.15812755 0.1461842
  0.04892237 0.11135392 0.4206285  0.05226623 0.15905413 0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [0. 0. 0. ... 0. 0. 1.] 3516 460 17 (8124, 30)
Error rate: 0.14209645296745638
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.07167529 0.04242734 0.06282712 0.04384158 0.15812755 0.1461842
  0.04892237 0.11135392 0.4206285  0.05226623 0.15905413 0.1656322
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [1. 1. 0. ... 0. 1. 1.] 3516 460 18 (8124, 30)
Error rate: 0.12854113763178712
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.07167529 0.04242734 0.06282712 0.04384158 0.15812755 0.1461842
  0.04892237 0.11135392 0.4206285  0.05226623 0.15905413 0.1656322
  0.1475011  0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [0. 1. 0. ... 0. 0. 0.] 3516 460 19 (8124, 30)
Error rate: 0.19028816161789822
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.07167529 0.04242734 0.06282712 0.04384158 0.15812755 0.1461842
  0.04892237 0.11135392 0.4206285  0.05226623 0.15905413 0.1656322
  0.1475011  0.23500726 0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)
/home/2014313303/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  FutureWarning)

result: [0. 0. 0. ... 0. 0. 1.] 3516 460 20 (8124, 30)
Error rate: 0.1976349138659354
[[0.05022831 0.02217036 0.07798742 0.04583371 0.02482589 0.12367824
  0.07167529 0.04242734 0.06282712 0.04384158 0.15812755 0.1461842
  0.04892237 0.11135392 0.4206285  0.05226623 0.15905413 0.1656322
  0.1475011  0.23500726 0.24631545 0.         0.         0.
  0.         0.         0.         0.         0.         0.        ]]
result: [0. 0. 0. ... 0. 0. 1.] 3516 460 21 (8124, 30)
Error rate: 0.0
(4148,) [0. 1. 0. ... 0. 0. 1.]
accuracy: 0.9985535197685632
auc: 0.9987255734919287
